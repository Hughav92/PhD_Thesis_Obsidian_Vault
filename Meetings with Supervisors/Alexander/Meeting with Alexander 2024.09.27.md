# **Previous Meeting**

Previous meeting on [[Meeting with Alexander 2024.09.18|18.09.2024]]

# **To Discuss**

- Paper idea - "Whose Time is it Anyway?". Looking at the synchronisation and alignment of multiple data modalities. When we synchronise and/or align multiple time-series signals, what are the underlying assumptions we are making about the temporality of the event? How does this relate to the spatial characteristics of the sensor placement and recording space? How does this relate to the human perception of the event? And how does this influence the analysis of the data? Main question: Whose or what's perspective are we taking when we synchronise, align, and trim data, how does this relate to the task being performed, and what does this imply about the analysis being performed on the synchronised data?
- Open-sourcing of the thesis writing on GitHub. Attempt at [[Open Science|open science]]. Not just sharing results and data, but also the process of research. Can share this Obsidian vault through GitHub integration.
# **Notes**

- Synchronisation paper, the here and now of the data - Husserlian phenomenology in reference to the here and now, what about the there and then
- Kork data - 48 mics, smaller hall than Stavanger - whose position are we listening too
- Human perceptual system both precise and sloppy in terms of time
- Average data - synch doesn't matter, trim does
- Method for paper - prototyping rapid iterations of examples
- Take one dataset - see what problems are
- Methodological papers difficult for journals
- Submit SMC - to get started - theory driven
- Iterative, user-centred
- Include potential end-users - extremes (Microtiming researchers timing important, others timing not important) - what do they need - present prototype back

# **Minutes**

- We discussed the potential of writing a paper on [[Data Synchronisation|synchronisation]] and [[Data Alignment|alignment]]. This paper will focus on the temporal and spatial perspective taken by a given analysis method, i.e. alignment of multiple modalities is not the same when performed using an external trigger, computer timestamps, properties of the signal, or with respective to perceptual qualities of the signal. Alexander framed this idea in relation to the experience of latency in [[Telematic Performance|telematic performance]]. He related this to Husserl's [[Phenomenology|phenomenology]] (in particular the idea of the "here and now") and relates it to the idea of the "there and then". Moreover, we discussed that the human perceptual system is at once sloppy and precise when it comes to timing, and that this might not be reflected in various alignment and synchronisation methods. Likewise, the intention of the analysis plays a role in this. If we intend to look at averages across the data, the alignment might not matter so much in contrast to an analysis focused on precise elements of [[Microtiming|microtiming]]. In my opinion a task-based framing might work well here, and fits well with [[@christodoulouMultimodalMusicDatasets2024]]'s definition of multimodality. However, I might want to push this a little further and argue that a task-based definition requires taking a spatio-temporal perspective for the analysis method. We discussed the possibility of also turning this into some sort of user-study, implementing various perspectives and recruiting researchers with various needs as users. We also talked about SMC as a potential publication venue, as journals tend not to be so open towards methodological papers. Alexander recommended looking at the [[KORK 2024]] dataset, which contains 48 microphone signals, as a venue to explore several of these ideas.
- We discussed the open-sourcing of this Obsidian vault as a way of open-sourcing not just research results but also the research process. Alexander was onboard with the idea.
# **Next Meeting**

Next meeting on [[Meeting with Alexander 2024.10.16|16.10.2024]]


