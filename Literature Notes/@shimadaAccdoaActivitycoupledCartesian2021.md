#literature-note 

---
category:: literaturenote
tags:: #Signal-processing #Estimation #read #Artificial-neural-networks #Direction-of-arrival-estimation #Event-detection #Location-awareness #Measurement #neural-network #Sound-event-localization-and-detection 
status:: read 
dateread:: 2025-04-01
reference:: Shimada, K., Koyama, Y., Takahashi, N., Takahashi, S., & Mitsufuji, Y. (2021). ‘Accdoa: Activity-coupled cartesian direction of arrival representation for sound event localization and detection’. _ICASSP 2021 - 2021 IEEE international conference on acoustics, speech and signal processing (ICASSP)_, pp. 915–9. DOI: [10.1109/ICASSP39728.2021.9413609](https://doi.org/10.1109/ICASSP39728.2021.9413609)

---

> [!Cite]
> Shimada, K., Koyama, Y., Takahashi, N., Takahashi, S., & Mitsufuji, Y. (2021). ‘Accdoa: Activity-coupled cartesian direction of arrival representation for sound event localization and detection’. _ICASSP 2021 - 2021 IEEE international conference on acoustics, speech and signal processing (ICASSP)_, pp. 915–9. DOI: [10.1109/ICASSP39728.2021.9413609](https://doi.org/10.1109/ICASSP39728.2021.9413609)
^cite

>[!Synth]
>%% begin synth %%
>
>**Contribution**:: This paper proposes Activity-Coupled Cartesian Direction of Arrival (ACCDOA) as a combined representation of sound event activity and direction of arrival for machine-learning sound event detection and localisation tasks. In comparison to previous methods, which propose separate representations for activity and direction of arrival, a combined representation enables single objective learning (i.e. a single branch model), allowing smaller networks providing better performance. The method is fundamentally the application of a step function (for active/inactive) to the Cartesian coordinates of sound source normalised to the unit sphere (for direction of arrival). The authors apply this representation to train a model on the DCASE 2020 Task 3 development set, achieving better results than the then state-of-the-art, dual-branch SELDnet with significantly fewer parameters.
>
>**Related**::  
>![[@wangNercslipSystemSound2022#^cite]]
>![[@wangNercslipSystemSound2023#^cite]]
>![[@wangNercslipSystemSound2024#^cite]]
>![[@wangFourstageDataAugmentation2023#^cite]]
>%% end synth %%

>[!md]
> **FirstAuthor**:: Shimada, Kazuki  
> **Author**:: Koyama, Yuichiro  
> **Author**:: Takahashi, Naoya  
> **Author**:: Takahashi, Shusuke  
> **Author**:: Mitsufuji, Yuki  
~    
> **Title**:: Accdoa: Activity-coupled cartesian direction of arrival representation for sound event localization and detection  
> **Year**:: 2021   
> **Citekey**:: shimadaAccdoaActivitycoupledCartesian2021  
> **itemType**:: conferencePaper   
> **Pages**:: 915-919  
> **DOI**:: 10.1109/ICASSP39728.2021.9413609    

> [!LINK] 
>
> [[Shimada et al._2021_Accdoa Activity-coupled cartesian direction of arrival representation for sound event localization.pdf]].

> [!Abstract]
>.
> 
# Notes

%% begin notes %%

%% end notes %%


# Annotations%% begin annotations %%


%% end annotations %%









%% Import Date: 2025-04-01T17:14:00.803+02:00 %%
