#literature-note 

---
category:: literaturenote
tags:: unread
citekey:: vrigkasReviewHumanActivity2015
status:: unread
reference:: Vrigkas, M., Nikou, C., & Kakadiaris, I. A. (2015). ‘A Review of Human Activity Recognition Methods’, _Frontiers in Robotics and AI_, 2. DOI: [10.3389/frobt.2015.00028](https://doi.org/10.3389/frobt.2015.00028)
dateread:
---

> [!Cite]
> Vrigkas, M., Nikou, C., & Kakadiaris, I. A. (2015). ‘A Review of Human Activity Recognition Methods’, _Frontiers in Robotics and AI_, 2. DOI: [10.3389/frobt.2015.00028](https://doi.org/10.3389/frobt.2015.00028)

^cite

>[!Synth]
>**Contribution**:: 
>
>**Related**:: 
>

>[!md]
> **FirstAuthor**:: Vrigkas, Michalis  
> **Author**:: Nikou, Christophoros  
> **Author**:: Kakadiaris, Ioannis A.  
~    
> **Title**:: A Review of Human Activity Recognition Methods  
> **Year**:: 2015   
> **Citekey**:: vrigkasReviewHumanActivity2015  
> **itemType**:: journalArticle  
> **Journal**:: *Frontiers in Robotics and AI*  
> **Volume**:: 2  
> **DOI**:: 10.3389/frobt.2015.00028    

> [!LINK] 
>
> [[Vrigkas et al_2015_A Review of Human Activity Recognition Methods.pdf]].

> [!Abstract]
>.
> 
# Notes
>
># Annotations  
(02/09/2024, 09:15:32)

[Go to annotation](zotero://open-pdf/library/items/5BRCC5V8?page=1&annotation=9ILP8WRI) “Among various classification techniques two main questions arise: “What action?” (i.e., the recognition problem) and “Where in the video?” (i.e., the localization problem).” ([Vrigkas et al., 2015, p. 1](zotero://select/library/items/YA249BXB)) The two main problems of HAR

[Go to annotation](zotero://open-pdf/library/items/5BRCC5V8?page=2&annotation=4WPML9YC) “To overcome these problems, a task is required that consists of three components, namely: (i) background subtraction (Elgammal et al., 2002; Mumtaz et al., 2014), in which the system attempts to separate the parts of the image that are invariant over time (background) from the objects that are moving or changing (foreground); (ii) human tracking, in which the system locates human motion over time (Liu et al., 2010; Wang et al., 2013; Yan et al., 2014); and (iii) human action and object detection (Pirsiavash and Ramanan, 2012; Gan et al., 2015; Jainy et al., 2015), in which the system is able to localize a human activity in an image.” ([Vrigkas et al., 2015, p. 2](zotero://select/library/items/YA249BXB)) The three components of a HAR task

[Go to annotation](zotero://open-pdf/library/items/5BRCC5V8?page=2&annotation=FIDRIM26) “Depending on their complexity, human activities are categorized into: (i) gestures; (ii) atomic actions; (iii) human-to-object or human-to-human interactions; (iv) group actions; (v) behaviors; and (vi) events. Figure 1 visualizes the decomposition of human activities according to their complexity.” ([Vrigkas et al., 2015, p. 2](zotero://select/library/items/YA249BXB)) The 6 categories of HAR depending upon complexity.

[Go to annotation](zotero://open-pdf/library/items/5BRCC5V8?page=2&annotation=KYDXY9TK) “Gestures are considered as primitive movements of the body parts of a person that may correspond to a particular action of this person (Yang et al., 2013). Atomic actions are movements of a person describing a certain motion that may be part of more complex activities (Ni et al., 2015). Human-to-object or humanto-human interactions are human activities that involve two or more persons or objects (Patron-Perez et al., 2012). Group actions are activities performed by a group or persons (Tran et al., 2014b). Human behaviors refer to physical actions that are associated with the emotions, personality, and psychological state of the individual (Martinez et al., 2014). Finally, events are high-level activities that describe social actions between individuals and indicate the intention or the social role of a person (Lan et al., 2012a).” ([Vrigkas et al., 2015, p. 2](zotero://select/library/items/YA249BXB)) Definitions of categories of HAR.

[Go to annotation](zotero://open-pdf/library/items/5BRCC5V8?page=3&annotation=LF37FKWB) “Unimodal methods represent human activities from data of a single modality, such as images, and they are further categorized as: (i) space-time, (ii) stochastic, (iii) rule-based, and (iv) shapebased methods. Space-time methods involve activity recognition methods, which represent human activities as a set of spatiotemporal features (Shabani et al., 2011; Li and Zickler, 2012) or trajectories (Li et al., 2012; Vrigkas et al., 2013). Stochastic methods recognize activities by applying statistical models to represent human actions (e.g., hidden Markov models) (Lan et al., 2011; Iosifidis et al., 2012a). Rule-based methods use a set of rules to describe human activities (Morariu and Davis, 2011; Chen and Grauman, 2012). Shape-based methods efficiently represent activities with high-level reasoning by modeling the motion of human body parts (Sigal et al., 2012b; Tran et al., 2012).” ([Vrigkas et al., 2015, p. 3](zotero://select/library/items/YA249BXB)) Description of unimodal methods.

[Go to annotation](zotero://open-pdf/library/items/5BRCC5V8?page=3&annotation=Y3896GTK) “Multimodal methods combine features collected from different sources (Wu et al., 2013) and are classified into three categories: (i) affective, (ii) behavioral, and (iii) social networking methods. Affective methods represent human activities according to emotional communications and the affective state of a person” ([Vrigkas et al., 2015, p. 3](zotero://select/library/items/YA249BXB)) Description of multimodal methods (part 1)

[Go to annotation](zotero://open-pdf/library/items/5BRCC5V8?page=4&annotation=8WACDC9A) “(Liu et al., 2011b; Martinez et al., 2014). Behavioral methods aim to recognize behavioral attributes, non-verbal multimodal cues, such as gestures, facial expressions, and auditory cues (Song et al., 2012a; Vrigkas et al., 2014b). Finally, social networking methods model the characteristics and the behavior of humans in several layers of human-to-human interactions in social events from gestures, body motion, and speech (Patron-Perez et al., 2012; Marín-Jiménez et al., 2014).” ([Vrigkas et al., 2015, p. 4](zotero://select/library/items/YA249BXB)) Description of multimodal methods (part 2)

[Go to annotation](zotero://open-pdf/library/items/5BRCC5V8?page=4&annotation=FPLJIS9U) “Usually, the terms “activity” and “behavior” are used interchangeably in the literature (Castellano et al., 2007; Song et al., 2012a). In this survey, we differentiate between these two terms in the sense that the term “activity” is used to describe a sequence of actions that correspond to specific body motion. On the other hand, the term “behavior” is used to characterize both activities and events that are associated with gestures, emotional states, facial expressions, and auditory cues of a single person.” ([Vrigkas et al., 2015, p. 4](zotero://select/library/items/YA249BXB)) Difference between "activity" and "behaviour".

[Go to annotation](zotero://open-pdf/library/items/5BRCC5V8?page=13&annotation=2UE87CLB) “Multimodal cues are usually correlated in time, thus a temporal association of the underlying event and the different modalities is an important issue for understanding the data. In that context, audio-visual analysis is used in many applications not only for audio-visual synchronization (Lichtenauer et al., 2011) but also for tracking (Perez et al., 2004) and activity recognition (Wu et al., 2013).” ([Vrigkas et al., 2015, p. 13](zotero://select/library/items/YA249BXB)) Temporality of multimodal data fusion.

([Vrigkas et al., 2015, p. 18](zotero://select/library/items/YA249BXB)) Good description of the when of fusion. Should read the Karpathy paper.

[Go to annotation](zotero://open-pdf/library/items/5BRCC5V8?page=19&annotation=8UEZEZNL) “An ideal human activity dataset should address the following issues: (i) the input media should include either still images and/or video sequences, (ii) the amount of data should be sufficient, (iii) input media quality (resolution, grayscale or color), (iv) large number of subjects performing an action, (v) large number of action classes, (vi) changes in illuminations, (vii) large intraclass variations (i.e., variations in subjects’ poses), (viii) photo shooting under partial occlusion of human structure, and (ix) complex backgrounds.” ([Vrigkas et al., 2015, p. 19](zotero://select/library/items/YA249BXB)) Issues that should be addressed by an ideal HAR dataset.

([Vrigkas et al., 2015, p. 20](zotero://select/library/items/YA249BXB)) The four basic questions to ask about a HAR system..


# Annotations%% begin annotations %%



### Imported: 2024-09-23 7:01 pm



<mark style="background-color: #ffaa00">Quote</mark>
> Among various classification techniques two main questions arise: “What action?” (i.e., the recognition problem) and “Where in the video?” (i.e., the localization problem).

<mark style="background-color: #ffaa00">Quote</mark>
> To overcome these problems, a task is required that consists of three components, namely: (i) background subtraction (Elgammal et al., 2002; Mumtaz et al., 2014), in which the system attempts to separate the parts of the image that are invariant over time (background) from the objects that are moving or changing (foreground); (ii) human tracking, in which the system locates human motion over time (Liu et al., 2010; Wang et al., 2013; Yan et al., 2014); and (iii) human action and object detection (Pirsiavash and Ramanan, 2012; Gan et al., 2015; Jainy et al., 2015), in which the system is able to localize a human activity in an image.

<mark style="background-color: #ffaa00">Quote</mark>
> Depending on their complexity, human activities are categorized into: (i) gestures; (ii) atomic actions; (iii) human-to-object or human-to-human interactions; (iv) group actions; (v) behaviors; and (vi) events. Figure 1 visualizes the decomposition of human activities according to their complexity.

<mark style="background-color: #ffaa00">Quote</mark>
> Gestures are considered as primitive movements of the body parts of a person that may correspond to a particular action of this person (Yang et al., 2013). Atomic actions are movements of a person describing a certain motion that may be part of more complex activities (Ni et al., 2015). Human-to-object or humanto-human interactions are human activities that involve two or more persons or objects (Patron-Perez et al., 2012). Group actions are activities performed by a group or persons (Tran et al., 2014b). Human behaviors refer to physical actions that are associated with the emotions, personality, and psychological state of the individual (Martinez et al., 2014). Finally, events are high-level activities that describe social actions between individuals and indicate the intention or the social role of a person (Lan et al., 2012a).

<mark style="background-color: #ffaa00">Quote</mark>
> Unimodal methods represent human activities from data of a single modality, such as images, and they are further categorized as: (i) space-time, (ii) stochastic, (iii) rule-based, and (iv) shapebased methods. Space-time methods involve activity recognition methods, which represent human activities as a set of spatiotemporal features (Shabani et al., 2011; Li and Zickler, 2012) or trajectories (Li et al., 2012; Vrigkas et al., 2013). Stochastic methods recognize activities by applying statistical models to represent human actions (e.g., hidden Markov models) (Lan et al., 2011; Iosifidis et al., 2012a). Rule-based methods use a set of rules to describe human activities (Morariu and Davis, 2011; Chen and Grauman, 2012). Shape-based methods efficiently represent activities with high-level reasoning by modeling the motion of human body parts (Sigal et al., 2012b; Tran et al., 2012).

<mark style="background-color: #ffaa00">Quote</mark>
> Multimodal methods combine features collected from different sources (Wu et al., 2013) and are classified into three categories: (i) affective, (ii) behavioral, and (iii) social networking methods. Affective methods represent human activities according to emotional communications and the affective state of a person

<mark style="background-color: #ffaa00">Quote</mark>
> (Liu et al., 2011b; Martinez et al., 2014). Behavioral methods aim to recognize behavioral attributes, non-verbal multimodal cues, such as gestures, facial expressions, and auditory cues (Song et al., 2012a; Vrigkas et al., 2014b). Finally, social networking methods model the characteristics and the behavior of humans in several layers of human-to-human interactions in social events from gestures, body motion, and speech (Patron-Perez et al., 2012; Marín-Jiménez et al., 2014).

<mark style="background-color: #ffaa00">Quote</mark>
> Usually, the terms “activity” and “behavior” are used interchangeably in the literature (Castellano et al., 2007; Song et al., 2012a). In this survey, we differentiate between these two terms in the sense that the term “activity” is used to describe a sequence of actions that correspond to specific body motion. On the other hand, the term “behavior” is used to characterize both activities and events that are associated with gestures, emotional states, facial expressions, and auditory cues of a single person.

<mark style="background-color: #ffaa00">Quote</mark>
> Multimodal cues are usually correlated in time, thus a temporal association of the underlying event and the different modalities is an important issue for understanding the data. In that context, audio-visual analysis is used in many applications not only for audio-visual synchronization (Lichtenauer et al., 2011) but also for tracking (Perez et al., 2004) and activity recognition (Wu et al., 2013).

<mark style="background-color: #ffaa00">Quote</mark>
> 

<mark style="background-color: #ffaa00">Quote</mark>
> An ideal human activity dataset should address the following issues: (i) the input media should include either still images and/or video sequences, (ii) the amount of data should be sufficient, (iii) input media quality (resolution, grayscale or color), (iv) large number of subjects performing an action, (v) large number of action classes, (vi) changes in illuminations, (vii) large intraclass variations (i.e., variations in subjects’ poses), (viii) photo shooting under partial occlusion of human structure, and (ix) complex backgrounds.

<mark style="background-color: #ffaa00">Quote</mark>
> 


%% end annotations %%

%% Import Date: 2024-09-23T19:01:16.858+02:00 %%
