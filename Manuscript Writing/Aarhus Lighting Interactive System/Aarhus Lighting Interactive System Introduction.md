#my-work #introduction

# Draft 1

Symphonic orchestral performance involves large-scale musical interaction between a large number of musicians and large audiences. The complexity of this interaction is demonstrated through the range of physiological responses and gestural actions displayed by both audience members and musicians, which correlate not only to the sounding music [refs] but can display a great degree of interpersonal synchrony [refs]. However, although an increasing number of symphony orchestras are integrating technological systems into their wider infrastructure [refs], the integration of interactive systems which leverage physiological and motion signals measured from this interaction into the concert programme to support or generate the musical material performed are rarely found, potentially as a facet of the relative rigidity both of the musical material that can be performed [ref] and social roles assumed both by performers and audience [ref].

As part of an ongoing series of live orchestral concert research involving the collection of a diverse range of physiological and motion signals from symphonic orchestra performers and audiences, in May 2025 we will undertake a large scale data collection over several days with the Aarhus Symphony Orchestra (ASO), consisting of various sensor measurements from both musicians and audiences. As part of this collection, we also have the opportunity to implement a real-time, interactive system mapping the sensor measurements to the concert house's lighting system, consisting of 60 individually controllable lights, during the concert. In particular, we are interested in working with ECG, EMG, and motion signals collected from several musicians, Infra-Red (IR) and thermal imaging of the audience, as well as audio signals of the sounding music, with the aim that this enhance the audience's understanding of musical structure and intended conveyed emotional content of the performed works, as well as the underlying interaction between participants.

In this paper, we outline several elements of the preliminary work that has taken place centred around a one-day visit to the ASO concert house. In particular, we present the implementation of a preliminary testing system to extract performer RR intervals and heart-rate using the Pan-Tompkins algorithm from a wrist-worn EMG implemented in Max/MSP, a validation of the extracted heart-rate, and an evaluation of end-to-end system latency within the concert hall. In addition, we outline the wider direction of our work which will take place in the run-up to the concert in May 2025.

# Draft 2

Symphonic orchestral performance involves large-scale musical interaction between numerous musicians and audience members. The complexity of this interaction is demonstrated through the range of physiological responses and gestural actions displayed by both audience members and musicians, which correlate not only to the sounding music [refs] but can display a great degree of interpersonal synchrony [refs]. However, although an increasing number of symphony orchestras are integrating technological systems into their wider concert infrastructure [refs], the integration of interactive systems which leverage physiological and motion signals measured from this interaction into the concert programme in order to support or generate the performed musical material are rarely found, potentially as a facet of the relative rigidity both of the musical material that can be performed [ref] and social roles assumed both by performers and audience [ref].

As part of an ongoing series of live orchestral concert research involving the collection of a diverse range of physiological and motion signals from symphonic orchestra performers and audiences, in May 2025 we will undertake an extensive data collection with the Aarhus Symphony Orchestra (ASO) over the course of several days, consisting of various sensor measurements from both musicians and audiences. As part of this collection, we also have the opportunity to implement a real-time, interactive system mapping these sensor measurements to the concert house's lighting system during the concert. In particular, we are interested in working with ECG, EMG, and motion signals collected from several musicians, Infra-Red (IR) and thermal imaging of the audience, as well as audio signals of the sounding music, with the aim that this enhance the audience's understanding of musical structure and intended conveyed emotional content of the performed works, as well as the underlying interaction between participants.

In this paper, we outline several elements of the preliminary work that has taken place centred around a one-day visit to the ASO concert house. In particular, we present the implementation of a preliminary testing system to extract performer RR intervals and heart-rate using the Pan-Tompkins algorithm from a wrist-worn EMG implemented in Max/MSP, a validation of the extracted heart-rate, and an evaluation of end-to-end system latency within the concert hall. In addition, we outline the wider direction of our work which will take place in the run-up to the concert in May 2025.

# Draft 3

Symphonic orchestral performance involves large-scale musical interaction between numerous musicians and audience members. The complexity of this interaction is demonstrated through the range of physiological responses and gestural actions displayed by both audience members and musicians, which correlate not only to the sounding music [refs] but can display a great degree of interpersonal synchrony [refs]. While many symphony orchestras are beginning to integrate technological systems into their wider concert infrastructure [refs], interactive systems that utilise physiological and motion signals to enhance or generate musical material remain rare. <span style="background:#ff4d4f">This scarcity may stem from the rigidity of the musical material typically performed [ref] and the traditional social roles assumed by performers and audiences [ref].</span>

As part of an ongoing series of live orchestral concert research involving the collection of a diverse range of physiological and motion signals from symphonic orchestra performers and audiences, in May 2025 we will undertake an extensive data collection with the Aarhus Symphony Orchestra (ASO) over the course of several days. This will consist of various sensor measurements from both musicians and audiences. As part of this collection, we also have the opportunity to implement a real-time, interactive system mapping these sensor measurements to the concert house's lighting system during the concert. In particular, we are interested in working with ECG, EMG, and motion signals collected from several musicians, and thermal imaging of the audience, as well as audio signals of the sounding music, with the aim that this enhance the audience's understanding of musical structure and intended conveyed emotional content of the performed works, as well as the underlying interaction between participants.

In this paper, we outline several elements of the preliminary work that has taken place centred around a one-day visit to the ASO concert house. In particular, we present the implementation of a preliminary testing system to extract performer RR intervals and heart-rate from a wrist-worn EMG implemented in Max/MSP, a validation of the extracted heart-rate, and an evaluation of end-to-end system latency within the concert hall. In addition, we outline the wider direction of our work which will take place in the run-up to the concert in May 2025.