[{"id":"aagaard-hansenChallengesCrossdisciplinaryResearch2007","accessed":{"date-parts":[["2024",9,9]]},"author":[{"family":"Aagaard‐Hansen","given":"Jens"}],"citation-key":"aagaard-hansenChallengesCrossdisciplinaryResearch2007","container-title":"Social Epistemology","container-title-short":"Social Epistemology","DOI":"10.1080/02691720701746540","ISSN":"0269-1728, 1464-5297","issue":"4","issued":{"date-parts":[["2007",10]]},"language":"en","page":"425-438","source":"DOI.org (Crossref)","title":"The Challenges of Cross‐disciplinary Research","type":"article-journal","URL":"http://www.tandfonline.com/doi/abs/10.1080/02691720701746540","volume":"21"},{"id":"abadiTensorFlowSystemLargeScale2016","author":[{"family":"Abadi","given":"Martín"},{"family":"Barham","given":"Paul"},{"family":"Chen","given":"Jianmin"},{"family":"Chen","given":"Zhifeng"},{"family":"Davis","given":"Andy"},{"family":"Dean","given":"Jeffrey"},{"family":"Devin","given":"Matthieu"},{"family":"Ghemawat","given":"Sanjay"},{"family":"Irving","given":"Geoffrey"},{"family":"Isard","given":"Michael"}],"citation-key":"abadiTensorFlowSystemLargeScale2016","event-title":"12th USENIX symposium on operating systems design and implementation (OSDI 16)","ISBN":"1-931971-33-1","issued":{"date-parts":[["2016"]]},"page":"265-283","title":"{TensorFlow}: A System for {Large-Scale} Machine Learning","type":"paper-conference"},{"id":"abbateUnsungVoicesOpera1991","author":[{"family":"Abbate","given":"Carolyn"}],"call-number":"ML3858 .A2 1991","citation-key":"abbateUnsungVoicesOpera1991","collection-title":"Princeton studies in opera","event-place":"Princeton, N.J","ISBN":"978-0-691-09140-2","issued":{"date-parts":[["1991"]]},"number-of-pages":"288","publisher":"Princeton University Press","publisher-place":"Princeton, N.J","source":"Library of Congress ISBN","title":"Unsung Voices: Opera and Musical Narrative in the Nineteenth Century","title-short":"Unsung voices","type":"book"},{"id":"abbavoyageABBAVoyageHow","author":[{"literal":"ABBA Voyage"}],"citation-key":"abbavoyageABBAVoyageHow","title":"ABBA Voyage: How ABBA used motion capture to create their avatars","type":"webpage","URL":"https://www.facebook.com/ABBAVoyage/videos/abba-voyage-how-abba-used-motion-capture-to-create-their-avatars/399264848445591/"},{"id":"abbavoyageABBAVoyageHow2021","accessed":{"date-parts":[["2023",7,7]]},"author":[{"literal":"ABBA Voyage"}],"citation-key":"abbavoyageABBAVoyageHow2021","container-title":"Facebook","issued":{"date-parts":[["2021",10,13]]},"note":"Accessed 07 July 2023","title":"ABBA Voyage: How ABBA used motion capture to create their avatars","type":"webpage","URL":"https://www.facebook.com/ABBAVoyage/videos/abba-voyage-how-abba-used-motion-capture-to-create-their-avatars/399264848445591/"},{"id":"abbaxxiABBAVoyageInterview2022","accessed":{"date-parts":[["2023",9,19]]},"author":[{"literal":"ABBA XXI"}],"citation-key":"abbaxxiABBAVoyageInterview2022","container-title":"YouTube","issued":{"date-parts":[["2022",2,26]]},"title":"ABBA Voyage interview with the choreographer of the show Wayne McGregor","type":"webpage","URL":"https://www.youtube.com/watch?v=hI6GuKxVCkI"},{"id":"abouafBipedDanceVirtual1999","author":[{"family":"Abouaf","given":"Jeffrey"}],"citation-key":"abouafBipedDanceVirtual1999","container-title":"IEEE MultiMedia","container-title-short":"IEEE MultiMedia","DOI":"10.1109/93.790605","ISSN":"1941-0166","issue":"3","issued":{"literal":"July-Sept. 1999"},"page":"4-7","title":"\"Biped\": a dance with virtual and company dancers. 1","type":"article-journal","volume":"6"},{"id":"abouafBipedDanceVirtual1999a","author":[{"family":"Abouaf","given":"J."}],"citation-key":"abouafBipedDanceVirtual1999a","container-title":"IEEE MultiMedia","container-title-short":"IEEE MultiMedia","DOI":"10.1109/93.809227","ISSN":"1941-0166","issue":"4","issued":{"literal":"Oct.-Dec. 1999"},"page":"5-7","title":"\"Biped\": a dance with virtual and company dancers. 2","type":"article-journal","volume":"6"},{"id":"acerT22022","accessed":{"date-parts":[["2022",11,26]]},"author":[{"literal":"Acer"}],"citation-key":"acerT22022","container-title":"Acer","issued":{"date-parts":[["2022"]]},"title":"T2","type":"webpage","URL":"https://www.acer.com/us-en/monitors/touch/t2"},{"id":"adafruitAdafruitNeoPixelDigital","accessed":{"date-parts":[["2022",11,26]]},"author":[{"literal":"adafruit"}],"citation-key":"adafruitAdafruitNeoPixelDigital","container-title":"adafruit","title":"Adafruit NeoPixel Digital RGB LED Strip - White 60 LED - WHITE","type":"webpage","URL":"https://www.adafruit.com/product/1138?length=2"},{"id":"adelsteinHeadTrackingLatency2003","abstract":"Quantification of perceptual sensitivity to latency in virtual environments (VEs) and elucidation of the mechanism by which latency is perceived is essential for development of countermeasures by VE designers. We test the hypothesis that observers use “image slip” (i.e., motion of the VE scene caused by system time lags) to detect the consequences of latency rather than explicitly detecting time delay. Our presumption is that forcing observers to change from constant rate to randomly paced head motion will disrupt their ability to discriminate latency based on perceived image slip. This study indicates that the disruption in motion pattern causes a shift in latency detection criteria and a minor degradation in discrimination ability. It is likely therefore that observers make at least some use of image slip in discriminating VE latency. It can also be inferred that when observers learn to discriminate latency, their Just Noticeable Difference (JND) remains below 17 ms.","accessed":{"date-parts":[["2023",4,30]]},"author":[{"family":"Adelstein","given":"Bernard D."},{"family":"Lee","given":"Thomas G."},{"family":"Ellis","given":"Stephen R."}],"citation-key":"adelsteinHeadTrackingLatency2003","container-title":"Proceedings of the Human Factors and Ergonomics Society Annual Meeting","container-title-short":"Proceedings of the Human Factors and Ergonomics Society Annual Meeting","DOI":"10.1177/154193120304702001","ISSN":"2169-5067, 1071-1813","issue":"20","issued":{"date-parts":[["2003",10]]},"language":"en","page":"2083-2087","source":"DOI.org (Crossref)","title":"Head Tracking Latency in Virtual Environments: Psychophysics and a Model","title-short":"Head Tracking Latency in Virtual Environments","type":"article-journal","URL":"http://journals.sagepub.com/doi/10.1177/154193120304702001","volume":"47"},{"id":"ahmadUniversitySurreyParticipation1999","author":[{"family":"Ahmad","given":"Khurshid"},{"family":"Gillam","given":"Lee"},{"family":"Tostevin","given":"Lena"}],"citation-key":"ahmadUniversitySurreyParticipation1999","container-title":"Proceedings of the Eigth Text Retrieval Conference","event-title":"TREC","issued":{"date-parts":[["1999"]]},"page":"1-8","title":"University of Surrey Participation in TREC8: Weirdness Indexing for Logical Document Extrapolation and Retrieval (WILDER).","type":"paper-conference"},{"id":"ahrcpressCompositionsCochlearImplant2012","accessed":{"date-parts":[["2021",1,27]]},"author":[{"literal":"ahrcpress"}],"citation-key":"ahrcpressCompositionsCochlearImplant2012","container-title":"YouTube","issued":{"date-parts":[["2012",12,3]]},"title":"Compositions for Cochlear Implant Users","type":"webpage","URL":"https://www.youtube.com/watch?v=kpv1iF5158Y"},{"id":"ai-mediaSigningCaptionsBring2018","accessed":{"date-parts":[["2021",1,30]]},"author":[{"literal":"Ai-Media"}],"citation-key":"ai-mediaSigningCaptionsBring2018","container-title":"YouTube","issued":{"date-parts":[["2018",2,6]]},"title":"Signing and captions bring music to life","type":"webpage","URL":"https://www.youtube.com/watch?v=m_WabojwQ6Y"},{"id":"akerlyEmbodiedFlowExperiential2015","abstract":"During the design of interactive dance performances, dancers generate a strong relationship to the responsive media after they are given information about how to use the system. This case study observes a dancer's experience of improvising in a responsive audio system (RAS). A triangulated analysis and conclusion is formed from Laban Movement Analysis in conjunction with post-experience discussions relating to Optimal Flow. This study examines whether or not providing information about how an audio system responds to movement affects a dancers ability to achieve a heightened state of Embodied Flow while improvising in a RAS.","author":[{"family":"Akerly","given":"Julie"}],"citation-key":"akerlyEmbodiedFlowExperiential2015","collection-title":"MOCO '15","container-title":"Proceedings of the 2nd international workshop on movement and computing","DOI":"10.1145/2790994.2790997","event-place":"Vancouver, British Columbia, Canada","ISBN":"978-1-4503-3457-0","issued":{"date-parts":[["2015"]]},"number-of-pages":"8","page":"9–16","publisher":"Association for Computing Machinery","publisher-place":"Vancouver, British Columbia, Canada","title":"Embodied flow in experiential media systems: A study of the dancer's lived experience in a responsive audio system","type":"paper-conference","URL":"https://doi.org/10.1145/2790994.2790997"},{"id":"al-naymatSparseDTWNovelApproach2009","abstract":"We present a new space-efficient approach, (SparseDTW), to compute the Dynamic Time Warping (DTW) distance between two time series that always yields the optimal result. This is in contrast to other known approaches which typically sacrifice optimality to attain space efficiency. The main idea behind our approach is to dynamically exploit the existence of similarity and/or correlation between the time series. The more the similarity between the time series the less space required to compute the DTW between them. To the best of our knowledge, all other techniques to speedup DTW, impose apriori constraints and do not exploit similarity characteristics that may be present in the data. We conduct experiments and demonstrate that SparseDTW outperforms previous approaches.","author":[{"family":"Al-Naymat","given":"Ghazi"},{"family":"Chawla","given":"Sanjay"},{"family":"Taheri","given":"Javid"}],"citation-key":"al-naymatSparseDTWNovelApproach2009","collection-title":"AusDM '09","container-title":"Proceedings of the Eighth Australasian Data Mining Conference - Volume 101","event-place":"Melbourne, Australia","ISBN":"978-1-920682-82-8","issued":{"date-parts":[["2009"]]},"page":"117–127","publisher":"Australian Computer Society, Inc.","publisher-place":"AUS","title":"SparseDTW: A Novel Approach to Speed up Dynamic Time Warping","type":"paper-conference"},{"id":"alaouiChoreographyMediatedCompositional2014","accessed":{"date-parts":[["2023",3,6]]},"author":[{"family":"Alaoui","given":"Sarah Fdili"},{"family":"Carlson","given":"Kristin"},{"family":"Schiphorst","given":"Thecla"}],"citation-key":"alaouiChoreographyMediatedCompositional2014","container-title":"Proceedings of the 2014 International Workshop on Movement and Computing","DOI":"10.1145/2617995.2617996","event-place":"Paris France","event-title":"MOCO '14: International Workshop on Movement and Computing","ISBN":"978-1-4503-2814-2","issued":{"date-parts":[["2014",6,16]]},"language":"en","page":"1-6","publisher":"ACM","publisher-place":"Paris France","source":"DOI.org (Crossref)","title":"Choreography as Mediated through Compositional Tools for Movement: Constructing A Historical Perspective","title-short":"Choreography as Mediated through Compositional Tools for Movement","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/2617995.2617996"},{"id":"alaouiChoreographyMediatedCompositional2014a","abstract":"Choreography is the art of crafting movement, developed through a long history of techniques. Like other compositional processes, choreography is a complex creative process that explores a variety of formal procedures that can result in unique artistic creations. Current computational systems for assisting choreography tend to be idiosyncratic, with emphasis on different feature sets of the compositional process (including movement, structure or expression). In this paper we examine existing technological systems for supporting choreography and group them by their purpose: reflection, generation, real-time interaction, and annotation. We then analyze these system features using Laban Movement Analysis, a comprehensive language for movement description, representation, expression and performance. Our paper articulates the relative benefits of these systems based on experiential aspects of choreography, and posits future directions of intelligent systems for supporting and partnering with choreography.","author":[{"family":"Alaoui","given":"Sarah Fdili"},{"family":"Carlson","given":"Kristin"},{"family":"Schiphorst","given":"Thecla"}],"citation-key":"alaouiChoreographyMediatedCompositional2014a","collection-title":"MOCO '14","container-title":"Proceedings of the 2014 international workshop on movement and computing","DOI":"10.1145/2617995.2617996","event-place":"Paris, France","ISBN":"978-1-4503-2814-2","issued":{"date-parts":[["2014"]]},"number-of-pages":"6","page":"1–6","publisher":"Association for Computing Machinery","publisher-place":"Paris, France","title":"Choreography as mediated through compositional tools for movement: Constructing a historical perspective","type":"paper-conference","URL":"https://doi.org/10.1145/2617995.2617996"},{"id":"alaouiInteractiveVisualsMetaphors2015","abstract":"The notion of “movement qualities” is central in contemporary dance; it describes the manner in which a movement is executed. Movement qualities convey information revealing movement expressiveness; their use has strong potential for movement-based interaction with applications in arts, entertainment, education, or rehabilitation. The purpose of our research is to design and evaluate interactive reflexive visuals for movement qualities. The theoretical basis for this research is drawn from a collaboration with the members of the international dance company Emio Greco|PC to study their formalization of movement qualities. We designed a pedagogical interactive installation called\n              Double Skin/Double Mind (DS/DM)\n              for the analysis and visualization of movement qualities through physical model-based interactive renderings.\n            \n            \n              In this article, we first evaluate dancers’ perception of the visuals as metaphors for movement qualities. This evaluation shows that, depending on the physical model parameterization, the visuals are capable of generating dynamic behaviors that the dancers associate with\n              DS/DM\n              movement qualities. Moreover, we evaluate dance students’ and professionals’ experience of the interactive visuals in the context of a dance pedagogical workshop and a professional dance training. The results of these evaluations show that the dancers consider the interactive visuals to be a reflexive system that encourages them to perform, improves their experience, and contributes to a better understanding of movement qualities. Our findings support research on interactive systems for real-time analysis and visualization of movement qualities, which open new perspectives in movement-based interaction design.","accessed":{"date-parts":[["2023",11,25]]},"author":[{"family":"Alaoui","given":"Sarah Fdili"},{"family":"Bevilacqua","given":"Frederic"},{"family":"Jacquemin","given":"Christian"}],"citation-key":"alaouiInteractiveVisualsMetaphors2015","container-title":"ACM Transactions on Interactive Intelligent Systems","container-title-short":"ACM Trans. Interact. Intell. Syst.","DOI":"10.1145/2738219","ISSN":"2160-6455, 2160-6463","issue":"3","issued":{"date-parts":[["2015",10,16]]},"language":"en","page":"1-24","source":"DOI.org (Crossref)","title":"Interactive Visuals as Metaphors for Dance Movement Qualities","type":"article-journal","URL":"https://dl.acm.org/doi/10.1145/2738219","volume":"5"},{"id":"alemiMovaInteractiveMovement2014","abstract":"There is an increasing interest in analyzing, extracting, and representing human movements in terms of a set of spatial, temporal, and qualitative characteristics for applications such as human-computer interactions and sports and health movement analysis. Information visualization techniques can be used to help people better understand the contents of movements. While all the characteristics of movement may not always be visible or detectable by humans, visualizations can illustrate detailed information about the characteristics of the movement. We present the prototype of an interactive movement analytics framework, called Mova, for feature extraction, feature visualization, and analysis of human movement data. Integrated with a library of feature extraction methods, this platform can be used to anaylze movement qualities and investigate the relationships between its characteristics. In addition, Mova can be used to develop and validate new feature extraction methods with the help of parallel visualization of multiple features. We discuss test-cases in which Mova can be used and detail the road-map for its further development. Link to the platform: http://www.sfu.ca/ oalemi/mova","author":[{"family":"Alemi","given":"Omid"},{"family":"Pasquier","given":"Philippe"},{"family":"Shaw","given":"Chris"}],"citation-key":"alemiMovaInteractiveMovement2014","collection-title":"MOCO '14","container-title":"Proceedings of the 2014 international workshop on movement and computing","DOI":"10.1145/2617995.2618002","event-place":"Paris, France","ISBN":"978-1-4503-2814-2","issued":{"date-parts":[["2014"]]},"number-of-pages":"6","page":"37–42","publisher":"Association for Computing Machinery","publisher-place":"Paris, France","title":"Mova: Interactive movement analytics platform","type":"paper-conference","URL":"https://doi.org/10.1145/2617995.2618002"},{"id":"alfredoThatStudentShould2023","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Alfredo","given":"Riordan Dervin"},{"family":"Nie","given":"Lanbing"},{"family":"Kennedy","given":"Paul"},{"family":"Power","given":"Tamara"},{"family":"Hayes","given":"Carolyn"},{"family":"Chen","given":"Hui"},{"family":"McGregor","given":"Carolyn"},{"family":"Swiecki","given":"Zachari"},{"family":"Gašević","given":"Dragan"},{"family":"Martinez-Maldonado","given":"Roberto"}],"citation-key":"alfredoThatStudentShould2023","container-title":"LAK23: 13th International Learning Analytics and Knowledge Conference","DOI":"10.1145/3576050.3576058","event-place":"Arlington TX USA","event-title":"LAK 2023: 13th International Learning Analytics and Knowledge Conference","ISBN":"978-1-4503-9865-7","issued":{"date-parts":[["2023",3,13]]},"language":"en","page":"57-67","publisher":"ACM","publisher-place":"Arlington TX USA","source":"DOI.org (Crossref)","title":"\"That Student Should be a Lion Tamer!\" StressViz: Designing a Stress Analytics Dashboard for Teachers","title-short":"\"That Student Should be a Lion Tamer!\" StressViz","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3576050.3576058"},{"id":"allchinVideoStoryVodafone2014","accessed":{"date-parts":[["2021",1,27]]},"author":[{"family":"Allchin","given":"Josie"}],"citation-key":"allchinVideoStoryVodafone2014","container-title":"MarketingWeek","issued":{"date-parts":[["2014",1,3]]},"title":"Video: The story behind Vodafone Firsts","type":"webpage","URL":"https://www.marketingweek.com/video-the-story-behind-vodafone-firsts/"},{"id":"allenDynamicPredictiveCoding2023","abstract":"Due to transmission delays, the perceptual information our brain can access quickly becomes outdated as events unfold in real-time. We suggest our perceptual system learns in- ternal representations that encode sequences (or timelines) rather than single points to compensate for transmission de- lays. Specifically, we investigate the dynamic predictive coding (DPC) model in which high-level states predict the transi- tion dynamics of lower-level states and represent lower-level state sequences. We show that a two-level DPC network trained to predict videos captures several aspects of the well-known flash-lag illusion and exhibits both predictive and post- dictive effects resembling those observed in human visual motion processing. Our results support the view that visual per- ception relies on temporally abstracted representations that encode sequences (or timelines) rather than single time points.","author":[{"family":"Allen","given":"P. G."}],"citation-key":"allenDynamicPredictiveCoding2023","issued":{"date-parts":[["2023"]]},"title":"Dynamic predictive coding explains both prediction and postdiction in visual motion perception","type":"article-journal","URL":"https://www.semanticscholar.org/paper/d0162fc2d4ef4f7f794b9e528ab4e97beb5731fd"},{"id":"almenTheoryMusicalNarrative2017","abstract":"\"Byron Almen proposes an original synthesis of approaches to musical narrative from literary criticism, semiotics, historiography, musicology, and music theory, resulting in a significant critical reorientation of the field. This volume includes an extensive survey of traditional approaches to musical narrative, a careful delineation of the essential elements and preconditions of musical narrative organization, an eclectic analytical model applicable to a wide range of musical styles and repertoires, a diverse range of musical examples illustrating the range and applicability of the theoretical apparatus, a classification scheme of narrative types and subtypes reflecting conceptually distinct narrative strategies, a wide array of interpretive categories, and a sensitivity to the dependence of narrative interpretation on the cultural milieu of the work, its various audiences, and the analyst. A Theory of Musical Narrative provides both an excellent introduction to an increasingly important conceptual domain and a complex reassessment of its possibilities and characteristics.\"-- Amazon.com","author":[{"family":"Almén","given":"Byron"}],"call-number":"ML3800 .A46 2017","citation-key":"almenTheoryMusicalNarrative2017","collection-title":"Musical meaning and interpretation","edition":"First paperback edition","event-place":"Bloomington","ISBN":"978-0-253-03009-2","issued":{"date-parts":[["2017"]]},"note":"OCLC: ocn966393264","number-of-pages":"248","publisher":"Indiana University Press","publisher-place":"Bloomington","source":"Library of Congress ISBN","title":"A Theory of Musical Narrative","type":"book"},{"id":"AmericansDisabilitiesAct2004","citation-key":"AmericansDisabilitiesAct2004","issued":{"date-parts":[["2004"]]},"title":"Americans with Disabilities Act of 1990, 42 U.S.C. §§ 12101 et seq. Assistive Technology Act of 1998, as amended, PL 108-364, §3, 118 stat 1707","type":"legislation"},{"id":"andreadisRealtimeMotionCapture2010","author":[{"family":"Andreadis","given":"Anthousis"},{"family":"Hemery","given":"Alexander"},{"family":"Antonakakis","given":"Andronikos"},{"family":"Gourdoglou","given":"Gabriel"},{"family":"Mauridis","given":"Pavlos"},{"family":"Christopoulos","given":"Dimitrios"},{"family":"Karigiannis","given":"John N."}],"citation-key":"andreadisRealtimeMotionCapture2010","container-title":"2010 14th panhellenic conference on informatics","DOI":"10.1109/PCI.2010.14","issued":{"date-parts":[["2010"]]},"page":"148-152","title":"Real-time motion capture technology on a live theatrical performance with computer generated scenery","type":"paper-conference"},{"id":"andrewsGlossaryTermsCommunity2004","author":[{"family":"Andrews","given":"Gary"},{"family":"Faulkner","given":"Debbie"},{"family":"Andrews","given":"Melinda"}],"citation-key":"andrewsGlossaryTermsCommunity2004","container-title":"WHO Document","container-title-short":"WHO Document","issued":{"date-parts":[["2004"]]},"title":"A Glossary of Terms for Community Health Care and Services for Older Persons","type":"article-journal"},{"id":"anjosThreedimensionalVisualizationMovement2018","abstract":"Analyzing and documenting contemporary dance movement data has proven to be a very difficult task due to the vast existence of styles and aesthetics which are characteristic of each individual choreographer. Indeed, identifying movement qualities with the intention of co-relating them to specific meanings and choreographic intentions is practically impossible without taking an artist-driven approach. Moreover, equipping dancers with wearable technology in order to accurately track each of their movements is only applicable in controlled laboratory scenarios, therefore not being a viable approach to analyze large scale real-world rehearsals or performances. This paper describes a visualization system that exposes movement qualities for dance through rendering effects. Combining optical flow analysis with depth video information, we were able to estimate the three-dimensional flow for each point in the cloud. This information was used to color point cloud videos with this information, showing potential to be used for the creation of different rendering effects, which are also discussed in this paper. The data used was captured in a non-intrusive manner during the creation process of a dance piece by Portuguese choreographer Rui Lopes Graça, enabling us to examine nuances and details of the rehearsals' process, which would not be replicable in a laboratory environment.","author":[{"family":"Anjos","given":"Rafael Kuffner","dropping-particle":"dos"},{"family":"Ribeiro","given":"Claudia"},{"family":"Fernandes","given":"Carla"}],"citation-key":"anjosThreedimensionalVisualizationMovement2018","collection-title":"MOCO '18","container-title":"Proceedings of the 5th international conference on movement and computing","DOI":"10.1145/3212721.3212812","event-place":"Genoa, Italy","ISBN":"978-1-4503-6504-8","issued":{"date-parts":[["2018"]]},"number-of-pages":"7","publisher":"Association for Computing Machinery","publisher-place":"Genoa, Italy","title":"Three-dimensional visualization of movement qualities in contemporary dance","type":"paper-conference","URL":"https://doi.org/10.1145/3212721.3212812"},{"id":"annettHowLowShould2020","author":[{"family":"Annett","given":"Michelle"},{"family":"Ng","given":"Albert"},{"family":"Dietz","given":"Paul"},{"family":"Bischof","given":"Walter F"},{"family":"Gupta","given":"Anoop"}],"citation-key":"annettHowLowShould2020","container-title":"Graphics Interface 2014","issued":{"date-parts":[["2020"]]},"page":"167-174","publisher":"AK Peters/CRC Press","title":"How low should we go? Understanding the perception of latency while inking","type":"chapter"},{"id":"ansiS351997Methods1997","author":[{"family":"ANSI","given":"ANSI"}],"citation-key":"ansiS351997Methods1997","container-title":"New York: American National Standards Institute","container-title-short":"New York: American National Standards Institute","issued":{"date-parts":[["1997"]]},"page":"90-119","title":"S3. 5-1997, Methods for the Calculation of the Speech Intelligibility Index","type":"article-journal","volume":"19"},{"id":"anthonyMixingPerformanceCreative2017","author":[{"family":"Anthony","given":"Brendan"}],"citation-key":"anthonyMixingPerformanceCreative2017","container-title":"Journal on the Art of Record Production","container-title-short":"Journal on the Art of Record Production","issue":"11","issued":{"date-parts":[["2017"]]},"title":"Mixing as a performance: Creative approaches to the popular music mix process","type":"article-journal","volume":"11"},{"id":"antilaValkokankaanEnergiapakkaus2009","accessed":{"date-parts":[["2021",1,7]]},"author":[{"family":"Antila","given":"Hanna"}],"citation-key":"antilaValkokankaanEnergiapakkaus2009","container-title":"Kirkko ja Kaupanki","issued":{"date-parts":[["2009",8,6]]},"title":"Valkokankaan energiapakkaus","type":"webpage","URL":"https://www.kirkkojakaupunki.fi/-/valkokankaan-energiapakkaus"},{"id":"antoineUsingHighFrequency2018","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Antoine","given":"Axel"},{"family":"Malacria","given":"Sylvain"},{"family":"Casiez","given":"Géry"}],"citation-key":"antoineUsingHighFrequency2018","container-title":"Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","DOI":"10.1145/3173574.3174183","event-place":"Montreal QC Canada","event-title":"CHI '18: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-5620-6","issued":{"date-parts":[["2018",4,21]]},"language":"en","page":"1-11","publisher":"ACM","publisher-place":"Montreal QC Canada","source":"DOI.org (Crossref)","title":"Using High Frequency Accelerometer and Mouse to Compensate for End-to-end Latency in Indirect Interaction","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3173574.3174183"},{"id":"arduinoArduinoMega25602021","accessed":{"date-parts":[["2022",11,26]]},"author":[{"literal":"Arduino"}],"citation-key":"arduinoArduinoMega25602021","container-title":"store.arduino","issued":{"date-parts":[["2021"]]},"title":"Arduino Mega 2560 Rev3","type":"webpage","URL":"https://store.arduino.cc/products/arduino-mega-2560-rev3"},{"id":"arehartEffectsNoiseNonlinear2011","author":[{"family":"Arehart","given":"Kathryn H."},{"family":"Kates","given":"James M."},{"family":"Anderson","given":"Melinda C."}],"citation-key":"arehartEffectsNoiseNonlinear2011","container-title":"International Journal of Audiology","container-title-short":"International Journal of Audiology","ISSN":"1499-2027","issue":"3","issued":{"date-parts":[["2011"]]},"page":"177-190","publisher":"Taylor & Francis","title":"Effects of Noise, Nonlinear Processing, and Linear Filtering on Perceived Music Quality","type":"article-journal","volume":"50"},{"id":"arellanoRadearTangibleSpinning2014","author":[{"family":"Arellano","given":"Daniel Gábana"},{"family":"McPherson","given":"Andrew P"}],"citation-key":"arellanoRadearTangibleSpinning2014","event-title":"NIME","issued":{"date-parts":[["2014"]]},"page":"84-85","title":"Radear: A Tangible Spinning Music Sequencer.","type":"paper-conference"},{"id":"argentinoTripartiteStructuresSchoenberg2013","author":[{"family":"Argentino","given":"Joe R"}],"citation-key":"argentinoTripartiteStructuresSchoenberg2013","container-title":"Music Theory Online","container-title-short":"Music Theory Online","ISSN":"1067-3040","issue":"1","issued":{"date-parts":[["2013"]]},"title":"Tripartite Structures in Schoenberg's A Survivor from Warsaw.","type":"article-journal","volume":"19"},{"id":"arias-vergaraMultichannelSpectrogramsSpeech2021","abstract":"Time–frequency representations of the speech signals provide dynamic information about how the frequency component changes with time. In order to process this information, deep learning models with convolution layers can be used to obtain feature maps. In many speech processing applications, the time–frequency representations are obtained by applying the short-time Fourier transform and using single-channel input tensors to feed the models. However, this may limit the potential of convolutional networks to learn different representations of the audio signal. In this paper, we propose a methodology to combine three different time–frequency representations of the signals by computing continuous wavelet transform, Mel-spectrograms, and Gammatone spectrograms and combining then into 3D-channel spectrograms to analyze speech in two different applications: (1) automatic detection of speech deficits in cochlear implant users and (2) phoneme class recognition to extract phone-attribute features. For this, two different deep learning-based models are considered: convolutional neural networks and recurrent neural networks with convolution layers.","author":[{"family":"Arias-Vergara","given":"T."},{"family":"Klumpp","given":"P."},{"family":"Vasquez-Correa","given":"J. C."},{"family":"Nöth","given":"E."},{"family":"Orozco-Arroyave","given":"J. R."},{"family":"Schuster","given":"M."}],"citation-key":"arias-vergaraMultichannelSpectrogramsSpeech2021","container-title":"Pattern Analysis and Applications","container-title-short":"Pattern Analysis and Applications","DOI":"10.1007/s10044-020-00921-5","ISSN":"1433-755X","issue":"2","issued":{"date-parts":[["2021",5,1]]},"page":"423-431","title":"Multi-channel spectrograms for speech processing applications using deep learning methods","type":"article-journal","URL":"https://doi.org/10.1007/s10044-020-00921-5","volume":"24"},{"id":"arlanderArtisticResearchApartness2009","abstract":"During the last 30 years, the development of practice-based research in the arts in Finland has occurred mainly within arts universities, and has followed slightly different strategies in each, due to the requirements of various art fields. This chapter concerns the Theatre Academy (TeaK), where I studied directing from 1977–81 and now work as Professor of Performance Art and Theory and as Head of the Department of Research.1 To some extent, the institutional history of research at TeaK coincides with my own journey into artistic research — a trip from theatre through performance to visual art and from space through place to landscape.","author":[{"family":"Arlander","given":"Annette"}],"citation-key":"arlanderArtisticResearchApartness2009","container-title":"Mapping landscapes for performance as research: Scholarly acts and creative cartographies","DOI":"10.1057/9780230244481_9","editor":[{"family":"Riley","given":"Shannon Rose"},{"family":"Hunter","given":"Lynette"}],"event-place":"London","ISBN":"978-0-230-24448-1","issued":{"date-parts":[["2009"]]},"page":"77–83","publisher":"Palgrave Macmillan UK","publisher-place":"London","title":"Artistic research — from apartness to the umbrella concept at the theatre academy, finland","type":"chapter","URL":"https://doi.org/10.1057/9780230244481_9"},{"id":"arteagaIntroductionAmbisonics2015","author":[{"family":"Arteaga","given":"Daniel"}],"citation-key":"arteagaIntroductionAmbisonics2015","issued":{"date-parts":[["2015",6,1]]},"title":"Introduction to Ambisonics","type":"book"},{"id":"aspertiBalancingReconstructionError2020","author":[{"family":"Asperti","given":"Andrea"},{"family":"Trentin","given":"Matteo"}],"citation-key":"aspertiBalancingReconstructionError2020","container-title":"IEEE Access","DOI":"10.1109/ACCESS.2020.3034828","issued":{"date-parts":[["2020"]]},"page":"199440-199448","title":"Balancing Reconstruction Error and Kullback-Leibler Divergence in Variational Autoencoders","type":"article-journal","volume":"8"},{"id":"astrakhantsevATR4SToolkitStateart2018","abstract":"Automatically recognized terminology is widely used for various domain-specific texts processing tasks, such as machine translation, information retrieval or ontology construction. However, there is still no agreement on which methods are best suited for particular settings and, moreover, there is no reliable comparison of already developed methods. We believe that one of the main reasons is the lack of state-of-the-art method implementations, which are usually non-trivial to recreate—mostly, in terms of software engineering efforts. In order to address these issues, we present ATR4S, an open-source software written in Scala that comprises 13 state-of-the-art methods for automatic terminology recognition (ATR) and implements the whole pipeline from text document preprocessing, to term candidates collection, term candidate scoring, and finally, term candidate ranking. It is highly scalable, modular and configurable tool with support of automatic caching. We also compare 13 state-of-the-art methods on 7 open datasets by average precision and processing time. Experimental comparison reveals that no single method demonstrates best average precision for all datasets and that other available tools for ATR do not contain the best methods.","author":[{"family":"Astrakhantsev","given":"Nikita"}],"citation-key":"astrakhantsevATR4SToolkitStateart2018","container-title":"Language Resources and Evaluation","container-title-short":"Language Resources and Evaluation","DOI":"10.1007/s10579-017-9409-4","ISSN":"1574-0218","issue":"3","issued":{"date-parts":[["2018",9,1]]},"page":"853-872","title":"ATR4S: toolkit with state-of-the-art automatic terms recognition methods in Scala","type":"article-journal","URL":"https://doi.org/10.1007/s10579-017-9409-4","volume":"52"},{"id":"astrakhantsevMethodsSoftwareTerminology2015","accessed":{"date-parts":[["2024",9,27]]},"author":[{"family":"Astrakhantsev","given":"Nikita"}],"citation-key":"astrakhantsevMethodsSoftwareTerminology2015","event-place":"Moscow. Russia","genre":"Ph.D Thesis","issued":{"date-parts":[["2015"]]},"publisher":"Ph. D. thesis, Institute for System Programming of Russian Academy of Sciences","publisher-place":"Moscow. Russia","title":"Methods and software for terminology extraction from domain-specific text collection","type":"thesis","URL":"https://www.ispras.ru/en/publications/2015/methods_and_software_for_terminology_extraction_from_domain_specific_text_collection/"},{"id":"atreyMultimodalFusionMultimedia2010","accessed":{"date-parts":[["2024",8,20]]},"author":[{"family":"Atrey","given":"Pradeep K."},{"family":"Hossain","given":"M. Anwar"},{"family":"El Saddik","given":"Abdulmotaleb"},{"family":"Kankanhalli","given":"Mohan S."}],"citation-key":"atreyMultimodalFusionMultimedia2010","container-title":"Multimedia Systems","container-title-short":"Multimedia Systems","DOI":"10.1007/s00530-010-0182-0","ISSN":"0942-4962, 1432-1882","issue":"6","issued":{"date-parts":[["2010",11]]},"language":"en","license":"http://www.springer.com/tdm","page":"345-379","source":"DOI.org (Crossref)","title":"Multimodal fusion for multimedia analysis: a survey","title-short":"Multimodal fusion for multimedia analysis","type":"article-journal","URL":"http://link.springer.com/10.1007/s00530-010-0182-0","volume":"16"},{"id":"auslanderLivenessPerformanceMediatized2023","abstract":"\"Liveness: Performance in a Mediatized Culture addresses what may be the single most important question facing all kinds of performance today. What is the status of live performance in a culture dominated by mass media and digital technologies? Since its first appearance, Philip Auslander's ground-breaking book has helped to reconfigure a new area of study. Looking at specific instances of live performance such as theatre, music, sport, and courtroom testimony, Liveness offers penetrating insights into media culture, suggesting that media technology has encroached on live events to the point where many are hardly live at all. In this new edition, the author thoroughly updates his provocative argument to take into account the impact of the internet, and cultural, social, and legal developments. He also addresses the situation of live performance during the Covid-19 pandemic. In tackling some of the last great shibboleths surrounding the high cultural status of the live event, this classic book will continue to shape opinion and to provoke lively debate on a crucial artistic dilemma: what is live performance and what can it mean to us now? This is extensively revised, new edition of Liveness is an essential read for all students and scholars of performance-based courses\"-- Provided by publisher","author":[{"family":"Auslander","given":"Philip"}],"citation-key":"auslanderLivenessPerformanceMediatized2023","edition":"Third edition","event-place":"Abingdon, Oxon","ISBN":"978-1-003-03131-4","issued":{"date-parts":[["2023"]]},"language":"eng","note":"OCLC: 1334727146","publisher":"Routledge","publisher-place":"Abingdon, Oxon","source":"Open WorldCat","title":"Liveness: performance in a mediatized culture","title-short":"Liveness","type":"book"},{"id":"baalmanSpatialCompositionTechniques2010","accessed":{"date-parts":[["2023",4,2]]},"author":[{"family":"Baalman","given":"Marije A.J."}],"citation-key":"baalmanSpatialCompositionTechniques2010","container-title":"Organised Sound","container-title-short":"Org. Sound","DOI":"10.1017/S1355771810000245","ISSN":"1355-7718, 1469-8153","issue":"03","issued":{"date-parts":[["2010",12]]},"language":"en","page":"209-218","source":"DOI.org (Crossref)","title":"Spatial Composition Techniques and Sound Spatialisation Technologies","type":"article-journal","URL":"http://www.journals.cambridge.org/abstract_S1355771810000245","volume":"15"},{"id":"baculaCharacterRecognitionHumanoid2018","abstract":"An active area of research is exploring how to mimic human movement on a robotic platform. One step toward achieving this goal is the ability to create a method in which a robotic platform successfully portrays a character or character traits that a human can recognize. Ballet is a performing art in which recognizable character types are conveyed through movement. This paper explores the recognition and differentiation of archetypal characters used in classical ballet based on their upper body movements and applies this information to a robotic platform. An observational guide was created using Laban Movement Analysis (LMA) for analyzing the movements of distinct characters found across several classical ballets. Eleven examples were chosen: three villain character types, three bird character types, and five dying character types. The upper body movements of these characters were tracked utilizing the observational guide to see if their movements utilized the LMA characteristics in distinguishable ways. The results from tracking the movements were analyzed, and movement sequences were created on a NAO robot to emulate these character types: a process subsequently validated by a user study.","author":[{"family":"Bacula","given":"Alexandra"},{"family":"LaViers","given":"Amy"}],"citation-key":"baculaCharacterRecognitionHumanoid2018","collection-title":"MOCO '18","container-title":"Proceedings of the 5th international conference on movement and computing","DOI":"10.1145/3212721.3212836","event-place":"Genoa, Italy","ISBN":"978-1-4503-6504-8","issued":{"date-parts":[["2018"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Genoa, Italy","title":"Character recognition on a humanoid robotic platform via a laban movement analysis","type":"paper-conference","URL":"https://doi.org/10.1145/3212721.3212836"},{"id":"baderSpringerHandbookSystematic2018","accessed":{"date-parts":[["2024",4,3]]},"citation-key":"baderSpringerHandbookSystematic2018","collection-title":"Springer Handbooks","DOI":"10.1007/978-3-662-55004-5","editor":[{"family":"Bader","given":"Rolf"}],"event-place":"Berlin, Heidelberg","ISBN":"978-3-662-55002-1 978-3-662-55004-5","issued":{"date-parts":[["2018"]]},"license":"http://www.springer.com/tdm","publisher":"Springer Berlin Heidelberg","publisher-place":"Berlin, Heidelberg","source":"DOI.org (Crossref)","title":"Springer Handbook of Systematic Musicology","type":"book","URL":"http://link.springer.com/10.1007/978-3-662-55004-5"},{"id":"baekgaardDesigningHearingAid2013","author":[{"family":"Baekgaard","given":"Lars"},{"family":"Knudsen","given":"Niels Ole"},{"family":"Arshad","given":"Tayyib"},{"family":"Andersen","given":"Hanne Pernille"}],"citation-key":"baekgaardDesigningHearingAid2013","container-title":"Hearing Review","container-title-short":"Hearing Review","issue":"3","issued":{"date-parts":[["2013"]]},"page":"42-59","title":"Designing Hearing Aid Technology to Support Benefits in Demanding Situations, Part 1","type":"article-journal","volume":"20"},{"id":"bahanFacetofaceTraditionAmerican2006","author":[{"family":"Bahan","given":"Benjamin"}],"citation-key":"bahanFacetofaceTraditionAmerican2006","issued":{"date-parts":[["2006",12,20]]},"page":"21-50","title":"Face-to-face tradition in the American deaf community: Dynamics of the teller, the tale, and the audience","type":"chapter"},{"id":"bahanFacetoFaceTraditionAmerican2006","author":[{"family":"Bahan","given":"Benjamin"}],"call-number":"HV2353 .S53 2006","citation-key":"bahanFacetoFaceTraditionAmerican2006","container-title":"Signing the Body Poetic: Essays on American Sign Language Literature","editor":[{"family":"Bauman","given":"H.-Dirksen L."},{"family":"Nelson","given":"Jennifer L."},{"family":"Rose","given":"Heidi M."}],"event-place":"Berkeley","ISBN":"978-0-520-22975-4 978-0-520-22976-1","issued":{"date-parts":[["2006"]]},"note":"OCLC: ocm69331526","page":"21 - 50","publisher":"University of California Press","publisher-place":"Berkeley","source":"Library of Congress ISBN","title":"Face-to-Face Tradition in the American Deaf Community: Dynamics of the Teller, the Tale, and the Audience","type":"chapter"},{"id":"bahanFormationVisualVariety2008","author":[{"family":"Bahan","given":"Benjamin"}],"call-number":"HV2380 .D43 2002","citation-key":"bahanFormationVisualVariety2008","container-title":"Open Your Eyes: Deaf Studies Talking","editor":[{"family":"Bauman","given":"H.-Dirksen L."}],"event-place":"Minneapolis","ISBN":"978-0-8166-4618-0 978-0-8166-4619-7","issued":{"date-parts":[["2008"]]},"note":"OCLC: ocn167497734","page":"83 - 99","publisher":"University of Minnesota Press","publisher-place":"Minneapolis","source":"Library of Congress ISBN","title":"Upon the Formation of a Visual Variety of the Human Race","type":"chapter"},{"id":"baiEmpiricalEvaluationGeneric2018","abstract":"For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as LSTMs across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at http://github.com/locuslab/TCN .","accessed":{"date-parts":[["2024",9,2]]},"author":[{"family":"Bai","given":"Shaojie"},{"family":"Kolter","given":"J. Zico"},{"family":"Koltun","given":"Vladlen"}],"citation-key":"baiEmpiricalEvaluationGeneric2018","issued":{"date-parts":[["2018",4,19]]},"number":"arXiv:1803.01271","publisher":"arXiv","source":"arXiv.org","title":"An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling","type":"article","URL":"http://arxiv.org/abs/1803.01271"},{"id":"bakanBeingAppliedEthnomusicology2019","author":[{"family":"Bakan","given":"Michael B."}],"call-number":"ML3799.2 .D4 2019","citation-key":"bakanBeingAppliedEthnomusicology2019","collection-title":"Oxford handbooks","container-title":"De-Colonization, Heritage, & Advocacy: An Oxford Handbook of Applied Ethnomusicology, Volume 2","editor":[{"family":"Pettan","given":"Svanibor"},{"family":"Titon","given":"Michael B. Bakan"}],"event-place":"New York, NY","ISBN":"978-0-19-088573-1","issued":{"date-parts":[["2019"]]},"page":"148 - 186","publisher":"Oxford University Press","publisher-place":"New York, NY","source":"Library of Congress ISBN","title":"Being Applied in the Ethnomusicology of Autism","type":"chapter"},{"id":"bakanDonGoChanging2015","abstract":"[Abstract. Ethnomusicology is the study of how people make and experience music, and of why it matters to them that they do. Building from the epistemological foundations of the autistic self-advocacy and neurodiversity movements, as well as from the musical, ethnographic, and relativistic priorities of ethnomusicology itself, this article advances the position that our field, thus defined, is inherently well suited to the task of creating and sustaining vital, neurodiverse musical communities. The focus is on one such community, the Artism Ensemble, which serves as the basis of a case study featuring transcripts of dialogue with a child member of the group diagnosed with Asperger’s syndrome.]","accessed":{"date-parts":[["2020",10,2]]},"archive":"JSTOR","author":[{"family":"Bakan","given":"Michael B."}],"citation-key":"bakanDonGoChanging2015","container-title":"Ethnomusicology","DOI":"10.5406/ethnomusicology.59.1.0116","ISSN":"00141836, 21567417","issue":"1","issued":{"date-parts":[["2015"]]},"page":"116-144","publisher":"[University of Illinois Press, Society for Ethnomusicology]","title":"“Don’t Go Changing to Try and Please Me”: Combating Essentialism through Ethnography in the Ethnomusicology of Autism","type":"article-journal","URL":"https://www.jstor.org/stable/10.5406/ethnomusicology.59.1.0116","volume":"59"},{"id":"bakanEthnographicModelDisability2016","author":[{"family":"Bakan","given":"Michael B."}],"citation-key":"bakanEthnographicModelDisability2016","container-title":"The Oxford Handbook of Music and Disability Studies","editor":[{"family":"Howe","given":"Blake"},{"family":"Jensen-Moulton","given":"Stephanie"},{"family":"Lerner","given":"Neil William"},{"family":"Straus","given":"Joseph Nathan"}],"event-place":"Oxford ; New York","ISBN":"978-0-19-933144-4 978-0-19-065060-5","issued":{"date-parts":[["2016"]]},"page":"54 - 72","publisher":"Oxford University Press","publisher-place":"Oxford ; New York","source":"Library of Congress ISBN","title":"Towards an Ethnographic Model of Disability in the Ethnomusicology of Autism","type":"chapter"},{"id":"bakanEthnomusicologicalPerspectivesAutism2014","author":[{"family":"Bakan","given":"Michael B."}],"citation-key":"bakanEthnomusicologicalPerspectivesAutism2014","container-title":"Voices: A World Forum for Music Therapy","container-title-short":"Voices: A World Forum for Music Therapy","DOI":"10.15845/voices.v14i3.799","issued":{"date-parts":[["2014",10,21]]},"title":"Ethnomusicological Perspectives on Autism, Neurodiversity, and Music Therapy","type":"article-journal","volume":"14"},{"id":"bakanEthnomusicologyScholarshipTeaching2014","abstract":"[In this article, I explore how musical experience and an emergent ethnomusicology of autism can provide both people with autism and their neurotypical counterparts with opportunities to collectively live, model, and promote an epistemology of autism acceptance, in turn challenging and subverting the dominant paradigm of autism as tragedy, disease, disability, disorder, and impairment. I demonstrate how musical performance, ethnographic method, and cultural relativism, the epistemological cornerstones of ethnomusicological endeavor, may be combined toward efficacious ends in the struggle for autistic rights, agency, empowerment, and self-determination. My principal argument is that ethnomusicologically grounded ways of knowing autism, and of knowing about autism, have great potential to expand and enlighten autism-related discourses, as well as foster better self-regard, relationships, and levels of mutual understanding between autistic people and their non-autistic Others. Building from my own ethnomusicological work with the Artism Ensemble, a music performance collective featuring children on the autism spectrum, their co-participating parents, and professional musicians of diverse musical and cultural background, I interact with quoted passages from College Music Society publications of the past half century to stimulate new avenues of thought and action concerning how engagement with music can motivate advocacy, activism, and progressive social change. I am interested in making music make a difference, and I want to motivate others to take on that challenge as well.]","accessed":{"date-parts":[["2020",10,2]]},"archive":"JSTOR","author":[{"family":"Bakan","given":"Michael B."}],"citation-key":"bakanEthnomusicologyScholarshipTeaching2014","container-title":"College Music Symposium","ISSN":"00695696, 2334203X","issued":{"date-parts":[["2014"]]},"publisher":"College Music Society","title":"Ethnomusicology Scholarship and Teaching - Neurodiversity and the Ethnomusicology of Autism","type":"article-journal","URL":"https://www.jstor.org/stable/26574375","volume":"54"},{"id":"bakanMusicDeathNew1999","author":[{"family":"Bakan","given":"Michael B."}],"call-number":"ML345.I5 B35 1999","citation-key":"bakanMusicDeathNew1999","collection-title":"Chicago studies in ethnomusicology","event-place":"Chicago","ISBN":"978-0-226-03487-4 978-0-226-03488-1","issued":{"date-parts":[["1999"]]},"number-of-pages":"384","publisher":"University of Chicago Press","publisher-place":"Chicago","source":"Library of Congress ISBN","title":"Music of Death and New Creation: Experiences in the World of Balinese Gamelan Beleganjur","title-short":"Music of death and new creation","type":"book"},{"id":"bakogiannisDevelopmentDancemusificationModel2021","accessed":{"date-parts":[["2022",3,14]]},"author":[{"family":"Bakogiannis","given":"Konstantinos"},{"family":"Andreopoulou","given":"Areti"},{"family":"Georgaki","given":"Anastasia"}],"citation-key":"bakogiannisDevelopmentDancemusificationModel2021","container-title":"Audio Mostly 2021","DOI":"10.1145/3478384.3478407","event-place":"virtual/Trento Italy","event-title":"AM '21: Audio Mostly 2021","ISBN":"978-1-4503-8569-5","issued":{"date-parts":[["2021",9]]},"language":"en","page":"81-88","publisher":"ACM","publisher-place":"virtual/Trento Italy","source":"DOI.org (Crossref)","title":"The development of a dance-musification model with the use of machine learning techniques under COVID-19 restrictions","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3478384.3478407"},{"id":"baldoComputationalNeurobiologyFlashlag2005","abstract":"S2 TL;DR: A simple feed-forward network reproduces the standard FLE and several related manifestations, such as its modulation by stimulus luminance, trajectory, priming, and spatial predictability, based on plausible neuronal mechanisms.","author":[{"family":"Baldo","given":"M."},{"family":"Caticha","given":"N."}],"citation-key":"baldoComputationalNeurobiologyFlashlag2005","container-title":"Vision Research","DOI":"10.1016/j.visres.2005.04.014","issued":{"date-parts":[["2005"]]},"note":"QID: Q81918515","page":"2620-2630","PMID":"15993457","title":"Computational neurobiology of the flash-lag effect","type":"article-journal","URL":"https://www.semanticscholar.org/paper/16e154950da931ce28c2b9a72907cef77f26989a","volume":"45"},{"id":"balsamoFormsTechnologicalEmbodiment1995","abstract":"Illuminates the ways that contemporary discourses of technology rely on a logic of binary gender identity as an underlying organizational framework to structure the possibilities of technological engagement, and ultimately to limit the revisionary potential of such technologies.","author":[{"family":"Balsamo","given":"Anne"}],"citation-key":"balsamoFormsTechnologicalEmbodiment1995","container-title":"Body & society","ISSN":"1357-034X","issue":"3-4","issued":{"date-parts":[["1995"]]},"language":"eng","page":"215–237","publisher":"SAGE Publications","title":"Forms of technological embodiment: Reading the body in contemporary culture","type":"article-journal","volume":"1"},{"id":"banVariationalBayesianInference2021","author":[{"family":"Ban","given":"Yutong"},{"family":"Alameda-Pineda","given":"Xavier"},{"family":"Girin","given":"Laurent"},{"family":"Horaud","given":"Radu"}],"citation-key":"banVariationalBayesianInference2021","container-title":"IEEE Transactions on Pattern Analysis and Machine Intelligence","DOI":"10.1109/TPAMI.2019.2953020","issue":"5","issued":{"date-parts":[["2021"]]},"page":"1761-1776","title":"Variational bayesian inference for audio-visual tracking of multiple speakers","type":"article-journal","volume":"43"},{"id":"barberGhostcatchingGhostcatchingDances2015","abstract":"In 1999, Bill T. Jones, in collaboration with digital artists Paul Kaiser and Shelley Eshkar, presented an installation at the intersection of dance, drawing, and digital imaging. Ghostcatching featured Jones's previously improvised movements recorded using motion capture technology. In 2010, Kaiser, Eshkar, and Marc Downie of the OpenEndedGroup revised Ghostcatching into a new piece titled After Ghostcatching, composed of unused sequences of Jones's movement and sound captured for Ghostcatching. This essay focuses on the extended relation between Ghostcatching and After Ghostcatching to track a shift from so-called identity politics to a discourse of post-racialism over a ten-year period in U.S. history. A consideration of various media—motion capture technology, digital art and imaging, and improvised, virtual dance—as well as formal analysis of each piece, highlight the political effects and visual implications of each work in a racially mediated world. In this article, I question the status of Jones's raced, sexed, and gendered body within neoliberal fantasies of post-racialism. In spite of the persistence of visible markers such as skin color that are mobilized to construct racial subjects, with the development of digital imaging and new visual technologies, to what degree is race actually visual? That is, how are race and the racialized body in motion subject to and determined by specific media, i.e., photography and digital art, improvised dance and choreographic form? This analysis of Ghostcatching and After Ghostcatching reveals how each piece tests the boundaries of choreographic form and digital imaging technologies as well as the category of race as inherently visual—a test that posits race as technology itself in visual, haptic, and spatial terms.","archive":"Cambridge Core","author":[{"family":"Barber","given":"Tiffany E."}],"citation-key":"barberGhostcatchingGhostcatchingDances2015","container-title":"Dance Research Journal","DOI":"10.1017/S0149767715000030","edition":"2015/05/22","ISSN":"0149-7677","issue":"1","issued":{"date-parts":[["2015"]]},"page":"45-67","publisher":"Cambridge University Press","source":"Cambridge University Press","title":"Ghostcatching and After Ghostcatching, Dances in the Dark","type":"article-journal","URL":"https://www.cambridge.org/core/article/ghostcatching-and-after-ghostcatching-dances-in-the-dark/640ED2639C8B408212ADDBAF97388053","volume":"47"},{"id":"barberGhostcatchingGhostcatchingDances2015a","abstract":"In 1999, Bill T. Jones, in collaboration with digital artists Paul Kaiser and Shelley Eshkar, presented an installation at the intersection of dance, drawing, and digital imaging.\n              Ghostcatching\n              featured Jones's previously improvised movements recorded using motion capture technology. In 2010, Kaiser, Eshkar, and Marc Downie of the OpenEndedGroup revised\n              Ghostcatching\n              into a new piece titled\n              After Ghostcatching\n              , composed of unused sequences of Jones's movement and sound captured for\n              Ghostcatching\n              . This essay focuses on the extended relation between\n              Ghostcatching\n              and\n              After Ghostcatching\n              to track a shift from so-called identity politics to a discourse of post-racialism over a ten-year period in U.S. history. A consideration of various media—motion capture technology, digital art and imaging, and improvised, virtual dance—as well as formal analysis of each piece, highlight the political effects and visual implications of each work in a racially mediated world. In this article, I question the status of Jones's raced, sexed, and gendered body within neoliberal fantasies of post-racialism. In spite of the persistence of visible markers such as skin color that are mobilized to construct racial subjects, with the development of digital imaging and new visual technologies, to what degree is race actually visual? That is, how are race and the racialized body in motion subject to and determined by specific media, i.e., photography and digital art, improvised dance and choreographic form? This analysis of\n              Ghostcatching\n              and\n              After Ghostcatching\n              reveals how each piece tests the boundaries of choreographic form and digital imaging technologies as well as the category of race as inherently visual—a test that posits race as technology itself in visual, haptic, and spatial terms.","accessed":{"date-parts":[["2023",9,29]]},"author":[{"family":"Barber","given":"Tiffany E."}],"citation-key":"barberGhostcatchingGhostcatchingDances2015a","container-title":"Dance Research Journal","container-title-short":"Dance Res. J.","DOI":"10.1017/S0149767715000030","ISSN":"0149-7677, 1940-509X","issue":"1","issued":{"date-parts":[["2015",4]]},"language":"en","page":"44-67","source":"DOI.org (Crossref)","title":"<i>Ghostcatching</i> and <i>After Ghostcatching</i> , Dances in the Dark","type":"article-journal","URL":"https://www.cambridge.org/core/product/identifier/S0149767715000030/type/journal_article","volume":"47"},{"id":"barbosaDisplacedSoundscapesSurvey2003","abstract":"The introduction of various collaborative tools, made possible by the expansion of computer network systems and communications technology, has led to new methods of musical composition and improvisation. The author describes a number of recent music and sound art projects involving the use of network systems that enable geographically displaced creators to collaboratively generate shared soundscapes. Various system designs, ideas and concepts associated with this interaction paradigm are presented and classified by the author.","accessed":{"date-parts":[["2021",8,30]]},"author":[{"family":"Barbosa","given":"Álvaro"}],"citation-key":"barbosaDisplacedSoundscapesSurvey2003","container-title":"Leonardo Music Journal","container-title-short":"Leonardo Music Journal","DOI":"10.1162/096112104322750791","ISSN":"0961-1215, 1531-4812","issued":{"date-parts":[["2003",12]]},"language":"en","page":"53-59","source":"DOI.org (Crossref)","title":"Displaced Soundscapes: A Survey of Network Systems for Music and Sonic Art Creation","title-short":"Displaced Soundscapes","type":"article-journal","URL":"https://direct.mit.edu/lmj/article/63347","volume":"13"},{"id":"bardzellFeministHCITaking2010","accessed":{"date-parts":[["2023",2,27]]},"author":[{"family":"Bardzell","given":"Shaowen"}],"citation-key":"bardzellFeministHCITaking2010","container-title":"Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","DOI":"10.1145/1753326.1753521","event-place":"Atlanta Georgia USA","event-title":"CHI '10: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-60558-929-9","issued":{"date-parts":[["2010",4,10]]},"language":"en","page":"1301-1310","publisher":"ACM","publisher-place":"Atlanta Georgia USA","source":"DOI.org (Crossref)","title":"Feminist HCI: taking stock and outlining an agenda for design","title-short":"Feminist HCI","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/1753326.1753521"},{"id":"barthesImageMusicText1987","author":[{"family":"Barthes","given":"Roland"},{"family":"Heath","given":"Stephen"}],"citation-key":"barthesImageMusicText1987","event-place":"London","ISBN":"978-0-00-686135-5","issued":{"date-parts":[["1987"]]},"language":"eng","note":"OCLC: ocm27934077","number-of-pages":"220","publisher":"Fontana Press","publisher-place":"London","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"Image, Music, Text","type":"book"},{"id":"bartonIntroductionWhereforePAR2017","author":[{"family":"Barton","given":"Bruce"}],"citation-key":"bartonIntroductionWhereforePAR2017","container-title":"Performance as research","editor":[{"family":"Arlander","given":"Annette"},{"family":"Barton","given":"Bruce"},{"family":"Dreyer-Lude","given":"Melanie"},{"family":"Spatz","given":"Ben"}],"event-place":"London","ISBN":"1-315-15767-5","issued":{"date-parts":[["2017"]]},"page":"1-19","publisher":"Routledge","publisher-place":"London","title":"Introduction I: Wherefore PAR?: Discussions on “a line of flight”","type":"chapter"},{"id":"baselizadehPriMACarePrivacyPreservingMultimodal2024","accessed":{"date-parts":[["2024",8,24]]},"author":[{"family":"Baselizadeh","given":"Adel"},{"family":"Uddin","given":"Md Zia"},{"family":"Khaksar","given":"Weria"},{"family":"Lindblom","given":"Diana Saplacan"},{"family":"Torresen","given":"Jim"}],"citation-key":"baselizadehPriMACarePrivacyPreservingMultimodal2024","container-title":"Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction","DOI":"10.1145/3610978.3640701","event-place":"Boulder CO USA","event-title":"HRI '24: ACM/IEEE International Conference on Human-Robot Interaction","ISBN":"979-8-4007-0323-2","issued":{"date-parts":[["2024",3,11]]},"language":"en","page":"233-237","publisher":"ACM","publisher-place":"Boulder CO USA","source":"DOI.org (Crossref)","title":"PriMA-Care: Privacy-Preserving Multi-modal Dataset for Human Activity Recognition in Care Robots","title-short":"PriMA-Care","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3610978.3640701"},{"id":"batesonAngelsFearEpistemology1987","author":[{"family":"Bateson","given":"Gregory"},{"family":"Bateson","given":"Mary Catherine"}],"citation-key":"batesonAngelsFearEpistemology1987","event-place":"New York","issued":{"date-parts":[["1987"]]},"publisher":"Macmillan","publisher-place":"New York","title":"Angels Fear: Towards and Epistemology of the Sacred","type":"book"},{"id":"batesonMindNatureNecessary1979","author":[{"family":"Bateson","given":"Gregory"}],"citation-key":"batesonMindNatureNecessary1979","event-place":"London","issued":{"date-parts":[["1979"]]},"publisher":"Wildwood House; Fonatana/Collins","publisher-place":"London","title":"Mind and Nature: A Necessary Unity","type":"book"},{"id":"batesonStepsEcologyMind1972","author":[{"family":"Bateson","given":"Gregory"}],"citation-key":"batesonStepsEcologyMind1972","event-place":"New York","issued":{"date-parts":[["1972"]]},"publisher":"Chandler Publishing Company","publisher-place":"New York","title":"Steps to an Ecology of Mind: Collected Essays in Anthropology, Psychiatry, Evolution and Epistemology","type":"book"},{"id":"baumanGettingOutLine2006","author":[{"family":"Bauman","given":"H.-Dirksen L."}],"citation-key":"baumanGettingOutLine2006","container-title":"Signing the body poetic: Essays on American sign language literature","issued":{"date-parts":[["2006"]]},"page":"95-117","publisher":"UC Press Los Angeles","title":"Getting Out of Line: Toward a Visual and Cinematic Poetics of ASL","type":"chapter"},{"id":"baumanIntroductionListeningDeaf2008","author":[{"family":"Bauman","given":"H.-Dirksen L."}],"call-number":"HV2380 .D43 2002","citation-key":"baumanIntroductionListeningDeaf2008","container-title":"Open Your Eyes: Deaf Studies Talking","editor":[{"family":"Bauman","given":"H.-Dirksen L."}],"event-place":"Minneapolis","ISBN":"978-0-8166-4618-0 978-0-8166-4619-7","issued":{"date-parts":[["2008"]]},"note":"OCLC: ocn167497734","page":"1 - 32","publisher":"University of Minnesota Press","publisher-place":"Minneapolis","source":"Library of Congress ISBN","title":"Introduction: Listening to Deaf Studies","type":"chapter"},{"id":"baumanOpenYourEyes2008","call-number":"HV2380 .D43 2002","citation-key":"baumanOpenYourEyes2008","editor":[{"family":"Bauman","given":"H.-Dirksen L."}],"event-place":"Minneapolis","ISBN":"978-0-8166-4618-0 978-0-8166-4619-7","issued":{"date-parts":[["2008"]]},"note":"OCLC: ocn167497734","number-of-pages":"349","publisher":"University of Minnesota Press","publisher-place":"Minneapolis","source":"Library of Congress ISBN","title":"Open Your Eyes: Deaf Studies Talking","title-short":"Open your eyes","type":"book"},{"id":"baumanPreface2008","author":[{"family":"Bauman","given":"H.-Dirksen L."}],"call-number":"HV2380 .D43 2002","citation-key":"baumanPreface2008","container-title":"Open Your Eyes: Deaf Studies Talking","editor":[{"family":"Bauman","given":"H.-Dirksen L."}],"event-place":"Minneapolis","ISBN":"978-0-8166-4618-0 978-0-8166-4619-7","issued":{"date-parts":[["2008"]]},"note":"OCLC: ocn167497734","page":"vii - ix","publisher":"University of Minnesota Press","publisher-place":"Minneapolis","source":"Library of Congress ISBN","title":"Preface","type":"chapter"},{"id":"baumanSigningBodyPoetic2006","call-number":"HV2353 .S53 2006","citation-key":"baumanSigningBodyPoetic2006","editor":[{"family":"Bauman","given":"H.-Dirksen L."},{"family":"Nelson","given":"Jennifer L."},{"family":"Rose","given":"Heidi M."}],"event-place":"Berkeley","ISBN":"978-0-520-22975-4 978-0-520-22976-1","issued":{"date-parts":[["2006"]]},"note":"OCLC: ocm69331526","number-of-pages":"264","publisher":"University of California Press","publisher-place":"Berkeley","source":"Library of Congress ISBN","title":"Signing the Body Poetic: Essays on American Sign Language Literature","title-short":"Signing the body poetic","type":"book"},{"id":"baumanSpeechWritingRecognizing1997","author":[{"family":"Bauman","given":"H-Dirksen L"}],"citation-key":"baumanSpeechWritingRecognizing1997","container-title":"Profession","container-title-short":"Profession","ISSN":"0740-6959","issued":{"date-parts":[["1997"]]},"page":"168-179","publisher":"JSTOR","title":"Beyond Speech and Writing: Recognizing American Sign Language Literature in the MLA","type":"article-journal"},{"id":"baumgartnerHowCatchGhost1999","accessed":{"date-parts":[["2023",7,3]]},"archive":"Gale Academic OneFile","author":[{"family":"Baumgartner","given":"Henry"}],"citation-key":"baumgartnerHowCatchGhost1999","container-title":"Mechanical Engineering-CIME","ISSN":"00256501","issue":"4","issued":{"date-parts":[["1999",4]]},"language":"English","page":"108","section":"108","source":"Gale","title":"How to catch a ghost","type":"article-journal","URL":"link.gale.com/apps/doc/A54482570/AONE?u=googlescholar&sid=googleScholar&xid=24012d69","volume":"121"},{"id":"baumgartnerHowCatchGhost1999a","accessed":{"date-parts":[["2024",2,14]]},"archive":"Gale Academic OneFile","author":[{"family":"Baumgartner","given":"Henry"}],"citation-key":"baumgartnerHowCatchGhost1999a","container-title":"Mechanical Engineering-CIME","ISSN":"00256501","issue":"4","issued":{"date-parts":[["1999",4]]},"language":"English","page":"108","section":"108","source":"Gale","title":"How to catch a ghost","type":"article-magazine","URL":"https://link.gale.com/apps/doc/A54482570/AONE?u=googlescholar&sid=googleScholar&xid=24012d69","volume":"121"},{"id":"beerIntroducingGitHub2nd2018","abstract":"If you're new to GitHub, this concise book shows you just what you need to get started and no more. It's perfect for project and product managers, stakeholders, and other team members who want to collaborate on a development project--whether it's to review and comment on work in progress or to contribute specific changes. It's also great for developers just learning GitHub. GitHub has rapidly become the default platform for software development, but it's also ideal for other text-based documents, from contracts to screenplays. This hands-on book shows you how to use GitHub's web interface to view projects and collaborate effectively with your team. The updated second edition covers code review, and includes updates to the desktop application, the Atom text editor, protected branches, and project management features. Keep track of, and work with, developers more effectively Learn the basics so you can contribute to your software projects Understand foundational Git knowledge, including commits and cloning Get tips on positive interaction with developers","accessed":{"date-parts":[["2021",8,30]]},"author":[{"family":"Beer","given":"Brent"}],"citation-key":"beerIntroducingGitHub2nd2018","ISBN":"978-1-4919-8180-1","issued":{"date-parts":[["2018"]]},"language":"English","note":"OCLC: 1019732994","source":"Open WorldCat","title":"Introducing GitHub, 2nd Edition","type":"book","URL":"https://www.safaribooksonline.com/library/view//9781491981801/?ar"},{"id":"beethovensnightmareARTISTS2019","accessed":{"date-parts":[["2021",1,4]]},"author":[{"literal":"Beethoven's Nightmare"}],"citation-key":"beethovensnightmareARTISTS2019","container-title":"Beethoven's Nightmare","issued":{"date-parts":[["2019"]]},"title":"ARTISTS","type":"webpage","URL":"https://www.beethovensnightmare.com/artists"},{"id":"behringerUMC404HD2022","accessed":{"date-parts":[["2022",11,26]]},"author":[{"literal":"Behringer"}],"citation-key":"behringerUMC404HD2022","container-title":"Behringer","issued":{"date-parts":[["2022"]]},"title":"UMC404HD","type":"webpage","URL":"https://www.behringer.com/product.html?modelCode=P0BK1"},{"id":"bellDawnDAWStudio2018","abstract":"Dawn of the DAW tells the story of how the dividing line between the traditional roles of musicians and recording studio personnel (producers, recording engineers, mixing engineers, technicians, etc.) has eroded throughout the latter half of the twentieth century to the present. Whereas those equally adept in music and technology such as Les Paul were exceptions to their eras, the millennial music-maker is ensconced in a world in which the symbiosis of music and technology is commonplace. As audio production skills such as recording, editing, and mixing are increasingly co-opted by musicians teaching themselves in their do-it-yourself (DIY) recording studios, conventions of how music production is taught and practiced are remixed to reflect this reality. Divided into three parts, part I first examines DIY recording practices within the context of recording history from the late nineteenth century to the present. Second, part I discusses the concept of the studio as musical instrument, and the evolving role of the producer. Part II details current practices of DIY recording—how recording technologies are incorporated into music-making, and also how they are learned by DIY studio users in the musically-chic borough of Brooklyn. Part III examines the broader trends heard throughout the stories presented in part II, summarizing the different models of learning and approaches to music-making. Dawn of the DAW concludes by discussing the ramifications of these new directions for music educators.","author":[{"family":"Bell","given":"Adam Patrick"}],"citation-key":"bellDawnDAWStudio2018","DOI":"10.1093/oso/9780190296605.001.0001","ISBN":"978-0-19-029660-5","issued":{"date-parts":[["2018",4]]},"publisher":"Oxford University Press","title":"Dawn of the DAW: The studio as musical instrument","type":"book","URL":"https://doi.org/10.1093/oso/9780190296605.001.0001"},{"id":"bennettBeatBearingTangibleRhythm2008","author":[{"family":"Bennett","given":"Peter"},{"family":"O’Modhrain","given":"Sile"}],"citation-key":"bennettBeatBearingTangibleRhythm2008","event-title":"Proc. of NordiCHI","issued":{"date-parts":[["2008"]]},"title":"The BeatBearing: a tangible rhythm sequencer","type":"paper-conference","volume":"2008"},{"id":"bergnerFirstStepsDance2019","abstract":"We report results of a design-research effort to develop a culturally-relevant educational experience that can engage high school dancers in statistics and data science. In partnership with a local high school and members of its step team, we explore quantitative analysis of both visual and acoustic data captured from student dance. We describe prototype visualizations and interactive applications for evaluating pose precision, tempo, and timbre. With educational goals in mind, we have constrained our design to using only interpretable features and simple, accessible algorithms.","author":[{"family":"Bergner","given":"Yoav"},{"family":"Mund","given":"Shiri"},{"family":"Chen","given":"Ofer"},{"family":"Payne","given":"Willie"}],"citation-key":"bergnerFirstStepsDance2019","collection-title":"MOCO '19","container-title":"Proceedings of the 6th international conference on movement and computing","DOI":"10.1145/3347122.3347137","event-place":"Tempe, AZ, USA","ISBN":"978-1-4503-7654-9","issued":{"date-parts":[["2019"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Tempe, AZ, USA","title":"First steps in dance data science: Educational design","type":"paper-conference","URL":"https://doi.org/10.1145/3347122.3347137"},{"id":"bergnerMovementComputingEducation2020","abstract":"This paper takes a theoretical approach to movement computing education for young learners, with a focus on middle grades (grades 6-8, ages 11-14). This age group is targeted as a lower bound because, while some elements of computational thinking may be available to still younger learners, there are abstractions involved in movement computation that pre-require a certain amount of formal operation, in the Piagetian sense. We outline a parallel foundation of key ideas in movement (specifically dance) and key ideas in computing (specifically data representations) at this age-appropriate level. We describe how these foundations might be laid down together early on so that they can later be integrated via the introduction of sensing and feedback technology. Concepts in movement and choreography are studied using words and bodies, as in traditional dance education, and later using computer simulations and motion capture. Data concepts are introduced first by appeal to general questions and later by specification to the movement of individual and collective joints and bodies.","author":[{"family":"Bergner","given":"Yoav"},{"family":"Damast","given":"Deborah"},{"family":"Romita","given":"Allegra"},{"family":"Smock","given":"Anne Marie Robson"}],"citation-key":"bergnerMovementComputingEducation2020","collection-title":"MOCO '20","container-title":"Proceedings of the 7th international conference on movement and computing","DOI":"10.1145/3401956.3404238","event-place":"Jersey City/Virtual, NJ, USA","ISBN":"978-1-4503-7505-4","issued":{"date-parts":[["2020"]]},"number-of-pages":"5","publisher":"Association for Computing Machinery","publisher-place":"Jersey City/Virtual, NJ, USA","title":"Movement computing education for middle grades","type":"paper-conference","URL":"https://doi.org/10.1145/3401956.3404238"},{"id":"bermanLiveDanceImprovisation2014","abstract":"This paper presents an attempt to generate novel dance movement based on motion captured human dance. Captured movements are analyzed statistically using nonlinear principal component analysis in order to create a \"map\" of observed poses. A method for automatically exploring the map by generating random trajectories is then presented, constituting a kind of improvisation. The result is an animated avatar that exhibits creative and novel movements in the style of its teacher, and paves the way towards a fully improvised live performance between an avatar and a human dancer.","author":[{"family":"Berman","given":"Alexander"},{"family":"James","given":"Valencia"}],"citation-key":"bermanLiveDanceImprovisation2014","collection-title":"MOCO '14","container-title":"Proceedings of the 2014 international workshop on movement and computing","DOI":"10.1145/2617995.2618026","event-place":"Paris, France","ISBN":"978-1-4503-2814-2","issued":{"date-parts":[["2014"]]},"number-of-pages":"4","page":"162–165","publisher":"Association for Computing Machinery","publisher-place":"Paris, France","title":"Towards a live dance improvisation between an avatar and a human dancer","type":"paper-conference","URL":"https://doi.org/10.1145/2617995.2618026"},{"id":"bermudezPrechoreographicMovementKit2014","abstract":"This paper describes the concept and development of the interactive installation \"Pre-Choreographic Movement Kit\". It utilizes a dance concept as a starting point to use physical objects for generating movements, using sensor-based motion tracking. The \"Pre-Choreographic Movement Kit\" is part of the interdisciplinary research project \"Pre-Choreographic Alphabet\", initiated by Bertha Bermudez and Emio Greco, ICKAmsterdam (International Choreographic Center in Amsterdam) joined by Chris Ziegler (School of Arts Media Engineering ASU, Tempe) for design and development under LABO21. The objective of the research project, is to reflect upon previous artistic work, define methodologies for the articulation of dance experiences using interactive environments for transmission and dissemination of knowledge. Choreographer Emio Greco and Pieter C. Scholten have developed over many years an understanding of dancer's technologies to generate movement material for dance creation. Chris Ziegler cites the idea of \"art in a box\" first developed by George Maciunas \"Fluxkit\" (1964), by designing a playful environment for dancers and non-dancers alike. The \"Pre-Choreographic Movement Kit\" proposes interactive Objects, generating a physical encounter to\"Pre-choreographic Knowledge\" of thinking and performing movements.","author":[{"family":"Bermudez","given":"Bertha"},{"family":"Ziegler","given":"Chris"}],"citation-key":"bermudezPrechoreographicMovementKit2014","collection-title":"MOCO '14","container-title":"Proceedings of the 2014 international workshop on movement and computing","DOI":"10.1145/2617995.2617997","event-place":"Paris, France","ISBN":"978-1-4503-2814-2","issued":{"date-parts":[["2014"]]},"number-of-pages":"6","page":"7–12","publisher":"Association for Computing Machinery","publisher-place":"Paris, France","title":"Pre-choreographic movement kit","type":"paper-conference","URL":"https://doi.org/10.1145/2617995.2617997"},{"id":"bernardetM+mNovelMiddleware2016","abstract":"Embodied interaction has the potential to provide users with uniquely engaging and meaningful experiences. m+m: Movement + Meaning middleware is an open source software framework that enables users to construct real-time, interactive systems that are based on movement data. The acquisition, processing, and rendering of movement data can be local or distributed, real-time or off-line. Key features of the m+m middleware are a small footprint in terms of computational resources, portability between different platforms, and high performance in terms of reduced latency and increased bandwidth. Examples of systems that can be built with m+m as the internal communication middleware include those for the semantic interpretation of human movement data, machine-learning models for movement recognition, and the mapping of movement data as a controller for online navigation, collaboration, and distributed performance.","author":[{"family":"Bernardet","given":"Ulysses"},{"family":"Adhia","given":"Dhruv"},{"family":"Jaffe","given":"Norman"},{"family":"Wang","given":"Johnty"},{"family":"Nixon","given":"Michael"},{"family":"Alemi","given":"Omid"},{"family":"Phillips","given":"Jordon"},{"family":"DiPaola","given":"Steve"},{"family":"Pasquier","given":"Philippe"},{"family":"Schiphorst","given":"Thecla"}],"citation-key":"bernardetM+mNovelMiddleware2016","collection-title":"MOCO '16","container-title":"Proceedings of the 3rd international symposium on movement and computing","DOI":"10.1145/2948910.2948942","event-place":"Thessaloniki, GA, Greece","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016"]]},"number-of-pages":"9","publisher":"Association for Computing Machinery","publisher-place":"Thessaloniki, GA, Greece","title":"M+m: A novel middleware for distributed, movement based interactive multimedia systems","type":"paper-conference","URL":"https://doi.org/10.1145/2948910.2948942"},{"id":"bernsenMultimodalityTheory2008","accessed":{"date-parts":[["2023",5,2]]},"author":[{"family":"Bernsen","given":"Niels Ole"}],"citation-key":"bernsenMultimodalityTheory2008","container-title":"Multimodal User Interfaces","DOI":"10.1007/978-3-540-78345-9_2","editor":[{"family":"Tzovaras","given":"Dimitrios"}],"event-place":"Berlin, Heidelberg","ISBN":"978-3-540-78344-2 978-3-540-78345-9","issued":{"date-parts":[["2008"]]},"language":"en","page":"5-29","publisher":"Springer Berlin Heidelberg","publisher-place":"Berlin, Heidelberg","source":"DOI.org (Crossref)","title":"Multimodality Theory","type":"chapter","URL":"http://link.springer.com/10.1007/978-3-540-78345-9_2"},{"id":"bernsteinVirtuosityNineteenthCentury1998","author":[{"family":"Bernstein","given":"Susan"}],"call-number":"ML3849 .B37 1998","citation-key":"bernsteinVirtuosityNineteenthCentury1998","event-place":"Stanford, Calif","ISBN":"978-0-8047-3279-6 978-0-8047-3505-6","issued":{"date-parts":[["1998"]]},"number-of-pages":"239","publisher":"Stanford University Press","publisher-place":"Stanford, Calif","source":"Library of Congress ISBN","title":"Virtuosity of the Nineteenth Century: Performing Music and Language in Heine, Liszt, and Baudelaire","title-short":"Virtuosity of the nineteenth century","type":"book"},{"id":"berthautFirstPersonShooters2011","abstract":"First Person Shooters are among the most played computer videogames. They combine navigation, interaction and collaboration in3D virtual environments using simple input devices, i.e. mouseand keyboard. In this paper, we study the possibilities broughtby these games for musical interaction. We present the Couacs, acollaborative multiprocess instrument which relies on interactiontechniques used in FPS together with new techniques adding theexpressiveness required for musical interaction. In particular, theFaders For All game mode allows musicians to perform patternbased electronic compositions.","accessed":{"date-parts":[["2022",9,13]]},"author":[{"family":"Berthaut","given":"Florent"},{"family":"Katayose","given":"Haruhiro"},{"family":"Wakama","given":"Hironori"},{"family":"Totani","given":"Naoyuki"},{"family":"Sato","given":"Yuichi"}],"citation-key":"berthautFirstPersonShooters2011","DOI":"10.5281/ZENODO.1177961","issued":{"date-parts":[["2011",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"First Person Shooters As Collaborative Multiprocess Instruments","type":"article-journal","URL":"https://zenodo.org/record/1177961"},{"id":"bevilacquaGestureCaptureParadigms2011","accessed":{"date-parts":[["2023",4,19]]},"author":[{"family":"Bevilacqua","given":"Frédéric"},{"family":"Schnell","given":"Norbert"},{"family":"Alaoui","given":"Sarah Fdili"}],"citation-key":"bevilacquaGestureCaptureParadigms2011","container-title":"Emerging Bodies: The Performance of Worldmaking in Dance and Choreography","editor":[{"family":"Klein","given":"Gabriele"},{"family":"Noeth","given":"Sandra"}],"event-place":"Bielefeld","ISBN":"978-3-8394-1596-2","issued":{"date-parts":[["2011"]]},"page":"183–194","publisher":"transcript Verlag","publisher-place":"Bielefeld","title":"Gesture Capture: Paradigms in Interactive Music/ Dance Systems","type":"chapter"},{"id":"bevilacquaVirtualDanceMusic2001","author":[{"family":"Bevilacqua","given":"Frédéric"},{"family":"Naugle","given":"Lisa"},{"family":"Valverde","given":"Isabel"}],"citation-key":"bevilacquaVirtualDanceMusic2001","event-title":"Proc. of the IEEE-Multimedia Technology And Applications Conference, Irvine CA","issued":{"date-parts":[["2001"]]},"title":"Virtual dance and music environment using motion capture","type":"paper-conference"},{"id":"BiggerPictureABBA2022","citation-key":"BiggerPictureABBA2022","container-title":"Engineering & Technology","container-title-short":"Engineering & Technology","DOI":"10.1049/et.2022.0622","ISSN":"1750-9637","issue":"6","issued":{"date-parts":[["2022",7]]},"page":"14-15","title":"The bigger picture: ABBA Voyage","type":"article-journal","volume":"17"},{"id":"BiggerPictureABBA2022a","citation-key":"BiggerPictureABBA2022a","container-title":"Engineering & Technology","container-title-short":"Engineering & Technology","DOI":"10.1049/et.2022.0622","ISSN":"1750-9637","issue":"6","issued":{"date-parts":[["2022",7]]},"page":"14-15","title":"The bigger picture: ABBA Voyage","type":"article-journal","volume":"17"},{"id":"bigoniDogDogSomabasedInterface2020","abstract":"Improvisation is embodied thought and expression. This paper outlines strategies and tactics to design expressive musical interfaces for improvisers. Some of these strategies are explored through a case study: a non-tactile hand-arm movement interface controlling a granular synthesizer (DogDog), based on high-level movement descriptors. The research through design and performance experience indicates that movement quality descriptors are inherently scalable from hand-arm movements to full body interaction, and that a textural approach to motion tracking fits well the morphing sonic masses generated through granular sound synthesis.","author":[{"family":"Bigoni","given":"Francesco"},{"family":"Erkut","given":"Cumhur"}],"citation-key":"bigoniDogDogSomabasedInterface2020","collection-title":"MOCO '20","container-title":"Proceedings of the 7th international conference on movement and computing","DOI":"10.1145/3401956.3404242","event-place":"Jersey City/Virtual, NJ, USA","ISBN":"978-1-4503-7505-4","issued":{"date-parts":[["2020"]]},"number-of-pages":"4","publisher":"Association for Computing Machinery","publisher-place":"Jersey City/Virtual, NJ, USA","title":"DogDog: Soma-based interface design for an improvising musician","type":"paper-conference","URL":"https://doi.org/10.1145/3401956.3404242"},{"id":"birnbaumMusicalVibrotactileFeedback2007","author":[{"family":"Birnbaum","given":"David M."}],"citation-key":"birnbaumMusicalVibrotactileFeedback2007","event-place":"Montreal","genre":"Master Thesis","issued":{"date-parts":[["2007"]]},"publisher":"McGill University","publisher-place":"Montreal","title":"Musical vibrotactile feedback","type":"thesis","URL":"https://escholarship.mcgill.ca/concern/theses/xd07gx894"},{"id":"birringerGesturalMaterialitiesWorn2015","author":[{"family":"Birringer","given":"Johannes"}],"call-number":"QP303 .C57 2015","citation-key":"birringerGesturalMaterialitiesWorn2015","collection-title":"Palgrave studies in performance and technology","container-title":"Digital movement: essays in motion technology and performance","editor":[{"family":"Sutil","given":"Nicolás Salazar"},{"family":"Popat","given":"Sita"}],"event-place":"Houndmills, Basingstoke Hampshire ; New York, NY","ISBN":"978-1-137-43040-3","issued":{"date-parts":[["2015"]]},"page":"162-185","publisher":"Palgrave Macmillan","publisher-place":"Houndmills, Basingstoke Hampshire ; New York, NY","source":"Library of Congress ISBN","title":"Gestural Materialities and the Worn Dispositif","type":"chapter"},{"id":"birringerInteractiveDanceBody2004","accessed":{"date-parts":[["2023",10,12]]},"author":[{"family":"Birringer","given":"Johannes"}],"citation-key":"birringerInteractiveDanceBody2004","container-title":"Journal of Visual Art Practice","container-title-short":"Journal of Visual Art Practice","DOI":"10.1386/jvap.3.3.165/0","ISSN":"1470-2029, 1758-9185","issue":"3","issued":{"date-parts":[["2004",1]]},"language":"en","page":"165-178","source":"DOI.org (Crossref)","title":"Interactive dance, the body and the Internet","type":"article-journal","URL":"https://www.tandfonline.com/doi/full/10.1386/jvap.3.3.165/0","volume":"3"},{"id":"bishopPerformersActiveAudience2018","abstract":"Musical communication involves performance and perception processes, both of which engage the sensorimotor system. In much of the performance science literature, however, musical communication is conceptualized as a one-way trajectory from active performer to passive listener, minimizing the contribution of the listener and the collaborative nature of communication. In this paper, we discuss how movement contributes to 1) music performance, through sound production, interperformer coordination, and visual expressivity, and 2) music perception, through the simulation of observed gestures, activation of crossmodal associations, and induction of overt synchronized responses. Embodied music cognition, which treats musical communication as a process of dynamic interaction between individuals, and emphasizes the role of the physical body in mediating between environmental stimuli and subjective experiences, provides a background for our discussion. We conclude the paper with a discussion of how ongoing technological developments are simultaneously enhancing our ability to study musical communication (e.g., via integration of optical motion capture and mobile eye tracking) and, by introducing means of performing music that do not rely on human movement, challenging our understanding of how music and movement relate.","accessed":{"date-parts":[["2024",1,23]]},"author":[{"family":"Bishop","given":"Laura"},{"family":"Goebl","given":"Werner"}],"citation-key":"bishopPerformersActiveAudience2018","container-title":"Jahrbuch Musikpsychologie","container-title-short":"Jahrb. Musik.","DOI":"10.5964/jbdgm.2018v28.19","ISSN":"2569-5665","issued":{"date-parts":[["2018",8,13]]},"page":"e19","source":"DOI.org (Crossref)","title":"Performers and an active audience: Movement in music production and perception","title-short":"Performers and an active audience","type":"article-journal","URL":"https://jbdgm.psychopen.eu/index.php/jbdgm/article/view/19","volume":"28"},{"id":"bisigGenerativeDanceTaxonomy2022","accessed":{"date-parts":[["2023",12,12]]},"author":[{"family":"Bisig","given":"Daniel"}],"citation-key":"bisigGenerativeDanceTaxonomy2022","container-title":"Proceedings of the 8th International Conference on Movement and Computing","DOI":"10.1145/3537972.3537978","event-place":"Chicago IL USA","event-title":"MOCO '22: 8th International Conference on Movement and Computing","ISBN":"978-1-4503-8716-3","issued":{"date-parts":[["2022",6,22]]},"language":"en","page":"1-10","publisher":"ACM","publisher-place":"Chicago IL USA","source":"DOI.org (Crossref)","title":"Generative Dance - a Taxonomy and Survey","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3537972.3537978"},{"id":"bisigGenerativeDanceTaxonomy2022a","abstract":"Generative Art is a creative approach that has found applications in several artistic disciplines. In some of these disciplines, formalization has historically played an important role, which predisposes them for employing generative methods. In dance, the relationship to Generative Art is less obvious and the role of formalization is more contested than in other disciplines. This paper tries to contribute to an understanding of the specific role that Generative Art currently plays in dance. It does so by proposing a taxonomy of topics that cover both common and dance specific aspects of Generative Art. This taxonomy is used for comparing a wide diversity of generative works that have been created in the context of dance.","author":[{"family":"Bisig","given":"Daniel"}],"citation-key":"bisigGenerativeDanceTaxonomy2022a","collection-title":"MOCO '22","container-title":"Proceedings of the 8th international conference on movement and computing","DOI":"10.1145/3537972.3537978","event-place":"Chicago, IL, USA","ISBN":"978-1-4503-8716-3","issued":{"date-parts":[["2022"]]},"number-of-pages":"10","publisher":"Association for Computing Machinery","publisher-place":"Chicago, IL, USA","title":"Generative dance - a taxonomy and survey","type":"paper-conference","URL":"https://doi.org/10.1145/3537972.3537978"},{"id":"bisigNeuralNarrativesDance2016","abstract":"From the context of two dance productions, the Neural Narratives project has started to emerge as a comprehensive exploration of simulation-based approaches that enable the creation of artificial body extensions for dancers. The simulation, visualisation and sonification of these body extensions allow a dancer to alter and enlarge his or her bodily presence and movement possibilities. The main focus of this publication lies in the contextualisation and discussion of a number of questions that have arisen during the realisation of the dance productions. These questions relate to concepts of embodiment, agency, and creativity and their possible implications for the realisation of interactive systems for dance. We try to address these questions by drawing from ideas that originate from a wide range of fields including dance and technology, cognitive science, systems science, and medical engineering. By connecting our own practical activities to a broad disciplinary context, we hope to contribute to a discourse concerning future directions for research and creation that deepen the integration of technology and dance.","author":[{"family":"Bisig","given":"Daniel"},{"family":"Palacio","given":"Pablo"}],"citation-key":"bisigNeuralNarrativesDance2016","collection-title":"MOCO '16","container-title":"Proceedings of the 3rd international symposium on movement and computing","DOI":"10.1145/2948910.2948925","event-place":"Thessaloniki, GA, Greece","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Thessaloniki, GA, Greece","title":"Neural narratives: Dance with virtual body extensions","type":"paper-conference","URL":"https://doi.org/10.1145/2948910.2948925"},{"id":"bisigRawMusicFree2021","author":[{"family":"Bisig","given":"Daniel"},{"family":"Tatar","given":"Kıvanç"}],"citation-key":"bisigRawMusicFree2021","container-title":"The Proceedings of 2nd Conference on AI Music Creativity","event-title":"2nd Conference on AI Music Creativity","ISBN":"978-3-200-08272-4","issued":{"date-parts":[["2021",7]]},"title":"Raw Music from Free Movements: Early Experiments in Using Machine Learning to Create Raw Audio from Dance Movements","type":"paper-conference","URL":"https://aimc2021.iem.at/wp-content/uploads/2021/06/AIMC_2021_Bisig_Tatar.pdf"},{"id":"bjerknesComputersDemocracyScandinavian1987","citation-key":"bjerknesComputersDemocracyScandinavian1987","editor":[{"family":"Bjerknes","given":"Gro"},{"family":"Ehn","given":"Pelle"},{"family":"Kyng","given":"Morten"}],"ISBN":"0-566-05476-0","issued":{"date-parts":[["1987"]]},"language":"English","publisher":"Gower Publishing","title":"Computers and democracy - a scandinavian challenge","type":"book"},{"id":"blakePerceptionHumanMotion2007","abstract":"Abstract  Humans, being highly social creatures, rely heavily on the ability to perceive what others are doing and to infer from gestures and expressions what others may be intending to do. These perceptual skills are easily mastered by most, but not all, people, in large part because human action readily communicates intentions and feelings. In recent years, remarkable advances have been made in our understanding of the visual, motoric, and affective influences on perception of human action, as well as in the elucidation of the neural concomitants of perception of human action. This article reviews those advances and, where possible, draws links among those findings.","accessed":{"date-parts":[["2024",7,11]]},"author":[{"family":"Blake","given":"Randolph"},{"family":"Shiffrar","given":"Maggie"}],"citation-key":"blakePerceptionHumanMotion2007","container-title":"Annual Review of Psychology","container-title-short":"Annu. Rev. Psychol.","DOI":"10.1146/annurev.psych.57.102904.190152","ISSN":"0066-4308, 1545-2085","issue":"1","issued":{"date-parts":[["2007",1,1]]},"language":"en","note":"QID: Q48449271","page":"47-73","source":"DOI.org (Crossref)","title":"Perception of Human Motion","type":"article-journal","URL":"https://www.annualreviews.org/doi/10.1146/annurev.psych.57.102904.190152","volume":"58"},{"id":"blomPredictionsDriveNeural2020","abstract":"Significance Visual information takes time to travel from the retina and through the visual system, such that the sensory information available to the brain lags behind events in the present moment. Prediction has long been considered a fundamental principle in neuroscience. Using time-resolved EEG decoding, we show that predictive mechanisms are sufficient to activate sensory-like neural representations of anticipated future events, and that these representations are activated before the arrival of afferent sensory information. This reveals that predictive neural mechanisms might allow the visual system to overcome its neural processing delays and interact with our environment in real time. The transmission of sensory information through the visual system takes time. As a result of these delays, the visual information available to the brain always lags behind the timing of events in the present moment. Compensating for these delays is crucial for functioning within dynamic environments, since interacting with a moving object (e.g., catching a ball) requires real-time localization of the object. One way the brain might achieve this is via prediction of anticipated events. Using time-resolved decoding of electroencephalographic (EEG) data, we demonstrate that the visual system represents the anticipated future position of a moving object, showing that predictive mechanisms activate the same neural representations as afferent sensory input. Importantly, this activation is evident before sensory input corresponding to the stimulus position is able to arrive. Finally, we demonstrate that, when predicted events do not eventuate, sensory information arrives too late to prevent the visual system from representing what was expected but never presented. Taken together, we demonstrate how the visual system can implement predictive mechanisms to preactivate sensory representations, and argue that this might allow it to compensate for its own temporal constraints, allowing us to interact with dynamic visual environments in real time.","author":[{"family":"Blom","given":"Tessel"},{"family":"Feuerriegel","given":"Daniel"},{"family":"Johnson","given":"Philippa A."},{"family":"Bode","given":"S."},{"family":"Hogendoorn","given":"Hinze"}],"citation-key":"blomPredictionsDriveNeural2020","container-title":"Proceedings of the National Academy of Sciences","DOI":"10.1073/pnas.1917777117","issued":{"date-parts":[["2020"]]},"note":"QID: Q90370926","page":"7510 - 7515","PMID":"32179666","title":"Predictions drive neural representations of visual events ahead of incoming sensory information","type":"article-journal","URL":"https://www.semanticscholar.org/paper/e12ce592b4e9bf41134c20f60ad405469c4b2487","volume":"117"},{"id":"blomTimecoursePredictionFormation2021","abstract":"S2 TL;DR: The results suggest that two complementary mechanisms interact to form and revise predictions in visual motion processing, modulating the latencies of neural position representations at different levels of visual processing.","author":[{"family":"Blom","given":"Tessel"},{"family":"Bode","given":"S."},{"family":"Hogendoorn","given":"Hinze"}],"citation-key":"blomTimecoursePredictionFormation2021","container-title":"Cortex; a journal devoted to the study of the nervous system and behavior","container-title-short":"Cortex","DOI":"10.1016/j.cortex.2021.02.008","issued":{"date-parts":[["2021"]]},"page":"191-202","PMID":"33711770","title":"The time-course of prediction formation and revision in human visual motion processing","type":"article-journal","URL":"https://www.semanticscholar.org/paper/42c7cf1b384f26ff9841ec65d0490c832bf1a1fb","volume":"138"},{"id":"blomWhenPredictionsFail2019","abstract":"Motion-induced position shifts constitute a broad class of visual illusions in which motion and position signals interact in the human visual pathway. In such illusions, the presence of visual motion distorts the perceived positions of objects in nearby space. Predictive mechanisms, which could contribute to compensating for processing delays due to neural transmission, have been given as an explanation. However, such mechanisms have struggled to explain why we do not usually perceive objects extrapolated beyond the end of their trajectory. Advocates of this interpretation have proposed a \"correction-for-extrapolation\" mechanism to explain this: When the object motion ends abruptly, this mechanism corrects the overextrapolation by shifting the perceived object location backwards to its actual location. However, such a mechanism has so far not been empirically demonstrated. Here, we use a novel version of the flash-grab illusion to demonstrate this mechanism. In the flash-grab effect, a target is flashed on a moving background that abruptly changes direction, leading to the mislocalization of the target. Here, we manipulate the angle of the direction change to dissociate the contributions of the background motion before and after the flash. Consistent with previous reports, we observe that perceptual mislocalization in the flash-grab illusion is mainly driven by motion after the flash. Importantly, however, we reveal a small but consistent mislocalization component in the direction opposite to the direction of the first motion sequence. This provides empirical support for the proposed correction-for-extrapolation mechanism, and therefore corroborates the interpretation that motion-induced position shifts might result from predictive interactions between motion and position signals.","author":[{"family":"Blom","given":"Tessel"},{"family":"Liang","given":"Qianchen"},{"family":"Hogendoorn","given":"Hinze"}],"citation-key":"blomWhenPredictionsFail2019","container-title":"Journal of vision","DOI":"10.1167/19.2.3","issued":{"date-parts":[["2019"]]},"note":"QID: Q91372503","page":"3","PMID":"30725096","title":"When predictions fail: Correction for extrapolation in the flash-grab effect.","type":"article-journal","URL":"https://www.semanticscholar.org/paper/f046d69be856603f4f65a3fbb95acdc08cfb5280","volume":"19 2"},{"id":"blytheResearchFictionStorytelling2017","accessed":{"date-parts":[["2023",11,12]]},"author":[{"family":"Blythe","given":"Mark"}],"citation-key":"blytheResearchFictionStorytelling2017","container-title":"Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems","DOI":"10.1145/3025453.3026023","event-place":"Denver Colorado USA","event-title":"CHI '17: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-4655-9","issued":{"date-parts":[["2017",5,2]]},"language":"en","page":"5400-5411","publisher":"ACM","publisher-place":"Denver Colorado USA","source":"DOI.org (Crossref)","title":"Research Fiction: Storytelling, Plot and Design","title-short":"Research Fiction","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3025453.3026023"},{"id":"bodenheimerProcessMotionCapture1997","accessed":{"date-parts":[["2023",10,17]]},"author":[{"family":"Bodenheimer","given":"Bobby"},{"family":"Rose","given":"Chuck"},{"family":"Rosenthal","given":"Seth"},{"family":"Pella","given":"John"}],"citation-key":"bodenheimerProcessMotionCapture1997","collection-editor":[{"family":"Hansmann","given":"W."},{"family":"Hewitt","given":"W. T."},{"family":"Purgathofer","given":"W."}],"container-title":"Computer Animation and Simulation ’97","DOI":"10.1007/978-3-7091-6874-5_1","editor":[{"family":"Thalmann","given":"Daniel"},{"family":"Van De Panne","given":"Michiel"}],"event-place":"Vienna","ISBN":"978-3-211-83048-2 978-3-7091-6874-5","issued":{"date-parts":[["1997"]]},"language":"en","page":"3-18","publisher":"Springer Vienna","publisher-place":"Vienna","source":"DOI.org (Crossref)","title":"The Process of Motion Capture: Dealing with the Data","title-short":"The Process of Motion Capture","type":"chapter","URL":"http://link.springer.com/10.1007/978-3-7091-6874-5_1"},{"id":"bolinkValidityInertialMeasurement2016","accessed":{"date-parts":[["2024",1,4]]},"author":[{"family":"Bolink","given":"S.A.A.N."},{"family":"Naisas","given":"H."},{"family":"Senden","given":"R."},{"family":"Essers","given":"H."},{"family":"Heyligers","given":"I.C."},{"family":"Meijer","given":"K."},{"family":"Grimm","given":"B."}],"citation-key":"bolinkValidityInertialMeasurement2016","container-title":"Medical Engineering & Physics","container-title-short":"Medical Engineering & Physics","DOI":"10.1016/j.medengphy.2015.11.009","ISSN":"13504533","issue":"3","issued":{"date-parts":[["2016",3]]},"language":"en","page":"225-231","source":"DOI.org (Crossref)","title":"Validity of an inertial measurement unit to assess pelvic orientation angles during gait, sit–stand transfers and step-up transfers: Comparison with an optoelectronic motion capture system*","title-short":"Validity of an inertial measurement unit to assess pelvic orientation angles during gait, sit–stand transfers and step-up transfers","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S1350453315002672","volume":"38"},{"id":"bongersPhysicalInterfacesElectronic2000","author":[{"family":"Bongers","given":"Bert"}],"citation-key":"bongersPhysicalInterfacesElectronic2000","container-title":"Trends in Gestural Control of Music","container-title-short":"Trends in Gestural Control of Music","editor":[{"family":"Wanderley","given":"M.M"},{"family":"Battier","given":"M."}],"issued":{"date-parts":[["2000",1,1]]},"page":"41-70","title":"Physical interfaces in the electronic arts. Interaction theory and interfacing techniques for real-time performance","type":"article-journal"},{"id":"bordeaDomainindependentTermExtraction2013","author":[{"family":"Bordea","given":"Georgeta"},{"family":"Buitelaar","given":"Paul"},{"family":"Polajnar","given":"Tamara"}],"citation-key":"bordeaDomainindependentTermExtraction2013","container-title":"TIA 2013-10th International Conference on Terminology and Artificial Intelligence","event-place":"Paris, France","event-title":"TIA 2013-10th International Conference on Terminology and Artificial Intelligence","issued":{"date-parts":[["2013"]]},"publisher-place":"Paris, France","title":"Domain-independent term extraction through domain modelling","type":"paper-conference"},{"id":"borgdorffDebateResearchArts2006","author":[{"family":"Borgdorff","given":"Henk"}],"citation-key":"borgdorffDebateResearchArts2006","container-title":"Sensuous Knowledge 2","event-place":"Bergen","issued":{"date-parts":[["2006"]]},"publisher":"Kunsthøgskolen i Bergen","publisher-place":"Bergen","title":"The debate on research in the arts","type":"paper-conference"},{"id":"bornMicrosoundVaporwaveInternetMediated2017","accessed":{"date-parts":[["2021",11,10]]},"author":[{"family":"Born","given":"Georgina"},{"family":"Haworth","given":"Christopher"}],"citation-key":"bornMicrosoundVaporwaveInternetMediated2017","container-title":"Music and Letters","DOI":"10.1093/ml/gcx095","ISSN":"0027-4224, 1477-4631","issue":"4","issued":{"date-parts":[["2017",11,1]]},"language":"en","page":"601-647","source":"DOI.org (Crossref)","title":"From Microsound to Vaporwave: Internet-Mediated Musics, Online Methods, and Genre","title-short":"From Microsound to Vaporwave","type":"article-journal","URL":"https://academic.oup.com/ml/article/98/4/601/4828180","volume":"98"},{"id":"bosmaBodiesEvidenceSinging2003","abstract":"This article is part of PhD research dealing with gender issues in electroacoustic music, focusing on the voice. The first part of the article begins with a discussion of the musical material under research. Thereafter follows an elaborate overview of the number of male and female composers, vocalists and recorded voices in several series of CDs of electroacoustic and computer music. The gendered roles of the live, pre-recorded and synthesised voices are discussed and the musical couple of the male composer and the female vocalist emerges. The second part touches upon several issues raised by the results of part one: the roles of the performer and the composer, (dis)embodiment, femininity and technology. This is a preview into some of the remaining research. In section 2, other music than the CD series of section 1 is discussed as well. The gender patterns are interpreted in a broader context. The role of the female vocalist is many sided. Cyborg voices relate to old patterns as well as new possibilities.","archive":"Cambridge Core","author":[{"family":"Bosma","given":"Hannah"}],"citation-key":"bosmaBodiesEvidenceSinging2003","container-title":"Organised Sound","DOI":"10.1017/S135577180300102X","edition":"2004/01/19","ISSN":"1355-7718","issue":"1","issued":{"date-parts":[["2003"]]},"page":"5-17","publisher":"Cambridge University Press","source":"Cambridge University Press","title":"Bodies of Evidence, Singing Cyborgs and Other Gender Issues in Electrovocal Music","type":"article-journal","URL":"https://www.cambridge.org/core/article/bodies-of-evidence-singing-cyborgs-and-other-gender-issues-in-electrovocal-music/E4F75A88AC039AFF095986A4977A0D0F","volume":"8"},{"id":"bouckAssistiveTechnology2017","author":[{"family":"Bouck","given":"Emily C."}],"call-number":"LC4019 .B67 2017","citation-key":"bouckAssistiveTechnology2017","event-place":"Los Angeles","ISBN":"978-1-4833-7443-7","issued":{"date-parts":[["2017"]]},"number-of-pages":"308","publisher":"Sage Publications","publisher-place":"Los Angeles","source":"Library of Congress ISBN","title":"Assistive Technology","type":"book"},{"id":"boulangerAudioProgrammingBook2011","call-number":"ML74.3 .A93 2011","citation-key":"boulangerAudioProgrammingBook2011","editor":[{"family":"Boulanger","given":"Richard Charles"},{"family":"Lazzarini","given":"Victor"}],"event-place":"Cambridge, Mass","ISBN":"978-0-262-01446-5","issued":{"date-parts":[["2011"]]},"note":"OCLC: ocn503654559","number-of-pages":"889","publisher":"MIT Press","publisher-place":"Cambridge, Mass","source":"Library of Congress ISBN","title":"The Audio Programming Book","type":"book"},{"id":"bourguetDesigningPrototypingMultimodal2003","author":[{"family":"Bourguet","given":"Marie-Luce"}],"citation-key":"bourguetDesigningPrototypingMultimodal2003","container-title":"Interact","event-title":"Interact","issued":{"date-parts":[["2003"]]},"page":"717-720","publisher":"Citeseer","title":"Designing and Prototyping Multimodal Commands.","type":"paper-conference","volume":"3"},{"id":"bouzos3DSceneModellingProfessional2016","abstract":"In this paper, we present good practices of applying and extending Random Decision Forests (RDFs) for the 3D modelling of scenes where humans interact with moving, deformable and revolving objects in a professional context. We apply our method to two use-cases; the first is in the industrial context of the luxury leather good production while the second is in an atelier specialised in the wheel-throwing art of pottery. In the first use-case we use a single RDF, while for the second one of pottery, we extend the typical application of RDFs, by introducing the Hierarchical Random Decision Forests (HRDFs). More precisely, we use three RDFs in a tree structure architecture. The parent RDF is used to create a rough initial segmentation of the scene, while the two children RDFs are used to further classify the regions of the left and right arm, hand and fingers respectively. Results demonstrate that the proposed algorithm is sufficient for the accurate classification of scenes where humans interact with objects by using hand gestures in both simple and complex scenarios.","author":[{"family":"Bouzos","given":"Odysseas"},{"family":"Jacob","given":"Yannick"},{"family":"Manitsaris","given":"Sotiris"},{"family":"Glushkova","given":"Alina"}],"citation-key":"bouzos3DSceneModellingProfessional2016","collection-title":"MOCO '16","container-title":"Proceedings of the 3rd international symposium on movement and computing","DOI":"10.1145/2948910.2948949","event-place":"Thessaloniki, GA, Greece","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016"]]},"number-of-pages":"7","publisher":"Association for Computing Machinery","publisher-place":"Thessaloniki, GA, Greece","title":"3D-Scene modelling of professional gestures when interacting with moving, deformable and revolving objects","type":"paper-conference","URL":"https://doi.org/10.1145/2948910.2948949"},{"id":"bowersHybridResonantAssemblages2014","author":[{"family":"Bowers","given":"John"},{"family":"Haas","given":"Annika"}],"citation-key":"bowersHybridResonantAssemblages2014","DOI":"10.5281/zenodo.1178718","event-place":"London, United Kingdom","event-title":"Proceedings of the International Conference on New Interfaces for Musical Expression","issued":{"date-parts":[["2014",6]]},"page":"7-12","publisher":"Goldsmiths, University of London","publisher-place":"London, United Kingdom","title":"Hybrid Resonant Assemblages: Rethinking Instruments, Touch and Performance in New Interfaces for Musical Expression","type":"paper-conference","URL":"http://www.nime.org/proceedings/2014/nime2014_438.pdf"},{"id":"bowersNotHyperNot2005","author":[{"family":"Bowers","given":"John"},{"family":"Archer","given":"Phil"}],"citation-key":"bowersNotHyperNot2005","DOI":"10.5281/zenodo.1176713","event-place":"Vancouver, BC, Canada","event-title":"Proceedings of the International Conference on New Interfaces for Musical Expression","issued":{"date-parts":[["2005"]]},"page":"5-10","publisher-place":"Vancouver, BC, Canada","title":"Not Hyper, Not Meta, Not Cyber but Infra-Instruments","type":"paper-conference","URL":"http://www.nime.org/proceedings/2005/nime2005_005.pdf"},{"id":"braaschTelematicMusicSystem2009","accessed":{"date-parts":[["2021",8,30]]},"author":[{"family":"Braasch","given":"Jonas"}],"citation-key":"braaschTelematicMusicSystem2009","container-title":"Contemporary Music Review","container-title-short":"Contemporary Music Review","DOI":"10.1080/07494460903422404","ISSN":"0749-4467, 1477-2256","issue":"4-5","issued":{"date-parts":[["2009",8]]},"language":"en","page":"421-432","source":"DOI.org (Crossref)","title":"The Telematic Music System: Affordances for a New Instrument to Shape the Music of Tomorrow","title-short":"The Telematic Music System","type":"article-journal","URL":"http://www.tandfonline.com/doi/abs/10.1080/07494460903422404","volume":"28"},{"id":"bradskiOpenCVLibrary2000","author":[{"family":"Bradski","given":"G."}],"citation-key":"bradskiOpenCVLibrary2000","container-title":"Dr. Dobb's Journal of Software Tools","issued":{"date-parts":[["2000"]]},"title":"The OpenCV Library","type":"article-journal"},{"id":"bradskiOpenCVLibrary2000a","author":[{"family":"Bradski","given":"Gary"}],"citation-key":"bradskiOpenCVLibrary2000a","container-title":"Dr. Dobb's Journal: Software Tools for the Professional Programmer","container-title-short":"Dr. Dobb's Journal: Software Tools for the Professional Programmer","ISSN":"1044-789X","issue":"11","issued":{"date-parts":[["2000"]]},"page":"120-123","publisher":"Miller Freeman Inc.","title":"The openCV library.","type":"article-journal","volume":"25"},{"id":"brandBeautyMatters2000","call-number":"HQ1219 .B348 2000","citation-key":"brandBeautyMatters2000","editor":[{"family":"Brand","given":"Peggy Zeglin"}],"event-place":"Bloomington","ISBN":"978-0-253-33726-9 978-0-253-21375-4","issued":{"date-parts":[["2000"]]},"number-of-pages":"329","publisher":"Indiana University Press","publisher-place":"Bloomington","source":"Library of Congress ISBN","title":"Beauty Matters","type":"book"},{"id":"bransonDamnedTheirDifference2002","author":[{"family":"Branson","given":"Jan"},{"family":"Miller","given":"Don"}],"call-number":"HV2380 .B685 2002","citation-key":"bransonDamnedTheirDifference2002","event-place":"Washington, D.C","ISBN":"978-1-56368-118-9 978-1-56368-121-9","issued":{"date-parts":[["2002"]]},"number-of-pages":"300","publisher":"Gallaudet","publisher-place":"Washington, D.C","source":"Library of Congress ISBN","title":"Damned for Their Difference: the Cultural Construction of Deaf People as \"Disabled\": A Sociological History","title-short":"Damned for their difference","type":"book"},{"id":"brentonEmbodiedDesignDance2014","accessed":{"date-parts":[["2023",11,13]]},"author":[{"family":"Brenton","given":"Harry"},{"family":"Kleinsmith","given":"Andrea"},{"family":"Gillies","given":"Marco"}],"citation-key":"brentonEmbodiedDesignDance2014","container-title":"Proceedings of the 2014 International Workshop on Movement and Computing","DOI":"10.1145/2617995.2618017","event-place":"Paris France","event-title":"MOCO '14: International Workshop on Movement and Computing","ISBN":"978-1-4503-2814-2","issued":{"date-parts":[["2014",6,16]]},"language":"en","page":"124-129","publisher":"ACM","publisher-place":"Paris France","source":"DOI.org (Crossref)","title":"Embodied Design of Dance Visualisations","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/2617995.2618017"},{"id":"brinkmannDoingInterviews2018","accessed":{"date-parts":[["2023",10,30]]},"author":[{"family":"Brinkmann","given":"Svend"},{"family":"Kvale","given":"Steinar"}],"citation-key":"brinkmannDoingInterviews2018","DOI":"10.4135/9781529716665","event-place":"1 Oliver’s Yard, 55 City Road London EC1Y 1SP","ISBN":"978-1-4739-1295-3 978-1-5297-1666-5","issued":{"date-parts":[["2018"]]},"publisher":"SAGE Publications Ltd","publisher-place":"1 Oliver’s Yard, 55 City Road London EC1Y 1SP","source":"DOI.org (Crossref)","title":"Doing Interviews","type":"book","URL":"https://methods.sagepub.com/book/doing-interviews-2e"},{"id":"britishdeafassociationPolicyCochleaImplants1994","author":[{"literal":"British Deaf Association"}],"citation-key":"britishdeafassociationPolicyCochleaImplants1994","event-place":"Carlisle","issued":{"date-parts":[["1994"]]},"publisher":"British Deaf Association","publisher-place":"Carlisle","title":"Policy on Cochlea Implants","type":"report"},{"id":"britishdeafnewsCochlearImplantsOralism1985","author":[{"literal":"British Deaf News"}],"citation-key":"britishdeafnewsCochlearImplantsOralism1985","container-title":"British Deaf News","edition":"November","event-place":"Carlisle","issued":{"date-parts":[["1985"]]},"page":"1","publisher-place":"Carlisle","title":"Cochlear Implants – Oralism’s Final Solution?","type":"article-newspaper"},{"id":"buckinghamshumMultimodalMatrixQuantitative2019","accessed":{"date-parts":[["2024",1,10]]},"author":[{"family":"Buckingham Shum","given":"Simon"},{"family":"Echeverria","given":"Vanessa"},{"family":"Martinez-Maldonado","given":"Roberto"}],"citation-key":"buckinghamshumMultimodalMatrixQuantitative2019","container-title":"Advances in Quantitative Ethnography","DOI":"10.1007/978-3-030-33232-7_3","editor":[{"family":"Eagan","given":"Brendan"},{"family":"Misfeldt","given":"Morten"},{"family":"Siebert-Evenstone","given":"Amanda"}],"event-place":"Cham","ISBN":"978-3-030-33231-0 978-3-030-33232-7","issued":{"date-parts":[["2019"]]},"language":"en","page":"26-40","publisher":"Springer International Publishing","publisher-place":"Cham","source":"DOI.org (Crossref)","title":"The Multimodal Matrix as a Quantitative Ethnography Methodology","type":"chapter","URL":"http://link.springer.com/10.1007/978-3-030-33232-7_3","volume":"1112"},{"id":"burgerMoCapToolboxMatlab2013","author":[{"family":"Burger","given":"Birgitta"},{"family":"Toiviainen","given":"Petri"}],"citation-key":"burgerMoCapToolboxMatlab2013","container-title":"Proceedings of the 10th sound and music computing conference","editor":[{"family":"Bresin","given":"Roberto"}],"event-place":"Stockholm, Sweden","issued":{"date-parts":[["2013"]]},"page":"172–178","publisher":"KTH Royal Institute of Technology","publisher-place":"Stockholm, Sweden","title":"MoCap Toolbox – A Matlab toolbox for computational analysis of movement data","type":"paper-conference"},{"id":"burkittPredictiveVisualMotion2020","abstract":"The fact that the transmission and processing of visual information in the brain takes time presents a problem for the accurate real-time localisation of a moving object. One way this problem might be solved is extrapolation: using an object’s past trajectory to predict its location in the present moment. Here, we investigate how a simulated in silico layered neural network might implement such extrapolation mechanisms, and how the necessary neural circuits might develop. We allowed an unsupervised hierarchical network of velocity-tuned neurons to learn its connectivity through spike-timing dependent plasticity. We show that the temporal contingencies between the different neural populations that are activated by an object as it moves causes the receptive fields of higher-level neurons to shift in the direction opposite to their preferred direction of motion. The result is that neural populations spontaneously start to represent moving objects as being further along their trajectory than where they were physically detected. Due to the inherent delays of neural transmission, this effectively compensates for (part of) those delays by bringing the represented position of a moving object closer to its instantaneous position in the world. Finally, we show that this model accurately predicts the pattern of perceptual mislocalisation that arises when human observers are required to localise a moving object relative to a flashed static object (the flash-lag effect). Significance Statement Our ability to track and respond to rapidly changing visual stimuli, such as a fast moving tennis ball, indicates that the brain is capable of extrapolating the trajectory of a moving object in order to predict its current position, despite the delays that result from neural transmission. Here we show how the neural circuits underlying this ability can be learned through spike-timing dependent synaptic plasticity, and that these circuits emerge spontaneously and without supervision. This demonstrates how the neural transmission delays can, in part, be compensated to implement the extrapolation mechanisms required to predict where a moving object is at the present moment.","author":[{"family":"Burkitt","given":"A."},{"family":"Hogendoorn","given":"Hinze"}],"citation-key":"burkittPredictiveVisualMotion2020","container-title":"bioRxiv : the preprint server for biology","container-title-short":"bioRxiv","DOI":"10.1101/2020.08.01.232595","issued":{"date-parts":[["2020"]]},"page":"null","title":"Predictive visual motion extrapolation emerges spontaneously and without supervision from a layered neural network with spike-timing-dependent plasticity","type":"article-journal","URL":"https://www.semanticscholar.org/paper/cf35b11b081ba9c26afb6433a3d204bd4cf96456","volume":"null"},{"id":"bursteinConciseIntroductionTonal2016","author":[{"family":"Burstein","given":"L. Poundie"},{"family":"Straus","given":"Joseph Nathan"}],"call-number":"MT50.B979 C66 2016","citation-key":"bursteinConciseIntroductionTonal2016","edition":"First edition","event-place":"New York","ISBN":"978-0-393-26476-0","issued":{"date-parts":[["2016"]]},"number-of-pages":"370","publisher":"W. W. Norton & Company","publisher-place":"New York","source":"Library of Congress ISBN","title":"Concise introduction to tonal harmony","type":"book"},{"id":"bursteinConciseIntroductionTonal2016a","author":[{"family":"Burstein","given":"L. Poundie"},{"family":"Straus","given":"Joseph Nathan"}],"citation-key":"bursteinConciseIntroductionTonal2016a","ISBN":"978-0-393-26476-0 978-0-393-60045-2 978-0-393-26477-7 978-0-393-26482-1","issued":{"date-parts":[["2016"]]},"language":"English","note":"OCLC: 912140490","source":"Open WorldCat","title":"Concise Introduction to Tonal Harmony","type":"book"},{"id":"butlerBodiesThatMatter2011","author":[{"family":"Butler","given":"Judith"}],"call-number":"HQ1190 .B88 2011","citation-key":"butlerBodiesThatMatter2011","collection-title":"Routledge classics","event-place":"Abingdon, Oxon ; New York, NY","ISBN":"978-0-415-61015-5 978-0-203-82827-4","issued":{"date-parts":[["2011"]]},"number-of-pages":"219","publisher":"Routledge","publisher-place":"Abingdon, Oxon ; New York, NY","source":"Library of Congress ISBN","title":"Bodies that matter: on the discursive limits of \"sex\"","title-short":"Bodies that matter","type":"book"},{"id":"butlerGenderTroubleFeminism2006","author":[{"family":"Butler","given":"Judith"}],"call-number":"HQ1154 .B88 2006","citation-key":"butlerGenderTroubleFeminism2006","collection-title":"Routledge classics","event-place":"New York","ISBN":"978-0-415-38955-6","issued":{"date-parts":[["2006"]]},"number-of-pages":"236","publisher":"Routledge","publisher-place":"New York","source":"Library of Congress ISBN","title":"Gender trouble: feminism and the subversion of identity","title-short":"Gender trouble","type":"book"},{"id":"buyensMusicMixingPreferences2014","author":[{"family":"Buyens","given":"Wim"},{"family":"Dijk","given":"Bas","non-dropping-particle":"van"},{"family":"Moonen","given":"Marc"},{"family":"Wouters","given":"Jan"}],"citation-key":"buyensMusicMixingPreferences2014","container-title":"International journal of audiology","container-title-short":"International journal of audiology","ISSN":"1499-2027","issue":"5","issued":{"date-parts":[["2014"]]},"page":"294-301","publisher":"Taylor & Francis","title":"Music Mixing Preferences of Cochlear Implant Recipients: A Pilot Study","type":"article-journal","volume":"53"},{"id":"byrneInternationalComparisonLong1994","author":[{"family":"Byrne","given":"Denis"},{"family":"Dillon","given":"Harvey"},{"family":"Tran","given":"Khanh"},{"family":"Arlinger","given":"Stig"},{"family":"Wilbraham","given":"Keith"},{"family":"Cox","given":"Robyn"},{"family":"Hagerman","given":"Bjorn"},{"family":"Hetu","given":"Raymond"},{"family":"Kei","given":"Joseph"},{"family":"Lui","given":"C"}],"citation-key":"byrneInternationalComparisonLong1994","container-title":"The Journal of the Acoustical Society of America","container-title-short":"The Journal of the Acoustical Society of America","ISSN":"0001-4966","issue":"4","issued":{"date-parts":[["1994"]]},"page":"2108-2120","publisher":"Acoustical Society of America","title":"An International Comparison of Long‐Term Average Speech Spectra","type":"article-journal","volume":"96"},{"id":"calicoArnoldSchoenbergSurvivor2014","abstract":"\"Joy H. Calico examines the cultural history of postwar Europe through the lens of the performance and reception of Arnold Schoenberg's A Survivor from Warsaw--a short but powerful work, she argues, capable of irritating every exposed nerve in postwar Europe. A twelve-tone piece in three languages about the Holocaust, it was written for an American audience by a Jewish composer whose oeuvre had been one of the Nazis' prime exemplars of entartete (degenerate) music. Both admired and reviled as a pioneer of dodecaphony, Schoenberg had immigrated to the United States and become an American citizen. This book investigates the meanings attached to the work as it circulated through Europe during the early Cold War in a kind of symbolic musical remigration, focusing on six case studies: West Germany, Austria, Norway, East Germany, Poland, and Czechoslovakia. Each case is unique, informed by individual geopolitical concerns, but this analysis also reveals common themes in anxieties about musical modernism, Holocaust memory and culpability, the coexistence of Jews and former Nazis, anti-Semitism, dislocation, and the presence of occupying forces on both sides of the Cold War divide\"--","author":[{"family":"Calico","given":"Joy Haslam"}],"call-number":"ML410.S283 C25 2014","citation-key":"calicoArnoldSchoenbergSurvivor2014","collection-number":"17","collection-title":"California studies in 20th-century music","event-place":"Berkeley","ISBN":"978-0-520-28186-8","issued":{"date-parts":[["2014"]]},"number-of-pages":"254","publisher":"University of California Press","publisher-place":"Berkeley","source":"Library of Congress ISBN","title":"Arnold Schoenberg's A Survivor from Warsaw in Postwar Europe","type":"book"},{"id":"calicoSchoenbergSymbolicRemigration2009","abstract":"Abstract\n            Musicologists have recently begun to study a crucial component in the reconstruction of European cultural life after World War II——the remigration of displaced musicians, either in person or (adopting Marita Krauss's notion of \"remigrating ideas\") in the form of their music. Because composers are most significantly present in the aural materiality of their music, and because Arnold Schoenberg's name was synonymous with modernism and its persecution across Europe, his symbolic postwar reappearance via performances of his music was a powerful and problematic form of remigration.\n            The case of Schoenberg's A Survivor from Warsaw and the former Nazi music critic Hans Schnoor serves as a representative example. Schnoor derided Schoenberg and Survivor in a newspaper column in 1956 using the rhetoric of National Socialist journalism as part of his campaign against federal funding of musical modernism via radio and festivals. When radio journalist Fred Prieberg took him to task for this on the air, Schnoor sued for defamation. A series of lawsuits ensued in which issues of denazification and the occupying Allied forces put a distinctly West German spin on the universal postwar European themes of anti-Semitism, the Holocaust, remigration, and modernism.","accessed":{"date-parts":[["2021",1,14]]},"author":[{"family":"Calico","given":"Joy H."}],"citation-key":"calicoSchoenbergSymbolicRemigration2009","container-title":"Journal of Musicology","DOI":"10.1525/jm.2009.26.1.17","ISSN":"0277-9269, 1533-8347","issue":"1","issued":{"date-parts":[["2009",1,1]]},"language":"en","page":"17-43","source":"DOI.org (Crossref)","title":"Schoenberg's Symbolic Remigration: A Survivor from Warsaw in Postwar West Germany","title-short":"Schoenberg's Symbolic Remigration","type":"article-journal","URL":"https://online.ucpress.edu/jm/article/26/1/17/46481/Schoenbergs-Symbolic-Remigration-A-Survivor-from","volume":"26"},{"id":"camurriDancerEyeMultiLayered2016","accessed":{"date-parts":[["2023",11,25]]},"author":[{"family":"Camurri","given":"Antonio"},{"family":"Volpe","given":"Gualtiero"},{"family":"Piana","given":"Stefano"},{"family":"Mancini","given":"Maurizio"},{"family":"Niewiadomski","given":"Radoslaw"},{"family":"Ferrari","given":"Nicola"},{"family":"Canepa","given":"Corrado"}],"citation-key":"camurriDancerEyeMultiLayered2016","container-title":"Proceedings of the 3rd International Symposium on Movement and Computing","DOI":"10.1145/2948910.2948927","event-place":"Thessaloniki GA Greece","event-title":"MOCO'16: 3rd International Symposium on Movement and Computing","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016",7,5]]},"language":"en","page":"1-7","publisher":"ACM","publisher-place":"Thessaloniki GA Greece","source":"DOI.org (Crossref)","title":"The Dancer in the Eye: Towards a Multi-Layered Computational Framework of Qualities in Movement","title-short":"The Dancer in the Eye","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/2948910.2948927"},{"id":"camurriDancerEyeMultilayered2016a","abstract":"This paper presents a conceptual framework for the analysis of expressive qualities of movement. Our perspective is to model an observer of a dance performance. The conceptual framework is made of four layers, ranging from the physical signals that sensors capture to the qualities that movement communicate (e.g., in terms of emotions). The framework aims to provide a conceptual background the development of computational systems can build upon, with a particular reference to systems analyzing a vocabulary of expressive movement qualities, and translating them to other sensory channels, such as the auditory modality. Such systems enable their users to \"listen to a choreography\" or to \"feel a ballet\", in a new kind of cross-modal mediated experience.","author":[{"family":"Camurri","given":"Antonio"},{"family":"Volpe","given":"Gualtiero"},{"family":"Piana","given":"Stefano"},{"family":"Mancini","given":"Maurizio"},{"family":"Niewiadomski","given":"Radoslaw"},{"family":"Ferrari","given":"Nicola"},{"family":"Canepa","given":"Corrado"}],"citation-key":"camurriDancerEyeMultilayered2016a","collection-title":"MOCO '16","container-title":"Proceedings of the 3rd international symposium on movement and computing","DOI":"10.1145/2948910.2948927","event-place":"Thessaloniki, GA, Greece","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016"]]},"number-of-pages":"7","publisher":"Association for Computing Machinery","publisher-place":"Thessaloniki, GA, Greece","title":"The dancer in the eye: Towards a multi-layered computational framework of qualities in movement","type":"paper-conference","URL":"https://doi.org/10.1145/2948910.2948927"},{"id":"camurriMultilayeredConceptualFramework2001","abstract":"The paper aims at (i) understanding expressiveness in gestures using computational modeling and (ii) exploit this understanding in artistic applications, where the enhancement of the expressiveness in interactive music/dance/video systems is a major goal. A multi-layered conceptual framework is presented and examples are given of its use in interactive art performances.","author":[{"family":"Camurri","given":"Antonio"},{"family":"De Poli","given":"Giovanni"},{"family":"Leman","given":"Marc"},{"family":"Volpe","given":"Gualtiero"}],"citation-key":"camurriMultilayeredConceptualFramework2001","container-title":"Proceedings of the International MOSART Workshop, November 2001","event-place":"Barcelona, Spain","issued":{"date-parts":[["2001",1,1]]},"publisher-place":"Barcelona, Spain","title":"A Multi-layered Conceptual Framework for Expressive Gesture Applications","type":"paper-conference"},{"id":"canceWhatInstrumentalityNew2009","abstract":"As far as music is concerned, instruments have always been part of a cultural ?landscape? (on technical, expressive and symbolic levels). The present contribution explores the changes brought about by the shift that occurred during the 20th century, from mechanical to digital instruments (also named ?virtual instruments?). First and foremost, a short recall of some historical steps of the technological developments that have renewed our relationship to sound, music, and instruments will be presented. Second, an analysis of different discourses and terminologies presently used in the domains of musicology and computer music will account for the evolution of the notion of instrumentality.","accessed":{"date-parts":[["2022",6,22]]},"author":[{"family":"Cance","given":"Caroline"},{"family":"Genevois","given":"Hugues"},{"family":"Dubois","given":"Danièle"}],"citation-key":"canceWhatInstrumentalityNew2009","DOI":"10.48550/ARXIV.0911.1288","issued":{"date-parts":[["2009"]]},"license":"arXiv.org perpetual, non-exclusive license","publisher":"arXiv","source":"DOI.org (Datacite)","title":"What is instrumentality in new digital msuical devices ? A contribution from cognitive linguistics and psychology","title-short":"What is instrumentality in new digital msuical devices ?","type":"article-journal","URL":"https://arxiv.org/abs/0911.1288","version":"1"},{"id":"candyConstraintsCreativityDigital2007","accessed":{"date-parts":[["2023",3,6]]},"author":[{"family":"Candy","given":"Linda"}],"citation-key":"candyConstraintsCreativityDigital2007","container-title":"Leonardo","container-title-short":"Leonardo","DOI":"10.1162/leon.2007.40.4.366","ISSN":"0024-094X, 1530-9282","issue":"4","issued":{"date-parts":[["2007",8]]},"language":"en","page":"366-367","source":"DOI.org (Crossref)","title":"Constraints and Creativity in the Digital Arts","type":"article-journal","URL":"https://direct.mit.edu/leon/article/40/4/366-367/97900","volume":"40"},{"id":"candyPracticeBasedResearch2006","author":[{"family":"Candy","given":"Linda"}],"citation-key":"candyPracticeBasedResearch2006","container-title":"CCS report","container-title-short":"CCS report","issue":"2","issued":{"date-parts":[["2006"]]},"page":"1-19","title":"Practice based research: A guide","type":"article-journal","volume":"1"},{"id":"caoOpenPoseRealtimeMultiperson2021","author":[{"family":"Cao","given":"Zhe"},{"family":"Hidalgo","given":"Gines"},{"family":"Simon","given":"Tomas"},{"family":"Wei","given":"Shih-En"},{"family":"Sheikh","given":"Yaser"}],"citation-key":"caoOpenPoseRealtimeMultiperson2021","container-title":"IEEE Transactions on Pattern Analysis and Machine Intelligence","DOI":"10.1109/TPAMI.2019.2929257","issue":"1","issued":{"date-parts":[["2021"]]},"page":"172-186","title":"OpenPose: Realtime multi-person 2D pose estimation using part affinity fields","type":"article-journal","volume":"43"},{"id":"caoRealtimeMultiperson2D2017","author":[{"family":"Cao","given":"Zhe"},{"family":"Simon","given":"Tomas"},{"family":"Wei","given":"Shih-En"},{"family":"Sheikh","given":"Yaser"}],"citation-key":"caoRealtimeMultiperson2D2017","container-title":"Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR)","issued":{"date-parts":[["2017",7]]},"title":"Realtime multi-person 2D pose estimation using part affinity fields","type":"paper-conference"},{"id":"captainvalorQueenBohemianRhapsody2010","accessed":{"date-parts":[["2021",1,10]]},"author":[{"literal":"CaptainValor"}],"citation-key":"captainvalorQueenBohemianRhapsody2010","container-title":"YouTube","issued":{"date-parts":[["2010",6,15]]},"title":"Queen - Bohemian Rhapsody - ASL Song","type":"webpage","URL":"https://www.youtube.com/watch?v=sjln9OMOw-0"},{"id":"carlsonDanceYourOwn2020","accessed":{"date-parts":[["2022",5,11]]},"author":[{"family":"Carlson","given":"Emily"},{"family":"Saari","given":"Pasi"},{"family":"Burger","given":"Birgitta"},{"family":"Toiviainen","given":"Petri"}],"citation-key":"carlsonDanceYourOwn2020","container-title":"Journal of New Music Research","container-title-short":"Journal of New Music Research","DOI":"10.1080/09298215.2020.1711778","ISSN":"0929-8215, 1744-5027","issue":"2","issued":{"date-parts":[["2020",3,14]]},"language":"en","page":"162-177","source":"DOI.org (Crossref)","title":"Dance to your own drum: Identification of musical genre and individual dancer from motion capture using machine learning","title-short":"Dance to your own drum","type":"article-journal","URL":"https://www.tandfonline.com/doi/full/10.1080/09298215.2020.1711778","volume":"49"},{"id":"carlsonDanceYourOwn2020a","accessed":{"date-parts":[["2022",5,11]]},"author":[{"family":"Carlson","given":"Emily"},{"family":"Saari","given":"Pasi"},{"family":"Burger","given":"Birgitta"},{"family":"Toiviainen","given":"Petri"}],"citation-key":"carlsonDanceYourOwn2020a","container-title":"Journal of New Music Research","container-title-short":"Journal of New Music Research","DOI":"10.1080/09298215.2020.1711778","ISSN":"0929-8215, 1744-5027","issue":"2","issued":{"date-parts":[["2020",3,14]]},"language":"en","page":"162-177","source":"DOI.org (Crossref)","title":"Dance to your own drum: Identification of musical genre and individual dancer from motion capture using machine learning","title-short":"Dance to your own drum","type":"article-journal","URL":"https://www.tandfonline.com/doi/full/10.1080/09298215.2020.1711778","volume":"49"},{"id":"carlsonPerceivingLightExploring2020","abstract":"The \"Light the Way\" project focuses on how intention can be transmitted through a media agent in a dance performance. We are interested in both how the agent may transmit its intention, how it may perceive the intention of humans, as well as how the human perceived and then expresses their intention to fulfill their gesture; particularly in relation to space. We describe a trajectory of interactive performance works that explore embodied cues as intention in space through four steps: 1) a fully autonomous and interactive sonic agent with its own behaviours, 2) a human-operated, non-autonomous or interactive visual agent in a controlled workshop, 3) a dancer-operated, non-autonomous or interactive visual agent in a live performance, and 4) an autonomous, non-interactive visual agent with its own behaviours in a controlled workshop. This work explores the balance between different forms of embodied connections that are developed between human and agent performers, and the ways that this work could be developed in the future to support more intuitive interactions.","author":[{"family":"Carlson","given":"Kristin"},{"family":"Corness","given":"Greg"}],"citation-key":"carlsonPerceivingLightExploring2020","collection-title":"MOCO '20","container-title":"Proceedings of the 7th international conference on movement and computing","DOI":"10.1145/3401956.3404241","event-place":"Jersey City/Virtual, NJ, USA","ISBN":"978-1-4503-7505-4","issued":{"date-parts":[["2020"]]},"number-of-pages":"4","publisher":"Association for Computing Machinery","publisher-place":"Jersey City/Virtual, NJ, USA","title":"Perceiving the light: Exploring embodied cues in interactive agents for dance","type":"paper-conference","URL":"https://doi.org/10.1145/3401956.3404241"},{"id":"carlsonShiftingSpacesUsing2019","abstract":"Choreography includes much improvisation and situated decision-making. These embodied abilities have inspired recent trends in HCI to design systems for nuanced experiences of movement [1]. We look to defamiliarization as one tactic that can enable new perspectives in the creative process during otherwise familiar experiences. We became interested in more deeply analyzing the interaction between mover and choreographic systems when we discovered limitations when attempting to choreograph collaboratively with a variety of existing systems. This led us to look more closely at how defamiliarization has been used in existing human-computer interaction projects, to understand provocative interaction in a different domain. We then applied the same analysis to choreographic technology projects to confirm the creative options enabled by this framework. This paper presents a framework for co-creative systems that proposes analytical components of: Disorientation, Open-Play, Closed-Exploration, and Balanced Creativity. These components focus on design for choreography yet they can be applied to many creative domains. To test our framework, we also present a variety of speculative designs that would engage with a choreographer in the sensory exploration, movement generation, and composition processes.","author":[{"family":"Carlson","given":"Kristin"},{"family":"Alaoui","given":"Sarah Fdili"},{"family":"Corness","given":"Greg"},{"family":"Schiphorst","given":"Thecla"}],"citation-key":"carlsonShiftingSpacesUsing2019","collection-title":"MOCO '19","container-title":"Proceedings of the 6th international conference on movement and computing","DOI":"10.1145/3347122.3347140","event-place":"Tempe, AZ, USA","ISBN":"978-1-4503-7654-9","issued":{"date-parts":[["2019"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Tempe, AZ, USA","title":"Shifting spaces: Using defamiliarization to design choreographic technologies that support co-creation","type":"paper-conference","URL":"https://doi.org/10.1145/3347122.3347140"},{"id":"carlsonSketchingMovementDesigning2015","abstract":"Tools for interaction with movement data are proliferating on the consumer market, demonstrating the increased valuation of whole-body movement in product and interaction design. However, few of these tools support creative authoring on user-friendly platforms. We present a system titled 'iDanceForms' (iDF) as a mobile sketching tool for designing creative movement in-situ. Sketching is a unique and often under-valued process in creative design, enabling the user to quickly prototype and evaluate ideas. iDF is designed around the affordances of mobile tablets, and is based on an animation platform to easily segment movement data as keyframes. The design around keyframe segmentation enables multiple user-friendly editing options as well as camera capture functions to bridge embodied exploration with digital editing. iDF is a creativity support tool that engages with choreographers' creative movement process by design: it was developed based on the epistemology of choreographic process. This paper presents the design of iDF and evaluations from two studies that explore professional and novice choreographer's creative experience with the application.","author":[{"family":"Carlson","given":"Kristin"},{"family":"Tsang","given":"Herbert H."},{"family":"Phillips","given":"Jordon"},{"family":"Schiphorst","given":"Thecla"},{"family":"Calvert","given":"Tom"}],"citation-key":"carlsonSketchingMovementDesigning2015","collection-title":"MOCO '15","container-title":"Proceedings of the 2nd international workshop on movement and computing","DOI":"10.1145/2790994.2791007","event-place":"Vancouver, British Columbia, Canada","ISBN":"978-1-4503-3457-0","issued":{"date-parts":[["2015"]]},"number-of-pages":"8","page":"68–75","publisher":"Association for Computing Machinery","publisher-place":"Vancouver, British Columbia, Canada","title":"Sketching movement: Designing creativity tools for in-Situ, whole-body authorship","type":"paper-conference","URL":"https://doi.org/10.1145/2790994.2791007"},{"id":"carlyonTemporalPitchProcessing2008","author":[{"family":"Carlyon","given":"Robert P."},{"family":"Kong","given":"Ying‐Yee"},{"family":"Lynch","given":"Cathy"},{"family":"Deeks","given":"John"}],"citation-key":"carlyonTemporalPitchProcessing2008","container-title":"The Journal of the Acoustical Society of America","container-title-short":"The Journal of the Acoustical Society of America","ISSN":"0001-4966","issue":"5","issued":{"date-parts":[["2008"]]},"page":"3054-3054","publisher":"Acoustical Society of America","title":"Temporal Pitch Processing by Cochlear Implant Users","type":"article-journal","volume":"123"},{"id":"carotFundamentalsPrinciplesMusical2009","abstract":"The idea of playing livemusic with someone abroad represents a major challenge for musicians and sound engineers likewise. Cognitive, technical and purely musical aspects make high demands on a network music performance that should fulfill conditions of a realistic rehearsing scenarios in the same room. In turn the idea of a network music performance has generally been considered as an impracticable application. However, a precise and comprehensive analysis has so far not been published, which equally issue_covers technical, cognitive aspects and their interdependencies equally. In order to give a final and valid statement about the feasibility of distributed real time music we take any of such relevant aspect into consideration and explain it accordingly to the reader. Finally we conclude that in recent wide area networks remote music sessions are possible assuming an awareness of latency conditions and appropriate interaction categories.","accessed":{"date-parts":[["2022",2,6]]},"author":[{"family":"Carôt","given":"Alexander"},{"family":"Werner","given":"Christian"}],"citation-key":"carotFundamentalsPrinciplesMusical2009","container-title":"Journal of Science and Technology of the Arts","DOI":"10.7559/CITARJ.V1I1.6","issued":{"date-parts":[["2009",1,1]]},"language":"en","license":"Creative Commons Attribution 4.0 International","page":"26-37","publisher":"Journal of Science and Technology of the Arts","source":"DOI.org (Datacite)","title":"Fundamentals and principles of musical telepresence","type":"article-journal","URL":"https://revistas.ucp.pt/index.php/jsta/article/view/6956"},{"id":"carrascalMultitouchInterfaceAudio2011","abstract":"Audio mixing is the adjustment of relative volumes, panning and other parameters corresponding to different soundsources, in order to create a technically and aestheticallyadequate sound sum. To do this, audio engineers employ\"panpots\" and faders, the standard controls in audio mixers. The design of such devices has remained practically unchanged for decades since their introduction. At the time,no usability studies seem to have been conducted on suchdevices, so one could question if they are really optimizedfor the task they are meant for.This paper proposes a new set of controls that might beused to simplify and/or improve the performance of audiomixing tasks, taking into account the spatial characteristicsof modern mixing technologies such as surround and 3Daudio and making use of multitouch interface technologies.A preliminary usability test has shown promising results.","accessed":{"date-parts":[["2024",1,25]]},"author":[{"family":"Carrascal","given":"Juan P."},{"family":"Jordà","given":"Sergi"}],"citation-key":"carrascalMultitouchInterfaceAudio2011","DOI":"10.5281/ZENODO.1177983","issued":{"date-parts":[["2011",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"Multitouch Interface For Audio Mixing","type":"article-journal","URL":"https://zenodo.org/record/1177983"},{"id":"carterRoutledgeDanceStudies2010","call-number":"GV1594 .R68 2010","citation-key":"carterRoutledgeDanceStudies2010","edition":"2nd ed","editor":[{"family":"Carter","given":"Alexandra"},{"family":"O'Shea","given":"Janet"}],"event-place":"London ; New York","ISBN":"978-0-415-48599-9 978-0-415-48598-2 978-0-203-86098-4","issued":{"date-parts":[["2010"]]},"note":"OCLC: ocn427645007","number-of-pages":"405","publisher":"Routledge","publisher-place":"London ; New York","source":"Library of Congress ISBN","title":"The Routledge dance studies reader","type":"book"},{"id":"casarrubeaTpatternAnalysisStudy2015","abstract":"A basic tenet in the realm of modern behavioral sciences is that behavior consists of patterns in time. For this reason, investigations of behavior deal with sequences that are not easily perceivable by the unaided observer. This problem calls for improved means of detection, data handling and analysis. This review focuses on the analysis of the temporal structure of behavior carried out by means of a multivariate approach known as T-pattern analysis. Using this technique, recurring sequences of behavioral events, usually hard to detect, can be unveiled and carefully described. T-pattern analysis has been successfully applied in the study of various aspects of human or animal behavior such as behavioral modifications in neuro-psychiatric diseases, route-tracing stereotypy in mice, interaction between human subjects and animal or artificial agents, hormonal–behavioral interactions, patterns of behavior associated with emesis and, in our laboratories, exploration and anxiety-related behaviors in rodents. After describing the theory and concepts of T-pattern analysis, this review will focus on the application of the analysis to the study of the temporal characteristics of behavior in different species from rodents to human beings. This work could represent a useful background for researchers who intend to employ such a refined multivariate approach to the study of behavior.","accessed":{"date-parts":[["2024",11,29]]},"author":[{"family":"Casarrubea","given":"M."},{"family":"Jonsson","given":"G. K."},{"family":"Faulisi","given":"F."},{"family":"Sorbera","given":"F."},{"family":"Di Giovanni","given":"G."},{"family":"Benigno","given":"A."},{"family":"Crescimanno","given":"G."},{"family":"Magnusson","given":"M. S."}],"citation-key":"casarrubeaTpatternAnalysisStudy2015","container-title":"Journal of Neuroscience Methods","container-title-short":"Journal of Neuroscience Methods","DOI":"10.1016/j.jneumeth.2014.09.024","ISSN":"0165-0270","issued":{"date-parts":[["2015",1,15]]},"page":"34-46","source":"ScienceDirect","title":"T-pattern analysis for the study of temporal structure of animal and human behavior: A comprehensive review","title-short":"T-pattern analysis for the study of temporal structure of animal and human behavior","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0165027014003495","volume":"239"},{"id":"cascheraMultimodalInteractionSystems2007","abstract":"Multimodal interaction systems combine visual information (involving images, text, sketches and so on) with voice, gestures and other modalities to provide flexible and powerful dialogue approaches, enabling users to choose one or more of the multiple interaction modalities. They break down the barriers in adopting mobile devices for value-added services and the use of integrated multiple input modes enables users to benefit from the natural approach used in human communication. This paper deals with the main features of multimodal interaction and systems, starting from the definition of visual language given in Bottoni et al. (1995) and extending it to multimodality. Modal/multimodal message, interpretation and materialisation functions and multimodal sentence are defined. This paper introduces and formally defines the different classes of cooperation between different modes, introducing the time relationships among the involved modalities and the relationships between chunks of information connected with these modalities.","accessed":{"date-parts":[["2023",5,2]]},"author":[{"family":"Caschera","given":"Maria Chiara"},{"family":"Ferri","given":"Fernando"},{"family":"Grifoni","given":"Patrizia"}],"citation-key":"cascheraMultimodalInteractionSystems2007","container-title":"International Journal of Web and Grid Services","DOI":"10.1504/IJWGS.2007.012638","ISSN":"1741-1106","issue":"1","issued":{"date-parts":[["2007",1,1]]},"page":"82-99","publisher":"Inderscience Publishers","title":"Multimodal interaction systems: information and time features","type":"article-journal","URL":"https://www.inderscienceonline.com/doi/abs/10.1504/IJWGS.2007.012638","volume":"3"},{"id":"casperAbletonTutorialMaking2012","accessed":{"date-parts":[["2022",11,26]]},"author":[{"family":"Casper","given":"Joshua"}],"citation-key":"casperAbletonTutorialMaking2012","container-title":"Joshua Casper","issued":{"date-parts":[["2012",1,23]]},"title":"Ableton Tutorial: Making Custom Effects: Fade to Grey","type":"webpage","URL":"https://www.joshuacasper.com/ableton-tutorials/ableton-tutorial-making-custom-effects-fade-to-grey/"},{"id":"cavanaghFlashGrabEffect2012","abstract":"S2 TL;DR: A new \"flash grab\" effect in the family of motion-induced position shifts is revealed, which most resembles the flash drag effect, but differs from this in the following ways: it has a different temporal profile, it requires attention, and it is about 10 times larger.","author":[{"family":"Cavanagh","given":"P."},{"family":"Anstis","given":"S."}],"citation-key":"cavanaghFlashGrabEffect2012","container-title":"Vision Research","DOI":"10.1016/j.visres.2013.07.007","issued":{"date-parts":[["2012"]]},"note":"QID: Q27303047","page":"8-20","PMID":"23872166","title":"The flash grab effect","type":"article-journal","URL":"https://www.semanticscholar.org/paper/5aa83b20464bf5dc2e5b6d2761438cbe9be18413","volume":"91"},{"id":"cavdirFeltSoundShared2020","abstract":"We present a musical interface specifically designed for inclusive performance that offers a shared experience for both individuals who are hard of hearing as well as those who are not. This interface borrows gestures (with or without their overt meaning) from American Sign Language (ASL), rendered using low-frequency sounds that can be felt by everyone in the performance. The Hard of Hearing cannot experience the sound in the same way. Instead, they are able to physically experience the vibrations, nuances, contours, as well as their correspondences with the hand gestures. Those who are not hard of hearing can experience the sound, but also feel it just the same, with the knowledge that the same physical vibrations are shared by everyone. The employment of sign language adds another aesthetic dimension to the instrument-a nuanced borrowing of a functional communication medium for an artistic end.","author":[{"family":"Cavdir","given":"Doga"},{"family":"Wang","given":"Ge"}],"citation-key":"cavdirFeltSoundShared2020","issued":{"date-parts":[["2020",7,21]]},"title":"Felt Sound: A Shared Musical Experience for the Deaf and Hard of Hearing","type":"paper-conference"},{"id":"cavdirPerformersUseSpace2022","abstract":"Movement-based musical interfaces support performers’ music and movement expressions by drawing from expertise and creative practices of both disciplines. In this work, we qualitatively and quantitatively analyze the movement interaction of participants with Bodyharp, a movement-based musical instrument. This wearable instrument offers musical affordances that allow performers to extend beyond small gestural spaces. Its wearable design encourages the performers to move while creating music and to express while using their bodies. Data was collected from twenty participants’ interactions, reflections, and compositions with Bodyharp. Video recordings of the experiment were annotated and qualitatively analyzed to reveal which performed gestures directly contribute to sound production and modification and which gestures accompany these musical actions. For a subset of participants, Musical Gestures Toolbox was used to further quantify the gestures. Using the Laban Movement Analysis framework, we observed participants’ use of space and body in their interaction with a movement-based musical instrument and how their backgrounds in music or movement (based on participants’ self-reported experiences) influenced the interaction. Our results offer design practices for creating new interactions at the intersection of music and dance.","author":[{"family":"Cavdir","given":"Doga"},{"family":"Dahl","given":"Sofia"}],"citation-key":"cavdirPerformersUseSpace2022","collection-title":"MOCO '22","container-title":"Proceedings of the 8th international conference on movement and computing","DOI":"10.1145/3537972.3537976","event-place":"Chicago, IL, USA","ISBN":"978-1-4503-8716-3","issued":{"date-parts":[["2022"]]},"number-of-pages":"12","publisher":"Association for Computing Machinery","publisher-place":"Chicago, IL, USA","title":"Performers’ use of space and body in movement interaction with a movement-based digital musical instrument","type":"paper-conference","URL":"https://doi.org/10.1145/3537972.3537976"},{"id":"cazuriagaPerceptiveEvaluationSound2018","accessed":{"date-parts":[["2021",11,30]]},"author":[{"family":"Cazuriaga","given":"Jorgos Estrella"},{"family":"Plogsties","given":"Jan"},{"family":"Neumayer","given":"Maximilian"},{"family":"Bruemmerstedt","given":"Jan"}],"citation-key":"cazuriagaPerceptiveEvaluationSound2018","container-title":"I  Fortschritte der Akustik - DAGA 2018","event-place":"Munich","event-title":"44. Deutsche Jahrestagung für Akustik","issued":{"date-parts":[["2018",3,21]]},"publisher":"Deutsche Gesellschaft für Akustik e.V.","publisher-place":"Munich","title":"Perceptive Evaluation of Sound Field Rotation Methods in the Context of Dynamic Binaural Rendering of Ambisonics Signals","type":"paper-conference","URL":"https://pub.dega-akustik.de/DAGA_2018/data/articles/000204.pdf"},{"id":"chakhtounaModelingSpeechEmotion2024","accessed":{"date-parts":[["2024",10,11]]},"author":[{"family":"Chakhtouna","given":"Adil"},{"family":"Sekkate","given":"Sara"},{"family":"Adib","given":"Abdellah"}],"citation-key":"chakhtounaModelingSpeechEmotion2024","container-title":"Procedia Computer Science","container-title-short":"Procedia Computer Science","DOI":"10.1016/j.procs.2024.05.050","ISSN":"18770509","issued":{"date-parts":[["2024"]]},"language":"en","page":"428-435","source":"DOI.org (Crossref)","title":"Modeling Speech Emotion Recognition via ImageBind representations","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S1877050924010664","volume":"236"},{"id":"chakrabartiMotionEstimationVideo2015","author":[{"family":"Chakrabarti","given":"Indrajit"},{"family":"Batta","given":"Kota Naga Srinivasarao"},{"family":"Chatterjee","given":"Sumit Kumar"}],"citation-key":"chakrabartiMotionEstimationVideo2015","event-place":"New York, NY","ISBN":"978-3-319-14375-0","issued":{"date-parts":[["2015"]]},"publisher":"Springer Berlin Heidelberg","publisher-place":"New York, NY","source":"Library of Congress ISBN","title":"Motion estimation for video coding","type":"book"},{"id":"chakrabartiMotionEstimationVideo2015a","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Chakrabarti","given":"Indrajit"},{"family":"Batta","given":"Kota Naga Srinivasarao"},{"family":"Chatterjee","given":"Sumit Kumar"}],"citation-key":"chakrabartiMotionEstimationVideo2015a","collection-title":"Studies in Computational Intelligence","DOI":"10.1007/978-3-319-14376-7","event-place":"Cham","ISBN":"978-3-319-14375-0 978-3-319-14376-7","issued":{"date-parts":[["2015"]]},"language":"en","license":"https://www.springernature.com/gp/researchers/text-and-data-mining","publisher":"Springer International Publishing","publisher-place":"Cham","source":"DOI.org (Crossref)","title":"Motion Estimation for Video Coding: Efficient Algorithms and Architectures","title-short":"Motion Estimation for Video Coding","type":"book","URL":"https://link.springer.com/10.1007/978-3-319-14376-7","volume":"590"},{"id":"changMSSincResNetJointLearning2021","abstract":"In this study, we proposed a new end-to-end convolutional neural network, called MS-SincResNet, for music genre classification. MS-SincResNet appends 1D multi-scale SincNet (MS-SincNet) to 2D ResNet as the first convolutional layer in an attempt to jointly learn 1D kernels and 2D kernels during the training stage. First, an input music signal is divided into a number of fixed-duration (3 seconds in this study) music clips, and the raw waveform of each music clip is fed into 1D MS-SincNet filter learning module to obtain three-channel 2D representations. The learned representations carry rich timbral, harmonic, and percussive characteristics comparing with spectrograms, harmonic spectrograms, percussive spectrograms and Mel-spectrograms. ResNet is then used to extract discriminative embeddings from these 2D representations. The spatial pyramid pooling (SPP) module is further used to enhance the feature discriminability, in terms of both time and frequency aspects, to obtain the classification label of each music clip. Finally, the voting strategy is applied to summarize the classification results from all 3-second music clips. In our experimental results, we demonstrate that the proposed MS-SincResNet outperforms the baseline SincNet and many well-known hand-crafted features. Considering individual 2D representation, MS-SincResNet also yields competitive results with the state-of-the-art methods on the GTZAN dataset and the ISMIR2004 dataset. The code is available at https://github.com/PeiChunChang/MS-SincResNet.","author":[{"family":"Chang","given":"Pei-Chun"},{"family":"Chen","given":"Yong-Sheng"},{"family":"Lee","given":"Chang-Hsing"}],"citation-key":"changMSSincResNetJointLearning2021","collection-title":"Icmr '21","container-title":"Proceedings of the 2021 international conference on multimedia retrieval","DOI":"10.1145/3460426.3463619","event-place":"Taipei, Taiwan","ISBN":"978-1-4503-8463-6","issued":{"date-parts":[["2021"]]},"number-of-pages":"8","page":"29–36","publisher":"Association for Computing Machinery","publisher-place":"Taipei, Taiwan","title":"MS-SincResNet: Joint learning of 1D and 2D kernels using multi-scale SincNet and ResNet for music genre classification","type":"paper-conference","URL":"https://doi.org/10.1145/3460426.3463619"},{"id":"chasinHearingAidsMusic2004","author":[{"family":"Chasin","given":"Marshall"},{"family":"Russo","given":"Frank A."}],"citation-key":"chasinHearingAidsMusic2004","container-title":"Trends in Amplification","container-title-short":"Trends in Amplification","ISSN":"1084-7138","issue":"2","issued":{"date-parts":[["2004"]]},"page":"35-47","publisher":"SAGE Publications Sage CA: Los Angeles, CA","title":"Hearing Aids and Music","type":"article-journal","volume":"8"},{"id":"chasinHearingAidsMusicians2006","author":[{"family":"Chasin","given":"Marshall"}],"citation-key":"chasinHearingAidsMusicians2006","container-title":"Hearing Review","container-title-short":"Hearing Review","ISSN":"1074-5734","issue":"3","issued":{"date-parts":[["2006"]]},"page":"11 - 16","publisher":"MWC/ALLIED HEALTHCARE GROUP PUBLICATION","title":"Hearing Aids for Musicians","type":"article-journal","volume":"13"},{"id":"chasinMusicHearingAids2012","author":[{"family":"Chasin","given":"Marshall"}],"citation-key":"chasinMusicHearingAids2012","container-title":"Trends in Amplification","container-title-short":"Trends in Amplification","ISSN":"1084-7138","issue":"3","issued":{"date-parts":[["2012"]]},"page":"136-139","publisher":"Sage Publications Sage CA: Los Angeles, CA","title":"Music and Hearing Aids—An introduction","type":"article-journal","volume":"16"},{"id":"chauTimbreFeaturesMusic2014","author":[{"family":"Chau","given":"Chuck-jee"},{"family":"Wu","given":"Bin"},{"family":"Horner","given":"Andrew"}],"citation-key":"chauTimbreFeaturesMusic2014","event-title":"ICMC","issued":{"date-parts":[["2014"]]},"title":"Timbre Features and Music Emotion in Plucked String, Mallet Percussion, and Keyboard Tones","type":"paper-conference"},{"id":"chenUTDMHADMultimodalDataset2015","accessed":{"date-parts":[["2024",9,3]]},"author":[{"family":"Chen","given":"Chen"},{"family":"Jafari","given":"Roozbeh"},{"family":"Kehtarnavaz","given":"Nasser"}],"citation-key":"chenUTDMHADMultimodalDataset2015","container-title":"2015 IEEE International Conference on Image Processing (ICIP)","DOI":"10.1109/ICIP.2015.7350781","event-place":"Quebec City, QC, Canada","event-title":"2015 IEEE International Conference on Image Processing (ICIP)","ISBN":"978-1-4799-8339-1","issued":{"date-parts":[["2015",9]]},"page":"168-172","publisher":"IEEE","publisher-place":"Quebec City, QC, Canada","source":"DOI.org (Crossref)","title":"UTD-MHAD: A multimodal dataset for human action recognition utilizing a depth camera and a wearable inertial sensor","title-short":"UTD-MHAD","type":"paper-conference","URL":"http://ieeexplore.ieee.org/document/7350781/"},{"id":"christodoulouMultimodalMusicDatasets2024","abstract":"Abstract\n            The term “multimodal music dataset” is often used to describe music-related datasets that represent music as a multimedia art form and multimodal experience. However, the term “multimodality” is often used differently in disciplines such as musicology, music psychology, and music technology. This paper proposes a definition of multimodality that works across different music disciplines. Many challenges are related to constructing, evaluating, and using multimodal music datasets. We provide a task-based categorization of multimodal datasets and suggest guidelines for their development. Diverse data pre-processing methods are illuminated, highlighting their contributions to transparent and reproducible music analysis. Additionally, evaluation metrics, methods, and benchmarks tailored for multimodal music processing tasks are scrutinized, empowering researchers to make informed decisions and facilitating cross-study comparisons.","accessed":{"date-parts":[["2024",9,3]]},"author":[{"family":"Christodoulou","given":"Anna-Maria"},{"family":"Lartillot","given":"Olivier"},{"family":"Jensenius","given":"Alexander Refsum"}],"citation-key":"christodoulouMultimodalMusicDatasets2024","container-title":"International Journal of Multimedia Information Retrieval","container-title-short":"Int J Multimed Info Retr","DOI":"10.1007/s13735-024-00344-6","ISSN":"2192-6611, 2192-662X","issue":"3","issued":{"date-parts":[["2024",9]]},"language":"en","page":"37","source":"DOI.org (Crossref)","title":"Multimodal music datasets? Challenges and future goals in music processing","title-short":"Multimodal music datasets?","type":"article-journal","URL":"https://link.springer.com/10.1007/s13735-024-00344-6","volume":"13"},{"id":"churchInverseDocumentFrequency1999","abstract":"Low frequency words tend to be rich in content, and vice versa. But not all equally frequent words are equally meaningful. We will use inverse document frequency (IDF), a quantity borrowed from Information Retrieval, to distinguish words like somewhat and boycott. Both somewhat and boycott appeared approximately 1000 times in a corpus of 1989 Associated Press articles, but boycott is a better keyword because its IDF is farther from what would be expected by chance (Poisson).","author":[{"family":"Church","given":"K."},{"family":"Gale","given":"W."}],"citation-key":"churchInverseDocumentFrequency1999","container-title":"Natural Language Processing Using Very Large Corpora","DOI":"10.1007/978-94-017-2390-9_18","editor":[{"family":"Armstrong","given":"Susan"},{"family":"Church","given":"Kenneth"},{"family":"Isabelle","given":"Pierre"},{"family":"Manzi","given":"Sandra"},{"family":"Tzoukermann","given":"Evelyne"},{"family":"Yarowsky","given":"David"}],"event-place":"Dordrecht","ISBN":"978-94-017-2390-9","issued":{"date-parts":[["1999"]]},"page":"283-295","publisher":"Springer Netherlands","publisher-place":"Dordrecht","title":"Inverse Document Frequency (IDF): A Measure of Deviations from Poisson","type":"chapter","URL":"https://doi.org/10.1007/978-94-017-2390-9_18"},{"id":"churchPreviewHeadspaceSage2006","accessed":{"date-parts":[["2021",1,19]]},"author":[{"family":"Church","given":"Michael"}],"citation-key":"churchPreviewHeadspaceSage2006","container-title":"Independent","issued":{"date-parts":[["2006",2,7]]},"title":"Preview: Headspace, The Sage, Gateshead","type":"webpage","URL":"https://www.independent.co.uk/arts-entertainment/music/features/preview-headspace-the-sage-gateshead-6109732.html"},{"id":"cicadaNoiseCarriers2011","accessed":{"date-parts":[["2021",1,27]]},"author":[{"literal":"Cicada"}],"citation-key":"cicadaNoiseCarriers2011","container-title":"Cicada","issued":{"date-parts":[["2011"]]},"title":"Noise Carriers","type":"webpage","URL":"https://www.cicada.org.au/index.php/hidden/music-and-implants/404-noise-carriers"},{"id":"ciolfifeliceHowChoreographersCraft2016","abstract":"Choreographers rarely have access to interactive tools that are designed specifically to support their creative process. In order to design for such a technology, we interviewed six contemporary choreographers about their creative practice. We found that even though each process is unique, choreographers represent their ideas by applying a set of operations onto choreographic objects. Throughout different creative phases, choreographers compose by shifting among various degrees of specificity and vary their focal points from dancers to stage, to interaction, to the whole piece. Based on our findings, we present a framework for articulating the higher-level patterns that emerge from these complex and idiosyncratic processes. We then articulate the resulting implications for the design of interactive tools to support the choreographic practice.","author":[{"family":"Ciolfi Felice","given":"Marianela"},{"family":"Alaoui","given":"Sarah Fdili"},{"family":"Mackay","given":"Wendy E."}],"citation-key":"ciolfifeliceHowChoreographersCraft2016","collection-title":"MOCO '16","container-title":"Proceedings of the 3rd international symposium on movement and computing","DOI":"10.1145/2948910.2948941","event-place":"Thessaloniki, GA, Greece","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Thessaloniki, GA, Greece","title":"How do choreographers craft dance? Designing for a choreographer-technology partnership","type":"paper-conference","URL":"https://doi.org/10.1145/2948910.2948941"},{"id":"clarkIntensitiesOrchestralInstrument1965","author":[{"family":"Clark","given":"Melville"},{"family":"Luce","given":"David"}],"citation-key":"clarkIntensitiesOrchestralInstrument1965","container-title":"Journal of the Audio Engineering Society","container-title-short":"Journal of the Audio Engineering Society","issue":"2","issued":{"date-parts":[["1965"]]},"page":"151-157","publisher":"Audio Engineering Society","title":"Intensities of Orchestral Instrument Scales Played at Prescribed Dynamic Markings","type":"article-journal","volume":"13"},{"id":"clarkUsesAbusesHearing1981","author":[{"family":"Clark","given":"John"}],"citation-key":"clarkUsesAbusesHearing1981","container-title":"ASHA","container-title-short":"ASHA","issued":{"date-parts":[["1981",8,1]]},"page":"493-500","title":"Uses and Abuses of Hearing Loss Classification","type":"article-journal","volume":"23"},{"id":"clasonHealthyHearingConversation2017","accessed":{"date-parts":[["2021",1,28]]},"author":[{"family":"Clason","given":"Debbie"}],"citation-key":"clasonHealthyHearingConversation2017","container-title":"Healthy Hearing","issued":{"date-parts":[["2017",9,22]]},"title":"Healthy Hearing conversation | Mandy Harvey uses music to create community","type":"webpage","URL":"https://www.healthyhearing.com/report/52791-Healthy-hearing-conversation-mandy-harvey-uses-music-to-create-community"},{"id":"cookAssistiveTechnologiesPrinciples1995","author":[{"family":"Cook","given":"Albert M."},{"family":"Hussey","given":"Susan"}],"citation-key":"cookAssistiveTechnologiesPrinciples1995","edition":"First Edition","event-place":"St. Louis MO","issued":{"date-parts":[["1995"]]},"publisher":"Mosby","publisher-place":"St. Louis MO","title":"Assistive Technologies: Principles and Practice","type":"book"},{"id":"cookAssistiveTechnologiesPrinciples2015","author":[{"family":"Cook","given":"Albert M."},{"family":"Polgar","given":"Jan Miller"}],"call-number":"RM698 .C66 2015","citation-key":"cookAssistiveTechnologiesPrinciples2015","edition":"Fourth edition","event-place":"St. Louis, Missouri","ISBN":"978-0-323-09631-7","issued":{"date-parts":[["2015"]]},"number-of-pages":"480","publisher":"Elsevier/Mosby","publisher-place":"St. Louis, Missouri","source":"Library of Congress ISBN","title":"Assistive Technologies: Principles and Practice","title-short":"Assistive technologies","type":"book"},{"id":"cookReDesigningPrinciplesComputer2009","abstract":"Description","accessed":{"date-parts":[["2022",9,21]]},"author":[{"family":"Cook","given":"Perry R."}],"citation-key":"cookReDesigningPrinciplesComputer2009","DOI":"10.5281/ZENODO.1177493","issued":{"date-parts":[["2009",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"Re-Designing Principles For Computer Music Controllers : A Case Study Of Squeezevox Maggie","title-short":"Re-Designing Principles For Computer Music Controllers","type":"article-journal","URL":"https://zenodo.org/record/1177493"},{"id":"copelandMerceCunninghamModernizing2004","author":[{"family":"Copeland","given":"Roger"}],"call-number":"GV1785.C85 C66 2004","citation-key":"copelandMerceCunninghamModernizing2004","event-place":"New York","ISBN":"978-0-415-96575-0","issued":{"date-parts":[["2004"]]},"note":"OCLC: ocm54051440","number-of-pages":"304","publisher":"Routledge","publisher-place":"New York","source":"Library of Congress ISBN","title":"Merce Cunningham: the modernizing of modern dance","title-short":"Merce Cunningham","type":"book"},{"id":"coreyAudioProductionCritical2017","author":[{"family":"Corey","given":"Jason"},{"family":"Benson","given":"David H."}],"call-number":"TA365 .C678 2017","citation-key":"coreyAudioProductionCritical2017","collection-title":"Audio Engineering Society presents","edition":"Second edition","event-place":"New York","ISBN":"978-1-138-84594-7","issued":{"date-parts":[["2017"]]},"number-of-pages":"159","publisher":"Routledge, Taylor & Francis Group","publisher-place":"New York","source":"Library of Congress ISBN","title":"Audio Production and Critical Listening: Technical Ear Training","title-short":"Audio production and critical listening","type":"book"},{"id":"cornessPhysicalTimeModel2020","abstract":"Possibilities for cross disciplinary interactive performance continue to grow as new tools are developed and adapted. Yet, the qualitative aspects of cross disciplinary interaction has not advanced at the same rate. We suggest that new models for understanding gesture in different media will support the development of nuanced interaction for interactive performance. We have explored this premise by considering models for generating musical rhythmic gestures that enable implicit interaction between the gestures of a dancer and the generated music. We create a model that focuses on understanding rhythms as dynamic gestures that flow in, around, or out of goal points. Goal points can be layered and quantized to a meter, providing the rhythmic structure expected in music, while the figurations enable the generated rhythms to flow with the performer responding to the more qualitative aspects of performer. We have made a simple implementation of this model to test the conceptual and technical viability. We discuss both the model and our implementations suggesting that the model, even with a simple implementation, affords a unique ability to reflect the dynamic flow of gestures in movement paradigms while still providing a sense of structured time indicative of a musical paradigm.","author":[{"family":"Corness","given":"Greg"},{"family":"Carlson","given":"Kristin"}],"citation-key":"cornessPhysicalTimeModel2020","collection-title":"MOCO '20","container-title":"Proceedings of the 7th international conference on movement and computing","DOI":"10.1145/3401956.3404236","event-place":"Jersey City/Virtual, NJ, USA","ISBN":"978-1-4503-7505-4","issued":{"date-parts":[["2020"]]},"number-of-pages":"6","publisher":"Association for Computing Machinery","publisher-place":"Jersey City/Virtual, NJ, USA","title":"Physical time: A model for generating rhythmic gestures based on time metaphors","type":"paper-conference","URL":"https://doi.org/10.1145/3401956.3404236"},{"id":"cosmedTechnologyOverviewCOSMED","accessed":{"date-parts":[["2024",9,30]]},"author":[{"literal":"COSMED"}],"citation-key":"cosmedTechnologyOverviewCOSMED","genre":"White Paper","page":"4","title":"Technology Overview: COSMED Wearable Metabolic Systems","type":"report","URL":"https://www.cosmed.com/hires/WP_COSMED_wearable_metabolic_technology_EN.pdf&ved=2ahUKEwjRq974oOqIAxUyKBAIHeG6M6QQFnoECBcQAQ&usg=AOvVaw0yzIfrtnzuelYddVWkpj-M"},{"id":"costanzaIntroducingAudioDtouch2003","author":[{"family":"Costanza","given":"Enrico"},{"family":"Shelley","given":"Simon B"},{"family":"Robinson","given":"John"}],"citation-key":"costanzaIntroducingAudioDtouch2003","issued":{"date-parts":[["2003"]]},"title":"Introducing audio d-touch: A tangible user interface for music composition and performance","type":"article-journal"},{"id":"cottierExploringExtentWhich2023","abstract":"Motion-position illusions (MPIs) are visual motion illusions in which motion signals bias the perceived position of an object. Due to phenomenological similarities between these illusions, previous research has assumed that some are caused by common mechanisms. However, this assumption has yet to be directly tested. This study investigates this assumption by exploiting between-participant variations in illusion magnitude. During two sessions, 106 participants viewed the flash-lag effect, luminance flash-lag effect, Fröhlich effect, flash-drag effect, flash-grab effect, motion-induced position shift, twinkle-goes effect, and the flash-jump effect. For each effect, the magnitude of the illusion was reliable within participants, strongly correlating between sessions. When the pairwise correlations of averaged illusions magnitudes were explored, two clusters of statistically significant positively correlated illusions were identified. The first cluster comprised the flash-grab effect, motion-induced position shift, and twinkle-goes effect. The second cluster comprised the Fröhlich and flash-drag effect. The fact that within each of these two clusters, individual differences in illusion magnitude were correlated suggests that these clusters may reflect shared underlying mechanisms. An exploratory factor analysis provided additional evidence that these correlated clusters shared an underlying factor, with each cluster loading onto their own factor. Overall, our results reveal that, contrary to the prevailing perspective in the literature, while some motion-position illusions share processes, most of these illusions are unlikely to reflect any shared processes, instead implicating unique mechanisms.","author":[{"family":"Cottier","given":"Timothy V"},{"family":"Turner","given":"William"},{"family":"Holcombe","given":"A."},{"family":"Hogendoorn","given":"Hinze"}],"citation-key":"cottierExploringExtentWhich2023","container-title":"Journal of Vision","DOI":"10.1167/jov.23.10.8","issued":{"date-parts":[["2023"]]},"page":"null","PMID":"37703000","title":"Exploring the extent to which shared mechanisms contribute to motion-position illusions","type":"article-journal","URL":"https://www.semanticscholar.org/paper/aadd5ba0716b00a377913e5c9666236d7c3b8bed","volume":"23"},{"id":"couperMeasuringSurveyQuality1998","author":[{"family":"Couper","given":"Mick"}],"citation-key":"couperMeasuringSurveyQuality1998","container-title":"Proceedings of the Survey Research Methods Section of the ASA at JSM1998","container-title-short":"Proceedings of the Survey Research Methods Section of the ASA at JSM1998","issued":{"date-parts":[["1998"]]},"page":"41-49","title":"Measuring survey quality in a CASIC environment","type":"article-journal"},{"id":"coxDistributionShortTerm1988","author":[{"family":"Cox","given":"Robyn M."},{"family":"Matesich","given":"Joseph S."},{"family":"Moore","given":"Jeffrey N"}],"citation-key":"coxDistributionShortTerm1988","container-title":"The Journal of the Acoustical Society of America","container-title-short":"The Journal of the Acoustical Society of America","ISSN":"0001-4966","issue":"3","issued":{"date-parts":[["1988"]]},"page":"1100-1104","publisher":"Acoustical Society of America","title":"Distribution of Short‐Term RMS Levels in Conversational Speech","type":"article-journal","volume":"84"},{"id":"coxEmbodyingMusicPrinciples2011","author":[{"family":"Cox","given":"Arnie"}],"citation-key":"coxEmbodyingMusicPrinciples2011","container-title":"Music Theory Online","container-title-short":"Music Theory Online","issue":"2","issued":{"date-parts":[["2011"]]},"title":"Embodying Music: Principles of the Mimetic Hypothesis","type":"article-journal","volume":"17"},{"id":"cravoPsychophysicalComputationalAnalysis2008","abstract":"Several accounts put forth to explain the flash-lag effect (FLE) rely mainly on either spatial or temporal mechanisms. Here we investigated the relationship between these mechanisms by psychophysical and theoretical approaches. In a first experiment we assessed the magnitudes of the FLE and temporal-order judgments performed under identical visual stimulation. The results were interpreted by means of simulations of an artificial neural network, that was also employed to make predictions concerning the FLE. The model predicted that a spatio-temporal mislocalisation would emerge from two, continuous and abrupt-onset, moving stimuli. Additionally, a straightforward prediction of the model revealed that the magnitude of this mislocalisation should be task-dependent, increasing when the use of the abrupt-onset moving stimulus switches from a temporal marker only to both temporal and spatial markers. Our findings confirmed the model's predictions and point to an indissoluble interplay between spatial facilitation and processing delays in the FLE.","author":[{"family":"Cravo","given":"A."},{"family":"Baldo","given":"M."}],"citation-key":"cravoPsychophysicalComputationalAnalysis2008","container-title":"Perception","DOI":"10.1068/p6053","issued":{"date-parts":[["2008"]]},"note":"QID: Q51851418","page":"1850 - 1866","PMID":"19227376","title":"A psychophysical and computational analysis of the spatio-temporal mechanisms underlying the flash-lag effect","type":"article-journal","URL":"https://www.semanticscholar.org/paper/7336cda0ba4dcb3de139cd6eb4665011380d0f35","volume":"37"},{"id":"creswellQualitativeInquiryResearch2018","abstract":"This book explores the philosophical underpinnings, history, and key elements of five qualitative inquiry approaches: narrative research, phenomenology, grounded theory, ethnography, and case study. The authors compare the approaches and relate research designs to each of the traditions of inquiry in a highly accessible manner. Featuring new content, articles, pedagogy, references, and expanded coverage of ethics throughout, the book is an introduction to the theories, strategies, and practices of qualitative inquiry","author":[{"family":"Creswell","given":"John W."},{"family":"Poth","given":"Cheryl N."}],"call-number":"H61 .C73 2018","citation-key":"creswellQualitativeInquiryResearch2018","edition":"Fourth edition","event-place":"Los Angeles","ISBN":"978-1-5063-3020-4","issued":{"date-parts":[["2018"]]},"note":"OCLC: ocn954104455","number-of-pages":"459","publisher":"SAGE","publisher-place":"Los Angeles","source":"Library of Congress ISBN","title":"Qualitative inquiry & research design: choosing among five approaches","title-short":"Qualitative inquiry & research design","type":"book"},{"id":"creswellResearchDesignQualitative2018","author":[{"family":"Creswell","given":"John W."},{"family":"Creswell","given":"J. David"}],"call-number":"H62 .C6963 2018","citation-key":"creswellResearchDesignQualitative2018","edition":"Fifth edition","event-place":"Los Angeles","ISBN":"978-1-5063-8670-6","issued":{"date-parts":[["2018"]]},"number-of-pages":"275","publisher":"SAGE","publisher-place":"Los Angeles","source":"Library of Congress ISBN","title":"Research Design: Qualitative, Quantitative, and Mixed Methods Approaches","title-short":"Research design","type":"book"},{"id":"crossMusicMeaning2016","accessed":{"date-parts":[["2022",1,20]]},"author":[{"family":"Cross","given":"Ian"},{"family":"Tolbert","given":"Caroline"}],"citation-key":"crossMusicMeaning2016","DOI":"10.1093/oxfordhb/9780198722946.013.7","editor":[{"family":"Hallam","given":"Susan"},{"family":"Cross","given":"Ian"},{"family":"Thaut","given":"Michael"}],"issued":{"date-parts":[["2016",1,1]]},"publisher":"Oxford University Press","source":"DOI.org (Crossref)","title":"Music and Meaning","type":"book","URL":"http://oxfordhandbooks.com/view/10.1093/oxfordhb/9780198722946.001.0001/oxfordhb-9780198722946-e-7"},{"id":"crossNatureMusicIts2016","accessed":{"date-parts":[["2021",12,17]]},"author":[{"family":"Cross","given":"Ian"}],"citation-key":"crossNatureMusicIts2016","container-title":"The Oxford Handbook of Music Psychology","DOI":"10.1093/oxfordhb/9780198722946.013.5","editor":[{"family":"Hallam","given":"Susan"},{"family":"Cross","given":"Ian"},{"family":"Thaut","given":"Michael"}],"issued":{"date-parts":[["2016",1,1]]},"page":"3-17","publisher":"Oxford University Press","source":"DOI.org (Crossref)","title":"The Nature of Music and Its Evolution","type":"chapter","URL":"http://oxfordhandbooks.com/view/10.1093/oxfordhb/9780198722946.001.0001/oxfordhb-9780198722946-e-5"},{"id":"cuykendallFloatingDeparturesDeveloping2022","abstract":"We describe our process of quarantine dance technique in making the dance film and meditation, Floating Departures. This work, created during lockdown in 2021, brings together dance movement, poetry, painterly styles, and sound to explore cyclical patterns and points of departure in movement and life. To create Floating Departures we used a broad range of technologies–from everyday objects to smartphones to AI art systems. We experiment with various techniques to record ourselves and bring our movement together in a shared digital space with post-production video editing techniques. Using a bricolage approach, we incorporate materials, such as bubble wrap and balloons, to transform our spaces and explore our personal experiences during lockdown. We construct multiple layers of reality that are further transformed in unanticipated directions with AI technologies. Through our creation process, we develop a collective physical body to explore a new realm, unbound by reason or logic, that was only made possible through our remote collaborative processes and technologically-mediated interactions.","author":[{"family":"Cuykendall","given":"Shannon"},{"family":"DiPaola","given":"Steve"}],"citation-key":"cuykendallFloatingDeparturesDeveloping2022","collection-title":"MOCO '22","container-title":"Proceedings of the 8th international conference on movement and computing","DOI":"10.1145/3537972.3538009","event-place":"Chicago, IL, USA","ISBN":"978-1-4503-8716-3","issued":{"date-parts":[["2022"]]},"number-of-pages":"7","publisher":"Association for Computing Machinery","publisher-place":"Chicago, IL, USA","title":"Floating departures: Developing quarantine dance technique as an artistic practice beyond the pandemic","type":"paper-conference","URL":"https://doi.org/10.1145/3537972.3538009"},{"id":"cuykendallHearingMovementHow2015","abstract":"We describe the first stages of exploratory research undertaken to analyze expressive movement qualities of taiko performance, a Japaense artistic practice that combines stylized movement with drumming technique. The eventual goals of this research are to answer 1) Can expressive visual qualities of taiko be heard in the sound and 2) Can expressive sonic qualities of taiko be seen in the movement? We achieved high accuracy across multiple machine-learning algorithms in recognizing key sonic and visual qualities of taiko performance. In contrast to many current methods of studying expressive qualities of movement, we inform our data collection process and annotations with taiko technique. We seek to understand how the fundamentals of taiko create expression. More broadly, we suggest that codified artistic practices, like taiko, can inform automatic recognition and generation of expressive movement qualities that have been challenging to reliably classify, parse, and detect. In future work we propose ways to generalize expressive features of taiko so they can be recognized in other movement contexts.","author":[{"family":"Cuykendall","given":"Shannon"},{"family":"Junokas","given":"Michael"},{"family":"Amanzadeh","given":"Mohammad"},{"family":"Tcheng","given":"David Kim"},{"family":"Wang","given":"Yawen"},{"family":"Schiphorst","given":"Thecla"},{"family":"Garnett","given":"Guy"},{"family":"Pasquier","given":"Philippe"}],"citation-key":"cuykendallHearingMovementHow2015","collection-title":"MOCO '15","container-title":"Proceedings of the 2nd international workshop on movement and computing","DOI":"10.1145/2790994.2791004","event-place":"Vancouver, British Columbia, Canada","ISBN":"978-1-4503-3457-0","issued":{"date-parts":[["2015"]]},"number-of-pages":"8","page":"140–147","publisher":"Association for Computing Machinery","publisher-place":"Vancouver, British Columbia, Canada","title":"Hearing movement: How taiko can inform automatic recognition of expressive movement qualities","type":"paper-conference","URL":"https://doi.org/10.1145/2790994.2791004"},{"id":"cuykendallITECDesignFramework2022","abstract":"Disseminating dance in online spaces provides an opportunity for kinesthetic knowledge to reach broader audiences. However, the transmission of dance in online spaces also primarily relies on visual and aural modalities that cannot fully capture the nuanced physical sensations of a kinesthetic experience. In recent years there has been an influx of interactive online dance resources; yet there is little analysis of how these works effectively translate kinesthetic knowledge to online audiences. We bring together research in dance film and interaction design practices to explore kinesthetic transmission in online spaces and conduct analyses on interactive digital dance resources. Based on our literature review and analyses of these dance resources we propose the I-TEC design framework for kinesthetic transmission. In this framework, Instructional, Translational, Exploratory, and Contextual interactions are brought together to expose the multiple embodiments, perspectives, and translations of kinesthesia.","author":[{"family":"Cuykendall","given":"Shannon"},{"family":"Schiphorst","given":"Thecla"}],"citation-key":"cuykendallITECDesignFramework2022","collection-title":"MOCO '22","container-title":"Proceedings of the 8th international conference on movement and computing","DOI":"10.1145/3537972.3537987","event-place":"Chicago, IL, USA","ISBN":"978-1-4503-8716-3","issued":{"date-parts":[["2022"]]},"number-of-pages":"12","publisher":"Association for Computing Machinery","publisher-place":"Chicago, IL, USA","title":"The I-TEC design framework for kinesthetic transmission in online spaces","type":"paper-conference","URL":"https://doi.org/10.1145/3537972.3537987"},{"id":"czarniawska-joergesShadowingOtherTechniques2007","author":[{"family":"Czarniawska-Joerges","given":"Barbara"}],"call-number":"GN346 .C93 2007","citation-key":"czarniawska-joergesShadowingOtherTechniques2007","event-place":"Malmö, Sweden : Herndon, VA : Oslo","ISBN":"978-87-630-0215-8","issued":{"date-parts":[["2007"]]},"note":"OCLC: ocn183531953","number-of-pages":"134","publisher":"Liber ; Copenhagen Business School Press ; Universitetsforlaget","publisher-place":"Malmö, Sweden : Herndon, VA : Oslo","source":"Library of Congress ISBN","title":"Shadowing: and other techniques for doing fieldwork in modern societies","title-short":"Shadowing","type":"book"},{"id":"dahlDatadrivenDesignSound2017","abstract":"Since people communicate intentions and inner states through movement, robots can better interact with humans if they too can modify their movements to communicate changing state. These movements, which may be seen as supplementary to those required for workspace tasks, may be termed \"expressive.\" However, robot hardware, which cannot recreate the same range of dynamics as human limbs, often limit expressive capacity. One solution is to augment expressive robotic movement with expressive sound. To that end, this paper presents a study to find a qualitative mapping between movement and sound. Musicians were asked to vocalize sounds in response to animations of a simple simulated upper body movement performed with different movement qualities, parametrized according to Laban's Effort System. Qualitative labelling and quantitative signal analysis of these sounds suggests a number of correspondences between movement qualities and sound qualities. These correspondences are presented and analyzed here to set up future work that will test user perceptions when expressive movements and sounds are used in conjunction.","author":[{"family":"Dahl","given":"Luke"},{"family":"Bellona","given":"Jon"},{"family":"Bai","given":"Lin"},{"family":"LaViers","given":"Amy"}],"citation-key":"dahlDatadrivenDesignSound2017","collection-title":"MOCO '17","container-title":"Proceedings of the 4th international conference on movement computing","DOI":"10.1145/3077981.3078047","event-place":"London, United Kingdom","ISBN":"978-1-4503-5209-3","issued":{"date-parts":[["2017"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"London, United Kingdom","title":"Data-driven design of sound for enhancing the perception of expressive robotic movement","type":"paper-conference","URL":"https://doi.org/10.1145/3077981.3078047"},{"id":"damalaMUSETECHCompanionNavigating2019","author":[{"family":"Damala","given":"Areti"},{"family":"Ruthven","given":"Ian"},{"family":"Hornecker","given":"Eva"}],"citation-key":"damalaMUSETECHCompanionNavigating2019","issued":{"date-parts":[["2019"]]},"publisher":"University of Strathclyde","title":"The MUSETECH Companion: Navigating the Matrix","type":"article-journal"},{"id":"damalaMUSETECHModelComprehensive2019","abstract":"Digital technologies are being introduced in museums and other informal learning environments alongside more traditional interpretive and communication media. An increasing number of studies has proved the potential of digitally mediated cultural heritage experiences. However, there is still a lot of controversy as to the advantages and disadvantages of introducing the digital into museum settings, primarily related to the risks and investment in terms of time and human and financial resources required. This work introduces the MUSETECH model, a comprehensive framework for evaluating museum technology before and after its introduction into a museum setting. One of the unique features of our framework is to consider the evaluation of digital technologies from three different perspectives: the cultural heritage professional, cultural heritage institution, and museum visitor. The framework benefited from an extensive review of the current state of the art and from inputs from cultural heritage professionals, designers, and engineers. MUSETECH can be used as a tool for reflection before, during, and after introducing novel digital media resources. The model covers technologies as diverse as mobile museum guides, Augmented and Virtual Reality applications, hands-on museum interactives, edutainment applications, digitally mediated tangible and embodied experiences, or online approaches used for museum education and learning.","accessed":{"date-parts":[["2022",11,10]]},"author":[{"family":"Damala","given":"Areti"},{"family":"Ruthven","given":"Ian"},{"family":"Hornecker","given":"Eva"}],"citation-key":"damalaMUSETECHModelComprehensive2019","container-title":"Journal on Computing and Cultural Heritage","container-title-short":"J. Comput. Cult. Herit.","DOI":"10.1145/3297717","ISSN":"1556-4673, 1556-4711","issue":"1","issued":{"date-parts":[["2019",2,28]]},"language":"en","page":"1-22","source":"DOI.org (Crossref)","title":"The MUSETECH Model: A Comprehensive Evaluation Framework for Museum Technology","title-short":"The MUSETECH Model","type":"article-journal","URL":"https://dl.acm.org/doi/10.1145/3297717","volume":"12"},{"id":"danielsAverageMan1952","author":[{"family":"Daniels","given":"Gilbert S"}],"citation-key":"danielsAverageMan1952","issued":{"date-parts":[["1952"]]},"publisher":"Air Force Aerospace Medical Research Lab Wright-Patterson AFB OH","title":"The average man?","type":"report"},{"id":"danielsenBinsSpansTolerance2023","abstract":"Abstract\n            This study compares three recent theories of expressive microtiming in music. While each theory was originally designed to engage a particular musical genre—Anne Danielsen’s beat bins for funk, Neo-Soul, and other contemporary Black musical expressions, Chris Stover’s beat span for “timeline musics” from Africa and the African diaspora, and Mats Johansson’s rhythmic tolerance for Scandinavian fiddle music—we consider how they can productively coexist in a shared music-analytic space, each revealing aspects of musical structure and process in mutually reinforcing ways. In order to explore these possibilities, we bring all three theories to bear on a recording of Thelonious Monk’s “Monk’s Dream,” focusing on Monk’s piano gestures as well as the relationship between saxophonist Charlie Rouse’s improvised solo and Monk’s and bassist John Ore’s accompaniments.","accessed":{"date-parts":[["2024",3,29]]},"author":[{"family":"Danielsen","given":"Anne"},{"family":"Johansson","given":"Mats"},{"family":"Stover","given":"Chris"}],"citation-key":"danielsenBinsSpansTolerance2023","container-title":"Music Theory Spectrum","DOI":"10.1093/mts/mtad005","ISSN":"0195-6167, 1533-8339","issue":"2","issued":{"date-parts":[["2023",9,22]]},"language":"en","license":"https://creativecommons.org/licenses/by/4.0/","page":"181-198","source":"DOI.org (Crossref)","title":"Bins, Spans, and Tolerance: Three Theories of Microtiming Behavior","title-short":"Bins, Spans, and Tolerance","type":"article-journal","URL":"https://academic.oup.com/mts/article/45/2/181/7234305","volume":"45"},{"id":"danielsenTheresMoreTiming2024","abstract":"The TIME project: Timing and Sound in Musical Microrhythm (2017–2022) studied microrhythm; that is, how dynamic envelope, timbre, and center frequency, as well as the microtiming of a variety of sounds, affect their perceived rhythmic properties. The project involved theoretical work regarding the basic aspects of microrhythm; experimental studies of microrhythm perception, exploring both stimulus features and the participants’ enculturated expertise; observational studies of how musicians produce particular microrhythms; and ethnographic studies of musicians’ descriptions of microrhythm. Collectively, we show that: (a) altering the microstructure of a sound (“what” the sound is) changes its perceived temporal location (“when” it occurs), (b) there are systematic effects of core acoustic factors (duration, attack) on microrhythmic perception, (c) microrhythmic features in longer and more complex sounds can give rise to different perceptions of the same sound, and (d) musicians are highly aware of microrhythms and have developed vocabularies for describing them. In addition, our results shed light on conflicting results regarding the effect of microtiming on the “grooviness” of a rhythm. Our use of multiple, interdisciplinary methodologies enabled us to uncover the complexity of microrhythm perception and production in both laboratory and real-world musical contexts.","accessed":{"date-parts":[["2024",3,28]]},"author":[{"family":"Danielsen","given":"Anne"},{"family":"Brøvig","given":"Ragnhild"},{"family":"Bøhler","given":"Kjetil Klette"},{"family":"Câmara","given":"Guilherme Schmidt"},{"family":"Haugen","given":"Mari Romarheim"},{"family":"Jacobsen","given":"Eirik"},{"family":"Johansson","given":"Mats S."},{"family":"Lartillot","given":"Olivier"},{"family":"Nymoen","given":"Kristian"},{"family":"Oddekalv","given":"Kjell Andreas"},{"family":"Sandvik","given":"Bjørnar"},{"family":"Sioros","given":"George"},{"family":"London","given":"Justin"}],"citation-key":"danielsenTheresMoreTiming2024","container-title":"Music Perception: An Interdisciplinary Journal","DOI":"10.1525/mp.2024.41.3.176","ISSN":"0730-7829, 1533-8312","issue":"3","issued":{"date-parts":[["2024",2,1]]},"language":"en","page":"176-198","source":"DOI.org (Crossref)","title":"There’s More to Timing than Time","type":"article-journal","URL":"https://online.ucpress.edu/mp/article/41/3/176/199793/There-s-More-to-Timing-than-TimeInvestigating","volume":"41"},{"id":"dastonObjectivity2021","abstract":"Objectivity has a history, and it is full of surprises. In Objectivity, Lorraine Daston and Peter Galison chart the emergence of objectivity in the mid-nineteenth-century sciences — and show how the concept differs from alternatives, truth-to-nature and trained judgment. This is a story of lofty epistemic ideals fused with workaday practices in the making of scientific images.\nFrom the eighteenth through the early twenty-first centuries, the images that reveal the deepest commitments of the empirical sciences — from anatomy to crystallography — are those featured in scientific atlases: the compendia that teach practitioners of a discipline what is worth looking at and how to look at it. Atlas images define the working objects of the sciences of the eye: snowflakes, galaxies, skeletons, even elementary particles.\nGalison and Daston use atlas images to uncover a hidden history of scientific objectivity and its rivals. Whether an atlas maker idealizes an image to capture the essentials in the name of truth-to-nature or refuses to erase even the most incidental detail in the name of objectivity or highlights patterns in the name of trained judgment is a decision enforced by an ethos as well as by an epistemology.\nAs Daston and Galison argue, atlases shape the subjects as well as the objects of science. To pursue objectivity — or truth-to-nature or trained judgment — is simultaneously to cultivate a distinctive scientific self wherein knowing and knower converge. Moreover, the very point at which they visibly converge is in the very act of seeing not as a separate individual but as a member of a particular scientific community. Embedded in the atlas image, therefore, are the traces of consequential choices about knowledge, persona, and collective sight. Objectivity is a book addressed to any one interested in the elusive and crucial notion of objectivity — and in what it means to peer into the world scientifically.","accessed":{"date-parts":[["2024",11,4]]},"author":[{"family":"Daston","given":"Lorraine"},{"family":"Galison","given":"Peter L."}],"citation-key":"dastonObjectivity2021","event-place":"New York","ISBN":"978-1-890951-79-5","issued":{"date-parts":[["2021"]]},"publisher":"Princeton University Press","publisher-place":"New York","title":"Objectivity","type":"book"},{"id":"davisBendingBackwardsDisability2002","author":[{"family":"Davis","given":"Lennard J."}],"call-number":"HV1553 .D38 2002","citation-key":"davisBendingBackwardsDisability2002","collection-title":"Cultural front","event-place":"New York","ISBN":"978-0-8147-1949-7 978-0-8147-1950-3","issued":{"date-parts":[["2002"]]},"number-of-pages":"200","publisher":"New York University Press","publisher-place":"New York","source":"Library of Congress ISBN","title":"Bending Over Backwards: Disability, Dismodernism, and Other Difficult Positions","title-short":"Bending over backwards","type":"book"},{"id":"davisConstructingNormalcy1997","abstract":"Collects representative texts from the field of disability studies. Drawing together experts in cultural studies, literary criticism, sociology, biology, the visual arts, pedagogy and post-colonial studies, the collection provides a comprehensive approach to the issue of disability.","accessed":{"date-parts":[["2021",1,19]]},"author":[{"family":"Davis","given":"Lennard J."}],"citation-key":"davisConstructingNormalcy1997","container-title":"The Disability Studies Reader","edition":"First edition","editor":[{"family":"Davis","given":"Lennard J."}],"event-place":"New York","ISBN":"978-0-203-95711-0","issued":{"date-parts":[["1997"]]},"language":"English","note":"OCLC: 476055060","page":"9 - 28","publisher":"Routledge","publisher-place":"New York","source":"Open WorldCat","title":"Constructing Normalcy","type":"chapter"},{"id":"davisDisabilityStudiesReader2006","abstract":"Collects representative texts from the field of disability studies. Drawing together experts in cultural studies, literary criticism, sociology, biology, the visual arts, pedagogy and post-colonial studies, the collection provides a comprehensive approach to the issue of disability.","accessed":{"date-parts":[["2021",1,19]]},"author":[{"family":"Davis","given":"Lennard J"}],"citation-key":"davisDisabilityStudiesReader2006","edition":"Second edition","event-place":"Hoboken","ISBN":"978-0-203-95711-0","issued":{"date-parts":[["2006"]]},"language":"English","note":"OCLC: 476055060","publisher":"Routledge","publisher-place":"Hoboken","source":"Open WorldCat","title":"The Disability Studies Reader","type":"book","URL":"http://www.Bangor.eblib.com/patron/FullRecord.aspx?p=293586"},{"id":"davisDisabilityStudiesReader2013","author":[{"family":"Davis","given":"Lennard J."}],"call-number":"HV1568 .D5696 2013","citation-key":"davisDisabilityStudiesReader2013","edition":"Fourth edition","editor":[{"family":"Davis","given":"Lennard J."}],"event-place":"New York, NY","ISBN":"978-0-415-63052-8 978-0-415-63051-1 978-0-203-07788-7","issued":{"date-parts":[["2013"]]},"number-of-pages":"578","publisher":"Routledge","publisher-place":"New York, NY","source":"Library of Congress ISBN","title":"The Disability Studies Reader","type":"book"},{"id":"davisDisabilityStudiesReader2017","call-number":"HV1568 .D5696 2017","citation-key":"davisDisabilityStudiesReader2017","edition":"Fifth edition","editor":[{"family":"Davis","given":"Lennard J."}],"event-place":"New York","ISBN":"978-1-138-93022-3 978-1-138-93023-0","issued":{"date-parts":[["2017"]]},"number-of-pages":"554","publisher":"Routledge, Taylor & Francis Group","publisher-place":"New York","source":"Library of Congress ISBN","title":"The Disability Studies Reader","type":"book"},{"id":"davisEnforcingNormalcyDisability1995","author":[{"family":"Davis","given":"Lennard J."}],"call-number":"HV1568 .D39 1995","citation-key":"davisEnforcingNormalcyDisability1995","event-place":"London ; New York","ISBN":"978-1-85984-912-5 978-1-85984-007-8","issued":{"date-parts":[["1995"]]},"number-of-pages":"203","publisher":"Verso","publisher-place":"London ; New York","source":"Library of Congress ISBN","title":"Enforcing Normalcy: Disability, Deafness, and the Body","title-short":"Enforcing normalcy","type":"book"},{"id":"dawarDataAugmentationDeep2019","accessed":{"date-parts":[["2024",8,24]]},"author":[{"family":"Dawar","given":"Neha"},{"family":"Ostadabbas","given":"Sarah"},{"family":"Kehtarnavaz","given":"Nasser"}],"citation-key":"dawarDataAugmentationDeep2019","container-title":"IEEE Sensors Letters","container-title-short":"IEEE Sens. Lett.","DOI":"10.1109/LSENS.2018.2878572","ISSN":"2475-1472","issue":"1","issued":{"date-parts":[["2019",1]]},"license":"https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html","page":"1-4","source":"DOI.org (Crossref)","title":"Data Augmentation in Deep Learning-Based Fusion of Depth and Inertial Sensing for Action Recognition","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/8514027/","volume":"3"},{"id":"deberHowMuchFaster2015","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Deber","given":"Jonathan"},{"family":"Jota","given":"Ricardo"},{"family":"Forlines","given":"Clifton"},{"family":"Wigdor","given":"Daniel"}],"citation-key":"deberHowMuchFaster2015","container-title":"Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems","DOI":"10.1145/2702123.2702300","event-place":"Seoul Republic of Korea","event-title":"CHI '15: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-3145-6","issued":{"date-parts":[["2015",4,18]]},"language":"en","page":"1827-1836","publisher":"ACM","publisher-place":"Seoul Republic of Korea","source":"DOI.org (Crossref)","title":"How Much Faster is Fast Enough?: User Perception of Latency & Latency Improvements in Direct and Indirect Touch","title-short":"How Much Faster is Fast Enough?","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/2702123.2702300"},{"id":"deblockDopingUseArtistic2013","author":[{"family":"De Block","given":"Andreas"}],"citation-key":"deblockDopingUseArtistic2013","DOI":"10.1007/978-94-007-5101-9_8","editor":[{"family":"Tolleneer","given":"Jan"},{"family":"Sterckx","given":"Sigrid"},{"family":"Bonte","given":"Pieter"}],"event-place":"Dordrecht","issued":{"date-parts":[["2013",1,1]]},"page":"149-162","publisher":"Springer","publisher-place":"Dordrecht","title":"Doping Use as an Artistic Crime: On Natural Performances and Authentic Art","type":"chapter"},{"id":"delaneyTrailShadowWoman1998","author":[{"family":"Delaney","given":"Ben"}],"citation-key":"delaneyTrailShadowWoman1998","container-title":"IEEE Computer Graphics and Applications","container-title-short":"IEEE Computer Graphics and Applications","DOI":"10.1109/38.708556","ISSN":"1558-1756","issue":"5","issued":{"literal":"Sept.-Oct. 1998"},"page":"14-19","title":"On the trail of the shadow woman: the mystery of motion capture","type":"article-journal","volume":"18"},{"id":"delbridgeCostumeMoCapSpatial2014","abstract":"The rationale that governs motion of the organic in the cubical leans towards a transformation of the body in space, emphasizes its mathematical properties and highlights the potential to measure and plot movement – this is the work of a Motion Capture (MoCap) system. The translation\n in the MoCap studio from physical to virtual is facilitated by the MoCap suit, a device that determines the abstract cubical representation that drives first the neutral, and then the characterized avatar in screen space. The enabling nature of the suit, as apparatus, is a spatial phenomenon\n informed by Schlemmer’s abstract ‘native’ costume and his vision of the Tanzermensch as the most appropriate form to occupy cubical space. The MoCap suit is similarly native. It bridges the physical and virtual, provides a Victor Turner like threshold and connection between\n environments, enacting a spatial discourse facilitated by costume. This collision of Velcro, Avatar and Oskar Schlemmer allows a performance of space, binding historical modernity to contemporary practice. This performance of activated space is captured by a costume that endures, in Dorita\n Hannah’s words, despite the human form.","accessed":{"date-parts":[["2023",2,28]]},"author":[{"family":"Delbridge","given":"Matt"}],"citation-key":"delbridgeCostumeMoCapSpatial2014","container-title":"Scene","container-title-short":"scene","DOI":"10.1386/scene.2.1-2.221_1","ISSN":"2044-3714","issue":"1","issued":{"date-parts":[["2014",10,1]]},"language":"en","page":"221-232","source":"DOI.org (Crossref)","title":"The costume of MoCap: A spatial collision of velcro, avatar and Oskar Schlemmer","title-short":"The costume of MoCap","type":"article-journal","URL":"https://intellectdiscover.com/content/journals/10.1386/scene.2.1-2.221_1","volume":"2"},{"id":"delbridgeMotionCapturePerformance2015","accessed":{"date-parts":[["2022",5,12]]},"author":[{"family":"Delbridge","given":"Matt"}],"citation-key":"delbridgeMotionCapturePerformance2015","DOI":"10.1057/9781137505811","event-place":"London","ISBN":"978-1-349-50588-3 978-1-137-50581-1","issued":{"date-parts":[["2015"]]},"language":"en","publisher":"Palgrave Macmillan UK","publisher-place":"London","source":"DOI.org (Crossref)","title":"Motion Capture in Performance","type":"book","URL":"http://link.springer.com/10.1057/9781137505811"},{"id":"demirNewDeepCNN2020","author":[{"family":"Demir","given":"Fatih"},{"family":"Abdullah","given":"Daban Abdulsalam"},{"family":"Sengur","given":"Abdulkadir"}],"citation-key":"demirNewDeepCNN2020","container-title":"IEEE access : practical innovations, open solutions","container-title-short":"IEEE Access","DOI":"10.1109/ACCESS.2020.2984903","issued":{"date-parts":[["2020"]]},"page":"66529-66537","title":"A new deep CNN model for environmental sound classification","type":"article-journal","volume":"8"},{"id":"dengImageNetLargescaleHierarchical2009","author":[{"family":"Deng","given":"Jia"},{"family":"Dong","given":"Wei"},{"family":"Socher","given":"Richard"},{"family":"Li","given":"Li-Jia"},{"family":"Li","given":"Kai"},{"family":"Fei-Fei","given":"Li"}],"citation-key":"dengImageNetLargescaleHierarchical2009","container-title":"2009 IEEE conference on computer vision and pattern recognition","DOI":"10.1109/CVPR.2009.5206848","issued":{"date-parts":[["2009"]]},"page":"248-255","title":"ImageNet: A large-scale hierarchical image database","type":"paper-conference"},{"id":"denoraMusicEverydayLife2000","author":[{"family":"DeNora","given":"Tia"}],"call-number":"ML3795 .D343 2000","citation-key":"denoraMusicEverydayLife2000","event-place":"Cambridge ; New York","ISBN":"978-0-521-62206-6 978-0-521-62732-0","issued":{"date-parts":[["2000"]]},"number-of-pages":"181","publisher":"Cambridge University Press","publisher-place":"Cambridge ; New York","source":"Library of Congress ISBN","title":"Music in everyday life","type":"book"},{"id":"dereditaNewBahaImplant2012","author":[{"family":"D’Eredità","given":"Riccardo"},{"family":"Caroncini","given":"Matteo"},{"family":"Saetti","given":"Roberto"}],"citation-key":"dereditaNewBahaImplant2012","container-title":"Otolaryngology--Head and Neck Surgery","container-title-short":"Otolaryngology--Head and Neck Surgery","ISSN":"0194-5998","issue":"6","issued":{"date-parts":[["2012"]]},"page":"979-983","publisher":"SAGE Publications Sage CA: Los Angeles, CA","title":"The New Baha Implant: A Prospective Osseointegration Study","type":"article-journal","volume":"146"},{"id":"derryDesigningChoreographicInterface2022","abstract":"In 2019, metaLAB (at) Harvard began work on Curatorial A(i)gents, a digital exhibition that was slated to premiere at the Harvard Art Museums’ Lightbox Gallery in 2020. Half of the projects would be interactive, using mouse and keyboard conventions. With the advent of Covid-19 and the postponement of the show, the authors set out to develop an interface solution that would enable visitors to interact with the works without having to touch any public devices like a tablet. Toward this end, we prototyped a “choreographic interface” that uses machine vision and machine learning to interpret a full-torso gestural vocabulary, which is then translated into interactions. To make the choreographic interface, we relied on open-source solutions, which have all come with equal limitations and opportunities. In 2022, Curatorial A(i)gents was presented in the Lightbox Gallery, where we had the opportunity to test and demonstrate the interface. This paper discusses our design journey in making a choreographic interface using open-source technologies during Covid-19.","author":[{"family":"Derry","given":"Lins"},{"family":"Kruguer","given":"Jordan"},{"family":"Mueller","given":"Maximilian"},{"family":"Schnapp","given":"Jeffrey"}],"citation-key":"derryDesigningChoreographicInterface2022","collection-title":"MOCO '22","container-title":"Proceedings of the 8th international conference on movement and computing","DOI":"10.1145/3537972.3538020","event-place":"Chicago, IL, USA","ISBN":"978-1-4503-8716-3","issued":{"date-parts":[["2022"]]},"number-of-pages":"7","publisher":"Association for Computing Machinery","publisher-place":"Chicago, IL, USA","title":"Designing a choreographic interface during COVID-19","type":"paper-conference","URL":"https://doi.org/10.1145/3537972.3538020"},{"id":"dezeeuwTeachingCollegeMusic1977","archive":"JSTOR","author":[{"family":"Zeeuw","given":"Anne Marie","non-dropping-particle":"de"}],"citation-key":"dezeeuwTeachingCollegeMusic1977","container-title":"College Music Symposium","ISSN":"00695696, 2334203X","issue":"2","issued":{"date-parts":[["1977"]]},"page":"89-101","publisher":"College Music Society","title":"Teaching College Music Theory Classes That Include Blind Students","type":"article-journal","URL":"http://www.jstor.org/stable/40373893","volume":"17"},{"id":"dhekaneTransferLearningHuman2024","author":[{"family":"Dhekane","given":"Sourish Gunesh"},{"family":"Ploetz","given":"Thomas"}],"citation-key":"dhekaneTransferLearningHuman2024","issued":{"date-parts":[["2024"]]},"title":"Transfer learning in human activity recognition: a survey","type":"document","URL":"https://arxiv.org/abs/2401.10185"},{"id":"dibernardojonesImaginedHearingMusicMaking2016","author":[{"family":"DiBernardo Jones","given":"Jeannette"}],"citation-key":"dibernardojonesImaginedHearingMusicMaking2016","container-title":"The Oxford Handbook of Music and Disability Studies","editor":[{"family":"Howe","given":"Blake"},{"family":"Jensen-Moulton","given":"Stephanie"},{"family":"Lerner","given":"Neil William"},{"family":"Straus","given":"Joseph Nathan"}],"event-place":"Oxford ; New York","ISBN":"978-0-19-933144-4 978-0-19-065060-5","issued":{"date-parts":[["2016"]]},"page":"54 - 72","publisher":"Oxford University Press","publisher-place":"Oxford ; New York","source":"Library of Congress ISBN","title":"Imagined Hearing: Music-Making in Deaf Culture","type":"chapter"},{"id":"dilmiIterativeMultiscaleDynamic2020","abstract":"In many domains, such as weather forecasting, hydrology or civil protection, it is an important issue to characterize rainfall variability and intermittency in, either or both, a given time period or area. A variety of sensors, for instance, rain gauges, weather radars and satellites, are widely used for this purpose. Techniques to establish the similarity between rainfall time series are commonly based on the comparison of some extracted characteristic parameters (cumulative rainfall height, extreme values, rain occurrence, mean rain rate, etc.). The present study focuses on the development of a tool allowing to compare directly rainfall time series at a fine temporal scale. It allows quantifying the dissimilarity between the time series and determining a nonlinear relationship between their time axes. This study presents an algorithm based on a multiscale dynamic time warping approach, and it is based on the DTW algorithm applied on an iterative multiscale framework called IMs-DTW. This proposed algorithm is well suited for rain time series allowing point-to-point pairing between pairs of rainfall time. It takes the intermittency and the non-stationarity of the precipitation process into account. An application to measurements observed by four pluviometers located in the Paris area makes it possible to interpret the obtained results and to compare the IMs-DTW with more usual statistical features.","author":[{"family":"Dilmi","given":"Mohamed Djallel"},{"family":"Barthès","given":"Laurent"},{"family":"Mallet","given":"Cécile"},{"family":"Chazottes","given":"Aymeric"}],"citation-key":"dilmiIterativeMultiscaleDynamic2020","container-title":"International Journal of Data Science and Analytics","container-title-short":"International Journal of Data Science and Analytics","DOI":"10.1007/s41060-019-00193-1","ISSN":"2364-4168","issue":"1","issued":{"date-parts":[["2020",6,1]]},"page":"65-79","title":"Iterative multiscale dynamic time warping (IMs-DTW): a tool for rainfall time series comparison","type":"article-journal","URL":"https://doi.org/10.1007/s41060-019-00193-1","volume":"10"},{"id":"dilsGhostMachineMerce2002","accessed":{"date-parts":[["2023",9,29]]},"archive":"JSTOR","author":[{"family":"Dils","given":"Ann"}],"citation-key":"dilsGhostMachineMerce2002","container-title":"PAJ: A Journal of Performance and Art","ISSN":"1520281X, 15379477","issue":"1","issued":{"date-parts":[["2002"]]},"page":"94-104","publisher":"Performing Arts Journal, Inc.","title":"The Ghost in the Machine: Merce Cunningham and Bill T. Jones","type":"article-journal","URL":"http://www.jstor.org/stable/3246462","volume":"24"},{"id":"dilucaNewMethodMeasure2010","author":[{"family":"Di Luca","given":"Massimiliano"}],"citation-key":"dilucaNewMethodMeasure2010","container-title":"Presence","container-title-short":"Presence","DOI":"10.1162/pres_a_00023","ISSN":"1054-7460","issue":"6","issued":{"date-parts":[["2010",12,1]]},"page":"569-584","title":"New Method to Measure End-to-End Delay of Virtual Reality","type":"article-journal","volume":"19"},{"id":"discogsSignmarkBreakingRules","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Discogs"}],"citation-key":"discogsSignmarkBreakingRules","container-title":"Discogs","title":"Signmark ‎– Breaking The Rules","type":"webpage","URL":"https://www.discogs.com/Signmark-Breaking-The-Rules/release/2971289"},{"id":"discogsSignmarkSilentShout","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Discogs"}],"citation-key":"discogsSignmarkSilentShout","container-title":"Discogs","title":"Signmark ‎– Silent Shout","type":"webpage","URL":"https://www.discogs.com/Signmark-Silent-Shout/release/6247009"},{"id":"dixonDigitalPerformanceHistory2007","accessed":{"date-parts":[["2023",5,3]]},"author":[{"family":"Dixon","given":"Steve"}],"citation-key":"dixonDigitalPerformanceHistory2007","DOI":"10.7551/mitpress/2429.001.0001","ISBN":"978-0-262-27180-6","issued":{"date-parts":[["2007"]]},"language":"en","publisher":"The MIT Press","title":"Digital Performance: A History of New Media in Theater, Dance, Performance Art, and Installation","title-short":"Digital Performance","type":"book"},{"id":"dobrianNimeMusicalExpression2006","abstract":"Is there a distinction between New Interfaces for MusicalExpression and New Interfaces for Controlling Sound? Thisarticle begins with a brief overview of expression in musicalperformance, and examines some of the characteristics ofeffective \"expressive\" computer music instruments. Itbecomes apparent that sophisticated musical expressionrequires not only a good control interface but also virtuosicmastery of the instrument it controls. By studying effectiveacoustic instruments, choosing intuitive but complexgesture-sound mappings that take advantage of establishedinstrumental skills, designing intelligent characterizationsof performance gestures, and promoting long-term dedicatedpractice on a new interface, computer music instrumentdesigners can enhance the expressive quality of computermusic performance.","accessed":{"date-parts":[["2022",9,21]]},"author":[{"family":"Dobrian","given":"Christopher"},{"family":"Koppelman","given":"Daniel"}],"citation-key":"dobrianNimeMusicalExpression2006","DOI":"10.5281/ZENODO.1176893","issued":{"date-parts":[["2006",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"The E In Nime: Musical Expression With New Computer Interfaces","title-short":"The E In Nime","type":"article-journal","URL":"https://zenodo.org/record/1176893"},{"id":"dodgeComputerMusicSynthesis1997","author":[{"family":"Dodge","given":"Charles"},{"family":"Jerse","given":"Thomas A."}],"citation-key":"dodgeComputerMusicSynthesis1997","edition":"2. ed","event-place":"New York","ISBN":"978-0-02-864682-4","issued":{"date-parts":[["1997"]]},"language":"eng","number-of-pages":"455","publisher":"Schirmer Books [u.a.]","publisher-place":"New York","source":"K10plus ISBN","title":"Computer music: synthesis, composition, and performance","title-short":"Computer music","type":"book"},{"id":"doerschTutorialVariationalAutoencoders2016","abstract":"In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.","accessed":{"date-parts":[["2022",4,30]]},"author":[{"family":"Doersch","given":"Carl"}],"citation-key":"doerschTutorialVariationalAutoencoders2016","DOI":"10.48550/ARXIV.1606.05908","issued":{"date-parts":[["2016"]]},"license":"arXiv.org perpetual, non-exclusive license","publisher":"arXiv","source":"DOI.org (Datacite)","title":"Tutorial on Variational Autoencoders","type":"article-journal","URL":"https://arxiv.org/abs/1606.05908","version":"3"},{"id":"dolanOxfordHandbookTimbre2020","abstract":"\"With essays covering an array of topics including ancient Homeric texts, contemporary sound installations, violin mutes, birdsong, and cochlear implants, this volume reveals the richness of what it means to think and talk about timbre and the materiality of the experience of sound\"--","call-number":"ML3807 .O94 2020","citation-key":"dolanOxfordHandbookTimbre2020","editor":[{"family":"Dolan","given":"Emily I."},{"family":"Rehding","given":"Alexander"}],"event-place":"New York","ISBN":"978-0-19-063722-4","issued":{"date-parts":[["2020"]]},"publisher":"Oxford University Press","publisher-place":"New York","source":"Library of Congress ISBN","title":"The Oxford Handbook of Timbre","type":"book"},{"id":"dormanBenefitsCombiningAcoustic2008","author":[{"family":"Dorman","given":"Michael F."},{"family":"Gifford","given":"Rene H."},{"family":"Spahr","given":"Anthony J."},{"family":"McKarns","given":"Sharon A."}],"citation-key":"dormanBenefitsCombiningAcoustic2008","container-title":"Audiology and Neurotology","container-title-short":"Audiology and Neurotology","ISSN":"1420-3030","issue":"2","issued":{"date-parts":[["2008"]]},"page":"105-112","publisher":"Karger Publishers","title":"The Benefits of Combining Acoustic and Electric Stimulation for the Recognition of Speech, Voice and Melodies","type":"article-journal","volume":"13"},{"id":"doutreligneCriticalManifestoTransformative2020","abstract":"This article touches upon the problematic reception of the female pioneers of the historical avant-gardes - by contemporaries and art historians - more specifically within the movements of Futurism, Dadaism and Surrealism. What artistic strategies did avant-garde women apply to resist the omnipresent misogyny that was not only trivializing female creation but also sexualizing the female ‘other’? How is the gender binary embedded and challenged within their artistic practice?\n&nbsp;\nThis article observes firstly, how a critical engagement with the rather masculine format of the manifesto empowered women in dealing with the stereotypical imagery of womanhood at the time. Second, the application of so-called “inferior” media (embroidery, design, dance) and materials (textile, wood, the body) tackled the patriarchal classification of the arts and the subordinate role of women in it. Finally, the live performance of genderplay allowed female artists to articulate the bankruptcy of traditional gender conventions responsible for the problematic reception of many female artists through art history.","accessed":{"date-parts":[["2023",11,8]]},"author":[{"family":"Doutreligne","given":"Sophie"}],"citation-key":"doutreligneCriticalManifestoTransformative2020","container-title":"Documenta","DOI":"10.21825/documenta.81885","ISSN":"0771-8640","issue":"2","issued":{"date-parts":[["2020",6,30]]},"source":"DOI.org (Crossref)","title":"From critical manifesto to transformative genderplay: feminist Futurist and Dadaist strategies countering the misogyny within the historical avant-gardes","title-short":"From critical manifesto to transformative genderplay","type":"article-journal","URL":"https://documenta.ugent.be/article/id/81885/","volume":"38"},{"id":"downieChoreographingExtendedAgent2005","author":[{"family":"Downie","given":"Marc Norman"}],"citation-key":"downieChoreographingExtendedAgent2005","genre":"Ph.D Thesis","issued":{"date-parts":[["2005"]]},"publisher":"Massachusetts Institute of Technology, School of Architecture and Planning …","title":"Choreographing the Extended Agent: performance graphics for dance theater","type":"thesis","URL":"https://www.media.mit.edu/publications/choreographing-the-digital-agent-live-performance-graphics-for-dance-theater/"},{"id":"drennanClinicalEvaluationMusic2015","author":[{"family":"Drennan","given":"Ward R."},{"family":"Oleson","given":"Jacob J."},{"family":"Gfeller","given":"Kate"},{"family":"Crosson","given":"Jillian"},{"family":"Driscoll","given":"Virginia D."},{"family":"Won","given":"Jong Ho"},{"family":"Anderson","given":"Elizabeth S."},{"family":"Rubinstein","given":"Jay T."}],"citation-key":"drennanClinicalEvaluationMusic2015","container-title":"International journal of audiology","container-title-short":"International journal of audiology","ISSN":"1499-2027","issue":"2","issued":{"date-parts":[["2015"]]},"page":"114-123","publisher":"Taylor & Francis","title":"Clinical Evaluation of Music Perception, Appraisal and Experience in Cochlear Implant Users","type":"article-journal","volume":"54"},{"id":"drewingHapticVisualFlashlag2018","abstract":"When a short flash occurs in spatial alignment with a moving object, the moving object is seen ahead the stationary one. Similar to this visual “flash-lag effect” (FLE) it has been recently observed for the haptic sense that participants judge a moving hand to be ahead a stationary hand when judged at the moment of a short vibration (“haptic flash”) that is applied when the two hands are spatially aligned. We further investigated the haptic FLE. First, we compared participants’ performance in two isosensory visual or haptic conditions, in which moving object and flash were presented only in a single modality (visual: sphere and short color change, haptic: hand and vibration), and two bisensory conditions, in which the moving object was presented in both modalities (hand aligned with visible sphere), but the flash was presented only visually or only haptically. The experiment aimed to disentangle contributions of the flash’s and the objects’ modalities to the FLEs in haptics versus vision. We observed a FLE when the flash was visually displayed, both when the moving object was visual and visuo-haptic. Because the position of a visual flash, but not of an analogue haptic flash, is misjudged relative to a same visuo-haptic moving object, the difference between visual and haptic conditions can be fully attributed to characteristics of the flash. The second experiment confirmed that a haptic FLE can be observed depending on flash characteristics: the FLE increases with decreasing intensity of the flash (slightly modulated by flash duration), which had been previously observed for vision. These findings underline the high relevance of flash characteristics in different senses, and thus fit well with the temporal-sampling framework, where the flash triggers a high-level, supra-modal process of position judgement, the time point of which further depends on the processing time of the flash.","author":[{"family":"Drewing","given":"K."},{"family":"Hitzel","given":"Elena"},{"family":"Scocchia","given":"L."}],"citation-key":"drewingHapticVisualFlashlag2018","container-title":"PLoS ONE","DOI":"10.1371/journal.pone.0189291","issued":{"date-parts":[["2018"]]},"note":"QID: Q48316298","page":"null","PMID":"29298309","title":"The haptic and the visual flash-lag effect and the role of flash characteristics","type":"article-journal","URL":"https://www.semanticscholar.org/paper/7f1294609f3427fd30856ffece4a9f14ada0b5b3","volume":"13"},{"id":"drioliNetworkedPerformancesNatural2013","accessed":{"date-parts":[["2021",8,30]]},"author":[{"family":"Drioli","given":"Carlo"},{"family":"Allocchio","given":"Claudio"},{"family":"Buso","given":"Nicola"}],"citation-key":"drioliNetworkedPerformancesNatural2013","collection-editor":[{"family":"Hutchison","given":"David"},{"family":"Kanade","given":"Takeo"},{"family":"Kittler","given":"Josef"},{"family":"Kleinberg","given":"Jon M."},{"family":"Mattern","given":"Friedemann"},{"family":"Mitchell","given":"John C."},{"family":"Naor","given":"Moni"},{"family":"Nierstrasz","given":"Oscar"},{"family":"Pandu Rangan","given":"C."},{"family":"Steffen","given":"Bernhard"},{"family":"Sudan","given":"Madhu"},{"family":"Terzopoulos","given":"Demetri"},{"family":"Tygar","given":"Doug"},{"family":"Vardi","given":"Moshe Y."},{"family":"Weikum","given":"Gerhard"}],"container-title":"Information Technologies for Performing Arts, Media Access, and Entertainment","DOI":"10.1007/978-3-642-40050-6_21","editor":[{"family":"Nesi","given":"Paolo"},{"family":"Santucci","given":"Raffaella"}],"event-place":"Berlin, Heidelberg","ISBN":"978-3-642-40049-0 978-3-642-40050-6","issued":{"date-parts":[["2013"]]},"page":"240-250","publisher":"Springer Berlin Heidelberg","publisher-place":"Berlin, Heidelberg","source":"DOI.org (Crossref)","title":"Networked Performances and Natural Interaction via LOLA: Low Latency High Quality A/V Streaming System","title-short":"Networked Performances and Natural Interaction via LOLA","type":"chapter","URL":"http://link.springer.com/10.1007/978-3-642-40050-6_21","volume":"7990"},{"id":"drummondUnderstandingInteractiveSystems2009","abstract":"This article examines differing approaches to the definition, classification and modelling of interactive music systems, drawing together both historical and contemporary practice. Concepts of shared control, collaboration and conversation metaphors, mapping, gestural control, system responsiveness and separation of interface from sound generator are discussed. The article explores the potential of interactive systems to facilitate the creation of dynamic compositional sonic architectures through performance and improvisation.","archive":"Cambridge Core","author":[{"family":"Drummond","given":"Jon"}],"citation-key":"drummondUnderstandingInteractiveSystems2009","container-title":"Organised Sound","DOI":"10.1017/S1355771809000235","edition":"2009/06/29","ISSN":"1355-7718","issue":"2","issued":{"date-parts":[["2009"]]},"page":"124-133","publisher":"Cambridge University Press","source":"Cambridge University Press","title":"Understanding Interactive Systems","type":"article-journal","URL":"https://www.cambridge.org/core/article/understanding-interactive-systems/BF81A560B5C9D96355BC400065C7A1DF","volume":"14"},{"id":"duboisDesignEvaluationMixed2011","author":[{"family":"Dubois","given":"Emmanuel"},{"family":"Bortolaso","given":"Christophe"},{"family":"Bach","given":"Cédric"},{"family":"Duranthon","given":"Francis"},{"family":"Blanquer-Maumont","given":"Anne"}],"citation-key":"duboisDesignEvaluationMixed2011","container-title":"Int. J. Arts Technol.","container-title-short":"Int. J. Arts Technol.","issue":"4","issued":{"date-parts":[["2011"]]},"page":"408-441","title":"Design and evaluation of mixed interactive museographic exhibits.","type":"article-journal","volume":"4"},{"id":"dupontCoarseDTWSparseTime2016","abstract":"Dynamic Time Warping (DTW) is considered as a robust measure to compare numerical time series when some time elasticity is required. However, speed is a known major drawback of DTW due to its quadratic complexity. Previous work has mainly considered designing speed optimization based on early-abandoning strategies applied to nearest-neighbor classification, although some of these optimizations are restricted to uni-dimensional time series. In this paper, we introduce Coarse-DTW, a reinterpretation of DTW for sparse time series, which exploits adaptive downsampling to achieve speed enhancement, even when faced with multidimensional time series. We show that Coarse-DTW achieves nontrivial speedups in nearest-neighbor classification and even admits a positive-definite kernelization suitable for SVM classification, hence offering a good tradeoff between speed and accuracy.","author":[{"family":"Dupont","given":"Marc"},{"family":"Marteau","given":"Pierre-François"}],"citation-key":"dupontCoarseDTWSparseTime2016","container-title":"Advanced Analysis and Learning on Temporal Data","editor":[{"family":"Douzal-Chouakria","given":"Ahlame"},{"family":"Vilar","given":"José A."},{"family":"Marteau","given":"Pierre-François"}],"event-place":"Cham","ISBN":"978-3-319-44412-3","issued":{"date-parts":[["2016"]]},"page":"157-172","publisher":"Springer International Publishing","publisher-place":"Cham","title":"Coarse-DTW for Sparse Time Series Alignment","type":"paper-conference"},{"id":"dustin.noVoxiconHDUSB2022","accessed":{"date-parts":[["2022",11,26]]},"author":[{"literal":"dustin.no"}],"citation-key":"dustin.noVoxiconHDUSB2022","container-title":"dustin","issued":{"date-parts":[["2022"]]},"title":"Voxicon HD USB Webkamera Svart","type":"webpage","URL":"https://www.dustin.no/product/5011193629/hd?tab=specification"},{"id":"ealyEarTrumpetsResonance1994","accessed":{"date-parts":[["2020",10,12]]},"author":[{"family":"Ealy","given":"George Thomas"}],"citation-key":"ealyEarTrumpetsResonance1994","container-title":"19th-Century Music","DOI":"10.2307/746569","ISSN":"0148-2076","issue":"3","issued":{"date-parts":[["1994",4,1]]},"language":"en","page":"262-273","source":"DOI.org (Crossref)","title":"Of Ear Trumpets and a Resonance Plate: Early Hearing Aids and Beethoven's Hearing Perception","title-short":"Of Ear Trumpets and a Resonance Plate","type":"article-journal","URL":"https://online.ucpress.edu/ncm/article/17/3/262/69178/Of-Ear-Trumpets-and-a-Resonance-Plate-Early","volume":"17"},{"id":"echeverriaHuCETAFrameworkHumanCentered2023","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Echeverria","given":"Vanessa"},{"family":"Martinez-Maldonado","given":"Roberto"},{"family":"Yan","given":"Lixiang"},{"family":"Zhao","given":"Linxuan"},{"family":"Fernandez-Nieto","given":"Gloria"},{"family":"Gašević","given":"Dragan"},{"family":"Shum","given":"Simon Buckingham"}],"citation-key":"echeverriaHuCETAFrameworkHumanCentered2023","container-title":"IEEE Pervasive Computing","container-title-short":"IEEE Pervasive Comput.","DOI":"10.1109/MPRV.2022.3217454","ISSN":"1536-1268, 1558-2590","issue":"1","issued":{"date-parts":[["2023",1,1]]},"license":"https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html","page":"39-49","source":"DOI.org (Crossref)","title":"HuCETA: A Framework for Human-Centered Embodied Teamwork Analytics","title-short":"HuCETA","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/9965572/","volume":"22"},{"id":"eckMovementMaterialSpace2017","accessed":{"date-parts":[["2021",10,7]]},"archive":"Bloomsbury Collections","author":[{"family":"Eck","given":"Cathy","dropping-particle":"van"}],"citation-key":"eckMovementMaterialSpace2017","container-title":"Between Air and Electricity : Microphones and Loudspeakers as Musical Instruments","edition":"1","event-place":"New York","ISBN":"978-1-5013-2763-6","issued":{"date-parts":[["2017"]]},"language":"en","page":"83-144","publisher":"Bloomsbury Academic","publisher-place":"New York","title":"Movement, Material and Space: Interacting with Microphones and Loudspeakers","type":"chapter","URL":"http://www.bloomsburycollections.com/book/between-air-and-electricity-microphones-and-loudspeakers-as-musical-instruments/ch4-movement-material-and-space-interacting-with-microphones-and-loudspeakers/"},{"id":"eckReproducingSupportingGenerating2017","accessed":{"date-parts":[["2021",10,7]]},"archive":"Bloomsbury Collections","author":[{"family":"Eck","given":"Cathy","dropping-particle":"van"}],"citation-key":"eckReproducingSupportingGenerating2017","container-title":"Between Air and Electricity : Microphones and Loudspeakers as Musical Instruments","edition":"1","event-place":"New York","ISBN":"978-1-5013-2763-6","issued":{"date-parts":[["2017"]]},"language":"en","page":"25-54","publisher":"Bloomsbury Academic","publisher-place":"New York","title":"Reproducing – Supporting – Generating – Interacting: Four Approaches towards Microphones and Loudspeakers","type":"chapter","URL":"http://www.bloomsburycollections.com/book/between-air-and-electricity-microphones-and-loudspeakers-as-musical-instruments/ch2-reproducing-supporting-generating-interacting-four-approaches-towards-microphones-and-loudspeakers/"},{"id":"eddyBriefHistorySomatic2009","abstract":"This article outlines the historical development of somatic movement practices especially as they relate to dance, dancers, and dance education organizations. It begins with historical events, cultural trends, and individual occurrences that led up to the emergence of the classic somatic methods at the turn of the twentieth century (Alexander to Trager). It then defines somatic movement education and therapy, and the growth of three generations of somatic movement programmes. Interview data reveals how a second generation included a large proportion of dancers and speaks to how the bodymind thinking of dance professionals continues to shape the training and development of somatic education, as well as dance somatics. Finally it raises the question of the marginalizing of both dance and somatic education, and points to combining forces with their shared characteristics to alter this location in western culture. Another finding seeks to assess the potency and placement of somatic dance in a global schema.","author":[{"family":"Eddy","given":"Martha"}],"citation-key":"eddyBriefHistorySomatic2009","container-title":"Journal of Dance &amp; Somatic Practices","DOI":"https://doi.org/10.1386/jdsp.1.1.5_1","ISSN":"1757-188X","issue":"1","issued":{"date-parts":[["2009"]]},"page":"5-27","publisher":"Intellect","title":"A brief history of somatic practices and dance: historical development of the field of somatic education and its relationship to dance","type":"Journal article","URL":"https://intellectdiscover.com/content/journals/10.1386/jdsp.1.1.5_1","volume":"1"},{"id":"editorBloodSugarLevel2019","accessed":{"date-parts":[["2021",10,11]]},"author":[{"literal":"Editor"}],"citation-key":"editorBloodSugarLevel2019","container-title":"Diabetes.co.uk","issued":{"date-parts":[["2019",1,15]]},"title":"Blood Sugar Level Ranges","type":"webpage","URL":"https://www.diabetes.co.uk/diabetes_care/blood-sugar-level-ranges.html"},{"id":"edwardsLowLatencyFilteringKinect2014","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Edwards","given":"Matthew"},{"family":"Green","given":"Richard"}],"citation-key":"edwardsLowLatencyFilteringKinect2014","container-title":"Proceedings of the 29th International Conference on Image and Vision Computing New Zealand","DOI":"10.1145/2683405.2683453","event-place":"Hamilton New Zealand","event-title":"IVCNZ '14: The 29th International Conference on Image and Vision Computing New Zealand","ISBN":"978-1-4503-3184-5","issued":{"date-parts":[["2014",11,19]]},"language":"en","page":"190-195","publisher":"ACM","publisher-place":"Hamilton New Zealand","source":"DOI.org (Crossref)","title":"Low-Latency Filtering of Kinect Skeleton Data for Video Game Control","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/2683405.2683453"},{"id":"ehatisham-ul-haqRobustHumanActivity2019","accessed":{"date-parts":[["2024",8,24]]},"author":[{"family":"Ehatisham-Ul-Haq","given":"Muhammad"},{"family":"Javed","given":"Ali"},{"family":"Azam","given":"Muhammad Awais"},{"family":"Malik","given":"Hafiz M. A."},{"family":"Irtaza","given":"Aun"},{"family":"Lee","given":"Ik Hyun"},{"family":"Mahmood","given":"Muhammad Tariq"}],"citation-key":"ehatisham-ul-haqRobustHumanActivity2019","container-title":"IEEE Access","container-title-short":"IEEE Access","DOI":"10.1109/ACCESS.2019.2913393","ISSN":"2169-3536","issued":{"date-parts":[["2019"]]},"license":"https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/OAPA.html","page":"60736-60751","source":"DOI.org (Crossref)","title":"Robust Human Activity Recognition Using Multimodal Feature-Level Fusion","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/8701429/","volume":"7"},{"id":"eldridgeSelfResonatingFeedbackCello2017","abstract":"The Feedback Cello is a new electroacoustic actuated instrument in which feedback can be induced independently on each string. Built from retro-fitted acoustic cellos, the signals from electromagnetic pickups sitting under each string are passed to a speaker built into the back of the instrument and to transducers clamped in varying places across the instrument body. Placement of acoustic and mechanical actuators on the resonant body of the cello mean that this simple analogue feedback system is capable of a wide range of complex self-resonating behaviours. This paper describes the motivations for building these instruments as both a physical extension to live coding practice and an electroacoustic augmentation of cello. The design and physical construction is outlined, and modes of performance described with reference to the first six months of performances and installations. Future developments and planned investigations are outlined.","accessed":{"date-parts":[["2023",1,15]]},"author":[{"family":"Eldridge","given":"Alice"},{"family":"Kiefer","given":"Chris"}],"citation-key":"eldridgeSelfResonatingFeedbackCello2017","DOI":"10.5281/ZENODO.1176157","issued":{"date-parts":[["2017",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"Self-Resonating Feedback Cello: Interfacing Gestural And Generative Processes In Improvised Performance","title-short":"Self-Resonating Feedback Cello","type":"article-journal","URL":"https://zenodo.org/record/1176157"},{"id":"eldridgeSelfresonatingVibrotactileFeedback2021","accessed":{"date-parts":[["2023",1,15]]},"author":[{"family":"Eldridge","given":"Alice"},{"family":"Kiefer","given":"Chris"},{"family":"Overholt","given":"Dan"},{"family":"Ulfarsson","given":"Halldor"}],"citation-key":"eldridgeSelfresonatingVibrotactileFeedback2021","container-title":"NIME 2021","DOI":"10.21428/92fbeb44.1f29a09e","event-place":"Shanghai, China","event-title":"NIME 2021","issued":{"date-parts":[["2021",6,1]]},"publisher":"PubPub","publisher-place":"Shanghai, China","source":"DOI.org (Crossref)","title":"Self-resonating Vibrotactile Feedback Instruments ||: Making, Playing, Conceptualising :||","title-short":"Self-resonating Vibrotactile Feedback Instruments ||","type":"paper-conference","URL":"https://nime.pubpub.org/pub/6mhrjiqt"},{"id":"elfataHowMuchResidual2009","author":[{"family":"El Fata","given":"Fouad"},{"family":"James","given":"Chris J."},{"family":"Laborde","given":"Marie-Laurence"},{"family":"Fraysse","given":"Bernard"}],"citation-key":"elfataHowMuchResidual2009","container-title":"Audiology and Neurotology","container-title-short":"Audiology and Neurotology","ISSN":"1420-3030","issue":"Suppl. 1","issued":{"date-parts":[["2009"]]},"page":"14-21","publisher":"Karger Publishers","title":"How Much Residual Hearing is ‘Useful’for Music Perception with Cochlear Implants?","type":"article-journal","volume":"14"},{"id":"elrahebBalOnSeBalletOntology2016","abstract":"In this paper we present BalOnSe (named after the ballet step balance), an ontology-based web interface that allows the user to annotate classical ballet videos, with a hierarchical domain specific vocabulary and provides an archival system for videos of dance. The interface integrates a hierarchical vocabulary based on classical ballet syllabus terminology (Ballet.owl) implemented as an OWL-2 ontology. BalOnSe supports the search and browsing of the multimedia content using metadata (title, dancer featured, etc.), and also implements the functionality of \"searching by movement concepts\", i.e., filtering the videos that are associated with particular required terms of the vocabulary, based on previous submitted annotations. In the paper, we present the ballet.owl ontology, and its structure, explaining the conceptual modeling decisions. We highlight the main functionality of the system and finally, we present how the manual ontology guided annotation allows the user to search the content through the vocabularies and also view statistics in the form of tag clouds.","author":[{"family":"El Raheb","given":"Katerina"},{"family":"Papapetrou","given":"Nicolas"},{"family":"Katifori","given":"Vivi"},{"family":"Ioannidis","given":"Yannis"}],"citation-key":"elrahebBalOnSeBalletOntology2016","collection-title":"MOCO '16","container-title":"Proceedings of the 3rd international symposium on movement and computing","DOI":"10.1145/2948910.2948926","event-place":"Thessaloniki, GA, Greece","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Thessaloniki, GA, Greece","title":"BalOnSe: Ballet ontology for annotating and searching video performances","type":"paper-conference","URL":"https://doi.org/10.1145/2948910.2948926"},{"id":"elrahebConceptualFrameworkCreating2018","abstract":"As they are mainly based on bodily experiences and embodied knowledge, dance and movement practices present a great diversity and complexity across genre and context. Thus, developing a conceptual framework for archiving, managing, curating and analysing movement data, in order to develop reusable datasets and algorithms for a variety of purposes, remains a challenge. In this work, based on relevant literature on movement representation and existing systems such as Laban Movement Analysis, as well as working with dance experts through workshops, focus groups, and interviews, we propose a conceptual framework for creating, and analysing dance learning content. The conceptual framework, has been developed within an interdisciplinary project, that brings together technology and human computer interaction researchers, computer science engineers, motion capture experts from industry and academia, as well as dance experts with background on four different dance genres: contemporary, ballet, Greek folk, and flamenco. The framework has been applied: a) as a guidance to systematically create a movement library with multimodal recordings for dance education, including four different dance genres, b) as the basis for developing controlled vocabularies of dance for manual and automated annotation, and c) as the conceptual framework to define the requirements for similarity search and feature extraction.","author":[{"family":"El Raheb","given":"Katerina"},{"family":"Whatley","given":"Sarah"},{"family":"Camurri","given":"Antonio"}],"citation-key":"elrahebConceptualFrameworkCreating2018","collection-title":"MOCO '18","container-title":"Proceedings of the 5th international conference on movement and computing","DOI":"10.1145/3212721.3212837","event-place":"Genoa, Italy","ISBN":"978-1-4503-6504-8","issued":{"date-parts":[["2018"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Genoa, Italy","title":"A conceptual framework for creating and analyzing dance learning digital content","type":"paper-conference","URL":"https://doi.org/10.1145/3212721.3212837"},{"id":"elrahebDanceNotationConceptual2014","abstract":"In this paper, we discuss the key elements of a semantic dance-move representation model based on rule-based extractions of logical descriptions from existing Labanotation scores. This is part of a larger effort on representing and analyzing dance movement based on choreological approaches and notation systems. The main goal is to develop a Knowledge-Based System that provides functionality (a) to search by movement concepts and characteristics in a meaningful way for dance practitioners, who may not necessarily be specialists in notation or analysis, and (b) to link different manifestations of movement recordings, especially Labanotation scores. We use examples to highlight the primary and abstract representation model and outline the main challenges in interpreting and segmenting a Labanotation score to transform it in a semi-automated way into a sequence of meaningful recognizable movement concepts. We are not aiming to develop an alternative notation system, but to construct a model and methodology to access existing scores (in digital form) and exploit the underlying information about movement for further computational analysis. We take into account some existing choreological approaches, which use an analogy between dance structure analysis and morphological language studies, and identify multiple levels of describing dance and movement. Finally, we discuss limitations of our approach as well as potential uses of the \"search by movement\" idea and outline some theoretical observations that emerged during this work.","author":[{"family":"El Raheb","given":"Katerina"},{"family":"Ioannidis","given":"Yannis"}],"citation-key":"elrahebDanceNotationConceptual2014","collection-title":"MOCO '14","container-title":"Proceedings of the 2014 international workshop on movement and computing","DOI":"10.1145/2617995.2618000","event-place":"Paris, France","ISBN":"978-1-4503-2814-2","issued":{"date-parts":[["2014"]]},"number-of-pages":"6","page":"25–30","publisher":"Association for Computing Machinery","publisher-place":"Paris, France","title":"From dance notation to conceptual models: A multilayer approach","type":"paper-conference","URL":"https://doi.org/10.1145/2617995.2618000"},{"id":"elrahebWebbasedSystemAnnotation2018","abstract":"Recent advances in technologies for capturing, analyzing and visualizing movement can revolutionize the way we create, practice, learn dance, and transmit bodily knowledge. The need for creating meaningful, searchable and re-usable libraries of motion capture and video movement segments can only be fulfilled through the collaboration of both technologists and dance practitioners. Towards this direction, manual annotations of these segments by dance experts can play a four-fold role: a) enrich movement libraries with expert knowledge, b) create \"ground-truth\" datasets for comparing the results of automated algorithms, c) fertilize a dialogue across dance genres and disciplines on movement analysis and conceptualization, and d) raise questions on the subjectivity and diversity of characterizing movement segments using verbal descriptions. The web-based application presented in this work, is an archival system with, browsing, searching, visualization, personalization and textual annotation functionalities. Its main objective is to provide access to a repository of multimodal dance recordings including motion capture data, video, and audio, with the aim to also support dance education. The tool has been designed and developed within an interdisciplinary project, following a user-centered, iterative design approach involving dance researchers and practitioners of four different dance genres.","author":[{"family":"El Raheb","given":"Katerina"},{"family":"Kasomoulis","given":"Aristotelis"},{"family":"Katifori","given":"Akrivi"},{"family":"Rezkalla","given":"Marianna"},{"family":"Ioannidis","given":"Yannis"}],"citation-key":"elrahebWebbasedSystemAnnotation2018","collection-title":"MOCO '18","container-title":"Proceedings of the 5th international conference on movement and computing","DOI":"10.1145/3212721.3212722","event-place":"Genoa, Italy","ISBN":"978-1-4503-6504-8","issued":{"date-parts":[["2018"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Genoa, Italy","title":"A web-based system for annotation of dance multimodal recordings by dance practitioners and experts","type":"paper-conference","URL":"https://doi.org/10.1145/3212721.3212722"},{"id":"emersonExploringMotivationsBuilding2020","abstract":"Over the past four decades, the number, diversity and complexity of digital musical instruments (DMIs) has increased rapidly. There are very few constraints on DMI design as such systems can be easily reconfigured, offering near limitless flexibility for music-making. Given that new acoustic musical instruments have in many cases been created in response to the limitations of available technologies, what motivates the development of new DMIs? We conducted an interview study with ten designers of new DMIs, in order to explore (a) the motivations electronic musicians may have for wanting to build their own instruments; and (b) the extent to which these motivations relate to the context in which the artist works and performs (academic vs club settings). We found that four categories of motivation were mentioned most often: M1 ? wanting to bring greater embodiment to the activity of performing and producing electronic music; M2 ? wanting to improve audience experiences of DMI performances; M3 ? wanting to develop new sounds, and M4 ? wanting to build responsive systems for improvisation. There were also some detectable trends in motivation according to the context in which the artists work and perform. Our results offer the first systematically gathered insights into the motivations for new DMI design. It appears that the challenges of controlling digital sound synthesis drive the development of new DMIs, rather than the shortcomings of any one particular design or existing technology.","accessed":{"date-parts":[["2022",12,8]]},"author":[{"family":"Emerson","given":"Gina"},{"family":"Egermann","given":"Hauke"}],"citation-key":"emersonExploringMotivationsBuilding2020","container-title":"Musicae Scientiae","DOI":"10.1177/1029864918802983","ISSN":"1029-8649","issue":"3","issued":{"date-parts":[["2020",9,1]]},"page":"313-329","publisher":"SAGE Publications Ltd","title":"Exploring the motivations for building new digital musical instruments","type":"article-journal","URL":"https://doi.org/10.1177/1029864918802983","volume":"24"},{"id":"endoAutomaticDanceVideo2024","abstract":"Segmenting dance video into short movements is a popular way to easily understand dance choreography. However, it is currently done manually and requires a significant amount of effort by experts. That is, even if many dance videos are available on social media (e.g., TikTok and YouTube), it remains difficult for people, especially novices, to casually watch short video segments to practice dance choreography. In this paper, we propose a method to automatically segment a dance video into each movement. Given a dance video as input, we first extract visual and audio features: the former is computed from the keypoints of the dancer in the video, and the latter is computed from the Mel spectrogram of the music in the video. Next, these features are passed to a Temporal Convolutional Network (TCN), and segmentation points are estimated by picking peaks of the network output. To build our training dataset, we annotate segmentation points to dance videos in the AIST Dance Video Database, which is a shared database containing original street dance videos with copyright-cleared dance music. The evaluation study shows that the proposed method (i.e., combining the visual and audio features) can estimate segmentation points with high accuracy. In addition, we developed an application to help dancers practice choreography using the proposed method.","accessed":{"date-parts":[["2024",9,2]]},"author":[{"family":"Endo","given":"Koki"},{"family":"Tsuchida","given":"Shuhei"},{"family":"Fukusato","given":"Tsukasa"},{"family":"Igarashi","given":"Takeo"}],"citation-key":"endoAutomaticDanceVideo2024","container-title":"Proceedings of the 9th International Conference on Movement and Computing","DOI":"10.1145/3658852.3659076","event-place":"Utrecht Netherlands","event-title":"MOCO '24: 9th International Conference on Movement and Computing","ISBN":"979-8-4007-0994-4","issued":{"date-parts":[["2024",5,30]]},"language":"en","page":"1-9","publisher":"ACM","publisher-place":"Utrecht Netherlands","source":"DOI.org (Crossref)","title":"Automatic Dance Video Segmentation for Understanding Choreography","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3658852.3659076"},{"id":"erdemCAVICoadaptiveAudiovisual2022","accessed":{"date-parts":[["2023",10,11]]},"author":[{"family":"Erdem","given":"Cagri"},{"family":"Wallace","given":"Benedikte"},{"family":"Jensenius","given":"Alexander Refsum"}],"citation-key":"erdemCAVICoadaptiveAudiovisual2022","container-title":"NIME 2022","DOI":"10.21428/92fbeb44.803c24dd","event-place":"The University of Auckland, New Zealand","event-title":"NIME 2022","issued":{"date-parts":[["2022",6,28]]},"publisher":"PubPub","publisher-place":"The University of Auckland, New Zealand","source":"DOI.org (Crossref)","title":"CAVI: A Coadaptive Audiovisual Instrument–Composition","title-short":"CAVI","type":"paper-conference","URL":"https://nime.pubpub.org/pub/cavi"},{"id":"erkutEmbodiedInteractionMovement2017","abstract":"Designing for and through movement is becoming increasingly important in human computer interaction, and it is widely accepted that the designers should develop their bodily skills and learn how to use the movement as design material. Yet, the reports on the education space around embodied interaction are scarce. We present an approach for teaching and designing embodied interaction in collaboration with contemporary dance choreographers. We describe a workshop, where after movement sessions, simple projects were implemented by the participants. The evaluation of projects and student feedback indicate that the four learning objectives, namely: 1) movement as a design material, 2) bodily skills needed for technological implementation, 3) movement qualities, and 4) practical projects, were attained for most of the participants. For some participants, however, the movement qualities were hard concepts to grasp and utilize in design, and this difficulty had an impact on all the other learning objectives. Further experiments with new tools, techniques, contexts, and guidelines are therefore required to highlight the importance of movement qualities in design.","author":[{"family":"Erkut","given":"Cumhur"},{"family":"Dahl","given":"Sofia"}],"citation-key":"erkutEmbodiedInteractionMovement2017","collection-title":"MOCO '17","container-title":"Proceedings of the 4th international conference on movement computing","DOI":"10.1145/3077981.3078026","event-place":"London, United Kingdom","ISBN":"978-1-4503-5209-3","issued":{"date-parts":[["2017"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"London, United Kingdom","title":"Embodied interaction through movement in a course work","type":"paper-conference","URL":"https://doi.org/10.1145/3077981.3078026"},{"id":"erkutIncorporatingVirtualReality2018","abstract":"Engagement with virtual reality (VR) through movement is becoming increasingly important. Therefore, the VR developers should improve their bodily skills and learn how to use the movement as design material. In addition, first person accounts of the development and experience are necessary. We explore the education space in VR with attention to the first-person experiences, movement data and code, and present an approach for teaching and designing VR-based embodied interaction.","author":[{"family":"Erkut","given":"Cumhur"},{"family":"Dahl","given":"Sofia"}],"citation-key":"erkutIncorporatingVirtualReality2018","collection-title":"MOCO '18","container-title":"Proceedings of the 5th international conference on movement and computing","DOI":"10.1145/3212721.3212884","event-place":"Genoa, Italy","ISBN":"978-1-4503-6504-8","issued":{"date-parts":[["2018"]]},"number-of-pages":"6","publisher":"Association for Computing Machinery","publisher-place":"Genoa, Italy","title":"Incorporating virtual reality in an embodied interaction course","type":"paper-conference","URL":"https://doi.org/10.1145/3212721.3212884"},{"id":"evansCLARITTRECExperiments1995","abstract":"The CLARIT-TREC 2 system, the official processing results, and the results of experiments in system parameterization are presented. CLARIT-TREC 2 results demonstrate high precision and excellent recall in both the manual and automatic modes of processing. In addition, CLARIT query augmentation, using CLARIT thesaurus-discovery techniques, is a general technique that may be of benefit in all information-retrieval contexts. Because the technique is fully automatic, it can be applied either at the time of query formulation (if exemplary relevant texts are known) or at the time of first-pass retrieval. The CLARIT-TREC 2 system is not yet optimized. In several experiments, 2 simple adjustments to CLARIT parameters have been identified. These adjustments improve performance beyond the CLARIT-TREC 2 system baseline. Other improvements are possible. Many text processing functions currently available in the CLARIT system were not used in TREC-2 documents.","author":[{"family":"Evans","given":"David A."},{"family":"Lefferts","given":"Robert G."}],"citation-key":"evansCLARITTRECExperiments1995","container-title":"Information processing & management","container-title-short":"INFORM PROCESS MANAG","DOI":"10.1016/0306-4573(94)00054-7","event-place":"OXFORD","ISSN":"0306-4573","issue":"3","issued":{"date-parts":[["1995"]]},"page":"385-395","publisher":"OXFORD: Elsevier Ltd","publisher-place":"OXFORD","title":"CLARIT-TREC experiments","type":"article-journal","volume":"31"},{"id":"farnellDesigningSound2010","author":[{"family":"Farnell","given":"Andy"}],"call-number":"TK7881.4 .F365 2010","citation-key":"farnellDesigningSound2010","event-place":"Cambridge, Mass","ISBN":"978-0-262-01441-0","issued":{"date-parts":[["2010"]]},"note":"OCLC: ocn494275436","number-of-pages":"664","publisher":"MIT Press","publisher-place":"Cambridge, Mass","source":"Library of Congress ISBN","title":"Designing sound","type":"book"},{"id":"fascianiVoiceControlledInterface2014","abstract":"In recent decades, the sonic capabilities of digital musical instruments have significantly increased and today musicians confront a very high dimensional control space for interacting with these complex devices. The exploitation of the musical potential represents a significant challenge, as can be appreciated by surveying the proliferation of novel interfaces and techniques to map the performer gesture to instrument controls. Body gesture and in particular hand interaction have intrinsic limits on the number of instrument parameters that can be controlled simultaneously. This thesis proposes an approach in which gestures derived from the vocal timbre are used to extend common musical interfaces, providing an additional control layer for any sound synthesis or processing device. The software system embodying the techniques described in this thesis provides a novel end-to-end solution to implement ad hoc vocal interfaces, engendering new paradigms in musical performances that better exploit creativity and virtuosity.","author":[{"family":"Fasciani","given":"Stefano"}],"citation-key":"fascianiVoiceControlledInterface2014","genre":"Ph.D Thesis","issued":{"date-parts":[["2014"]]},"title":"Voice controlled interface for digital musical instrument","type":"thesis","URL":"https://scholarbank.nus.edu.sg/handle/10635/118256"},{"id":"fdilialaouiChiselingBodiesAugmented2013","accessed":{"date-parts":[["2023",11,13]]},"author":[{"family":"Fdili Alaoui","given":"Sarah"},{"family":"Jacquemin","given":"Christian"},{"family":"Bevilacqua","given":"Frédéric"}],"citation-key":"fdilialaouiChiselingBodiesAugmented2013","container-title":"CHI '13 Extended Abstracts on Human Factors in Computing Systems","DOI":"10.1145/2468356.2479573","event-place":"Paris France","event-title":"CHI '13: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-1952-2","issued":{"date-parts":[["2013",4,27]]},"language":"en","page":"2915-2918","publisher":"ACM","publisher-place":"Paris France","source":"DOI.org (Crossref)","title":"Chiseling bodies: an augmented dance performance","title-short":"Chiseling bodies","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/2468356.2479573"},{"id":"fdilialaouiHowExpertsObserve2015","abstract":"Laban Movement Analysis (LMA) is an expert-based method by which Certified Movement Analysts observe and analyze movement. LMA is increasingly used in a variety of research fields, particularly when studying movement expressivity and computation where it is essential to generate an understanding of the observation process. In this paper we articulate the application of LMA as a tool for movement analysis in HCI research by using qualitative methods to deconstruct the observation process of LMA experts. We conducted a focus group in which 12 expert-participants observed and annotated videos of movement according to LMA categories. We transcribed their observation process and analyzed it using grounded theory in order to extract categories, concepts and theories that best explain and describe the process of observation in LMA. By doing so, we open research perspectives in which LMA can be integrated as a method for observation in the design of movement-based computational systems.","author":[{"family":"Fdili Alaoui","given":"Sarah"},{"family":"Carlson","given":"Kristin"},{"family":"Cuykendall","given":"Shannon"},{"family":"Bradley","given":"Karen"},{"family":"Studd","given":"Karen"},{"family":"Schiphorst","given":"Thecla"}],"citation-key":"fdilialaouiHowExpertsObserve2015","collection-title":"MOCO '15","container-title":"Proceedings of the 2nd international workshop on movement and computing","DOI":"10.1145/2790994.2791000","event-place":"Vancouver, British Columbia, Canada","ISBN":"978-1-4503-3457-0","issued":{"date-parts":[["2015"]]},"number-of-pages":"8","page":"84–91","publisher":"Association for Computing Machinery","publisher-place":"Vancouver, British Columbia, Canada","title":"How do experts observe movement?","type":"paper-conference","URL":"https://doi.org/10.1145/2790994.2791000"},{"id":"fdilialaouiMakingInteractiveDance2019","accessed":{"date-parts":[["2023",2,26]]},"author":[{"family":"Fdili Alaoui","given":"Sarah"}],"citation-key":"fdilialaouiMakingInteractiveDance2019","container-title":"Proceedings of the 2019 on Designing Interactive Systems Conference","DOI":"10.1145/3322276.3322289","event-place":"San Diego CA USA","event-title":"DIS '19: Designing Interactive Systems Conference 2019","ISBN":"978-1-4503-5850-7","issued":{"date-parts":[["2019",6,18]]},"language":"en","page":"1195-1208","publisher":"ACM","publisher-place":"San Diego CA USA","source":"DOI.org (Crossref)","title":"Making an Interactive Dance Piece: Tensions in Integrating Technology in Art","title-short":"Making an Interactive Dance Piece","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3322276.3322289"},{"id":"federiciAssistiveTechnologyAssessment2018","call-number":"RM950 .A873 2018","citation-key":"federiciAssistiveTechnologyAssessment2018","collection-title":"Rehabilitation science in practice series","edition":"Second edition","editor":[{"family":"Federici","given":"Stefano"},{"family":"Scherer","given":"Marcia J."}],"event-place":"Boca Raton","ISBN":"978-1-4987-7411-6","issued":{"date-parts":[["2018"]]},"publisher":"CRC Press, Taylor & Francis Group,CRC Press is and imprint of the Taylor & Francis Group, an informa business","publisher-place":"Boca Raton","source":"Library of Congress ISBN","title":"Assistive Technology Assessment Handbook","type":"book"},{"id":"fehrIndirectionMovementSound2015","abstract":"We present a new interactive sound installation to be explored by movement, specifically by the movement qualities extracted from the motion tracking data. There is an indirection between movement and sound: movement qualities control a dynamical system (in our case a flock of agents), which in turn controls the visual and sonic feedback of the interface. The movement qualities are extracted by simple measures. The system is implemented, evaluated, and will be demonstrated during MOCO'15.","author":[{"family":"Fehr","given":"Jonas"},{"family":"Erkut","given":"Cumhur"}],"citation-key":"fehrIndirectionMovementSound2015","collection-title":"MOCO '15","container-title":"Proceedings of the 2nd international workshop on movement and computing","DOI":"10.1145/2790994.2791016","event-place":"Vancouver, British Columbia, Canada","ISBN":"978-1-4503-3457-0","issued":{"date-parts":[["2015"]]},"number-of-pages":"4","page":"160–163","publisher":"Association for Computing Machinery","publisher-place":"Vancouver, British Columbia, Canada","title":"Indirection between movement and sound in an interactive sound installation","type":"paper-conference","URL":"https://doi.org/10.1145/2790994.2791016"},{"id":"feldnerRememberingBerlinDavid2022","author":[{"family":"Feldner","given":"Maximilian"}],"citation-key":"feldnerRememberingBerlinDavid2022","container-title":"Popular Music and Society","container-title-short":"Popular Music and Society","DOI":"10.1080/03007766.2021.1980322","ISSN":"0300-7766","issue":"2","issued":{"date-parts":[["2022",3,15]]},"page":"129-145","publisher":"Routledge","title":"Remembering Berlin: David Bowie’s “‘Heroes’” (1977)","type":"article-journal","URL":"https://doi.org/10.1080/03007766.2021.1980322","volume":"45"},{"id":"felsDesigningIntimacyCreating2004","author":[{"family":"Fels","given":"Sidney"}],"citation-key":"felsDesigningIntimacyCreating2004","container-title":"Proceedings of the IEEE","container-title-short":"Proceedings of the IEEE","ISSN":"0018-9219","issue":"4","issued":{"date-parts":[["2004"]]},"page":"672-685","publisher":"IEEE","title":"Designing for intimacy: Creating new interfaces for musical expression","type":"article-journal","volume":"92"},{"id":"felsIntimacyEmbodimentImplications2000","accessed":{"date-parts":[["2023",11,20]]},"author":[{"family":"Fels","given":"Sidney"}],"citation-key":"felsIntimacyEmbodimentImplications2000","container-title":"Proceedings of the 2000 ACM workshops on Multimedia","DOI":"10.1145/357744.357749","event-place":"Los Angeles California USA","event-title":"MM00: ACM Multimedia 2000","ISBN":"978-1-58113-311-0","issued":{"date-parts":[["2000",11,4]]},"language":"en","page":"13-16","publisher":"ACM","publisher-place":"Los Angeles California USA","source":"DOI.org (Crossref)","title":"Intimacy and embodiment: implications for art and technology","title-short":"Intimacy and embodiment","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/357744.357749"},{"id":"felsMappingTransparencyMetaphor2002","abstract":"We define a two-axis transparency framework that can be used as a predictor of the expressivity of a musical device. One axis is the player's transparency scale, while the other is the audience's transparency scale. Through consideration of both traditional instruments and new technology-driven interfaces, we explore the role that metaphor plays in developing expressive devices. Metaphor depends on a literature, which forms the basis for making transparent device mappings. We examine four examples of systems that use metaphor: Iamascope, Sound Sculpting, MetaMuse and Glove-TalkII; and discuss implications on transparency and expressivity. We believe this theory provides a framework for design and evaluation of new human–machine and human–human interactions, including musical instruments.","archive":"Cambridge Core","author":[{"family":"Fels","given":"Sidney"},{"family":"Gadd","given":"Ashley"},{"family":"Mulder","given":"Axel"}],"citation-key":"felsMappingTransparencyMetaphor2002","container-title":"Organised Sound","DOI":"10.1017/S1355771802002042","edition":"2003/01/17","ISSN":"1355-7718","issue":"2","issued":{"date-parts":[["2002"]]},"page":"109-126","publisher":"Cambridge University Press","source":"Cambridge University Press","title":"Mapping transparency through metaphor: towards more expressive musical instruments","type":"article-journal","URL":"https://www.cambridge.org/core/article/mapping-transparency-through-metaphor-towards-more-expressive-musical-instruments/6A0DCDB0E31E7C01AEEA29427EA7F42A","volume":"7"},{"id":"feyerabendMethod2010","author":[{"family":"Feyerabend","given":"Paul"}],"citation-key":"feyerabendMethod2010","edition":"4. ed., new ed","event-place":"London","ISBN":"978-1-84467-442-8 978-1-84467-443-5","issued":{"date-parts":[["2010"]]},"language":"eng","note":"Originally published 1975","number-of-pages":"296","publisher":"Verso","publisher-place":"London","source":"K10plus ISBN","title":"Against method","type":"book"},{"id":"fiebrinkMachineLearningAlgorithm2018","abstract":"Machine learning is the capacity of a computational system to learn structure from data in order to make predictions on new data. This chapter draws on music, machine learning, and human-computer interaction to elucidate an understanding of machine learning algorithms as creative tools for music and the sonic arts. It motivates a new understanding of learning algorithms as human-computer interfaces: like other interfaces, learning algorithms can be characterized by the ways their affordances intersect with goals of human users. The chapter also argues that the nature of interaction between users and algorithms impacts the usability and usefulness of those algorithms in profound ways. This human-centred view of machine learning motivates a concluding discussion of what it means to employ machine learning as a creative tool.","accessed":{"date-parts":[["2022",4,25]]},"author":[{"family":"Fiebrink","given":"Rebecca A."},{"family":"Caramiaux","given":"Baptiste"}],"citation-key":"fiebrinkMachineLearningAlgorithm2018","container-title":"The Oxford Handbook of Algorithmic Music","DOI":"10.1093/oxfordhb/9780190226992.013.23","editor":[{"family":"Dean","given":"Roger T."},{"family":"McLean","given":"Alex"}],"issued":{"date-parts":[["2018",2,5]]},"language":"en","page":"181-208","publisher":"Oxford University Press","source":"DOI.org (Crossref)","title":"The Machine Learning Algorithm as Creative Musical Tool","type":"chapter","URL":"http://oxfordhandbooks.com/view/10.1093/oxfordhb/9780190226992.001.0001/oxfordhb-9780190226992-e-23"},{"id":"fiebrinkReflectionsEightYears2020","author":[{"family":"Fiebrink","given":"Rebecca"},{"family":"Sonami","given":"Laetitia"}],"citation-key":"fiebrinkReflectionsEightYears2020","container-title":"Proceedings of the International Conference on New Interfaces for Musical Expression","DOI":"10.5281/zenodo.4813334","editor":[{"family":"Michon","given":"Romain"},{"family":"Schroeder","given":"Franziska"}],"event-place":"Birmingham, UK","event-title":"NIME","issued":{"date-parts":[["2020"]]},"page":"237-242","publisher":"Goldsmiths, University of London","publisher-place":"Birmingham, UK","title":"Reflections on eight years of instrument creation with machine learning","type":"paper-conference","URL":"https://www.nime.org/proceedings/2020/nime2020_paper45.pdf"},{"id":"fiebrinkWekinatorSystemRealtime2010","author":[{"family":"Fiebrink","given":"Rebecca"},{"family":"Cook","given":"Perry R"}],"citation-key":"fiebrinkWekinatorSystemRealtime2010","event-title":"Proceedings of The Eleventh International Society for Music Information Retrieval Conference (ISMIR 2010)(Utrecht)","issued":{"date-parts":[["2010"]]},"title":"The Wekinator: a system for real-time, interactive machine learning in music","type":"paper-conference","volume":"3"},{"id":"filmflySignmarkDeafMan2010","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Filmfly"}],"citation-key":"filmflySignmarkDeafMan2010","container-title":"Vimeo","issued":{"date-parts":[["2010"]]},"title":"Signmark - Deaf Man’s Blues","type":"webpage","URL":"https://vimeo.com/18116887"},{"id":"filmflySignmarkMissRhythm2010","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Filmfly"}],"citation-key":"filmflySignmarkMissRhythm2010","container-title":"Vimeo","issued":{"date-parts":[["2010"]]},"title":"Signmark - Miss Rhythm","type":"webpage","URL":"https://vimeo.com/18117418"},{"id":"finleyArtsBasedResearch2007","author":[{"family":"Finley","given":"Susan"}],"call-number":"H62 .K6275 2008","citation-key":"finleyArtsBasedResearch2007","container-title":"Handbook of the arts in qualitative research: perspectives, methodologies, examples, and issues","editor":[{"family":"Knowles","given":"J. Gary"},{"family":"Cole","given":"Ardra L."}],"event-place":"Los Angeles","ISBN":"978-1-4129-0531-2","issued":{"date-parts":[["2007"]]},"note":"OCLC: ocn141187869","page":"71-81","publisher":"Sage Publications","publisher-place":"Los Angeles","source":"Library of Congress ISBN","title":"Arts-Based Research","type":"chapter"},{"id":"fischerLookingBackReader1993","citation-key":"fischerLookingBackReader1993","collection-number":"Vol. 20","collection-title":"International Studies on Sign Language and Communication of the Deaf","editor":[{"family":"Fischer","given":"Renate"},{"family":"Lane","given":"Harlan"}],"event-place":"Hamburg","ISBN":"978-3-927731-32-5","issued":{"date-parts":[["1993"]]},"language":"eng","note":"OCLC: 260206400","number-of-pages":"558","publisher":"Signum","publisher-place":"Hamburg","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"Looking Back: A Reader On the History of Deaf Communities and their Sign Languages","title-short":"Looking back","type":"book"},{"id":"fisherCapitalistRealismThere2009","author":[{"family":"Fisher","given":"Mark"}],"citation-key":"fisherCapitalistRealismThere2009","collection-title":"Zero books","event-place":"Winchester","ISBN":"978-1-84694-317-1","issued":{"date-parts":[["2009"]]},"language":"eng","note":"OCLC: 730656544","number-of-pages":"81","publisher":"O Books","publisher-place":"Winchester","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"Capitalist Realism: Is There No Alternative?","title-short":"Capitalist realism","type":"book"},{"id":"fontijnFunctionalFunTangible2007","author":[{"family":"Fontijn","given":"Willem"},{"family":"Hoonhout","given":"Jettie"}],"citation-key":"fontijnFunctionalFunTangible2007","event-title":"2007 First IEEE International Workshop on Digital Game and Intelligent Toy Enhanced Learning (DIGITEL'07)","ISBN":"0-7695-2801-5","issued":{"date-parts":[["2007"]]},"page":"119-123","publisher":"IEEE","title":"Functional fun with tangible user interfaces","type":"paper-conference"},{"id":"foucaultBirthBiopoliticsLectures2010","author":[{"family":"Foucault","given":"Michel"}],"citation-key":"foucaultBirthBiopoliticsLectures2010","collection-title":"Lectures at the Collège de France","contributor":[{"family":"Collège de France","given":""}],"edition":"1st pbk ed., [Repr.]","event-place":"New York","ISBN":"978-0-312-20341-2","issued":{"date-parts":[["2010"]]},"language":"eng","note":"OCLC: 837695755","number-of-pages":"346","publisher":"Picador","publisher-place":"New York","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"The Birth of Biopolitics: Lectures at the Collège de France, 1978 - 79","title-short":"The Birth of Biopolitics","type":"book"},{"id":"foucaultBirthClinicArchaeology1994","author":[{"family":"Foucault","given":"Michel"}],"call-number":"R133 .F6913 1994","citation-key":"foucaultBirthClinicArchaeology1994","event-place":"New York","ISBN":"978-0-679-75334-6","issued":{"date-parts":[["1994"]]},"language":"eng","number-of-pages":"215","publisher":"Vintage Books","publisher-place":"New York","source":"Library of Congress ISBN","title":"The Birth of the Clinic: An Archaeology of Medical Perception","title-short":"The Birth of the Clinic","type":"book"},{"id":"foucaultFoucaultReader2020","author":[{"family":"Foucault","given":"Michel"}],"citation-key":"foucaultFoucaultReader2020","editor":[{"family":"Rabinow","given":"Paul"}],"event-place":"Place of publication not identified","ISBN":"978-0-241-43514-4","issued":{"date-parts":[["2020"]]},"language":"English","note":"OCLC: 1130361542","number-of-pages":"390","publisher":"Penguin Books","publisher-place":"Place of publication not identified","source":"Open WorldCat","title":"The Foucault Reader","title-short":"The Foucault Reader","type":"book"},{"id":"foucaultHistorySexualityVolume1990","author":[{"family":"Foucault","given":"Michel"}],"citation-key":"foucaultHistorySexualityVolume1990","event-place":"New York","issued":{"date-parts":[["1990"]]},"publisher":"Vintage Books","publisher-place":"New York","title":"The History of Sexuality, Volume I: An Introduction","translator":[{"family":"Hurley","given":"Robert"}],"type":"book"},{"id":"foucaultSubjectPower1982","author":[{"family":"Foucault","given":"Michel"}],"citation-key":"foucaultSubjectPower1982","container-title":"Michel Foucault: Beyond Structuralism and Hermeneutics","event-place":"Chicago","issued":{"date-parts":[["1982"]]},"page":"208","publisher":"University of Chicago Press Chicago","publisher-place":"Chicago","title":"The Subject and Power","type":"chapter"},{"id":"fouratiCollectionCharacterizationEmotional2014","abstract":"This paper addressees two issues in modeling bodily expression of emotions; emotional behaviors collection and expressive movement characterization. In this paper, we describe our body movement coding schema intended to the characterization of bodily emotional expression in different movement tasks. We describe as well the database that we use for the characterization of emotion expression in different movement tasks through the proposed body movement coding schema.","author":[{"family":"Fourati","given":"Nesrine"},{"family":"Pelachaud","given":"Catherine"}],"citation-key":"fouratiCollectionCharacterizationEmotional2014","collection-title":"MOCO '14","container-title":"Proceedings of the 2014 international workshop on movement and computing","DOI":"10.1145/2617995.2618004","event-place":"Paris, France","ISBN":"978-1-4503-2814-2","issued":{"date-parts":[["2014"]]},"number-of-pages":"6","page":"49–54","publisher":"Association for Computing Machinery","publisher-place":"Paris, France","title":"Collection and characterization of emotional body behaviors","type":"paper-conference","URL":"https://doi.org/10.1145/2617995.2618004"},{"id":"fouratiMultisensorDataFusion2016","call-number":"TK7872.D48 M87 2016","citation-key":"fouratiMultisensorDataFusion2016","editor":[{"family":"Fourati","given":"Hassen"}],"event-place":"Boca Raton","ISBN":"978-1-4822-6374-9","issued":{"date-parts":[["2016"]]},"number-of-pages":"639","publisher":"CRC Press, Taylor & Francis Group","publisher-place":"Boca Raton","source":"Library of Congress ISBN","title":"Multisensor data fusion: from algorithm and architecture design to applications","title-short":"Multisensor data fusion","type":"book"},{"id":"fowlerSurveyResearchMethods2014","author":[{"family":"Fowler","given":"Floyd J."}],"call-number":"HN29 .F68 2014","citation-key":"fowlerSurveyResearchMethods2014","collection-title":"Applied Social Research Methods Series","edition":"Fifth edition","event-place":"Los Angeles","ISBN":"978-1-4522-5900-0 978-1-4833-1240-8","issued":{"date-parts":[["2014"]]},"number-of-pages":"171","publisher":"SAGE","publisher-place":"Los Angeles","source":"Library of Congress ISBN","title":"Survey Research Methods","type":"book"},{"id":"fradenHandbookModernSensors2016","author":[{"family":"Fraden","given":"Jacob"}],"citation-key":"fradenHandbookModernSensors2016","edition":"Fifth edition","event-place":"Cham Heidelberg New York Dordrecht London","ISBN":"978-3-319-19302-1","issued":{"date-parts":[["2016"]]},"language":"eng","number-of-pages":"758","publisher":"Springer","publisher-place":"Cham Heidelberg New York Dordrecht London","source":"K10plus ISBN","title":"Handbook of modern sensors: physics, designs, and applications","title-short":"Handbook of modern sensors","type":"book"},{"id":"fraleighDanceLivedBody1987","author":[{"family":"Fraleigh","given":"Sondra Horton"}],"citation-key":"fraleighDanceLivedBody1987","event-place":"Pittsburgh, PA","ISBN":"0-8229-7170-4","issued":{"date-parts":[["1987"]]},"publisher":"University of Pittsburgh Press","publisher-place":"Pittsburgh, PA","title":"Dance and the lived body : a descriptive aesthetics","type":"book"},{"id":"francoiseGestureSoundMapping2013","abstract":"In this paper we address the issue of mapping between gesture and sound in interactive music systems. Our approach, we call mapping by demonstration, aims at learning the mapping from examples provided by users while interacting with the system. We propose a general framework for modeling gesture–sound sequences based on a probabilistic, multimodal and hierarchical model. Two orthogonal modeling aspects are detailed and we describe planned research directions to improve and evaluate the proposed models.","author":[{"family":"Françoise","given":"Jules"}],"citation-key":"francoiseGestureSoundMapping2013","collection-title":"MM '13","container-title":"Proceedings of the 21st ACM International Conference on Multimedia","DOI":"10.1145/2502081.2502214","event-place":"Barcelona, Spain","ISBN":"978-1-4503-2404-5","issued":{"date-parts":[["2013"]]},"page":"1051–1054","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","title":"Gesture–Sound Mapping by Demonstration in Interactive Music Systems","type":"paper-conference","URL":"https://doi.org/10.1145/2502081.2502214"},{"id":"francoiseMovementAnalysisDecomposition2022","abstract":"Human movements support communication, and can be used to imitate actions or physical phenomenons. Observing gestural imitations of short sounds, we found that such gestures can be categorized by their frequency content. To analyse such movements, we propose an analysis method based on wavelet analysis for clustering or recognizing movement characteristics. Our technique draws upon the continuous wavelet transform to derive a time-frequency representation of movement information. We propose several global descriptors based on statistical descriptors, frequency tracking, or non-negative matrix factorization, that can be used for recognition or clustering to highlight relevant movement qualities. Additionally, we propose a real-time implementation of the continuous wavelet transform based on a set of approximations, that enables its use in interactive applications. Our method is evaluated on a database of gestures co-executed with vocal imitations of recorded sounds.","author":[{"family":"Françoise","given":"Jules"},{"family":"Meseguer-Brocal","given":"Gabriel"},{"family":"Bevilacqua","given":"Frédéric"}],"citation-key":"francoiseMovementAnalysisDecomposition2022","collection-title":"MOCO '22","container-title":"Proceedings of the 8th international conference on movement and computing","DOI":"10.1145/3537972.3537998","event-place":"Chicago, IL, USA","ISBN":"978-1-4503-8716-3","issued":{"date-parts":[["2022"]]},"number-of-pages":"13","publisher":"Association for Computing Machinery","publisher-place":"Chicago, IL, USA","title":"Movement analysis and decomposition with the continuous wavelet transform","type":"paper-conference","URL":"https://doi.org/10.1145/3537972.3537998"},{"id":"frankGabrielaLenaFrank2008","accessed":{"date-parts":[["2020",10,8]]},"archive":"NewMusicBox","author":[{"family":"Frank","given":"Gabriela Lena"}],"citation-key":"frankGabrielaLenaFrank2008","issued":{"date-parts":[["2008",4,1]]},"title":"Gabriela Lena Frank: Composite Identity","type":"interview","URL":"https://nmbx.newmusicusa.org/gabriela-lena-frank-composite-identity/"},{"id":"frantziAutomaticRecognitionMultiword2000","accessed":{"date-parts":[["2024",9,10]]},"author":[{"family":"Frantzi","given":"Katerina"},{"family":"Ananiadou","given":"Sophia"},{"family":"Mima","given":"Hideki"}],"citation-key":"frantziAutomaticRecognitionMultiword2000","container-title":"International Journal on Digital Libraries","container-title-short":"Int J Digit Libr","DOI":"10.1007/s007999900023","ISSN":"1432-5012","issue":"2","issued":{"date-parts":[["2000",8]]},"language":"en","license":"http://www.springer.com/tdm","page":"115-130","source":"DOI.org (Crossref)","title":"Automatic recognition of multi-word terms:. the C-value/NC-value method","title-short":"Automatic recognition of multi-word terms","type":"article-journal","URL":"http://link.springer.com/10.1007/s007999900023","volume":"3"},{"id":"fraylingResearchArtDesign1993","author":[{"family":"Frayling","given":"Christopher"}],"citation-key":"fraylingResearchArtDesign1993","container-title":"Royal College of Art research papers","container-title-short":"Royal College of Art research papers","issued":{"date-parts":[["1993"]]},"page":"1-5","title":"Research in art and design","type":"article-journal","volume":"1"},{"id":"frenchEqualTermsWorking07","citation-key":"frenchEqualTermsWorking07","editor":[{"family":"French","given":"Sally"}],"event-place":"Oxford Boston","ISBN":"978-0-7506-0751-3","issued":{"date-parts":[["7"]]},"language":"eng","note":"OCLC: 832313313","number-of-pages":"280","publisher":"Butterworth-Heinemann","publisher-place":"Oxford Boston","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"On Equal Terms: Working with Disabled People","title-short":"On equal terms","type":"book"},{"id":"fridAccessibleDigitalMusical2019","abstract":"Current advancements in music technology enable the creation of customized Digital Musical Instruments (DMIs). This paper presents a systematic review of Accessible Digital Musical Instruments (ADMIs) in inclusive music practice. History of research concerned with facilitating inclusion in music-making is outlined, and current state of developments and trends in the field are discussed. Although the use of music technology in music therapy contexts has attracted more attention in recent years, the topic has been relatively unexplored in Computer Music literature. This review investigates a total of 113 publications focusing on ADMIs. Based on the 83 instruments in this dataset, ten control interface types were identified: tangible controllers, touchless controllers, Brain–Computer Music Interfaces (BCMIs), adapted instruments, wearable controllers or prosthetic devices, mouth-operated controllers, audio controllers, gaze controllers, touchscreen controllers and mouse-controlled interfaces. The majority of the AMDIs were tangible or physical controllers. Although the haptic modality could potentially play an important role in musical interaction for many user groups, relatively few of the ADMIs (14.5%) incorporated vibrotactile feedback. Aspects judged to be important for successful ADMI design were instrument adaptability and customization, user participation, iterative prototyping, and interdisciplinary development teams.","accessed":{"date-parts":[["2023",5,7]]},"author":[{"family":"Frid","given":"Emma"}],"citation-key":"fridAccessibleDigitalMusical2019","container-title":"Multimodal Technologies and Interaction","container-title-short":"MTI","DOI":"10.3390/mti3030057","ISSN":"2414-4088","issue":"3","issued":{"date-parts":[["2019",7,26]]},"language":"en","page":"57","source":"DOI.org (Crossref)","title":"Accessible Digital Musical Instruments—A Review of Musical Interfaces in Inclusive Music Practice","type":"article-journal","URL":"https://www.mdpi.com/2414-4088/3/3/57","volume":"3"},{"id":"fristonMeasuringLatencyVirtual2014","accessed":{"date-parts":[["2023",4,30]]},"author":[{"family":"Friston","given":"Sebastian"},{"family":"Steed","given":"Anthony"}],"citation-key":"fristonMeasuringLatencyVirtual2014","container-title":"IEEE Transactions on Visualization and Computer Graphics","container-title-short":"IEEE Trans. Visual. Comput. Graphics","DOI":"10.1109/TVCG.2014.30","ISSN":"1077-2626","issue":"4","issued":{"date-parts":[["2014",4]]},"page":"616-625","source":"DOI.org (Crossref)","title":"Measuring Latency in Virtual Environments","type":"article-journal","URL":"http://ieeexplore.ieee.org/document/6777458/","volume":"20"},{"id":"fristonMeasuringLatencyVirtual2014a","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Friston","given":"Sebastian"},{"family":"Steed","given":"Anthony"}],"citation-key":"fristonMeasuringLatencyVirtual2014a","container-title":"IEEE Transactions on Visualization and Computer Graphics","container-title-short":"IEEE Trans. Visual. Comput. Graphics","DOI":"10.1109/TVCG.2014.30","ISSN":"1077-2626","issue":"4","issued":{"date-parts":[["2014",4]]},"license":"https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html","note":"QID: Q53594114","page":"616-625","source":"DOI.org (Crossref)","title":"Measuring Latency in Virtual Environments","type":"article-journal","URL":"http://ieeexplore.ieee.org/document/6777458/","volume":"20"},{"id":"fuhrerScientificComputingPython2016","author":[{"family":"Führer","given":"Claus"},{"family":"Solem","given":"Jan"},{"family":"Verdier","given":"Olivier"},{"family":"Solem","given":"Jan Erik"}],"citation-key":"fuhrerScientificComputingPython2016","event-place":"Birmingham Mumbai","ISBN":"978-1-78646-351-7","issued":{"date-parts":[["2016"]]},"language":"eng","number-of-pages":"314","publisher":"Packt Publishing","publisher-place":"Birmingham Mumbai","source":"K10plus ISBN","title":"Scientific computing with Python 3","type":"book"},{"id":"fulfordLearningNotListen2011","abstract":"The journey from playful musical exploration in childhood to an adult identity as a skilled musician is likely to be problematic for people with hearing impairments. Although a number of subjective accounts have been published, there is a lack of empirical research in the area. In this study, twelve musicians with hearing impairments were interviewed about their musical background, hearing loss and experiences of interactive music making. A thematic network analysis was performed on the verbatim transcripts. Musical families were shown to facilitate positive, early, influential experiences helping individuals to develop musical self-efficacy. These themes were found to operate independently of the challenges posed by a hearing impairment and in spite of negative music-making experiences. Dynamic listening styles were identified, ranging from full reliance on hearing to discriminate and even non-auditory attending. The development of listening styles was found to be crucial in negotiating problems in auditory perception caused by physiological changes in hearing level and the distorting effects of hearing aids.","author":[{"family":"Fulford","given":"Robert"},{"family":"Ginsborg","given":"Jane"},{"family":"Goldbart","given":"Juliet"}],"citation-key":"fulfordLearningNotListen2011","container-title":"Music Education Research","container-title-short":"null","DOI":"10.1080/14613808.2011.632086","ISSN":"1461-3808","issue":"4","issued":{"date-parts":[["2011",12,1]]},"page":"447-464","publisher":"Routledge","title":"Learning Not to Listen: the Experiences of Musicians with Hearing Impairments","type":"article-journal","URL":"https://doi.org/10.1080/14613808.2011.632086","volume":"13"},{"id":"fullerComparisonTwoMusic2018","author":[{"family":"Fuller","given":"Christina D."},{"family":"Galvin III","given":"John J."},{"family":"Maat","given":"Bert"},{"family":"Başkent","given":"Deniz"},{"family":"Free","given":"Rolien H."}],"citation-key":"fullerComparisonTwoMusic2018","container-title":"Trends in hearing","container-title-short":"Trends in hearing","ISSN":"2331-2165","issued":{"date-parts":[["2018"]]},"page":"2331216518765379","publisher":"SAGE Publications Sage CA: Los Angeles, CA","title":"Comparison of Two Music Training Approaches on Music and Speech Perception in Cochlear Implant Users","type":"article-journal","volume":"22"},{"id":"fuSensingTechnologyHuman2020","accessed":{"date-parts":[["2024",9,6]]},"author":[{"family":"Fu","given":"Biying"},{"family":"Damer","given":"Naser"},{"family":"Kirchbuchner","given":"Florian"},{"family":"Kuijper","given":"Arjan"}],"citation-key":"fuSensingTechnologyHuman2020","container-title":"IEEE Access","container-title-short":"IEEE Access","DOI":"10.1109/ACCESS.2020.2991891","ISSN":"2169-3536","issued":{"date-parts":[["2020"]]},"license":"https://creativecommons.org/licenses/by/4.0/legalcode","page":"83791-83820","source":"DOI.org (Crossref)","title":"Sensing Technology for Human Activity Recognition: A Comprehensive Survey","title-short":"Sensing Technology for Human Activity Recognition","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/9083980/","volume":"8"},{"id":"gallagherTakingStockPhenomenology2012","accessed":{"date-parts":[["2023",4,25]]},"author":[{"family":"Gallagher","given":"Shaun"}],"citation-key":"gallagherTakingStockPhenomenology2012","container-title":"The Southern Journal of Philosophy","DOI":"10.1111/j.2041-6962.2012.00108.x","ISSN":"00384283","issue":"2","issued":{"date-parts":[["2012",6]]},"language":"en","page":"304-318","source":"DOI.org (Crossref)","title":"Taking stock of phenomenology futures","title-short":"Taking stock of phenomenology futures","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/10.1111/j.2041-6962.2012.00108.x","volume":"50"},{"id":"gallagherWhatPhenomenology2022","abstract":"What is phenomenology? This chapter addresses this question by reviewing some classic definitions and then by looking briefly at the historical development of phenomenology. There is no one definition that captures all of the different variations of phenomenology as it has developed in the twentieth century and now into the twenty-first century. It is best characterized as a method rather than as a set of doctrines. There is, however, a central focus on consciousness and associated topics. As different philosophers applied phenomenology in different areas, they reshaped the meaning of phenomenology. That process continues, for example, in contemporary applications in the area of the cognitive sciences.","author":[{"family":"Gallagher","given":"Shaun"}],"citation-key":"gallagherWhatPhenomenology2022","container-title":"Phenomenology","DOI":"10.1007/978-3-031-11586-8_1","editor":[{"family":"Gallagher","given":"Shaun"}],"event-place":"Cham","ISBN":"978-3-031-11586-8","issued":{"date-parts":[["2022"]]},"page":"1-10","publisher":"Springer International Publishing","publisher-place":"Cham","title":"What Is Phenomenology?","type":"chapter","URL":"https://doi.org/10.1007/978-3-031-11586-8_1"},{"id":"gallaudetuniversity","accessed":{"date-parts":[["2020",12,10]]},"author":[{"literal":"Gallaudet University"}],"citation-key":"gallaudetuniversity","container-title":"Gallaudet University","title":"About","type":"webpage","URL":"https://www.gallaudet.edu/about"},{"id":"gallaudetuniversityAssistiveTechnologiesIndividuals2014","accessed":{"date-parts":[["2020",10,1]]},"author":[{"literal":"Gallaudet University"}],"citation-key":"gallaudetuniversityAssistiveTechnologiesIndividuals2014","container-title":"Laurent Clerc National Deaf Education Center","issued":{"date-parts":[["2014",10]]},"language":"English","title":"Assistive Technologies for Individuals Who are Deaf or Hard of Hearing","type":"webpage","URL":"https://www3.gallaudet.edu/clerc-center/info-to-go/assistive-technology/assistive-technologies.html"},{"id":"gallaudetuniversityFastFacts","accessed":{"date-parts":[["2020",12,10]]},"author":[{"literal":"Gallaudet University"}],"citation-key":"gallaudetuniversityFastFacts","container-title":"Gallaudet University","title":"Fast Facts","type":"webpage","URL":"https://www.gallaudet.edu/about/news-and-media/fast-facts"},{"id":"galviniiiMelodicContourIdentification2007","author":[{"family":"Galvin III","given":"John J."},{"family":"Fu","given":"Qian-Jie"},{"family":"Nogaki","given":"Geraldine"}],"citation-key":"galviniiiMelodicContourIdentification2007","container-title":"Ear and Hearing","container-title-short":"Ear and Hearing","issue":"3","issued":{"date-parts":[["2007"]]},"page":"302 - 319","publisher":"NIH Public Access","title":"Melodic Contour Identification by Cochlear Implant Listeners","type":"article-journal","volume":"28"},{"id":"gambleListeningVirtualSpace2019","author":[{"family":"Gamble","given":"Steve"}],"citation-key":"gambleListeningVirtualSpace2019","container-title":"Proceedings of the 12th Art of Record Production Conference Mono: Stereo: Multi","editor":[{"family":"Gullö","given":"Jan-Olof"},{"family":"Rambarran","given":"Shara"},{"family":"Isakoff","given":"Katia"}],"event-place":"Stockholm","issued":{"date-parts":[["2019"]]},"page":"105-118","publisher":"Royal College of Music (KMH) & Art of Record Production","publisher-place":"Stockholm","title":"Listening to virtual space in recorded popular music","type":"paper-conference"},{"id":"gaoSurveyDeepLearning2020","abstract":"With the wide deployments of heterogeneous networks, huge amounts of data with characteristics of high volume, high variety, high velocity, and high veracity are generated. These data, referred to multimodal big data, contain abundant intermodality and cross-modality information and pose vast challenges on traditional data fusion methods. In this review, we present some pioneering deep learning models to fuse these multimodal big data. With the increasing exploration of the multimodal big data, there are still some challenges to be addressed. Thus, this review presents a survey on deep learning for multimodal data fusion to provide readers, regardless of their original community, with the fundamentals of multimodal deep learning fusion method and to motivate new multimodal data fusion techniques of deep learning. Specifically, representative architectures that are widely used are summarized as fundamental to the understanding of multimodal deep learning. Then the current pioneering multimodal data fusion deep learning models are summarized. Finally, some challenges and future topics of multimodal data fusion deep learning models are described.","accessed":{"date-parts":[["2024",1,31]]},"author":[{"family":"Gao","given":"Jing"},{"family":"Li","given":"Peng"},{"family":"Chen","given":"Zhikui"},{"family":"Zhang","given":"Jianing"}],"citation-key":"gaoSurveyDeepLearning2020","container-title":"Neural Computation","container-title-short":"Neural Computation","DOI":"10.1162/neco_a_01273","ISSN":"0899-7667","issue":"5","issued":{"date-parts":[["2020",5,1]]},"page":"829-864","title":"A Survey on Deep Learning for Multimodal Data Fusion","type":"article-journal","URL":"https://doi.org/10.1162/neco_a_01273","volume":"32"},{"id":"garciaRecognitionLabanEffort2020","abstract":"In this paper, we conduct a study for recognizing motion qualities in hand gestures using virtual reality trackers attached to the hand. From this 6D signal, we extract Euclidean, equi-affine and moving frame features and compare their effectiveness in the task of recognizing Laban Effort qualities. Our experimental results reveal that equi-affine features are highly discriminant features for this task. We also compare two classification methods on this task. In the first method, we trained separate HMM models for the 6 Laban Effort qualities (light, strong, sudden, sustained, direct, indirect). In the second method, we trained separate HMM models for the 8 Laban motion verbs (dab, glide, float, flick, thrust, press, wring, slash) and combined them to recognize individual qualities. In our experiments, the second method gives improved results. Together, those findings suggest that low-dimensional signals from VR trackers can be used to predict motion qualities with reasonable precision.","author":[{"family":"Garcia","given":"Maxime"},{"family":"Ronfard","given":"Rémi"}],"citation-key":"garciaRecognitionLabanEffort2020","collection-title":"MOCO '20","container-title":"Proceedings of the 7th international conference on movement and computing","DOI":"10.1145/3401956.3404227","event-place":"Jersey City/Virtual, NJ, USA","ISBN":"978-1-4503-7505-4","issued":{"date-parts":[["2020"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Jersey City/Virtual, NJ, USA","title":"Recognition of laban effort qualities from hand motion","type":"paper-conference","URL":"https://doi.org/10.1145/3401956.3404227"},{"id":"gardnerIntelligenceReframedMultiple1999","author":[{"family":"Gardner","given":"Howard"}],"citation-key":"gardnerIntelligenceReframedMultiple1999","event-place":"New York, NY","ISBN":"978-0-465-02611-1 978-0-465-02610-4","issued":{"date-parts":[["1999"]]},"language":"eng","note":"OCLC: 247819868","number-of-pages":"292","publisher":"Basic Books","publisher-place":"New York, NY","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"Intelligence Reframed: Multiple Intelligences for the 21st Century","title-short":"Intelligence reframed","type":"book"},{"id":"garland-thomsonCaseConservingDisability2012","accessed":{"date-parts":[["2020",9,18]]},"author":[{"family":"Garland-Thomson","given":"Rosemarie"}],"citation-key":"garland-thomsonCaseConservingDisability2012","container-title":"Journal of Bioethical Inquiry","container-title-short":"Bioethical Inquiry","DOI":"10.1007/s11673-012-9380-0","ISSN":"1176-7529, 1872-4353","issue":"3","issued":{"date-parts":[["2012",9]]},"language":"en","page":"339-355","source":"DOI.org (Crossref)","title":"The Case for Conserving Disability","type":"article-journal","URL":"http://link.springer.com/10.1007/s11673-012-9380-0","volume":"9"},{"id":"garland-thomsonExtraordinaryBodiesFiguring1997","author":[{"family":"Garland-Thomson","given":"Rosemarie"}],"call-number":"PS374.P44 T49 1997","citation-key":"garland-thomsonExtraordinaryBodiesFiguring1997","event-place":"New York","ISBN":"978-0-231-10516-3 978-0-231-10517-0","issued":{"date-parts":[["1997"]]},"number-of-pages":"200","publisher":"Columbia University Press","publisher-place":"New York","source":"Library of Congress ISBN","title":"Extraordinary Bodies: Figuring Physical Disability in American Culture and Literature","title-short":"Extraordinary bodies","type":"book"},{"id":"garland-thomsonFreakeryCulturalSpectacles1996","call-number":"GT6730 .F74 1996","citation-key":"garland-thomsonFreakeryCulturalSpectacles1996","editor":[{"family":"Garland-Thomson","given":"Rosemarie"}],"event-place":"New York","ISBN":"978-0-8147-8217-0 978-0-8147-8222-4","issued":{"date-parts":[["1996"]]},"number-of-pages":"400","publisher":"New York University Press","publisher-place":"New York","source":"Library of Congress ISBN","title":"Freakery: Cultural Spectacles of the Extraordinary Body","title-short":"Freakery","type":"book"},{"id":"gaverTechnologyAffordances1991","author":[{"family":"Gaver","given":"William W"}],"citation-key":"gaverTechnologyAffordances1991","event-title":"Proceedings of the SIGCHI conference on Human factors in computing systems","issued":{"date-parts":[["1991"]]},"page":"79-84","title":"Technology affordances","type":"paper-conference"},{"id":"gehlhaarSoundSpaceInteractive1991","author":[{"family":"Gehlhaar","given":"Rolf"}],"citation-key":"gehlhaarSoundSpaceInteractive1991","container-title":"Contemporary Music Review","container-title-short":"Contemporary Music Review","ISSN":"0749-4467","issue":"1","issued":{"date-parts":[["1991"]]},"page":"59-72","publisher":"Taylor & Francis","title":"Sound= Space: an interactive musical environment","type":"article-journal","volume":"6"},{"id":"gelineckInterfaceMusicMixing2013","abstract":"This paper presents the continuous work towards the development of an interfacefor music mixing targeted towards expert sound technicians and producers. Themixing interface uses a stage metaphor mapping scheme where audio channels arerepresented as digital widgets on a 2D surface. These can be controlled bymulti touch or by smart tangibles, which are tangible blocks with embeddedsensors. The smart tangibles developed for this interface are able to sense howthey are grasped by the user. The paper presents the design of the mixinginterface including the smart tangible as well as a preliminary user studyinvolving a hands-on focus group session where 5 different control technologiesare contrasted and discussed. Preliminary findings suggest that smart tangibleswere preferred, but that an optimal interface would include a combination oftouch, smart tangibles and an extra function control tangible for extending thefunctionality of the smart tangibles. Finally, the interface should incorporateboth an edit and mix mode - the latter displaying very limited visual feedbackin order to force users to focus their attention to listening instead of theinterface.","accessed":{"date-parts":[["2024",1,25]]},"author":[{"family":"Gelineck","given":"Steven"},{"family":"Overholt","given":"Dan"},{"family":"Büchert","given":"Morten"},{"family":"Andersen","given":"Jesper"}],"citation-key":"gelineckInterfaceMusicMixing2013","container-title":"Proceedings of the International Conference on New Interfaces for Musical Expression","DOI":"10.5281/ZENODO.1178532","issued":{"date-parts":[["2013",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","page":"180--185","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"Towards An Interface For Music Mixing Based On Smart Tangibles And Multitouch","type":"paper-conference","URL":"https://zenodo.org/record/1178532"},{"id":"gemeinboeckMovementMattersHow2017","abstract":"This paper explores movement and its capacity for meaning-making and eliciting affect in human-robot interaction. Bringing together creative robotics, dance and machine learning, our research project develops a novel relational approach that harnesses dancers' movement expertise to design a non-anthropomorphic robot, its potential to move and capacity to learn. The project challenges the common assumption that robots need to appear human or animal-like to enable people to form connections with them. Our performative body-mapping (PBM) approach, in contrast, embraces the difference of machinic embodiment and places movement and its connection-making, knowledge-generating potential at the center of our social encounters. The paper discusses the first stage of the project, in which we collaborated with dancers to study how movement propels the becoming-body of a robot, and outlines our embodied approach to machine learning, grounded in the robot's performative capacity.","author":[{"family":"Gemeinboeck","given":"Petra"},{"family":"Saunders","given":"Rob"}],"citation-key":"gemeinboeckMovementMattersHow2017","collection-title":"MOCO '17","container-title":"Proceedings of the 4th international conference on movement computing","DOI":"10.1145/3077981.3078035","event-place":"London, United Kingdom","ISBN":"978-1-4503-5209-3","issued":{"date-parts":[["2017"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"London, United Kingdom","title":"Movement matters: How a robot becomes body","type":"paper-conference","URL":"https://doi.org/10.1145/3077981.3078035"},{"id":"geurtsCultureSensesBodily2002","author":[{"family":"Geurts","given":"Kathryn Linn"}],"call-number":"DT510.43.A58 G48 2002","citation-key":"geurtsCultureSensesBodily2002","collection-number":"3","collection-title":"Ethnographic studies in subjectivity","event-place":"Berkeley","ISBN":"978-0-520-23455-0 978-0-520-23456-7","issued":{"date-parts":[["2002"]]},"number-of-pages":"315","publisher":"University of California Press","publisher-place":"Berkeley","source":"Library of Congress ISBN","title":"Culture and the Senses: Bodily Ways of Knowing in an African Community","title-short":"Culture and the senses","type":"book"},{"id":"gfellerEffectsFrequencyInstrumental2002","author":[{"family":"Gfeller","given":"Kate"},{"family":"Witt","given":"Shelley"},{"family":"Mehr","given":"Maureen A."},{"family":"Woodworth","given":"George"},{"family":"Knutson","given":"John"}],"citation-key":"gfellerEffectsFrequencyInstrumental2002","container-title":"Annals of Otology, Rhinology & Laryngology","container-title-short":"Annals of Otology, Rhinology & Laryngology","ISSN":"0003-4894","issue":"4","issued":{"date-parts":[["2002"]]},"page":"349-356","publisher":"SAGE Publications Sage CA: Los Angeles, CA","title":"Effects of Frequency, Instrumental Family, and Cochlear Implant Type on Timbre Recognition and Appraisal","type":"article-journal","volume":"111"},{"id":"gfellerPreliminaryReportMusicBased2015","author":[{"family":"Gfeller","given":"Kate"},{"family":"Guthe","given":"Emily"},{"family":"Driscoll","given":"Virginia"},{"family":"Brown","given":"Carolyn J."}],"citation-key":"gfellerPreliminaryReportMusicBased2015","container-title":"Cochlear Implants International","container-title-short":"Cochlear Implants International","ISSN":"1467-0100","issue":"sup3","issued":{"date-parts":[["2015"]]},"page":"S22-S31","publisher":"Taylor & Francis","title":"A Preliminary Report of Music-Based Training for Adult Cochlear Implant Users: Rationales and Development","type":"article-journal","volume":"16"},{"id":"gfellerRecognitionFamiliarMelodies2002","author":[{"family":"Gfeller","given":"Kate"},{"family":"Turner","given":"Christopher"},{"family":"Mehr","given":"Maureen"},{"family":"Woodworth","given":"George"},{"family":"Fearn","given":"Robert"},{"family":"Knutson","given":"John F."},{"family":"Witt","given":"Shelley"},{"family":"Stordahl","given":"Julie"}],"citation-key":"gfellerRecognitionFamiliarMelodies2002","container-title":"Cochlear implants international","container-title-short":"Cochlear implants international","ISSN":"1467-0100","issue":"1","issued":{"date-parts":[["2002"]]},"page":"29-53","publisher":"Wiley Online Library","title":"Recognition of Familiar Melodies by Adult Cochlear Implant Recipients and Normal‐Hearing Adults","type":"article-journal","volume":"3"},{"id":"gibsonEcologicalApproachVisual2014","accessed":{"date-parts":[["2022",9,29]]},"author":[{"family":"Gibson","given":"James J."}],"citation-key":"gibsonEcologicalApproachVisual2014","DOI":"10.4324/9781315740218","edition":"1","ISBN":"978-1-315-74021-8","issued":{"date-parts":[["2014",11,20]]},"language":"en","publisher":"Psychology Press","source":"DOI.org (Crossref)","title":"The Ecological Approach to Visual Perception: Classic Edition","title-short":"The Ecological Approach to Visual Perception","type":"book","URL":"https://www.taylorfrancis.com/books/9781315740218"},{"id":"giomiSomaticSonificationDance2020","abstract":"Since the end of the 1980s, interactive musical systems have played an increasingly relevant role in dance performances. More recently, the use of interactive auditory feedback for sensorimotor learning such as movement sonification has gained currency and scientific attention in a variety of fields ranging from rehabilitation to sport training, neuroscience and product design. This paper investigates the convergence between interactive music/dance systems and movement sonification in the field of dance. The main question we address is whether the emergence of the notion of sonification can foster new perspectives for practice-based artistic research. In this context, we highlight a fundamental shift of perspective from musical interactivity per se to the somatic knowledge provided by the real time sonification of movement, which can be considered as a major somatic-sonification turn.","author":[{"family":"Giomi","given":"Andrea"}],"citation-key":"giomiSomaticSonificationDance2020","collection-title":"MOCO '20","container-title":"Proceedings of the 7th international conference on movement and computing","DOI":"10.1145/3401956.3404226","event-place":"Jersey City/Virtual, NJ, USA","ISBN":"978-1-4503-7505-4","issued":{"date-parts":[["2020"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Jersey City/Virtual, NJ, USA","title":"Somatic sonification in dance performances. From the artistic to the perceptual and back","type":"paper-conference","URL":"https://doi.org/10.1145/3401956.3404226"},{"id":"giorgiDescriptivePhenomenologicalPsychological2017","author":[{"family":"Giorgi","given":"Barbro"},{"family":"Giorgi","given":"Amedeo"},{"family":"Morley","given":"James"}],"citation-key":"giorgiDescriptivePhenomenologicalPsychological2017","container-title":"The SAGE Handbook of Qualitative Research in Psychology","edition":"2","editor":[{"family":"Willig","given":"Carla"},{"family":"Stainton Rogers","given":"Wendy"}],"event-place":"London","issued":{"date-parts":[["2017"]]},"page":"176-192","publisher":"SAGE Publications Ltd","publisher-place":"London","title":"The Descriptive Phenomenological Psychological Method","type":"chapter"},{"id":"giorginoComputingVisualizingDynamic2009","accessed":{"date-parts":[["2023",11,27]]},"author":[{"family":"Giorgino","given":"Toni"}],"citation-key":"giorginoComputingVisualizingDynamic2009","container-title":"Journal of Statistical Software","container-title-short":"J. Stat. Soft.","DOI":"10.18637/jss.v031.i07","ISSN":"1548-7660","issue":"7","issued":{"date-parts":[["2009"]]},"language":"en","source":"DOI.org (Crossref)","title":"Computing and Visualizing Dynamic Time Warping Alignments in <i>R</i> : The <b>dtw</b> Package","title-short":"Computing and Visualizing Dynamic Time Warping Alignments in <i>R</i>","type":"article-journal","URL":"http://www.jstatsoft.org/v31/i07/","volume":"31"},{"id":"gleicherAnimationObservationMotion1999","author":[{"family":"Gleicher","given":"Michael"}],"citation-key":"gleicherAnimationObservationMotion1999","container-title":"SIGGRAPH Comput. Graph.","DOI":"10.1145/345370.345409","event-place":"New York, NY, USA","ISSN":"0097-8930","issue":"4","issued":{"date-parts":[["1999",11]]},"number-of-pages":"4","page":"51–54","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","title":"Animation from observation: Motion capture and motion editing","type":"article-journal","URL":"https://doi.org/10.1145/345370.345409","volume":"33"},{"id":"gleicherEvaluatingVideobasedMotion2002","author":[{"family":"Gleicher","given":"M."},{"family":"Ferrier","given":"N."}],"citation-key":"gleicherEvaluatingVideobasedMotion2002","container-title":"Proceedings of computer animation 2002 (CA 2002)","DOI":"10.1109/CA.2002.1017510","issued":{"date-parts":[["2002"]]},"page":"75-80","title":"Evaluating video-based motion capture","type":"paper-conference"},{"id":"glennieBeatDifferentDrummer1999","archive":"https://archive.vn/20120908083201/http://www.pbs.org/newshour/bb/entertainment/jan-june99/drummer_6-14.html#selection-457.0-457.13","author":[{"family":"Glennie","given":"Evelyn"}],"citation-key":"glennieBeatDifferentDrummer1999","issued":{"date-parts":[["1999",6,14]]},"language":"English","medium":"PBS Radio Broadcast","title":"Beat of a Different Drummer","type":"interview","URL":"https://archive.vn/20120908083201/http://www.pbs.org/newshour/bb/entertainment/jan-june99/drummer_6-14.html#selection-457.0-457.13"},{"id":"glennieEvelynGlennieDeaf2019","accessed":{"date-parts":[["2021",1,11]]},"author":[{"family":"Glennie","given":"Evelyn"}],"citation-key":"glennieEvelynGlennieDeaf2019","issued":{"date-parts":[["2019",4]]},"title":"Evelyn Glennie | Deaf, Sound and Music Questions","type":"document","URL":"https://www.evelyn.co.uk/wp-content/uploads/2019/06/Evelyn-Glennie-Deaf-and-Music-Questions.pdf"},{"id":"glennieEvelynGlenniePerforms2011","accessed":{"date-parts":[["2021",1,13]]},"author":[{"family":"Glennie","given":"Evelyn"}],"citation-key":"glennieEvelynGlenniePerforms2011","container-title":"YouTube","issued":{"date-parts":[["2011",11,2]]},"title":"Evelyn Glennie performs Concerto in C major RV 443, Mov 1 by Vivaldi","type":"webpage","URL":"https://www.youtube.com/watch?v=YMZeBJJ5JJc"},{"id":"glennieHearingEssay2015","accessed":{"date-parts":[["2020",10,20]]},"author":[{"family":"Glennie","given":"Evelyn"}],"citation-key":"glennieHearingEssay2015","container-title":"Evelyn Glennie","issued":{"date-parts":[["2015",1,1]]},"title":"Hearing Essay","type":"webpage","URL":"https://www.evelyn.co.uk/hearing-essay/"},{"id":"glennieHowTrulyListen2003","abstract":"In this soaring demonstration, deaf percussionist Evelyn Glennie illustrates how listening to music involves much more than simply letting sound waves hit your eardrums.","accessed":{"date-parts":[["2020",10,1]]},"author":[{"family":"Glennie","given":"Evelyn"}],"citation-key":"glennieHowTrulyListen2003","event-place":"Monterey, CA, USA","event-title":"TED2003","issued":{"date-parts":[["2003",2]]},"publisher-place":"Monterey, CA, USA","title":"How to Truly Listen","type":"speech","URL":"https://www.ted.com/talks/evelyn_glennie_how_to_truly_listen"},{"id":"glennieThereDisabledMusic2019","abstract":"The presence of the phenomenological body is central to music in all of its varieties and contradictions. With the explosion of scholarly works on the body in virtually every field in the humanities, the social as well as the biomedical sciences, the question of how such a complex understanding of the body is related to music, with its own complexity, has been investigated within specific disciplinary perspectives. The Oxford Handbook of Music and the Body brings together scholars from across these fields, providing a platform for the discussion of the multidimensional interfaces of music and the body. The book is organized into six sections, each discussing a topic that defines the field: the moving and performing body; the musical brain and psyche; embodied mind, embodied rhythm; the disabled and sexual body; music as medicine; and the multimodal body. Connecting a wide array of diverse perspectives and presenting a survey of research and practice, the Handbook provides an introduction into the rich world of music and the body","author":[{"family":"Glennie","given":"Evelyn"},{"family":"Gilman","given":"Sander L."},{"family":"Kim","given":"Youn"}],"call-number":"ML3830 .O88 2019","citation-key":"glennieThereDisabledMusic2019","container-title":"The Oxford Handbook of Music and the Body","editor":[{"family":"Kim","given":"Youn"},{"family":"Gilman","given":"Sander L."}],"event-place":"New York, NY","ISBN":"978-0-19-063623-4","issued":{"date-parts":[["2019"]]},"page":"318 -330","publisher":"Oxford University Press","publisher-place":"New York, NY","source":"Library of Congress ISBN","title":"Is There Disabled Music?: Music and the Body from Dame Evelyn Glennie's Perspective","type":"chapter"},{"id":"glennieYouUseSign2019","accessed":{"date-parts":[["2021",1,11]]},"author":[{"family":"Glennie","given":"Evelyn"}],"citation-key":"glennieYouUseSign2019","container-title":"YouTube","issued":{"date-parts":[["2019",4,30]]},"title":"Q&A | Do you use sign language?","type":"webpage","URL":"https://www.youtube.com/watch?v=bXRmaMyi-zM"},{"id":"godowskyStudienUberEtuden1903","accessed":{"date-parts":[["2021",1,3]]},"author":[{"family":"Godowsky","given":"Leopold"}],"citation-key":"godowskyStudienUberEtuden1903","issued":{"literal":"n.d. (1903-1914)"},"publisher":"Schlesinger","title":"Studien über die Etüden von Chopin, Vol. I No. 1-12a","type":"document","URL":"https://ks4.imslp.info/files/imglnks/usimg/9/9f/IMSLP30943-PMLP09194-Godowsky_-_Etudes_d'Apres_Chopin_-_Book_1_(1-12a)_-pf-.pdf"},{"id":"godoyGesturalAffordancesMusical2010","author":[{"family":"Godøy","given":"Rolf Inge"}],"citation-key":"godoyGesturalAffordancesMusical2010","container-title":"Musical gestures: Sound, movement, and meaning","editor":[{"family":"Godøy","given":"Rolf Inge"},{"family":"Leman","given":"Marc"}],"event-place":"New York","ISBN":"978-0-415-99887-1","issued":{"date-parts":[["2010"]]},"page":"103-125","publisher":"Routledge","publisher-place":"New York","title":"Gestural affordances of musical sound","type":"chapter"},{"id":"godoyMusicalGesturesSound2010","accessed":{"date-parts":[["2022",2,16]]},"citation-key":"godoyMusicalGesturesSound2010","DOI":"10.4324/9780203863411","editor":[{"family":"Godøy","given":"Rolf Inge"},{"family":"Leman","given":"Marc"}],"ISBN":"978-1-135-18363-9","issued":{"date-parts":[["2010",2,12]]},"language":"en","publisher":"Routledge","source":"DOI.org (Crossref)","title":"Musical gestures: Sound, movement, and meaning","type":"book","URL":"https://www.taylorfrancis.com/books/9781135183639"},{"id":"goffmanStigmaNotesManagement1986","author":[{"family":"Goffman","given":"Erving"}],"citation-key":"goffmanStigmaNotesManagement1986","collection-title":"A Touchstone Book","edition":"26th pr","event-place":"New York","ISBN":"978-0-671-62244-2","issued":{"date-parts":[["1986"]]},"language":"eng","note":"OCLC: 299745941","number-of-pages":"147","publisher":"Simon & Schuster","publisher-place":"New York","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"Stigma: Notes on the Management of Spoiled Identity","title-short":"Stigma","type":"book"},{"id":"goldDynamicTimeWarping2018","abstract":"Dynamic Time Warping (DTW) and Geometric Edit Distance (GED) are basic similarity measures between curves or general temporal sequences (e.g., time series) that are represented as sequences of points in some metric space (\n              X\n              , dist). The DTW and GED measures are massively used in various fields of computer science and computational biology. Consequently, the tasks of computing these measures are among the core problems in P. Despite extensive efforts to find more efficient algorithms, the best-known algorithms for computing the DTW or GED between two sequences of points in\n              X\n              = R\n              d\n              are long-standing dynamic programming algorithms that require quadratic runtime, even for the one-dimensional case\n              d\n              = 1, which is perhaps one of the most used in practice.\n            \n            \n              In this article, we break the nearly 50-year-old quadratic time bound for computing DTW or GED between two sequences of\n              n\n              points in R by presenting deterministic algorithms that run in\n              O\n              (\n              n\n              2\n              log log log\n              n\n              / log log\n              n\n              ) time. Our algorithms can be extended to work also for higher-dimensional spaces R\n              d\n              , for any constant\n              d\n              , when the underlying distance-metric dist is polyhedral (e.g.,\n              L\n              1\n              ,\n              L\n              infin\n              ).","accessed":{"date-parts":[["2023",3,25]]},"author":[{"family":"Gold","given":"Omer"},{"family":"Sharir","given":"Micha"}],"citation-key":"goldDynamicTimeWarping2018","container-title":"ACM Transactions on Algorithms","container-title-short":"ACM Trans. Algorithms","DOI":"10.1145/3230734","ISSN":"1549-6325, 1549-6333","issue":"4","issued":{"date-parts":[["2018",10,31]]},"language":"en","page":"1-17","source":"DOI.org (Crossref)","title":"Dynamic Time Warping and Geometric Edit Distance: Breaking the Quadratic Barrier","title-short":"Dynamic Time Warping and Geometric Edit Distance","type":"article-journal","URL":"https://dl.acm.org/doi/10.1145/3230734","volume":"14"},{"id":"goldmanGhostcatchingIntersectionTechnology2003","accessed":{"date-parts":[["2023",9,29]]},"archive":"JSTOR","author":[{"family":"Goldman","given":"Danielle"}],"citation-key":"goldmanGhostcatchingIntersectionTechnology2003","container-title":"Dance Research Journal","ISSN":"01497677, 1940509X","issued":{"date-parts":[["2003"]]},"page":"68-87","publisher":"Congress on Research in Dance","title":"Ghostcatching: An Intersection of Technology, Labor, and Race","type":"article-journal","URL":"http://www.jstor.org/stable/30045070","volume":"35/36"},{"id":"gongAdvancedImageVideo2019","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Gong","given":"Shengrong"},{"family":"Liu","given":"Chunping"},{"family":"Ji","given":"Yi"},{"family":"Zhong","given":"Baojiang"},{"family":"Li","given":"Yonggang"},{"family":"Dong","given":"Husheng"}],"citation-key":"gongAdvancedImageVideo2019","collection-title":"Modeling and Optimization in Science and Technologies","DOI":"10.1007/978-3-319-77223-3","event-place":"Cham","ISBN":"978-3-319-77221-9 978-3-319-77223-3","issued":{"date-parts":[["2019"]]},"license":"http://www.springer.com/tdm","publisher":"Springer International Publishing","publisher-place":"Cham","source":"DOI.org (Crossref)","title":"Advanced Image and Video Processing Using MATLAB","type":"book","URL":"http://link.springer.com/10.1007/978-3-319-77223-3","volume":"12"},{"id":"gongAdvancedImageVideo2019a","author":[{"family":"Gong","given":"Shengrong"},{"family":"Liu","given":"Chunping"},{"family":"Ji","given":"Yi"},{"family":"Zhong","given":"Baojiang"},{"family":"Li","given":"Yonggang"},{"family":"Dong","given":"Husheng"}],"citation-key":"gongAdvancedImageVideo2019a","collection-number":"Volume 12","collection-title":"Modeling and optimization in science and technologies","event-place":"Cham, Switzerland","ISBN":"978-3-319-77221-9","issued":{"date-parts":[["2019"]]},"language":"eng","number-of-pages":"590","publisher":"Springer","publisher-place":"Cham, Switzerland","source":"K10plus ISBN","title":"Advanced image and video processing using MATLAB","type":"book"},{"id":"gouldDesigningUsabilityKey1985","author":[{"family":"Gould","given":"John D"},{"family":"Lewis","given":"Clayton"}],"citation-key":"gouldDesigningUsabilityKey1985","container-title":"Communications of the ACM","container-title-short":"Communications of the ACM","ISSN":"0001-0782","issue":"3","issued":{"date-parts":[["1985"]]},"page":"300-311","publisher":"ACM New York, NY, USA","title":"Designing for usability: key principles and what designers think","type":"article-journal","volume":"28"},{"id":"gouldDesigningUsabilityKey1985a","abstract":"This article is both theoretical and empirical. Theoretically, it describes three principles of system design which we believe must be followed to produce a useful and easy to use computer system. These principles are: early and continual focus on users; empirical measurement of usage; and iterative design whereby the system (simulated, prototype, and real) is modified, tested, modified again, tested again, and the cycle is repeated again and again. This approach is contrasted to other principled design approaches, for example, get it right the first time, reliance on design guidelines. Empirically, the article presents data which show that our design principles are not always intuitive to designers; identifies the arguments which designers often offer for not using these principles—and answers them; and provides an example in which our principles have been used successfully.","author":[{"family":"Gould","given":"John D."},{"family":"Lewis","given":"Clayton"}],"citation-key":"gouldDesigningUsabilityKey1985a","container-title":"Communications of The Acm","container-title-short":"Commun. ACM","DOI":"10.1145/3166.3170","event-place":"New York, NY, USA","ISSN":"0001-0782","issue":"3","issued":{"date-parts":[["1985",3]]},"number-of-pages":"12","page":"300–311","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","title":"Designing for usability: Key principles and what designers think","type":"article-journal","URL":"https://doi.org/10.1145/3166.3170","volume":"28"},{"id":"greenFoucaultTrainingDocile2003","author":[{"family":"Green","given":"Jill"}],"citation-key":"greenFoucaultTrainingDocile2003","container-title":"Arts and Learning Research Journal","container-title-short":"Arts and Learning Research Journal","issue":"1","issued":{"date-parts":[["2003"]]},"page":"99-125","title":"Foucault and the training of docile bodies in dance education","type":"article-journal","volume":"19"},{"id":"grietzerTheoryVibe2017","author":[{"family":"Grietzer","given":"Peli"}],"citation-key":"grietzerTheoryVibe2017","container-title":"Glass Bead","issued":{"date-parts":[["2017"]]},"title":"A Theory of Vibe","type":"article-journal","URL":"https://www.glass-bead.org/article/a-theory-of-vibe/?lang=enview","volume":"1"},{"id":"grietzerTheoryVibea","author":[{"family":"Grietzer","given":"Peli"}],"citation-key":"grietzerTheoryVibea","title":"A theory of vibe","type":"article-journal"},{"id":"groszSpaceTimePerversion1995","author":[{"family":"Grosz","given":"E. A."}],"call-number":"HQ1190 .G758 1995","citation-key":"groszSpaceTimePerversion1995","event-place":"New York","ISBN":"978-0-415-91136-8 978-0-415-91137-5","issued":{"date-parts":[["1995"]]},"number-of-pages":"273","publisher":"Routledge","publisher-place":"New York","source":"Library of Congress ISBN","title":"Space, Time, and Perversion: Essays on the Politics of Bodies","title-short":"Space, time, and perversion","type":"book"},{"id":"groszVolatileBodiesCorporeal1994","author":[{"family":"Grosz","given":"E. A."}],"call-number":"HQ1190 .G76 1994","citation-key":"groszVolatileBodiesCorporeal1994","collection-title":"Theories of representation and difference","event-place":"Bloomington","ISBN":"978-0-253-32686-7 978-0-253-20862-0","issued":{"date-parts":[["1994"]]},"number-of-pages":"250","publisher":"Indiana University Press","publisher-place":"Bloomington","source":"Library of Congress ISBN","title":"Volatile Bodies: Toward a Corporeal Feminism","title-short":"Volatile bodies","type":"book"},{"id":"grueProblemSupercrip2015","author":[{"family":"Grue","given":"Jan"}],"citation-key":"grueProblemSupercrip2015","container-title":"Disability research today: International perspectives","container-title-short":"Disability research today: International perspectives","ISSN":"1317750942","issued":{"date-parts":[["2015"]]},"page":"204-218","publisher":"Routledge London","title":"The problem of the supercrip","type":"article-journal"},{"id":"guerra-filhoOpticalMotionCapture2005","author":[{"family":"Guerra-Filho","given":"Gutemberg"}],"citation-key":"guerra-filhoOpticalMotionCapture2005","container-title":"RITA","container-title-short":"RITA","issue":"2","issued":{"date-parts":[["2005"]]},"page":"61-90","publisher":"Citeseer","title":"Optical Motion Capture: Theory and Implementation.","type":"article-journal","volume":"12"},{"id":"gunkelRelationalTurnThird2018","abstract":"Third wave HCI (Human Computer Interaction) proposes an innovative method for framing human computer interactions by putting emphasis on the terms and conditions of the interactive relationship prior to determinations concerning the human subject and its computational object. As promising as this “relational turn” appears to be, there are important theoretical, epistemological, and axiological challenges that remain and need to be addressed. This chapter takes up and investigates a number of these open questions regarding third wave HCI. It begins by briefly reconsidering the three waves or paradigms of HCI research and demonstrating how what appears last in the numbered sequence, the third wave, is actually older and “more original” than it initially appears to be. It then examines the opportunities and challenges of the phenomenological commitment that is operationalized in third wave HCI. And it concludes by identifying and outlining the consequences of this innovation for current and future research efforts.","author":[{"family":"Gunkel","given":"David J."}],"citation-key":"gunkelRelationalTurnThird2018","container-title":"New Directions in Third Wave Human-Computer Interaction: Volume 1 - Technologies","DOI":"10.1007/978-3-319-73356-2_2","editor":[{"family":"Filimowicz","given":"Michael"},{"family":"Tzankova","given":"Veronika"}],"event-place":"Cham","ISBN":"978-3-319-73356-2","issued":{"date-parts":[["2018"]]},"page":"11-24","publisher":"Springer International Publishing","publisher-place":"Cham","title":"The Relational Turn: Third Wave HCI and Phenomenology","type":"chapter","URL":"https://doi.org/10.1007/978-3-319-73356-2_2"},{"id":"guntherCutaneousGroovesComposing2003","abstract":"What if the traditional relationship between touch and music was essentially turned upside down, making the tactile sensation the aesthetic end? This paper presents a novel coupling of haptics technology and music, introducing the notion of tactile composition or aesthetic composition for the sense of touch. A system that facilitates the composition and perception of intricate, musically structured spatio-temporal patterns of vibration on the surface of the body is described. Relevant work from disciplines including sensory substitution, electronic musical instrument design, simulation design, entertainment technology, and visual music is considered. The psychophysical parameter space for our sense of touch is summarized and the building blocks of a compositional language for touch are explored. A series of concerts held for the skin and ears is described, as well as some of the lessons learned along the way. In conclusion, some potential evolutionary branches of tactile composition are posited.","author":[{"family":"Gunther","given":"Eric"},{"family":"O’Modhrain","given":"Sile"}],"citation-key":"guntherCutaneousGroovesComposing2003","container-title":"Journal of New Music Research","container-title-short":"null","DOI":"10.1076/jnmr.32.4.369.18856","ISSN":"0929-8215","issue":"4","issued":{"date-parts":[["2003",12,1]]},"page":"369-381","publisher":"Routledge","title":"Cutaneous Grooves: Composing for the Sense of Touch","type":"article-journal","URL":"https://www.tandfonline.com/doi/abs/10.1076/jnmr.32.4.369.18856","volume":"32"},{"id":"hailstoneItNotWhat2009","abstract":"Salient sensory experiences often have a strong emotional tone, but the neuropsychological relations between perceptual characteristics of sensory objects and the affective information they convey remain poorly defined. Here we addressed the relationship between sound identity and emotional information using music. In two experiments, we investigated whether perception of emotions is influenced by altering the musical instrument on which the music is played, independently of other musical features. In the first experiment, 40 novel melodies each representing one of four emotions (happiness, sadness, fear, or anger) were each recorded on four different instruments (an electronic synthesizer, a piano, a violin, and a trumpet), controlling for melody, tempo, and loudness between instruments. Healthy participants (23 young adults aged 18–30 years, 24 older adults aged 58–75 years) were asked to select which emotion they thought each musical stimulus represented in a four-alternative forced-choice task. Using a generalized linear mixed model we found a significant interaction between instrument and emotion judgement with a similar pattern in young and older adults ( p < .0001 for each age group). The effect was not attributable to musical expertise. In the second experiment using the same melodies and experimental design, the interaction between timbre and perceived emotion was replicated ( p < .05) in another group of young adults for novel synthetic timbres designed to incorporate timbral cues to particular emotions. Our findings show that timbre (instrument identity) independently affects the perception of emotions in music after controlling for other acoustic, cognitive, and performance factors.","accessed":{"date-parts":[["2022",5,12]]},"author":[{"family":"Hailstone","given":"Julia C."},{"family":"Omar","given":"Rohani"},{"family":"Henley","given":"Susie M. D."},{"family":"Frost","given":"Chris"},{"family":"Kenward","given":"Michael G."},{"family":"Warren","given":"Jason D."}],"citation-key":"hailstoneItNotWhat2009","container-title":"Quarterly Journal of Experimental Psychology","container-title-short":"Quarterly Journal of Experimental Psychology","DOI":"10.1080/17470210902765957","ISSN":"1747-0218, 1747-0226","issue":"11","issued":{"date-parts":[["2009",11]]},"language":"en","page":"2141-2155","source":"DOI.org (Crossref)","title":"It's not what you play, it's how you play it: Timbre affects perception of emotion in music","title-short":"It's not what you play, it's how you play it","type":"article-journal","URL":"http://journals.sagepub.com/doi/10.1080/17470210902765957","volume":"62"},{"id":"halbhuberUnderstandingEffectsPerceived2023","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Halbhuber","given":"David"},{"family":"Kocur","given":"Martin"},{"family":"Kalus","given":"Alexander"},{"family":"Angermeyer","given":"Kevin"},{"family":"Schwind","given":"Valentin"},{"family":"Henze","given":"Niels"}],"citation-key":"halbhuberUnderstandingEffectsPerceived2023","container-title":"Mensch und Computer 2023","DOI":"10.1145/3603555.3603580","event-place":"Rapperswil Switzerland","event-title":"MuC '23: Mensch und Computer 2023","ISBN":"979-8-4007-0771-1","issued":{"date-parts":[["2023",9,3]]},"language":"en","page":"1-15","publisher":"ACM","publisher-place":"Rapperswil Switzerland","source":"DOI.org (Crossref)","title":"Understanding the Effects of Perceived Avatar Appearance on Latency Sensitivity in Full-Body Motion-Tracked Virtual Reality","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3603555.3603580"},{"id":"hallamOxfordHandbookMusic2015","call-number":"ML3830 .O9 2015","citation-key":"hallamOxfordHandbookMusic2015","edition":"Second edition","editor":[{"family":"Hallam","given":"Susan"},{"family":"Cross","given":"Ian"},{"family":"Thaut","given":"Michael"}],"event-place":"New York, NY","ISBN":"978-0-19-872294-6","issued":{"date-parts":[["2015"]]},"number-of-pages":"950","publisher":"Oxford University Press","publisher-place":"New York, NY","source":"Library of Congress ISBN","title":"The Oxford Handbook of Music Psychology","type":"book"},{"id":"hallBioethicsEnhancementTranshumanism2018","accessed":{"date-parts":[["2021",1,13]]},"author":[{"family":"Hall","given":"Melinda C."}],"citation-key":"hallBioethicsEnhancementTranshumanism2018","event-place":"Lanham","ISBN":"978-1-4985-3349-2","issued":{"date-parts":[["2018"]]},"language":"English","note":"OCLC: 1100871634","publisher":"Lexington Books","publisher-place":"Lanham","source":"Open WorldCat","title":"The Bioethics of Enhancement: Transhumanism, Disability, and Biopolitics","title-short":"The Bioethics of Enhancement","type":"book","URL":"http://www.vlebooks.com/vleweb/product/openreader?id=none&isbn=9781498533492"},{"id":"hallettNeurophysiologyDystoniaRole2011","accessed":{"date-parts":[["2021",1,3]]},"author":[{"family":"Hallett","given":"Mark"}],"citation-key":"hallettNeurophysiologyDystoniaRole2011","container-title":"Neurobiology of Disease","container-title-short":"Neurobiology of Disease","DOI":"10.1016/j.nbd.2010.08.025","ISSN":"09699961","issue":"2","issued":{"date-parts":[["2011",5]]},"language":"en","page":"177-184","source":"DOI.org (Crossref)","title":"Neurophysiology of Dystonia: The Role of Inhibition","title-short":"Neurophysiology of dystonia","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0969996110002974","volume":"42"},{"id":"halmrastGestureTimbre2010","author":[{"family":"Halmrast","given":"Tor"},{"family":"Guettler","given":"Knut"},{"family":"Bader","given":"Rolf"}],"citation-key":"halmrastGestureTimbre2010","container-title":"Musical Gestures","event-place":"New York","ISBN":"978-0-415-99886-4","issued":{"date-parts":[["2010"]]},"page":"195-223","publisher":"Routledge","publisher-place":"New York","title":"Gesture and timbre","type":"chapter"},{"id":"hansenHowParticipatoryDesign2019","accessed":{"date-parts":[["2023",11,13]]},"author":[{"family":"Hansen","given":"Nicolai Brodersen"},{"family":"Dindler","given":"Christian"},{"family":"Halskov","given":"Kim"},{"family":"Iversen","given":"Ole Sejer"},{"family":"Bossen","given":"Claus"},{"family":"Basballe","given":"Ditte Amund"},{"family":"Schouten","given":"Ben"}],"citation-key":"hansenHowParticipatoryDesign2019","container-title":"Proceedings of the 31st Australian Conference on Human-Computer-Interaction","DOI":"10.1145/3369457.3369460","event-place":"Fremantle WA Australia","event-title":"OZCHI'19: 31ST AUSTRALIAN CONFERENCE ON HUMAN-COMPUTER-INTERACTION","ISBN":"978-1-4503-7696-9","issued":{"date-parts":[["2019",12,2]]},"language":"en","page":"30-41","publisher":"ACM","publisher-place":"Fremantle WA Australia","source":"DOI.org (Crossref)","title":"How Participatory Design Works: Mechanisms and Effects","title-short":"How Participatory Design Works","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3369457.3369460"},{"id":"hansenResearchbasedPracticeFacilitating2017","author":[{"family":"Hansen","given":"Pil"}],"citation-key":"hansenResearchbasedPracticeFacilitating2017","container-title":"Performance as Research","editor":[{"family":"Arlander","given":"Annette"},{"family":"Barton","given":"Bruce"},{"family":"Dreyer-Lude","given":"Melanie"},{"family":"Spatz","given":"Ben"}],"event-place":"London","ISBN":"1-315-15767-5","issued":{"date-parts":[["2017"]]},"page":"32-49","publisher":"Routledge","publisher-place":"London","title":"Research-based practice: Facilitating transfer across artistic, scholarly, and scientific inquiries","type":"chapter"},{"id":"harlowGlobalHyperorganPlatform2021","accessed":{"date-parts":[["2021",12,1]]},"author":[{"family":"Harlow","given":"Randall"},{"family":"Petersson","given":"Mattias"},{"family":"Ek","given":"Robert"},{"family":"Visi","given":"Federico"},{"family":"Östersjö","given":"Stefan"}],"citation-key":"harlowGlobalHyperorganPlatform2021","container-title":"NIME 2021","DOI":"10.21428/92fbeb44.d4146b2d","event-place":"Shanghai, China","event-title":"NIME 2021","issued":{"date-parts":[["2021",6,1]]},"publisher":"PubPub","publisher-place":"Shanghai, China","source":"DOI.org (Crossref)","title":"Global Hyperorgan: a platform for telematic musicking and research","title-short":"Global Hyperorgan","type":"paper-conference","URL":"https://nime.pubpub.org/pub/a626cbqh"},{"id":"harrawayActorsAreCyborg1991","abstract":"Case studies of groups including high-tech office workers, Star trek fans, Japanese technoporn producers, teenage hackers, AIDS activists, rap groups, and rock stars yield insights about the production and management of repressive technocultures, as well as new possibilities for the encouragement of technoliteracy, a requirement for the democratization of social communication. Annotation copyrighted by Book News, Inc., Portland, OR.","author":[{"family":"Harraway","given":"Donna"}],"citation-key":"harrawayActorsAreCyborg1991","container-title":"Technoculture","editor":[{"family":"Penley","given":"Constance"},{"family":"Ross","given":"Andrew"}],"ISBN":"978-0-8166-8371-0 978-0-8166-1932-0","issued":{"date-parts":[["1991"]]},"language":"English","note":"OCLC: 704577634","page":"21 - 26","source":"Open WorldCat","title":"The Actors Are Cyborg, Nature Is Coyote, and the Geography Is Elsewhere: Postscript to \"Cyborgs at Large\"","type":"chapter"},{"id":"harrimanFeedbackLapsteelExploring2015","abstract":"The Feedback Lap Steel is an actuated instrument which makes use of mechanical vibration of the instruments bridge to excite the strings. A custom bridge mounted directly to a tactile transducer enables the strings to be driven with any audio signal from a standard audio amplifier. The instrument can be played as a traditional lap steel guitar without any changes to playing technique as well as be used to create new sounds which blur the line between acoustic and electronic through a combination of acoustic and computer generated and controlled sounds. This introduces a new approach to string actuation using commonly available parts. This demonstration paper details the construction, uses and lessons learned in the making of the Feedback Lap Steel guitar.","accessed":{"date-parts":[["2023",1,16]]},"author":[{"family":"Harriman","given":"Jiffer"}],"citation-key":"harrimanFeedbackLapsteelExploring2015","DOI":"10.5281/ZENODO.1179076","issued":{"date-parts":[["2015",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"Feedback Lapsteel : Exploring Tactile Transducers As String Actuators","title-short":"Feedback Lapsteel","type":"article-journal","URL":"https://zenodo.org/record/1179076"},{"id":"harrisonWhenGuitarNot2018","author":[{"family":"Harrison","given":"Jacob"},{"family":"Jack","given":"Robert H"},{"family":"Morreale","given":"Fabio"},{"family":"McPherson","given":"Andrew P"}],"citation-key":"harrisonWhenGuitarNot2018","DOI":"10.5281/zenodo.1302589","editor":[{"family":"Luke Dahl","given":"Thomas Martin","suffix":"Douglas Bowman"}],"event-place":"Blacksburg, Virginia, USA","event-title":"Proceedings of the International Conference on New Interfaces for Musical Expression","issued":{"date-parts":[["2018",6]]},"page":"299-304","publisher":"Virginia Tech","publisher-place":"Blacksburg, Virginia, USA","title":"When is a Guitar not a Guitar? Cultural Form, Input Modality and Expertise","type":"paper-conference","URL":"http://www.nime.org/proceedings/2018/nime2018_paper0063.pdf"},{"id":"hartmannPrinciplesMusicalAcoustics2013","abstract":"Principles of Musical Acoustics focuses on the basic principles in the science and technology of music. Musical examples and specific musical instruments demonstrate the principles. The book begins with a study of vibrations and waves, in that order. These topics constitute the basic physical properties of sound, one of two pillars supporting the science of musical acoustics. The second pillar is the human element, the physiological and psychological aspects of acoustical science. The perceptual topics include loudness, pitch, tone color, and localization of sound. With these two pillars in place, it is possible to go in a variety of directions. The book treats in turn, the topics of room acoustics, audio both analog and digital, broadcasting, and speech. It ends with chapters on the traditional musical instruments, organized by family. The mathematical level of this book assumes that the reader is familiar with elementary algebra. Trigonometric functions, logarithms and powers also appear in the book, but computational techniques are included as these concepts are introduced, and there is further technical help in appendices","author":[{"family":"Hartmann","given":"William M."}],"call-number":"ML3805 .H32 2013","citation-key":"hartmannPrinciplesMusicalAcoustics2013","collection-title":"Undergraduate Lecture Notes in Physics","event-place":"New York, NY","ISBN":"978-1-4614-6785-4","issued":{"date-parts":[["2013"]]},"note":"OCLC: 863640203","number-of-pages":"348","publisher":"Springer","publisher-place":"New York, NY","source":"Library of Congress ISBN","title":"Principles of Musical Acoustics","type":"book"},{"id":"haugenInstructedTimingBody2023","abstract":"Body movements play a crucial role in music performance and perception, and they do so well beyond those devoted to sound production itself. Various movements related to the performer’s emotional intentions or structural aspects of the music are also part of the performance and crucial to the listening experience. In the present study, we investigated the effect of instructed timing on such non-sound producing body movements, focusing on musicians’ body posture. We used an infrared motion-capture system to record the movements of skilled guitarists and bassists while they were playing electric guitar and electric bass, respectively. We instructed the musicians to perform under three different timing-style conditions: laid-back (behind), on-the-beat, and pushed (ahead). We also conducted short semistructured interviews to gain further insight into their movement strategies. The results show that performers generally leaned forward when instructed to play systematically slightly ahead of the pulse. We suggest that this change is related to an alteration in the performer’s experience of the feel of the music. The results support the view that musicians’ non-sound-producing body movements are not random, but integral to the performance, and that they are closely related to the music’s microrhythmic feel.","accessed":{"date-parts":[["2024",3,29]]},"author":[{"family":"Haugen","given":"Mari Romarheim"},{"family":"Câmara","given":"Guilherme Schmidt"},{"family":"Nymoen","given":"Kristian"},{"family":"Danielsen","given":"Anne"}],"citation-key":"haugenInstructedTimingBody2023","container-title":"Musicae Scientiae","container-title-short":"Musicae Scientiae","DOI":"10.1177/10298649231182039","ISSN":"1029-8649, 2045-4147","issued":{"date-parts":[["2023",6,30]]},"language":"en","page":"10298649231182039","source":"DOI.org (Crossref)","title":"Instructed timing and body posture in guitar and bass playing in groove performance","type":"article-journal","URL":"http://journals.sagepub.com/doi/10.1177/10298649231182039"},{"id":"haugenInvestigatingMusicdanceRelationships2021","abstract":"Abstract This article studies the rhythm of Norwegian telespringar, a tradition with an intimate relationship between music and dance that features a nonisochronous meter","author":[{"family":"Haugen","given":"Mari Romarheim"}],"citation-key":"haugenInvestigatingMusicdanceRelationships2021","container-title":"Journal of music theory","DOI":"10.1215/00222909-9124714","ISSN":"0022-2909","issue":"1","issued":{"date-parts":[["2021"]]},"page":"17-38","publisher":"Duke University Press","title":"Investigating music-dance relationships","type":"article-journal","volume":"65"},{"id":"hayesAestheticsTouch2017","abstract":"In this paper we explore an interdisciplinary approach towards an aesthetics of touch. Research into the role of the body has become increasingly prevalent in fields ranging from philosophy of mind to human-computer interaction. At the same time, haptic technology has becoming ubiquitous within personalized devices and wearables. Despite this, touch remains largely under-explored within contemporary aesthetics. We firstly outline what might be gained from artistic practices that acknowledge a multisensory model of perception. Secondly, we discuss the difficulties of arriving at a standardized taxonomy for touch-based aesthetics and why this endeavor may not be fruitful. Finally, we outline an approach based on first-person felt experiences, drawing on creative practice research involving computational technology within the fields of somatics, dance, and music.","author":[{"family":"Hayes","given":"Lauren"},{"family":"Rajko","given":"Jessica"}],"citation-key":"hayesAestheticsTouch2017","collection-title":"MOCO '17","container-title":"Proceedings of the 4th international conference on movement computing","DOI":"10.1145/3077981.3078028","event-place":"London, United Kingdom","ISBN":"978-1-4503-5209-3","issued":{"date-parts":[["2017"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"London, United Kingdom","title":"Towards an aesthetics of touch","type":"paper-conference","URL":"https://doi.org/10.1145/3077981.3078028"},{"id":"haylesHowWeBecame1999","author":[{"family":"Hayles","given":"N. Katherine"}],"call-number":"Q335 .H394 1999","citation-key":"haylesHowWeBecame1999","event-place":"Chicago, Ill","ISBN":"978-0-226-32145-5 978-0-226-32146-2","issued":{"date-parts":[["1999"]]},"number-of-pages":"350","publisher":"University of Chicago Press","publisher-place":"Chicago, Ill","source":"Library of Congress ISBN","title":"How We Became Posthuman: Virtual Bodies in Cybernetics, Literature, and Informatics","title-short":"How we became posthuman","type":"book"},{"id":"haylesHowWeBecame1999a","author":[{"family":"Hayles","given":"N. Katherine"}],"call-number":"Q335 .H394 1999","citation-key":"haylesHowWeBecame1999a","event-place":"Chicago, Ill","ISBN":"978-0-226-32145-5 978-0-226-32146-2","issued":{"date-parts":[["1999"]]},"number-of-pages":"350","publisher":"University of Chicago Press","publisher-place":"Chicago, Ill","source":"Library of Congress ISBN","title":"How We Became Posthuman: Virtual Bodies in Cybernetics, Literature, and Informatics","title-short":"How We Became Posthuman","type":"book"},{"id":"haylesHowWeBecame1999b","author":[{"family":"Hayles","given":"N. Katherine"}],"call-number":"Q335 .H394 1999","citation-key":"haylesHowWeBecame1999b","event-place":"Chicago, Ill","ISBN":"978-0-226-32145-5 978-0-226-32146-2","issued":{"date-parts":[["1999"]]},"number-of-pages":"350","publisher":"University of Chicago Press","publisher-place":"Chicago, Ill","source":"Library of Congress ISBN","title":"How we became posthuman: virtual bodies in cybernetics, literature, and informatics","title-short":"How we became posthuman","type":"book"},{"id":"helmreichMusicCochlearImplants2020","abstract":"\"With essays covering an array of topics including ancient Homeric texts, contemporary sound installations, violin mutes, birdsong, and cochlear implants, this volume reveals the richness of what it means to think and talk about timbre and the materiality of the experience of sound\"--","author":[{"family":"Helmreich","given":"Stefan"}],"call-number":"ML3807 .O94 2020","citation-key":"helmreichMusicCochlearImplants2020","container-title":"The Oxford Handbook of Timbre","editor":[{"family":"Dolan","given":"Emily I."},{"family":"Rehding","given":"Alexander"}],"event-place":"New York","ISBN":"978-0-19-063722-4","issued":{"date-parts":[["2020"]]},"page":"11","publisher":"Oxford University Press","publisher-place":"New York","source":"Library of Congress ISBN","title":"Music for Cochlear Implants","type":"chapter"},{"id":"hepworth-sawyerMixingMusic2016","call-number":"ML3790 .H492 2017","citation-key":"hepworth-sawyerMixingMusic2016","collection-title":"Perspectives on music production","editor":[{"family":"Hepworth-Sawyer","given":"Russ"},{"family":"Hodgson","given":"Jay"}],"event-place":"New York ; London","ISBN":"978-1-138-18204-2 978-1-138-21873-4","issued":{"date-parts":[["2016"]]},"number-of-pages":"286","publisher":"Routledge","publisher-place":"New York ; London","source":"Library of Congress ISBN","title":"Mixing music","type":"book"},{"id":"heras-escribanoAreAffordancesNormative2016","accessed":{"date-parts":[["2023",11,1]]},"author":[{"family":"Heras-Escribano","given":"Manuel"},{"family":"De Pinedo","given":"Manuel"}],"citation-key":"heras-escribanoAreAffordancesNormative2016","container-title":"Phenomenology and the Cognitive Sciences","container-title-short":"Phenom Cogn Sci","DOI":"10.1007/s11097-015-9440-0","ISSN":"1568-7759, 1572-8676","issue":"4","issued":{"date-parts":[["2016",12]]},"language":"en","page":"565-589","source":"DOI.org (Crossref)","title":"Are affordances normative?","type":"article-journal","URL":"http://link.springer.com/10.1007/s11097-015-9440-0","volume":"15"},{"id":"hermawatiAssistiveTechnologiesSevere2020","abstract":"ABSTRACT Assistive technologies (ATs) offer capabilities that were previously inaccessible to individuals with severe and profound hearing loss who have no or limited access to hearing aids and implants. This literature review aims to explore existing ATs and identify what still needs to be done. It is found that there is a lack of focus on the overall objectives of ATs. In addition, several other issues are identified, i.e. only a very small number of ATs developed within a research context have led to commercial devices, and there is a predisposition to use the latest expensive technologies and a tendency to avoid designing products universally. Finally, the further development of plug-ins that translate the text content of a website to various sign languages is needed to make information on the internet more accessible.","author":[{"family":"Hermawati","given":"Setia"},{"family":"Pieri","given":"Katerina"}],"citation-key":"hermawatiAssistiveTechnologiesSevere2020","container-title":"Assistive Technology","container-title-short":"null","DOI":"10.1080/10400435.2018.1522524","ISSN":"1040-0435","issue":"4","issued":{"date-parts":[["2020",7,3]]},"page":"182-193","publisher":"Taylor & Francis","title":"Assistive Technologies for Severe and Profound Hearing Loss: Beyond Hearing Aids and Implants","type":"article-journal","URL":"https://doi.org/10.1080/10400435.2018.1522524","volume":"32"},{"id":"herrmannEarlyAbandoningPruning2021","abstract":"Nearest neighbor search under elastic distances is a key tool for time series analysis, supporting many applications. However, straightforward implementations of distances require $$O(n^2)$$space and time complexities, preventing these applications from scaling to long series. Much work has been devoted to speeding up the NN search process, mostly with the development of lower bounds, allowing to avoid costly distance computations when a given threshold is exceeded. This threshold, provided by the similarity search process, also allows to early abandon the computation of a distance itself. Another approach, is to prune parts of the computation. All these techniques are orthogonal to each other. In this work, we develop a new generic strategy, “EAPruned”, that tightly integrates pruning with early abandoning. We apply it to six elastic distance measures: DTW, CDTW, WDTW, ERP, MSM and TWE, showing substantial speedup in NN search applications. Pruning alone also shows substantial speedup for some distances, benefiting applications beyond the scope of NN search (e.g. requiring all pairwise distances), and hence where early abandoning is not applicable. We release our implementation as part of a new C++ library for time series classification, along with easy to use Python/Numpy bindings.","author":[{"family":"Herrmann","given":"Matthieu"},{"family":"Webb","given":"Geoffrey I."}],"citation-key":"herrmannEarlyAbandoningPruning2021","container-title":"Data Mining and Knowledge Discovery","container-title-short":"Data Mining and Knowledge Discovery","DOI":"10.1007/s10618-021-00782-4","ISSN":"1573-756X","issue":"6","issued":{"date-parts":[["2021",11,1]]},"page":"2577-2601","title":"Early abandoning and pruning for elastic distances including dynamic time warping","type":"article-journal","URL":"https://doi.org/10.1007/s10618-021-00782-4","volume":"35"},{"id":"hershAssistiveTechnologyHearingimpaired2014","author":[{"family":"Hersh","given":"Marion A."},{"family":"Johnson","given":"Michael A"}],"citation-key":"hershAssistiveTechnologyHearingimpaired2014","event-place":"Place of publication not identified","ISBN":"978-1-4471-3922-5","issued":{"date-parts":[["2014"]]},"language":"English","note":"OCLC: 905683954","publisher":"Springer","publisher-place":"Place of publication not identified","source":"Open WorldCat","title":"Assistive Technology for the Hearing-impaired, Deaf and Deafblind","type":"book"},{"id":"hersheyCNNArchitecturesLargescale2017","author":[{"family":"Hershey","given":"Shawn"},{"family":"Chaudhuri","given":"Sourish"},{"family":"Ellis","given":"Daniel PW"},{"family":"Gemmeke","given":"Jort F"},{"family":"Jansen","given":"Aren"},{"family":"Moore","given":"R Channing"},{"family":"Plakal","given":"Manoj"},{"family":"Platt","given":"Devin"},{"family":"Saurous","given":"Rif A"},{"family":"Seybold","given":"Bryan"},{"literal":"others"}],"citation-key":"hersheyCNNArchitecturesLargescale2017","container-title":"2017 ieee international conference on acoustics, speech and signal processing (icassp)","issued":{"date-parts":[["2017"]]},"page":"131–135","publisher":"IEEE","title":"CNN architectures for large-scale audio classification","type":"paper-conference"},{"id":"hershModellingAssistiveTechnology2008","abstract":"There has been increasing recognition of the importance and benefits to society of social inclusion and the full participation of disabled people. Many countries have also enacted legislation aimed at removing discrimination against disabled people. Removing barriers to full participation by disabled people will require the development of new assistive technology systems and improved information and distribution systems for existing assistive technologies. This will require an effective and ongoing dialogue between the disabled end-user community, social services, the clinical rehabilitation services, and the professional engineering disciplines involved in the development, provision, assessment, and ongoing support for assistive technology. To support this dialogue there is a need for common terminology, concepts, and definitions, embedded within a single, unified model framework. This paper presents the Comprehensive Assistive Technology (CAT) model, which was designed to meet this need.","author":[{"family":"Hersh","given":"Marion A."},{"family":"Johnson","given":"Michael A."}],"citation-key":"hershModellingAssistiveTechnology2008","container-title":"Technology and Disability","DOI":"10.3233/TAD-2008-20303","ISSN":"1878-643X","issue":"3","issued":{"date-parts":[["2008"]]},"page":"193-215","publisher":"IOS Press","title":"On Modelling Assistive Technology Systems – Part I: Modelling Framework","type":"article-journal","volume":"20"},{"id":"herzogAllGoodTime2020","abstract":"S2 TL;DR: This work proposes a two-stage discrete model, in which substantial periods of continuous unconscious processing precede discrete conscious percepts, that marries the advantages of both continuous and discrete models and resolves centuries old debates about perception and consciousness.","author":[{"family":"Herzog","given":"M."},{"family":"Drissi-Daoudi","given":"Leila"},{"family":"Doerig","given":"Adrien"}],"citation-key":"herzogAllGoodTime2020","container-title":"Trends in Cognitive Sciences","DOI":"10.1016/j.tics.2020.07.001","issued":{"date-parts":[["2020"]]},"note":"QID: Q99204169","page":"826-837","PMID":"32893140","title":"All in good time: Long-lasting postdictive effects reveal discrete perception","type":"article-journal","URL":"https://www.semanticscholar.org/paper/999b2cd46f9c38b1ce892044cd2c4d9c26c658d5","volume":"24"},{"id":"higginsMusicOurLives1991","author":[{"family":"Higgins","given":"Kathleen Marie"}],"call-number":"ML3920 .H5 1991","citation-key":"higginsMusicOurLives1991","event-place":"Philadelphia","ISBN":"978-0-87722-756-4","issued":{"date-parts":[["1991"]]},"number-of-pages":"258","publisher":"Temple University Press","publisher-place":"Philadelphia","source":"Library of Congress ISBN","title":"The Music of Our Lives","type":"book"},{"id":"hiyadiAdaptiveDynamicTime12","author":[{"family":"Hiyadi","given":"Hajar"},{"family":"Ababsa","given":"Fakhreddine"},{"family":"Montagne","given":"Christophe"},{"family":"Bouyakhf","given":"El Houssine"},{"family":"Regragui","given":"Fakhita"}],"citation-key":"hiyadiAdaptiveDynamicTime12","container-title":"2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)","container-title-short":"2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)","DOI":"10.1109/IPTA.2016.7820971","event-title":"2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)","ISBN":"2154-512X","issued":{"date-parts":[["12"],["2016",12,15]]},"page":"1-6","title":"Adaptive dynamic time warping for recognition of natural gestures","type":"paper-conference"},{"id":"hockleyAnalogtoDigitalConversionAccommodate2012","author":[{"family":"Hockley","given":"Neil S."},{"family":"Bahlmann","given":"Frauke"},{"family":"Fulton","given":"Bernadette"}],"citation-key":"hockleyAnalogtoDigitalConversionAccommodate2012","container-title":"Trends in Amplification","container-title-short":"Trends in Amplification","ISSN":"1084-7138","issue":"3","issued":{"date-parts":[["2012"]]},"page":"146-158","publisher":"Sage Publications Sage CA: Los Angeles, CA","title":"Analog-to-Digital Conversion to Accommodate the Dynamics of Live Music in Hearing Instruments","type":"article-journal","volume":"16"},{"id":"hodginsPerceptionHumanMotion1998","accessed":{"date-parts":[["2024",1,4]]},"author":[{"family":"Hodgins","given":"J.K."},{"family":"O'Brien","given":"J.F."},{"family":"Tumblin","given":"J."}],"citation-key":"hodginsPerceptionHumanMotion1998","container-title":"IEEE Transactions on Visualization and Computer Graphics","container-title-short":"IEEE Trans. Visual. Comput. Graphics","DOI":"10.1109/2945.765325","ISSN":"10772626","issue":"4","issued":{"literal":"Oct.-Dec./1998"},"page":"307-316","source":"DOI.org (Crossref)","title":"Perception of human motion with different geometric models","type":"article-journal","URL":"http://ieeexplore.ieee.org/document/765325/","volume":"4"},{"id":"hoffdingFramingPhenomenologicalInterview2016","abstract":"Research in phenomenology has benefitted from using exceptional cases from pathology and expertise. But exactly how are we to generate and apply knowledge from such cases to the phenomenological domain? As researchers of cerebral palsy and musical absorption, we together answer the how question by pointing to the resource of the qualitative interview. Using the qualitative interview is a direct response to Varela’s call for better pragmatics in the methodology of phenomenology and cognitive science and Gallagher’s suggestion for phenomenology to develop its methodology and outsource its tasks. We agree with their proposals, but want to develop them further by discussing and proposing a general framework that can integrate research paradigms of the well-established disciplines of phenomenological philosophy and qualitative science. We give this the working title, a “phenomenological interview”. First we describe the what of the interview, that is the nature of the interview in which one encounters another subject and generates knowledge of a given experience together with this other subject. In the second part, we qualify why it is worthwhile making the time-consuming effort to engage in a phenomenological interview. In the third and fourth parts, we in general terms discuss how to conduct the interview and the subsequent phenomenological analysis, by discussing the pragmatics of Vermersch’s and Petitmengin’s “Explicitation Interview”.","author":[{"family":"Høffding","given":"Simon"},{"family":"Martiny","given":"Kristian"}],"citation-key":"hoffdingFramingPhenomenologicalInterview2016","container-title":"Phenomenology and the Cognitive Sciences","container-title-short":"Phenomenology and the Cognitive Sciences","DOI":"10.1007/s11097-015-9433-z","ISSN":"1572-8676","issue":"4","issued":{"date-parts":[["2016",12,1]]},"page":"539-564","title":"Framing a phenomenological interview: what, why and how","type":"article-journal","URL":"https://doi.org/10.1007/s11097-015-9433-z","volume":"15"},{"id":"hoganTheySayWe2016","author":[{"family":"Hogan","given":"Brian"}],"citation-key":"hoganTheySayWe2016","container-title":"The Oxford Handbook of Music and Disability Studies","editor":[{"family":"Howe","given":"Blake"},{"family":"Jensen-Moulton","given":"Stephanie"},{"family":"Lerner","given":"Neil William"},{"family":"Straus","given":"Joseph Nathan"}],"event-place":"Oxford ; New York","ISBN":"978-0-19-933144-4 978-0-19-065060-5","issued":{"date-parts":[["2016"]]},"page":"112 - 130","publisher":"Oxford University Press","publisher-place":"Oxford ; New York","source":"Library of Congress ISBN","title":"“They Say We Exchanged Our Eyes for the Xylophone”: Resisting Tropes of Disability as Spiritual Deviance in Birifor Music","type":"chapter"},{"id":"hogendoornBlurredLinesMemory2022","abstract":"In the previous issue, Budson, Richman, and Kensinger (2022) put forth the intriguing proposal that consciousness may have evolved from the episodic memory system. In addition to providing a possible evolutionary trajectory for consciousness, I believe that viewing consciousness as an extension of memory in this way is particularly useful for understanding some of the puzzling temporal complexities that are inherent to consciousness. For example, due to neural transmission delays, our conscious experience must necessarily lag the outside world, which creates a paradox for both conscious perception (Do we see the past, rather than the present?) and action (How can we make rapid decisions if it takes so long to become conscious of something?). These paradoxes can be elegantly solved by treating consciousness as a memory system. Finally, the proposal put forth by Budson and colleagues (2022) aligns with the emerging perspective that consciousness, like memory, represents a narrative time line of events rather than any single instant. However, I believe that this conceptualization can be further extended to include not only the past, but also the future. In this way, consciousness can be provocatively viewed as the remembered past, present, and future.","author":[{"family":"Hogendoorn","given":"Hinze"}],"citation-key":"hogendoornBlurredLinesMemory2022","container-title":"Cognitive and Behavioral Neurology","DOI":"10.1097/WNN.0000000000000325","issued":{"date-parts":[["2022"]]},"page":"54 - 58","PMID":"36476579","title":"Blurred lines: Memory, perceptions, and consciousness: Commentary on “Consciousness as a memory system” by budson et al (2022)","type":"article-journal","URL":"https://www.semanticscholar.org/paper/c6db30aaeeca60f29168df5b359d7c46ea4b6223","volume":"36"},{"id":"hogendoornMotionExtrapolationVisual2020","abstract":"Because of the delays inherent in neural transmission, the brain needs time to process incoming visual information. If these delays were not somehow compensated, we would consistently mislocalize moving objects behind their physical positions. Twenty-five years ago, Nijhawan used a perceptual illusion he called the flash-lag effect (FLE) to argue that the brain's visual system solves this computational challenge by extrapolating the position of moving objects (Nijhawan, 1994). Although motion extrapolation had been proposed a decade earlier (e.g., Finke et al., 1986), the proposal that it caused the FLE and functioned to compensate for computational delays was hotly debated in the years that followed, with several alternative interpretations put forth to explain the effect. Here, I argue, 25 years later, that evidence from behavioral, computational, and particularly recent functional neuroimaging studies converges to support the existence of motion extrapolation mechanisms in the visual system, as well as their causal involvement in the FLE. First, findings that were initially argued to challenge the motion extrapolation model of the FLE have since been explained, and those explanations have been tested and corroborated by more recent findings. Second, motion extrapolation explains the spatial shifts observed in several FLE conditions that cannot be explained by alternative (temporal) models of the FLE. Finally, neural mechanisms that actually perform motion extrapolation have been identified at multiple levels of the visual system, in multiple species, and with multiple different methods. I outline key questions that remain, and discuss possible directions for future research.","author":[{"family":"Hogendoorn","given":"Hinze"}],"citation-key":"hogendoornMotionExtrapolationVisual2020","container-title":"The Journal of Neuroscience","DOI":"10.1523/JNEUROSCI.0275-20.2020","issued":{"date-parts":[["2020"]]},"note":"QID: Q97652657","page":"5698 - 5705","PMID":"32699152","title":"Motion extrapolation in visual processing: Lessons from 25 years of flash-lag debate","type":"article-journal","URL":"https://www.semanticscholar.org/paper/ec600a165854e1a678525d96f84eab84e1a0e5a4","volume":"40"},{"id":"hogendoornPerceptionRealtimePredicting2022","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Hogendoorn","given":"Hinze"}],"citation-key":"hogendoornPerceptionRealtimePredicting2022","container-title":"Trends in Cognitive Sciences","container-title-short":"Trends in Cognitive Sciences","DOI":"10.1016/j.tics.2021.11.003","ISSN":"13646613","issue":"2","issued":{"date-parts":[["2022",2]]},"language":"en","page":"128-141","source":"DOI.org (Crossref)","title":"Perception in real-time: predicting the present, reconstructing the past","title-short":"Perception in real-time","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S1364661321002886","volume":"26"},{"id":"hogendoornPredictiveCodingNeural2018","abstract":"Visual Abstract Hierarchical predictive coding is an influential model of cortical organization, in which sequential hierarchical levels are connected by backward connections carrying predictions, as well as forward connections carrying prediction errors. To date, however, predictive coding models have largely neglected to take into account that neural transmission itself takes time. For a time-varying stimulus, such as a moving object, this means that backward predictions become misaligned with new sensory input. We present an extended model implementing both forward and backward extrapolation mechanisms that realigns backward predictions to minimize prediction error. This realignment has the consequence that neural representations across all hierarchical levels become aligned in real time. Using visual motion as an example, we show that the model is neurally plausible, that it is consistent with evidence of extrapolation mechanisms throughout the visual hierarchy, that it predicts several known motion–position illusions in human observers, and that it provides a solution to the temporal binding problem.","author":[{"family":"Hogendoorn","given":"Hinze"},{"family":"Burkitt","given":"A."}],"citation-key":"hogendoornPredictiveCodingNeural2018","container-title":"eNeuro","DOI":"10.1523/ENEURO.0412-18.2019","issued":{"date-parts":[["2018"]]},"note":"QID: Q64065398","page":"null","PMID":"31064839","title":"Predictive coding with neural transmission delays: A real-time temporal alignment hypothesis","type":"article-journal","URL":"https://www.semanticscholar.org/paper/04e809dcbb8a5368f956f8acbb24a661feca5915","volume":"6"},{"id":"hogendoornStrikinglyRapidNeural2015","abstract":"S2 TL;DR: This work used a variant of the flash-grab illusion to shift the perceived positions of flashed stimuli, and applied multivariate pattern classification to individual 64-channel EEG trials to dissociate neural signals corresponding to veridical versus perceived position with high temporal resolution to show illusory effects of motion on perceived position.","author":[{"family":"Hogendoorn","given":"Hinze"},{"family":"Verstraten","given":"Frans A. J."},{"family":"Cavanagh","given":"P."}],"citation-key":"hogendoornStrikinglyRapidNeural2015","container-title":"Vision Research","DOI":"10.1016/j.visres.2015.05.005","issued":{"date-parts":[["2015"]]},"note":"QID: Q48155441","page":"1-10","PMID":"26021721","title":"Strikingly rapid neural basis of motion-induced position shifts revealed by high temporal-resolution EEG pattern classification","type":"article-journal","URL":"https://www.semanticscholar.org/paper/a06c2f2c6c8689470670be03f8cbd87613d127f9","volume":"113"},{"id":"holbrowVocalVibrationsMultisensory2014","abstract":"Vocal Vibrations is a new project by the Opera of the Future group at the MIT Media Lab that seeks to engage the public in thoughtful singing and vocalizing, while exploring the relationship between human physiology and the resonant vibrations of the voice. This paper describes the motivations, the technical implementation, and the experience design of the Vocal Vibrations public installation. This installation consists of a space for reflective listening to a vocal composition (the Chapel) and an interactive space for personal vocal exploration (the Cocoon). In the interactive experience, the participant also experiences a tangible exteriorization of his voice by holding the ORB, a handheld device that translates his voice and singing into tactile vibrations. This installation encourages visitors to explore the physicality and expressivity of their voices in a rich musical context.","accessed":{"date-parts":[["2020",10,7]]},"author":[{"family":"Holbrow","given":"Charles"},{"family":"Jessop","given":"Elena"},{"family":"Kleinberger","given":"Rebecca"}],"citation-key":"holbrowVocalVibrationsMultisensory2014","DOI":"10.5281/ZENODO.1178800","issued":{"date-parts":[["2014",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"Vocal Vibrations: A Multisensory Experience Of The Voice","title-short":"Vocal Vibrations","type":"paper-conference","URL":"https://zenodo.org/record/1178800"},{"id":"hollandMusicInteractionUnderstanding2013","author":[{"family":"Holland","given":"Simon"},{"family":"Wilkie","given":"Katie"},{"family":"Mulholland","given":"Paul"},{"family":"Seago","given":"Allan"}],"citation-key":"hollandMusicInteractionUnderstanding2013","container-title":"Music and human-computer interaction","issued":{"date-parts":[["2013"]]},"page":"1-28","publisher":"Springer","title":"Music interaction: understanding music and human-computer interaction","type":"chapter"},{"id":"holmesElectronicExperimentalMusic2008","accessed":{"date-parts":[["2022",10,5]]},"author":[{"family":"Holmes","given":"Thom"}],"citation-key":"holmesElectronicExperimentalMusic2008","DOI":"10.4324/9780203929599","edition":"3","event-place":"New York","ISBN":"978-1-135-90617-7","issued":{"date-parts":[["2008",4,22]]},"language":"en","publisher":"Routledge","publisher-place":"New York","source":"DOI.org (Crossref)","title":"Electronic and Experimental Music","type":"book","URL":"https://www.taylorfrancis.com/books/9781135906177"},{"id":"holmesExpertListeningLimits2017","abstract":"Attitudes to the relationship between music and deafness suffer from two related misconceptions: the enduring assumption that hearing is central to musical experience in conjunction with an extreme impression of deafness as total aural loss; and, more recently, the tendency to reduce deaf listening to tactility, as narratives about inborn sensory acuities among the deaf proliferate in the popular imaginary. Increasingly, deafness symbolizes a set of sensory polarities that obscure an intrinsic diversity of musical experiences from which musicology stands to gain, a diversity that encompasses members of Deaf culture and non-culturally deaf people alike, and that is signaled through the person-centered compound “d/Deaf.” My article builds on recent music scholarship on disability to offer a pluralistic understanding of music and deafness. Beginning with Scottish deaf percussionist Evelyn Glennie, I investigate a range of d/Deaf accounts of music, including those of Deaf sign language users, hearing aid wearers, and cochlear implant recipients, and of people with music-induced hearing loss. Deafness resists automatic entry points into music, unsettling any straightforward hierarchy of the senses. Deaf people reflect on the musical status of aurality in markedly different ways, just as they offer a complex understanding of vision and touch. For instance, vision is a highly versatile listening strategy and is often more reliable than vibration; touch is feasible because of its contextual dependence on visual cues, and is further tied to a set of material and environmental variables. Ultimately, I argue that d/Deaf listeners enrich customary notions of musical expertise: deafness belongs in musicology as a diverse set of experiences within the full spectrum of listening.","accessed":{"date-parts":[["2022",5,15]]},"author":[{"family":"Holmes","given":"Jessica A."}],"citation-key":"holmesExpertListeningLimits2017","container-title":"Journal of the American Musicological Society","DOI":"10.1525/jams.2017.70.1.171","ISSN":"0003-0139, 1547-3848","issue":"1","issued":{"date-parts":[["2017",4,1]]},"language":"en","page":"171-220","source":"DOI.org (Crossref)","title":"Expert Listening beyond the Limits of Hearing: Music and Deafness","title-short":"Expert Listening beyond the Limits of Hearing","type":"article-journal","URL":"https://online.ucpress.edu/jams/article/70/1/171/2043/Expert-Listening-beyond-the-Limits-of-Hearing","volume":"70"},{"id":"holmesExpertListeningLimits2017a","abstract":"Attitudes to the relationship between music and deafness suffer from two related misconceptions: the enduring assumption that hearing is central to musical experience in conjunction with an extreme impression of deafness as total aural loss; and, more recently, the tendency to reduce deaf listening to tactility, as narratives about inborn sensory acuities among the deaf proliferate in the popular imaginary. Increasingly, deafness symbolizes a set of sensory polarities that obscure an intrinsic diversity of musical experiences from which musicology stands to gain, a diversity that encompasses members of Deaf culture and non-culturally deaf people alike, and that is signaled through the person-centered compound “d/Deaf.” My article builds on recent music scholarship on disability to offer a pluralistic understanding of music and deafness. Beginning with Scottish deaf percussionist Evelyn Glennie, I investigate a range of d/Deaf accounts of music, including those of Deaf sign language users, hearing aid wearers, and cochlear implant recipients, and of people with music-induced hearing loss. Deafness resists automatic entry points into music, unsettling any straightforward hierarchy of the senses. Deaf people reflect on the musical status of aurality in markedly different ways, just as they offer a complex understanding of vision and touch. For instance, vision is a highly versatile listening strategy and is often more reliable than vibration; touch is feasible because of its contextual dependence on visual cues, and is further tied to a set of material and environmental variables. Ultimately, I argue that d/Deaf listeners enrich customary notions of musical expertise: deafness belongs in musicology as a diverse set of experiences within the full spectrum of listening.","accessed":{"date-parts":[["2020",1,10]]},"author":[{"family":"Holmes","given":"Jessica A."}],"citation-key":"holmesExpertListeningLimits2017a","container-title":"Journal of the American Musicological Society","container-title-short":"Journal of the American Musicological Society","DOI":"10.1525/jams.2017.70.1.171","ISSN":"0003-0139","issue":"1","issued":{"date-parts":[["2017",4,1]]},"page":"171-220","title":"Expert Listening beyond the Limits of Hearing: Music and Deafness","type":"article-journal","URL":"https://doi.org/10.1525/jams.2017.70.1.171","volume":"70"},{"id":"holtonDigitalSignalProcessing2020","abstract":"\"Combining clear explanations of elementary principles, advanced topics, and applications, with step-by-step mathematical derivations, this textbook provides a comprehensive yet accessible introduction to digital signal processing. All the key topics are covered, including discrete-time Fourier transform, z-transform, discrete Fourier transform, and A/D conversion, as well as more advanced topics such as FIR and IIR filtering algorithms, multi-rate systems, the discrete cosine transform, and spectral signal processing. Over 600 full-color illustrations, 200 fully worked examples, hundreds of end-of-chapter homework problems, and detailed computational examples of DSP algorithms implemented in Matlab and C aid understanding and help put knowledge into practice. A wealth of supplementary material accompanies the book online, including interactive programs for instructors, a full set of solutions, and Matlab laboratory exercises, making this the ideal text for senior undergraduate and graduate courses on digital signal processing\"--","author":[{"family":"Holton","given":"Thomas"}],"call-number":"TK5102.9 .H67 2020","citation-key":"holtonDigitalSignalProcessing2020","event-place":"Cambridge, United Kingdom ; New York, NY, USA","ISBN":"978-1-108-41844-7","issued":{"date-parts":[["2020"]]},"publisher":"Cambridge University Press","publisher-place":"Cambridge, United Kingdom ; New York, NY, USA","source":"Library of Congress ISBN","title":"Digital signal processing: principles and applications","title-short":"Digital signal processing","type":"book"},{"id":"horneckerLearningInteractiveMuseum2006","accessed":{"date-parts":[["2022",11,10]]},"author":[{"family":"Hornecker","given":"Eva"},{"family":"Stifter","given":"Matthias"}],"citation-key":"horneckerLearningInteractiveMuseum2006","container-title":"Proceedings of the 20th conference of the computer-human interaction special interest group (CHISIG) of Australia on Computer-human interaction: design: activities, artefacts and environments  - OZCHI '06","DOI":"10.1145/1228175.1228201","event-place":"Sydney, Australia","event-title":"the 20th conference of the computer-human interaction special interest group (CHISIG) of Australia","ISBN":"978-1-59593-545-8","issued":{"date-parts":[["2006"]]},"language":"en","page":"135","publisher":"ACM Press","publisher-place":"Sydney, Australia","source":"DOI.org (Crossref)","title":"Learning from interactive museum installations about interaction design for public settings","type":"paper-conference","URL":"http://portal.acm.org/citation.cfm?doid=1228175.1228201"},{"id":"houMotionPredictionPreRendering2020","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Hou","given":"Xueshi"},{"family":"Dey","given":"Sujit"}],"citation-key":"houMotionPredictionPreRendering2020","container-title":"IEEE Open Journal of the Communications Society","container-title-short":"IEEE Open J. Commun. Soc.","DOI":"10.1109/OJCOMS.2020.3032608","ISSN":"2644-125X","issued":{"date-parts":[["2020"]]},"license":"https://creativecommons.org/licenses/by/4.0/legalcode","page":"1674-1690","source":"DOI.org (Crossref)","title":"Motion Prediction and Pre-Rendering at the Edge to Enable Ultra-Low Latency Mobile 6DoF Experiences","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/9234536/","volume":"1"},{"id":"howeDisablingMusicPerformance2016","author":[{"family":"Howe","given":"Blake"}],"citation-key":"howeDisablingMusicPerformance2016","container-title":"The Oxford Handbook of Music and Disability Studies","editor":[{"family":"Howe","given":"Blake"},{"family":"Jensen-Moulton","given":"Stephanie"},{"family":"Lerner","given":"Neil William"},{"family":"Straus","given":"Joseph Nathan"}],"event-place":"Oxford ; New York","ISBN":"978-0-19-933144-4 978-0-19-065060-5","issued":{"date-parts":[["2016"]]},"page":"54 - 72","publisher":"Oxford University Press","publisher-place":"Oxford ; New York","source":"Library of Congress ISBN","title":"Disabling Music Performance","type":"chapter"},{"id":"howeOxfordHandbookMusic2016","call-number":"ML3916 .O96 2016","citation-key":"howeOxfordHandbookMusic2016","editor":[{"family":"Howe","given":"Blake"},{"family":"Jensen-Moulton","given":"Stephanie"},{"family":"Lerner","given":"Neil William"},{"family":"Straus","given":"Joseph Nathan"}],"event-place":"Oxford ; New York","ISBN":"978-0-19-933144-4 978-0-19-065060-5","issued":{"date-parts":[["2016"]]},"number-of-pages":"928","publisher":"Oxford University Press","publisher-place":"Oxford ; New York","source":"Library of Congress ISBN","title":"The Oxford Handbook of Music and Disability Studies","type":"book"},{"id":"howePaulWittgensteinPerformance2010","abstract":"Paul Wittgenstein's one-handedness has typically been framed as a physical limitation at odds with an able-bodied ideology driving musical performance. Contemporary reviews, for instance, frame the pianist's disability as a tragedy heroically transcended during the course of virtuosic performance; others suggest that Wittgenstein successfully \"passed\" as two-handed. A study of Wittgenstein's numerous one-hand arrangements reveals similar narratives: the pianist often attempted to imitate the sound of two-handed piano music, and many of his own keyboard exercises train his one hand to assume the load of two. The \"deficiency\" model can be seen most dramatically in three attempts to arrange Witt-genstein's commissions for left-hand piano into a more \"normal\" performance medium: Sergei Prokofiev's expressed (but abandoned) interest in arranging his left-hand piano concerto for piano two-hands, Alfred Cortot's completed draft of a two-hand arrangement of Ravel's Concerto pour la main gauche, and, most significantly, Friedrich W&#xfc;hrer's highly successful two-hand arrangements of Franz Schmidt's left-hand pieces for Wittgenstein, which explicitly adopt a program of \"strengthening\" and \"filling in\" the supposed weaknesses of a disabled performance medium. Yet, despite the stigma it may have accrued, one-handed pianism is but a more prominent, more public example of the \"bodily limits\" all performers must confront; similar discourse surrounds the deficiencies of small hands or stiff fingers, for example. For the performer's body must negotiate its corporeal finitude with the complex demands of the musical score. As seen here in the career of Wittgenstein, an aesthetics of disabled performance presents this dialectic in heightened microcosm.","archive":"JSTOR","author":[{"family":"Howe","given":"Blake"}],"citation-key":"howePaulWittgensteinPerformance2010","container-title":"The Journal of Musicology","DOI":"10.1525/jm.2010.27.2.135","ISSN":"02779269, 15338347","issue":"2","issued":{"date-parts":[["2010"]]},"page":"135-180","publisher":"University of California Press","title":"Paul Wittgenstein and the Performance Of Disability","type":"article-journal","URL":"http://www.jstor.org/stable/10.1525/jm.2010.27.2.135","volume":"27"},{"id":"howeSaulDavidMusic2016","author":[{"family":"Howe","given":"Blake"}],"citation-key":"howeSaulDavidMusic2016","container-title":"The Oxford Handbook of Music and Disability Studies","editor":[{"family":"Howe","given":"Blake"},{"family":"Jensen-Moulton","given":"Stephanie"},{"family":"Lerner","given":"Neil William"},{"family":"Straus","given":"Joseph Nathan"}],"event-place":"Oxford ; New York","ISBN":"978-0-19-933144-4 978-0-19-065060-5","issued":{"date-parts":[["2016"]]},"page":"539 - 562","publisher":"Oxford University Press","publisher-place":"Oxford ; New York","source":"Library of Congress ISBN","title":"Saul, David, and Music’s Ideal Body","type":"chapter"},{"id":"hsiaoMandarinMelodyRecognition2008","author":[{"family":"Hsiao","given":"Feilin"}],"citation-key":"hsiaoMandarinMelodyRecognition2008","container-title":"Journal of Music Therapy","container-title-short":"Journal of Music Therapy","ISSN":"2053-7395","issue":"4","issued":{"date-parts":[["2008"]]},"page":"390-404","publisher":"American Music Therapy Association","title":"Mandarin Melody Recognition by Pediatric Cochlear Implant Recipients","type":"article-journal","volume":"45"},{"id":"hsuWearableSportActivity2019","author":[{"family":"Hsu","given":"Yu-Liang"},{"family":"Chang","given":"Hsing-Cheng"},{"family":"Chiu","given":"Yung-Jung"}],"citation-key":"hsuWearableSportActivity2019","container-title":"IEEE access : practical innovations, open solutions","container-title-short":"IEEE Access","DOI":"10.1109/ACCESS.2019.2955545","issued":{"date-parts":[["2019"]]},"page":"170199-170212","title":"Wearable sport activity classification based on deep convolutional neural network","type":"article-journal","volume":"7"},{"id":"hubbardEffectContrastLuminance2014","abstract":"Effects of the contrast of target luminance and background luminance, and of the absolute level of target luminance, on representational momentum for the remembered final location of a previously viewed moving target were examined. Targets were high in contrast or luminance, decreasing in contrast or luminance, increasing in contrast or luminance, or low in contrast or luminance; the background was black or white. Representational momentum for target location was larger if targets were high or increasing in contrast or luminance and smaller if targets were low or decreasing in contrast or luminance. Representational momentum for target location was larger if targets were presented on a white background than on a black background. Implications for theories of localization and for theories of representational momentum are discussed.","author":[{"family":"Hubbard","given":"T."},{"family":"Ruppel","given":"S."}],"citation-key":"hubbardEffectContrastLuminance2014","container-title":"Perception","DOI":"10.1068/p7714","issued":{"date-parts":[["2014"]]},"note":"QID: Q50610323","page":"754 - 766","PMID":"25549506","title":"An effect of contrast and luminance on visual representational momentum for location","type":"article-journal","URL":"https://www.semanticscholar.org/paper/52b746247649612daf4ec1c0939e0f7a8377fe35","volume":"43"},{"id":"hubbardFlashlagEffectRelated2014","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Hubbard","given":"Timothy L."}],"citation-key":"hubbardFlashlagEffectRelated2014","container-title":"Psychological Bulletin","container-title-short":"Psychological Bulletin","DOI":"10.1037/a0032899","ISSN":"1939-1455, 0033-2909","issue":"1","issued":{"date-parts":[["2014"]]},"language":"en","note":"QID: Q38116614","page":"308-338","source":"DOI.org (Crossref)","title":"The flash-lag effect and related mislocalizations: Findings, properties, and theories.","title-short":"The flash-lag effect and related mislocalizations","type":"article-journal","URL":"https://doi.apa.org/doi/10.1037/a0032899","volume":"140"},{"id":"hubbardFlashlagEffectRepresentational2013","abstract":"In the flash-lag effect (FLE) and in representational momentum (RM), the represented position of a moving target is displaced in the direction of motion. Effects of numerous variables on the FLE and on RM are briefly considered. In many cases, variables appear to have the same effect on the FLE and on RM, and this is consistent with a hypothesis that displacements in the FLE and in RM result from overlapping or similar mechanisms. In other cases, variables initially appear to have different effects on the FLE and on RM, but accounts reconciling those apparent differences with a hypothesis of overlapping or similar mechanisms are suggested. Given that RM is simpler and accounts for a wider range of findings (i.e., RM involves a single stimulus rather than the relationship between two stimuli, RM accounts for displacement in absolute position of a single stimulus and for differences in relative position of two stimuli), it is suggested that (at least some cases of) the FLE might be a special case of RM in which the position of the target is assessed relative to the position of another stimulus (i.e., the flashed object) rather than relative to the actual position of the target.","author":[{"family":"Hubbard","given":"T."}],"citation-key":"hubbardFlashlagEffectRepresentational2013","container-title":"Frontiers in Psychology","DOI":"10.3389/fpsyg.2013.00290","issued":{"date-parts":[["2013"]]},"note":"QID: Q40956275","page":"null","PMID":"23734140","title":"Do the flash-lag effect and representational momentum involve similar extrapolations?","type":"article-journal","URL":"https://www.semanticscholar.org/paper/383ac91a44de544754b0f56916fc8fab536d5daa","volume":"4"},{"id":"hughesHistoryEuropeanMusic1974","author":[{"family":"Hughes","given":"David G."}],"call-number":"ML160 .H87","citation-key":"hughesHistoryEuropeanMusic1974","event-place":"New York","ISBN":"978-0-07-031105-3","issued":{"date-parts":[["1974"]]},"number-of-pages":"557","publisher":"McGraw-Hill","publisher-place":"New York","source":"Library of Congress ISBN","title":"A History of European Music: The Art Music Tradition of Western Culture","title-short":"A History of European Music","type":"book"},{"id":"humphriesTalkingCultureCulture2008","author":[{"family":"Humphries","given":"Tom"}],"call-number":"HV2380 .D43 2002","citation-key":"humphriesTalkingCultureCulture2008","container-title":"Open Your Eyes: Deaf Studies Talking","editor":[{"family":"Bauman","given":"H.-Dirksen L."}],"event-place":"Minneapolis","ISBN":"978-0-8166-4618-0 978-0-8166-4619-7","issued":{"date-parts":[["2008"]]},"note":"OCLC: ocn167497734","page":"35 - 41","publisher":"University of Minnesota Press","publisher-place":"Minneapolis","source":"Library of Congress ISBN","title":"Talking Culture and Culture Talking","type":"chapter"},{"id":"huntInteractiveSonification2011","author":[{"family":"Hunt","given":"Andy"},{"family":"Hermann","given":"Thomas"}],"citation-key":"huntInteractiveSonification2011","container-title":"The Sonification Handbook","editor":[{"family":"Hermann","given":"Thomas"},{"family":"Hunt","given":"Andy"},{"family":"Neuhoff","given":"John G."}],"event-place":"Berlin, Germany","ISBN":"3-8325-2819-9","issued":{"date-parts":[["2011"]]},"page":"273-298","publisher":"Logos Publishing House","publisher-place":"Berlin, Germany","title":"Interactive Sonification","type":"chapter"},{"id":"huntMappingStrategiesMusical2000","author":[{"family":"Hunt","given":"Andy"},{"family":"Kirk","given":"Ross"}],"citation-key":"huntMappingStrategiesMusical2000","container-title":"Trends in gestural control of music","event-place":"Paris","ISBN":"2-84426-039-X","issued":{"date-parts":[["2000"]]},"page":"231-258","publisher":"Ircam","publisher-place":"Paris","title":"Mapping strategies for musical performance","type":"chapter","volume":"21"},{"id":"huntModelInstrumentalMapping2000","abstract":"cote interne IRCAM: Hunt00a","author":[{"family":"Hunt","given":"Andy"},{"family":"Wanderley","given":"Marcelo"},{"family":"Kirk","given":"Ross"}],"citation-key":"huntModelInstrumentalMapping2000","issued":{"date-parts":[["2000",9,1]]},"title":"Towards a Model for Instrumental Mapping in Expert Musical Interaction","type":"book"},{"id":"hussainEvaluatingMovementQualities2019","abstract":"The focus of this paper is to investigate how the design of visual feedback on full body movement affects the quality of the movements. Informed by the theory of embodiment in interaction design and media technology, as well as by the Laban theory of effort, a computer application was implemented in which users are able to project their movements onto two visuals ('Particle' and 'Metal') We investigated whether the visual designs influenced movers through an experiment where participants were randomly assigned to one of the visuals while performing a set of simple tasks. Qualitative analysis of participants' verbal movement descriptions as well as analysis of quantitative movement features combine several perspectives with respect to describing the differences and the change in the movement qualities. The qualitative data shows clear differences between the groups. The quantitative data indicates that all groups move differently when visual feedback is provided. Our results contribute to the design effort of visual modality in movement-focused design of extended realities.","author":[{"family":"Hussain","given":"Aishah"},{"family":"Modekjaer","given":"Camilla"},{"family":"Austad","given":"Nicoline Warming"},{"family":"Dahl","given":"Sofia"},{"family":"Erkut","given":"Cumhur"}],"citation-key":"hussainEvaluatingMovementQualities2019","collection-title":"MOCO '19","container-title":"Proceedings of the 6th international conference on movement and computing","DOI":"10.1145/3347122.3347123","event-place":"Tempe, AZ, USA","ISBN":"978-1-4503-7654-9","issued":{"date-parts":[["2019"]]},"number-of-pages":"9","publisher":"Association for Computing Machinery","publisher-place":"Tempe, AZ, USA","title":"Evaluating movement qualities with visual feedback for real-time motion capture","type":"paper-conference","URL":"https://doi.org/10.1145/3347122.3347123"},{"id":"ihdeListeningVoicePhenomenologies2007","author":[{"family":"Ihde","given":"Don"}],"call-number":"B829.5 .I34 2007","citation-key":"ihdeListeningVoicePhenomenologies2007","edition":"2nd ed","event-place":"Albany","ISBN":"978-0-7914-7255-2 978-0-7914-7256-9","issued":{"date-parts":[["2007"]]},"note":"OCLC: ocm77004159","number-of-pages":"276","publisher":"State University of New York Press","publisher-place":"Albany","source":"Library of Congress ISBN","title":"Listening and Voice: Phenomenologies of Sound","title-short":"Listening and voice","type":"book"},{"id":"imaiSurveyEffectVideo2023","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Imai","given":"Rino"},{"family":"Matsui","given":"Ryota"},{"family":"Yanagisawa","given":"Yutaka"},{"family":"Takegawa","given":"Yoshinari"},{"family":"Hirata","given":"Keiji"}],"citation-key":"imaiSurveyEffectVideo2023","container-title":"Human-Computer Interaction","DOI":"10.1007/978-3-031-35599-8_24","editor":[{"family":"Kurosu","given":"Masaaki"},{"family":"Hashizume","given":"Ayako"}],"event-place":"Cham","ISBN":"978-3-031-35598-1 978-3-031-35599-8","issued":{"date-parts":[["2023"]]},"language":"en","page":"375-384","publisher":"Springer Nature Switzerland","publisher-place":"Cham","source":"DOI.org (Crossref)","title":"Survey on the Effect of Video Delay in Online Dance with Multiple Participants","type":"chapter","URL":"https://link.springer.com/10.1007/978-3-031-35599-8_24","volume":"14012"},{"id":"inmusicLPK252022","accessed":{"date-parts":[["2022",11,26]]},"author":[{"literal":"inMusic"}],"citation-key":"inmusicLPK252022","container-title":"akaipro","issued":{"date-parts":[["2022"]]},"title":"LPK25","type":"webpage","URL":"https://www.akaipro.com/lpk25"},{"id":"inmusicSamplePadMultiPadSample2022","accessed":{"date-parts":[["2022",11,26]]},"author":[{"literal":"inMusic"}],"citation-key":"inmusicSamplePadMultiPadSample2022","container-title":"alesis","issued":{"date-parts":[["2022"]]},"title":"SamplePad Multi-Pad Sample Instrument","type":"webpage","URL":"https://www.alesis.com/products/legacy/samplepad"},{"id":"ishiiTangibleBitsSeamless1997","author":[{"family":"Ishii","given":"Hiroshi"},{"family":"Ullmer","given":"Brygg"}],"citation-key":"ishiiTangibleBitsSeamless1997","event-title":"Proceedings of the ACM SIGCHI Conference on Human factors in computing systems","issued":{"date-parts":[["1997"]]},"page":"234-241","title":"Tangible bits: towards seamless interfaces between people, bits and atoms","type":"paper-conference"},{"id":"ishiiTangibleUserInterface2008","abstract":"Users sculpt and manipulate digital information throughsuch tangible media as clay, sand, and building models, coupled with underlying computation for design and analysis.","author":[{"family":"Ishii","given":"Hiroshi"}],"citation-key":"ishiiTangibleUserInterface2008","container-title":"Commun. ACM","DOI":"10.1145/1349026.1349034","event-place":"New York, NY, USA","ISSN":"0001-0782","issue":"6","issued":{"date-parts":[["2008",6]]},"page":"32–36","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","title":"The Tangible User Interface and Its Evolution","type":"article-journal","URL":"https://doi.org/10.1145/1349026.1349034","volume":"51"},{"id":"itakuraMinimumPredictionResidual1975","author":[{"family":"Itakura","given":"Fumitada"}],"citation-key":"itakuraMinimumPredictionResidual1975","container-title":"IEEE Transactions on Acoustics, Speech, and Signal Processing","container-title-short":"IEEE Transactions on Acoustics, Speech, and Signal Processing","DOI":"10.1109/TASSP.1975.1162641","ISSN":"0096-3518","issue":"1","issued":{"date-parts":[["1975",2]]},"page":"67-72","title":"Minimum prediction residual principle applied to speech recognition","type":"article-journal","volume":"23"},{"id":"itoApplicationCNNHuman2018","abstract":"At the SHL recognition challenge 2018, Team Tesaguri developed a human activity recognition method. First, we obtained the FFT spectrogram from 60-second acceleration and gyro sensor data for each of six axes. A five-second sliding window was used for FFT processing. About 70% of the spectrogram figures from the Sussex-Huawei Locomotion-Transportation dataset were used for training data. Our model was based on CNN using FFT spectrogram images. After training for 50 epochs, F-measure was about 90% for acceleration data and 85% for gyro data. Next, considering the results of each sensor axis, to improve the recognition rate, we combined the information of multiple sensors. Specifically, we synthesized new images by combining the FFT spectrogram figures of two axes and the best combination condition was examined by correlation analysis. The highest score, 93% recognition, came from the vertically arranged images derived from the norm of acceleration and the y-axis gyro.","author":[{"family":"Ito","given":"Chihiro"},{"family":"Cao","given":"Xin"},{"family":"Shuzo","given":"Masaki"},{"family":"Maeda","given":"Eisaku"}],"citation-key":"itoApplicationCNNHuman2018","collection-title":"UbiComp '18","container-title":"Proceedings of the 2018 ACM international joint conference and 2018 international symposium on pervasive and ubiquitous computing and wearable computers","DOI":"10.1145/3267305.3267517","event-place":"Singapore, Singapore","ISBN":"978-1-4503-5966-5","issued":{"date-parts":[["2018"]]},"number-of-pages":"8","page":"1503–1510","publisher":"Association for Computing Machinery","publisher-place":"Singapore, Singapore","title":"Application of CNN for human activity recognition with FFT spectrogram of acceleration and gyro sensors","type":"paper-conference","URL":"https://doi.org/10.1145/3267305.3267517"},{"id":"iversonMechanizedBodiesTechnology2016","author":[{"family":"Iverson","given":"Jennifer"}],"citation-key":"iversonMechanizedBodiesTechnology2016","container-title":"The Oxford Handbook of Music and Disability Studies","editor":[{"family":"Howe","given":"Blake"},{"family":"Jensen-Moulton","given":"Stephanie"},{"family":"Lerner","given":"Neil William"},{"family":"Straus","given":"Joseph Nathan"}],"event-place":"Oxford ; New York","ISBN":"978-0-19-933144-4 978-0-19-065060-5","issued":{"date-parts":[["2016"]]},"page":"54 - 72","publisher":"Oxford University Press","publisher-place":"Oxford ; New York","source":"Library of Congress ISBN","title":"Mechanized Bodies: Technology and Supplements in Björk’s Electronica","type":"chapter"},{"id":"ivkovicQuantifyingMitigatingNegative2015","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Ivkovic","given":"Zenja"},{"family":"Stavness","given":"Ian"},{"family":"Gutwin","given":"Carl"},{"family":"Sutcliffe","given":"Steven"}],"citation-key":"ivkovicQuantifyingMitigatingNegative2015","container-title":"Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems","DOI":"10.1145/2702123.2702432","event-place":"Seoul Republic of Korea","event-title":"CHI '15: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-3145-6","issued":{"date-parts":[["2015",4,18]]},"language":"en","page":"135-144","publisher":"ACM","publisher-place":"Seoul Republic of Korea","source":"DOI.org (Crossref)","title":"Quantifying and Mitigating the Negative Effects of Local Latencies on Aiming in 3D Shooter Games","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/2702123.2702432"},{"id":"iweonu_wonwooriWOWLOGElectronicMusic2020","accessed":{"date-parts":[["2021",1,27]]},"author":[{"literal":"이원우_WONWOORI"}],"citation-key":"iweonu_wonwooriWOWLOGElectronicMusic2020","container-title":"YouTube","issued":{"date-parts":[["2020",9,2]]},"title":"WOW-LOG : Electronic Music Project for Cochlear Implant Users","type":"webpage","URL":"https://www.youtube.com/watch?v=fbBWZClz-sk"},{"id":"jaggerFemaleMusicProducer2020","author":[{"family":"Jagger","given":"Sharon"},{"family":"Turner","given":"Helen"}],"citation-key":"jaggerFemaleMusicProducer2020","container-title":"Gender in Music Production","issued":{"date-parts":[["2020"]]},"page":"251-267","publisher":"Focal Press","title":"The Female Music Producer and the Leveraging of Difference","type":"chapter"},{"id":"jamesMovementbasedInteractiveDance2006","accessed":{"date-parts":[["2023",5,3]]},"author":[{"family":"James","given":"Jodi"},{"family":"Ingalls","given":"Todd"},{"family":"Qian","given":"Gang"},{"family":"Olsen","given":"Loren"},{"family":"Whiteley","given":"Daniel"},{"family":"Wong","given":"Siew"},{"family":"Rikakis","given":"Thanassis"}],"citation-key":"jamesMovementbasedInteractiveDance2006","container-title":"Proceedings of the 14th ACM international conference on Multimedia","DOI":"10.1145/1180639.1180733","event-place":"Santa Barbara CA USA","event-title":"MM06: The 14th ACM International Conference on Multimedia 2006","ISBN":"978-1-59593-447-5","issued":{"date-parts":[["2006",10,23]]},"language":"en","page":"470-480","publisher":"ACM","publisher-place":"Santa Barbara CA USA","title":"Movement-based interactive dance performance","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/1180639.1180733"},{"id":"janauskaiteEstablishingDialoguesMovement2019","abstract":"This paper investigates how human motion expressiveness can influence the perceived atmosphere of a space by using interactive lighting as an effector. As lighting is a common tool in theatrical settings it is important to know how a performer could shape the light and thus challenge the perception of the surrounding environment. For this purpose, an interactive light installation was created where human motion qualities are transformed into dynamic visuals. The evaluation was performed in two different experiments with dancers conveying expressive intentions to an audience during a dance performance. The experimental data show that motion qualities could unfold the audience's collective affective qualities, through the interplay between the performers and their environment and that the performers are able to subconsciously sense the generated atmosphere, through peripheral vision, and influence the experience.","author":[{"family":"Janauskaite","given":"Leva"},{"family":"Palamas","given":"George"}],"citation-key":"janauskaiteEstablishingDialoguesMovement2019","collection-title":"MOCO '19","container-title":"Proceedings of the 6th international conference on movement and computing","DOI":"10.1145/3347122.3359602","event-place":"Tempe, AZ, USA","ISBN":"978-1-4503-7654-9","issued":{"date-parts":[["2019"]]},"number-of-pages":"11","publisher":"Association for Computing Machinery","publisher-place":"Tempe, AZ, USA","title":"Establishing dialogues between movement and atmospheric ambiances","type":"paper-conference","URL":"https://doi.org/10.1145/3347122.3359602"},{"id":"jankowskiDeafEmpowermentEmergence1997","author":[{"family":"Jankowski","given":"Katherine A."}],"call-number":"HV2530 .J35 1997","citation-key":"jankowskiDeafEmpowermentEmergence1997","event-place":"Washington, D.C","ISBN":"978-1-56368-061-8","issued":{"date-parts":[["1997"]]},"number-of-pages":"197","publisher":"Gallaudet University Press","publisher-place":"Washington, D.C","source":"Library of Congress ISBN","title":"Deaf Empowerment: Emergence, Struggle, and Rhetoric","title-short":"Deaf empowerment","type":"book"},{"id":"janzen60FPSBetter2014","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Janzen","given":"Benjamin F."},{"family":"Teather","given":"Robert J."}],"citation-key":"janzen60FPSBetter2014","container-title":"CHI '14 Extended Abstracts on Human Factors in Computing Systems","DOI":"10.1145/2559206.2581214","event-place":"Toronto Ontario Canada","event-title":"CHI '14: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-2474-8","issued":{"date-parts":[["2014",4,26]]},"language":"en","page":"1477-1482","publisher":"ACM","publisher-place":"Toronto Ontario Canada","source":"DOI.org (Crossref)","title":"Is 60 FPS better than 30?: the impact of frame rate and latency on moving target selection","title-short":"Is 60 FPS better than 30?","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/2559206.2581214"},{"id":"jarrettTheoryApplicationsSpherical2017","accessed":{"date-parts":[["2024",3,14]]},"author":[{"family":"Jarrett","given":"Daniel P."},{"family":"Habets","given":"Emanuël A.P."},{"family":"Naylor","given":"Patrick A."}],"citation-key":"jarrettTheoryApplicationsSpherical2017","collection-title":"Springer Topics in Signal Processing","DOI":"10.1007/978-3-319-42211-4","event-place":"Cham","ISBN":"978-3-319-42209-1 978-3-319-42211-4","issued":{"date-parts":[["2017"]]},"publisher":"Springer International Publishing","publisher-place":"Cham","source":"DOI.org (Crossref)","title":"Theory and Applications of Spherical Microphone Array Processing","type":"book","URL":"http://link.springer.com/10.1007/978-3-319-42211-4","volume":"9"},{"id":"jenseniusActionsoundDevelopingMethods2007","author":[{"family":"Jensenius","given":"Alexander Refsum"}],"citation-key":"jenseniusActionsoundDevelopingMethods2007","event-place":"Oslo","genre":"Ph.D Thesis","issued":{"date-parts":[["2007"]]},"number-of-pages":"275","publisher":"University of Oslo","publisher-place":"Oslo","title":"Action-sound: Developing methods and tools to study music-related body movement","type":"thesis","URL":"https://www.duo.uio.no/bitstream/handle/10852/27149/jensenius-phd.pdf?sequence=1&isAllowed=y"},{"id":"jenseniusMusicalGesturesConcepts2010","author":[{"family":"Jensenius","given":"Alexander Refsum"},{"family":"Wanderley","given":"Marcelo M"},{"family":"Godøy","given":"Rolf Inge"},{"family":"Leman","given":"Marc"}],"citation-key":"jenseniusMusicalGesturesConcepts2010","container-title":"Musical gestures: Sound, movement, and meaning","editor":[{"family":"Godøy","given":"Rolf Inge"},{"family":"Leman","given":"Marc"}],"event-place":"New York","ISBN":"978-0-415-99887-1","issued":{"date-parts":[["2010"]]},"page":"12-35","publisher":"Routledge","publisher-place":"New York","title":"Musical gestures : concepts and methods in research","type":"chapter"},{"id":"jenseniusReducedDisplaysMultidimensional2009","abstract":"1. Background: Carrying out research on music-related body movements involves working with different types of data (e.g. motion capture and sensor data) and media (i.e. audio, video), each having its own size, dimensions, speed etc. While each of the data types and media have their own analytical tools and representation techniques, we see the need for developing more tools that allow for studying all the data and media together in a synchronised manner. We have previously developed solutions for studying musical sound and movement using synchronised spectrograms of audio and motiongrams of video. Now as we have started using an infrared motion capture system in our research, we see the need for better techniques for visualising the multidimensional data sets (e.g. 50 markers x 3 dimensions x 100 Hz). While there are several techniques for doing this independently of audio and video, we are working on tools that integrate well with our displays of spectrograms and motiongrams. 2. Aims: Creating reduced representations of multidimensional motion capture data of complex music-related body movement that can be used together with spectrograms and motiongrams. 3. Method (if applicable) 4. Results/Main Contribution: We present some of the visualisation techniques we have been developing to display multidimensional data sets: 1) reduction based on collapsing dimensions, 2) reduction based on frame differencing, 3) colour coding of movement features. Examples are given of how these techniques allow for displaying reduced displays of multidimensional motion capture data sets synchronised with spectrograms and motiongrams. 5. Conclusions/Implications: The techniques presented allows for studying relationships between movement and sound in music performance, and make it possible to create visual displays of movement and sound that can be used on screen and in printed documents.","author":[{"family":"Jensenius","given":"Alexander"},{"family":"Skogstad","given":"Ståle"},{"family":"Nymoen","given":"Kristian"},{"family":"Torresen","given":"Jim"},{"family":"Høvin","given":"Mats"}],"citation-key":"jenseniusReducedDisplaysMultidimensional2009","container-title":"Proceedings of ESCOM 2009: 7th Triennial Conference of the European Society for the Cognitive Sciences of Music","event-title":"ESCOM 2009: 7th Triennial Conference of the European Society for the Cognitive Sciences of Music","issued":{"date-parts":[["2009",1,1]]},"source":"ResearchGate","title":"Reduced displays of multidimensional motion capture data sets of musical performance","type":"paper-conference"},{"id":"jenseniusVideoAbstractionTechniques2013","author":[{"family":"Jensenius","given":"Alexander"}],"citation-key":"jenseniusVideoAbstractionTechniques2013","container-title":"Leonardo","DOI":"10.2307/23468117","issued":{"date-parts":[["2013",2]]},"title":"Some Video Abstraction Techniques for Displaying Body Movement in Analysis and Performance","type":"article-journal","volume":"46"},{"id":"jeongWeightedDynamicTime2011","abstract":"Dynamic time warping (DTW), which finds the minimum path by providing non-linear alignments between two time series, has been widely used as a distance measure for time series classification and clustering. However, DTW does not account for the relative importance regarding the phase difference between a reference point and a testing point. This may lead to misclassification especially in applications where the shape similarity between two sequences is a major consideration for an accurate recognition. Therefore, we propose a novel distance measure, called a weighted DTW (WDTW), which is a penalty-based DTW. Our approach penalizes points with higher phase difference between a reference point and a testing point in order to prevent minimum distance distortion caused by outliers. The rationale underlying the proposed distance measure is demonstrated with some illustrative examples. A new weight function, called the modified logistic weight function (MLWF), is also proposed to systematically assign weights as a function of the phase difference between a reference point and a testing point. By applying different weights to adjacent points, the proposed algorithm can enhance the detection of similarity between two time series. We show that some popular distance measures such as DTW and Euclidean distance are special cases of our proposed WDTW measure. We extend the proposed idea to other variants of DTW such as derivative dynamic time warping (DDTW) and propose the weighted version of DDTW. We have compared the performances of our proposed procedures with other popular approaches using public data sets available through the UCR Time Series Data Mining Archive for both time series classification and clustering problems. The experimental results indicate that the proposed approaches can achieve improved accuracy for time series classification and clustering problems.","author":[{"family":"Jeong","given":"Young-Seon"},{"family":"Jeong","given":"Myong K."},{"family":"Omitaomu","given":"Olufemi A."}],"citation-key":"jeongWeightedDynamicTime2011","container-title":"Computer Analysis of Images and Patterns","container-title-short":"Pattern Recognition","DOI":"10.1016/j.patcog.2010.09.022","ISSN":"0031-3203","issue":"9","issued":{"date-parts":[["2011",9,1]]},"page":"2231-2240","title":"Weighted dynamic time warping for time series classification","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S003132031000484X","volume":"44"},{"id":"jiamWhatDoesMusic2017","author":[{"family":"Jiam","given":"Nicole T."},{"family":"Caldwell","given":"Meredith T."},{"family":"Limb","given":"Charles J."}],"citation-key":"jiamWhatDoesMusic2017","container-title":"Otology & Neurotology","container-title-short":"Otology & Neurotology","ISSN":"1531-7129","issue":"8","issued":{"date-parts":[["2017"]]},"page":"e240-e247","publisher":"Wolters Kluwer","title":"What Does Music Sound like for a Cochlear Implant User?","type":"article-journal","volume":"38"},{"id":"jochumTonightWeImprovise2019","abstract":"We present an exploratory study based on dance improvisation to explore embodied interaction between human dancers and a mobile robot. Following extensive iterations with expert dancers, we developed a sequence of basic motion algorithms based on improvisation exercises to generate three unique, original performances between a robot and human performers trained in various dance styles. We developed a novel method for tracking the dancers in real time using inputs to generate choreography for the non-anthropomorphic robot. Although the motion algorithms were identical, the individual dancers generated vastly different performances and elicited unexpected motions and choreographies. We summarize our study and identify some challenges of devising performances between robots and humans, and outline future work to experiment with more advanced algorithms.","author":[{"family":"Jochum","given":"Elizabeth"},{"family":"Derks","given":"Jeroen"}],"citation-key":"jochumTonightWeImprovise2019","collection-title":"MOCO '19","container-title":"Proceedings of the 6th international conference on movement and computing","DOI":"10.1145/3347122.3347129","event-place":"Tempe, AZ, USA","ISBN":"978-1-4503-7654-9","issued":{"date-parts":[["2019"]]},"number-of-pages":"11","publisher":"Association for Computing Machinery","publisher-place":"Tempe, AZ, USA","title":"Tonight we improvise! Real-time tracking for human-robot improvisational dance","type":"paper-conference","URL":"https://doi.org/10.1145/3347122.3347129"},{"id":"johnsonAmplificationClassBetter1994","author":[{"family":"Johnson","given":"William A."},{"family":"Killion","given":"Mead C."}],"citation-key":"johnsonAmplificationClassBetter1994","container-title":"American Journal of Audiology","container-title-short":"American Journal of Audiology","ISSN":"1558-9137","issue":"1","issued":{"date-parts":[["1994"]]},"page":"11-13","publisher":"ASHA","title":"Amplification: Is class D better than class B?","type":"article-journal","volume":"3"},{"id":"johnsonMotionExtrapolationHighPhi2020","abstract":"A range of visual illusions, including the much-studied flash-lag effect, demonstrate that neural signals coding for motion and position interact in the visual system. One interpretation of these illusions is that they are the consequence of motion extrapolation mechanisms in the early visual system. Here, we study the recently reported High-Phi illusion to investigate whether it might be caused by the same underlying mechanisms. In the High-Phi illusion, a rotating texture is abruptly replaced by a new, uncorrelated texture. This leads to the percept of a large illusory jump, which can be forward or backward depending on the duration of the initial motion sequence (the inducer). To investigate whether this motion illusion also leads to illusions of perceived position, in three experiments we asked observers to localize briefly flashed targets presented concurrently with the new texture. Our results replicate the original finding of perceived forward and backward jumps, and reveal an illusion of perceived position. Like the observed effects on illusory motion, these position shifts could be forward or backward, depending on the duration of the inducer: brief inducers caused forward mislocalization, and longer inducers caused backward mislocalization. Additionally, we found that both jumps and mislocalizations scaled in magnitude with the speed of the inducer. Interestingly, forward position shifts were observed at shorter inducer durations than forward jumps. We interpret our results as an interaction of extrapolation and correction-for-extrapolation, and discuss possible mechanisms in the early visual system that might carry out these computations.","author":[{"family":"Johnson","given":"Philippa A."},{"family":"Davies","given":"Sidney"},{"family":"Hogendoorn","given":"Hinze"}],"citation-key":"johnsonMotionExtrapolationHighPhi2020","container-title":"Journal of Vision","DOI":"10.1167/jov.20.13.8","issued":{"date-parts":[["2020"]]},"note":"QID: Q104139423","page":"null","PMID":"33296460","title":"Motion extrapolation in the High-Phi illusion: Analogous but dissociable effects on perceived position and perceived motion","type":"article-journal","URL":"https://www.semanticscholar.org/paper/9df2d8bac61fff8cd6086b9ef40e133d223e7f90","volume":"20"},{"id":"johnstonDesigningEvaluatingVirtual2008","abstract":"This paper is concerned with the design of interactive virtual musical instruments. An interaction design strategy which uses on-screen objects that respond to user actions in physically realistic ways is described. This approach allows musicians to ‘play’ the virtual instruments using the sound of their familiar acoustic instruments. An investigation of user experience identified three modes of interaction that characterise the musicians' approach to the virtual instruments: instrumental, ornamental and conversational. When using the virtual instruments in instrumental mode, musicians prioritise detailed control; in ornamental mode, they surrender detailed control to the software and allow it to transform their sound; in conversational mode, the musicians allow the virtual instrument to ‘talk back’, helping to shape the musical direction of performance much as a human playing partner might. Finding a balance between controllability and complexity emerged as a key issue in facilitating ‘conversational’ interaction.","author":[{"family":"Johnston","given":"Andrew"},{"family":"Candy","given":"Linda"},{"family":"Edmonds","given":"Ernest"}],"citation-key":"johnstonDesigningEvaluatingVirtual2008","container-title":"Interaction Design and Creative Practice","container-title-short":"Design Studies","DOI":"10.1016/j.destud.2008.07.005","ISSN":"0142-694X","issue":"6","issued":{"date-parts":[["2008",11,1]]},"page":"556-571","title":"Designing and evaluating virtual musical instruments: facilitating conversational user interaction","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0142694X08000665","volume":"29"},{"id":"jonesArsElectronicaApplication1999","accessed":{"date-parts":[["2023",7,10]]},"author":[{"family":"Jones","given":"Bill T."},{"family":"Kaiser","given":"Paul"},{"family":"Eshkar","given":"Shelley"}],"citation-key":"jonesArsElectronicaApplication1999","issued":{"date-parts":[["1999"]]},"publisher":"Ars Electronica Archive","title":"Ars Electrónica Application: Ghostcatching A-74","type":"document","URL":"https://archive.aec.at/prix/showmode/33648/"},{"id":"jorgereyes-ortizHumanActivityRecognition2013","accessed":{"date-parts":[["2024",9,2]]},"author":[{"family":"Jorge Reyes-Ortiz","given":"Davide Anguita"}],"citation-key":"jorgereyes-ortizHumanActivityRecognition2013","DOI":"10.24432/C54S4K","issued":{"date-parts":[["2013"]]},"publisher":"UCI Machine Learning Repository","source":"DOI.org (Datacite)","title":"Human Activity Recognition Using Smartphones","type":"dataset","URL":"https://archive.ics.uci.edu/dataset/240"},{"id":"jotaHowFastFast2013","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Jota","given":"Ricardo"},{"family":"Ng","given":"Albert"},{"family":"Dietz","given":"Paul"},{"family":"Wigdor","given":"Daniel"}],"citation-key":"jotaHowFastFast2013","container-title":"Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","DOI":"10.1145/2470654.2481317","event-place":"Paris France","event-title":"CHI '13: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-1899-0","issued":{"date-parts":[["2013",4,27]]},"language":"en","page":"2291-2300","publisher":"ACM","publisher-place":"Paris France","source":"DOI.org (Crossref)","title":"How fast is fast enough?: a study of the effects of latency in direct-touch pointing tasks","title-short":"How fast is fast enough?","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/2470654.2481317"},{"id":"joungInteractiveEffectTempo2018","abstract":"We examined the relationship of temporal parameters, tempo and rhythm, to the perceived emotion of audience from viewing a dance. This is a problem of how choreographers manipulate the temporal parameters to express the aesthetic adequately. We conducted a psychophysical categorization task to reveal the relationship between temporal parameters of dance and subjects' subjective appreciation. Our goal was to find a distinctive point of temporal parameters that affect subjects' emotional transition, from positive to negative, vice versa. Subjects categorized dance stimuli in different combinations of tempo and rhythm by performing the two-alternative forced choice task. The results found that subjective interpretation of dance was mainly affected by the tempo, not rhythm. Rhythm had much less impact on the appreciation of affective body expression.","author":[{"family":"Joung","given":"Jeehyun"},{"family":"Kim","given":"Jeounghoon"}],"citation-key":"joungInteractiveEffectTempo2018","collection-title":"MOCO '18","container-title":"Proceedings of the 5th international conference on movement and computing","DOI":"10.1145/3212721.3212844","event-place":"Genoa, Italy","ISBN":"978-1-4503-6504-8","issued":{"date-parts":[["2018"]]},"number-of-pages":"4","publisher":"Association for Computing Machinery","publisher-place":"Genoa, Italy","title":"Interactive effect of tempo and rhythm on the emotional perception of dance movements","type":"paper-conference","URL":"https://doi.org/10.1145/3212721.3212844"},{"id":"jurgensBodyMovementMissed2021","accessed":{"date-parts":[["2023",2,26]]},"author":[{"family":"Jürgens","given":"Stephan"},{"family":"Correia","given":"Nuno N."},{"family":"Masu","given":"Raul"}],"citation-key":"jurgensBodyMovementMissed2021","container-title":"Proceedings of the Fifteenth International Conference on Tangible, Embedded, and Embodied Interaction","DOI":"10.1145/3430524.3440624","event-place":"Salzburg Austria","event-title":"TEI '21: Fifteenth International Conference on Tangible, Embedded, and Embodied Interaction","ISBN":"978-1-4503-8213-7","issued":{"date-parts":[["2021",2,14]]},"language":"en","page":"1-9","publisher":"ACM","publisher-place":"Salzburg Austria","source":"DOI.org (Crossref)","title":"The Body Beyond Movement: (Missed) Opportunities to Engage with Contemporary Dance in HCI","title-short":"The Body Beyond Movement","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3430524.3440624"},{"id":"justesonTechnicalTerminologyLinguistic1995","author":[{"family":"Justeson","given":"John S"},{"family":"Katz","given":"Slava M"}],"citation-key":"justesonTechnicalTerminologyLinguistic1995","container-title":"Natural language engineering","container-title-short":"Natural language engineering","ISSN":"1469-8110","issue":"1","issued":{"date-parts":[["1995"]]},"page":"9-27","publisher":"Cambridge University Press","title":"Technical terminology: some linguistic properties and an algorithm for identification in text","type":"article-journal","volume":"1"},{"id":"kaferFeministQueerCrip2013","author":[{"family":"Kafer","given":"Alison"}],"call-number":"HV1568.2 .K34 2013","citation-key":"kaferFeministQueerCrip2013","event-place":"Bloomington, Indiana","ISBN":"978-0-253-00922-7 978-0-253-00934-0 978-0-253-00941-8","issued":{"date-parts":[["2013"]]},"number-of-pages":"258","publisher":"Indiana University Press","publisher-place":"Bloomington, Indiana","source":"Library of Congress ISBN","title":"Feminist, Queer, Crip","type":"book"},{"id":"kaltenbrunnerTquencerTangibleMusical2018","author":[{"family":"Kaltenbrunner","given":"Martin"},{"family":"Vetter","given":"Jens"}],"citation-key":"kaltenbrunnerTquencerTangibleMusical2018","event-title":"Proceedings of the Twelfth International Conference on Tangible, Embedded, and Embodied Interaction","issued":{"date-parts":[["2018"]]},"page":"429-434","title":"Tquencer: A tangible musical sequencer using overlays","type":"paper-conference"},{"id":"kanaiStoppingMotionSleuthing2004","abstract":"S2 TL;DR: It is surmise that uncertainty in determining the position in space of a moving stimulus is a key requirement for the lag-effect, and proposes a schematic account of the present findings that subsumes previous psychological models and scaffolds past experimental findings.","author":[{"family":"Kanai","given":"R."},{"family":"Sheth","given":"B."},{"family":"Shimojo","given":"S."}],"citation-key":"kanaiStoppingMotionSleuthing2004","container-title":"Vision Research","DOI":"10.1016/j.visres.2003.10.028","issued":{"date-parts":[["2004"]]},"note":"QID: Q45052154","page":"2605-2619","PMID":"15358076","title":"Stopping the motion and sleuthing the flash-lag effect: spatial uncertainty is the key to perceptual mislocalization","type":"article-journal","URL":"https://www.semanticscholar.org/paper/ea4eb6aee7b7bdf8c9485ecafce04b918b208c49","volume":"44"},{"id":"kangDevelopmentValidationUniversity2009","author":[{"family":"Kang","given":"Robert"},{"family":"Nimmons","given":"Grace Liu"},{"family":"Drennan","given":"Ward"},{"family":"Longnion","given":"Jeff"},{"family":"Ruffin","given":"Chad"},{"family":"Nie","given":"Kaibao"},{"family":"Won","given":"Jong Ho"},{"family":"Worman","given":"Tina"},{"family":"Yueh","given":"Bevan"},{"family":"Rubinstein","given":"Jay"}],"citation-key":"kangDevelopmentValidationUniversity2009","container-title":"Ear and Hearing","container-title-short":"Ear and Hearing","issue":"4","issued":{"date-parts":[["2009"]]},"page":"411 - 418","publisher":"NIH Public Access","title":"Development and Validation of the University of Washington Clinical Assessment of Music Perception Test","type":"article-journal","volume":"30"},{"id":"karpashevichReinterpretingSchlemmerTriadic2018","accessed":{"date-parts":[["2023",2,27]]},"author":[{"family":"Karpashevich","given":"Pavel"},{"family":"Hornecker","given":"Eva"},{"family":"Honauer","given":"Michaela"},{"family":"Sanches","given":"Pedro"}],"citation-key":"karpashevichReinterpretingSchlemmerTriadic2018","container-title":"Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","DOI":"10.1145/3173574.3173635","event-place":"Montreal QC Canada","event-title":"CHI '18: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-5620-6","issued":{"date-parts":[["2018",4,19]]},"language":"en","page":"1-13","publisher":"ACM","publisher-place":"Montreal QC Canada","source":"DOI.org (Crossref)","title":"Reinterpreting Schlemmer's Triadic Ballet: Interactive Costume for Unthinkable Movements","title-short":"Reinterpreting Schlemmer's Triadic Ballet","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3173574.3173635"},{"id":"karremanMotionCaptureImaginary2017","author":[{"family":"Karreman","given":"Laura"}],"citation-key":"karremanMotionCaptureImaginary2017","genre":"Ph.D Thesis","issued":{"date-parts":[["2017"]]},"language":"eng","publisher":"Ghent University. Faculty of Arts and Philosophy","title":"The motion capture imaginary : digital renderings of dance knowledge","type":"thesis","URL":"http://hdl.handle.net/1854/LU-8518400"},{"id":"katesDigitalHearingAids2008","author":[{"family":"Kates","given":"James M"}],"citation-key":"katesDigitalHearingAids2008","event-place":"San Diego","ISBN":"1-59756-833-3","issued":{"date-parts":[["2008"]]},"number-of-pages":"453","publisher":"Plural Publishing","publisher-place":"San Diego","title":"Digital Hearing Aids","type":"book"},{"id":"kattenbeltIntermedialityTheatrePerformance1970","abstract":"This article provides a brief overview of the discourse on the relationships between the arts and media over the twentieth century, with specific reference to the concepts of mediality: multi-, trans- and intermediality set in discourse of arts and media relationships. I discuss the concepts, together with the impact of the growth of media technological developments, on the perception of audiences to the works of Wagner, Kandinsky, Meyerhold, Balázs, Eisenstein, Brecht, and to contemporary theatre and performance-makers, before concluding with a short presentation of my own current thinking about the concept and purpose of intermediality.","accessed":{"date-parts":[["2023",6,18]]},"author":[{"family":"Kattenbelt","given":"Chiel"}],"citation-key":"kattenbeltIntermedialityTheatrePerformance1970","container-title":"Cultura, Lenguaje y Representación","container-title-short":"CLR","issue":"0","issued":{"date-parts":[["1970",1,1]]},"page":"19-29","section":"ARTÍCULOS / ARTICLES","title":"Intermediality in Theatre and Performance: Definitions, Perceptions and Medial Relationships","type":"article-journal","URL":"https://www.e-revistes.uji.es/index.php/clr/article/view/30","volume":"6"},{"id":"katzCapturingSoundHow2010","abstract":"Synopsis: Fully revised and updated, this new edition of Mark Katz's award-winning text adds coverage of mashups and Auto-Tune, explores recent developments in file-sharing, and includes an expanded conclusion and bibliography. Find illustrative sound and film clips www.ucpress.edu/go/capturingsound","author":[{"family":"Katz","given":"Mark"}],"call-number":"ML3790 .K277 2010","citation-key":"katzCapturingSoundHow2010","edition":"Rev. ed","event-place":"Berkeley","ISBN":"978-0-520-26105-1","issued":{"date-parts":[["2010"]]},"note":"OCLC: ocn610019531","number-of-pages":"320","publisher":"University of California Press","publisher-place":"Berkeley","source":"Library of Congress ISBN","title":"Capturing Sound: How Technology Has Changed Music","title-short":"Capturing sound","type":"book"},{"id":"kaushikFeasibleStylizedMotion2020","abstract":"Socially intelligent robots are a priority for large manufacturing companies that want to deploy collaborative robots in many countries around the world. This paper presents an approach to robot motion generation in which a human demonstration is imitated, collisions are avoided, and a \"style\" is applied to subtly modify the feasible motion. The framework integrates three subsystems to create a holistic method that navigates the trade-off between form and function. The first subsystem uses depth camera information to track a human skeleton and create a low dimensional motion model. The second subsystem applies these angles to a simulated UR3 robot, modifying them to produce a feasible trajectory. The generated trajectory avoids physically infeasible configurations and collisions with the environment, while remaining as close to the original demonstration as possible. The final subsystem applies four style parameters, based on prior work using Laban Effort Factors, to endow the trajectory with a specific \"style\". This approach creates adaptive robot behavior in which one human demonstration can result in many subtly different robot motions. The effectiveness of the hybrid approach, which considers functional as well as expressive goals, is demonstrated on three environments of increasing clutter. As expected, in more cluttered environments, the desired imitation is not as pronounced as in unconstrained environments. Potential applications of this framework include programming robot motion on a factory floor with greater efficiency as well as creating feasible motion on multiple robots with a single demonstration. This quantitative work highlights the Function/Expression duality named in the Laban/Bartenieff Movement System, illuminating how the arts are critical for \"practical\" spaces like the factory.","author":[{"family":"Kaushik","given":"Roshni"},{"family":"Mishra","given":"Anant Kumar"},{"family":"LaViers","given":"Amy"}],"citation-key":"kaushikFeasibleStylizedMotion2020","collection-title":"MOCO '20","container-title":"Proceedings of the 7th international conference on movement and computing","DOI":"10.1145/3401956.3404188","event-place":"Jersey City/Virtual, NJ, USA","ISBN":"978-1-4503-7505-4","issued":{"date-parts":[["2020"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Jersey City/Virtual, NJ, USA","title":"Feasible stylized motion: Robotic manipulator imitation of a human demonstration with collision avoidance and style parameters in increasingly cluttered environments","type":"paper-conference","URL":"https://doi.org/10.1145/3401956.3404188"},{"id":"kawaguchiHumanActivitySensing2019","abstract":"Activity recognition has emerged as a challenging and high-impact research field, as over the past years smaller and more powerful sensors have been introduced in wide-spread consumer devices. Validation of techniques and algorithms requires large-scale human activity corpuses and improved methods to recognize activities and the contexts in which they occur. This book deals with the challenges of designing valid and reproducible experiments, running large-scale dataset collection campaigns, designing activity and context recognition methods that are robust and adaptive, and evaluating activity recognition systems in the real world with real users","author":[{"family":"Kawaguchi","given":"Nobuo"},{"family":"Nishio","given":"Nobuhiko"},{"family":"Roggen","given":"Daniel"},{"family":"Inoue","given":"Sozo"},{"family":"Pirttikangas","given":"Susanna"},{"family":"Laerhoven","given":"Kristof","dropping-particle":"van"}],"citation-key":"kawaguchiHumanActivitySensing2019","event-place":"Cham","ISBN":"978-3-030-13001-5","issued":{"date-parts":[["2019"]]},"language":"eng","note":"OCLC: 1119641567","publisher":"Springer","publisher-place":"Cham","source":"Open WorldCat","title":"Human Activity Sensing: Corpus and Applications","title-short":"Human Activity Sensing","type":"book"},{"id":"kayeEpistemologyEvaluationExperiencefocused2009","author":[{"family":"Kaye","given":"Joseph"}],"citation-key":"kayeEpistemologyEvaluationExperiencefocused2009","genre":"Ph.D Thesis","issued":{"date-parts":[["2009"]]},"publisher":"Cornell University","title":"The Epistemology and Evaluation of Experience-focused HCI","type":"thesis","URL":"https://hdl.handle.net/1813/11657"},{"id":"kayeEvaluatingExperiencefocusedHCI2007","abstract":"There is growing interest in experience-focused, rather than task-focused, HCI. Task-focused HCI has developed methods for creating and validating knowledge, but those methods may not be applicable or sufficient for experience-focused technology. In particular, new evaluation techniques to validate knowledge need to be created, discussed, and understood. I address this in three ways. First, it is important to understand the historical, technical and social factors that impact the evaluation criteria the community consider valid today. Second, I propose an ethnomethodological approach to evaluation that emphasizes the ways users use and make sense of technologies. And third, I demonstrate the validity of my approaches by means of several case studies.","author":[{"family":"Kaye","given":"Joseph 'Jofish'"}],"citation-key":"kayeEvaluatingExperiencefocusedHCI2007","collection-title":"CHI EA '07","container-title":"CHI '07 extended abstracts on human factors in computing systems","DOI":"10.1145/1240866.1240877","event-place":"San Jose, CA, USA","ISBN":"978-1-59593-642-4","issued":{"date-parts":[["2007"]]},"number-of-pages":"4","page":"1661–1664","publisher":"Association for Computing Machinery","publisher-place":"San Jose, CA, USA","title":"Evaluating experience-focused HCI","type":"paper-conference","URL":"https://doi.org/10.1145/1240866.1240877"},{"id":"kayKineticsHumanAction2017","abstract":"We describe the DeepMind Kinetics human action video dataset. The dataset contains 400 human action classes, with at least 400 video clips for each action. Each clip lasts around 10s and is taken from a different YouTube video. The actions are human focussed and cover a broad range of classes including human-object interactions such as playing instruments, as well as human-human interactions such as shaking hands. We describe the statistics of the dataset, how it was collected, and give some baseline performance figures for neural network architectures trained and tested for human action classification on this dataset. We also carry out a preliminary analysis of whether imbalance in the dataset leads to bias in the classifiers.","accessed":{"date-parts":[["2024",11,1]]},"author":[{"family":"Kay","given":"Will"},{"family":"Carreira","given":"Joao"},{"family":"Simonyan","given":"Karen"},{"family":"Zhang","given":"Brian"},{"family":"Hillier","given":"Chloe"},{"family":"Vijayanarasimhan","given":"Sudheendra"},{"family":"Viola","given":"Fabio"},{"family":"Green","given":"Tim"},{"family":"Back","given":"Trevor"},{"family":"Natsev","given":"Paul"},{"family":"Suleyman","given":"Mustafa"},{"family":"Zisserman","given":"Andrew"}],"citation-key":"kayKineticsHumanAction2017","DOI":"10.48550/ARXIV.1705.06950","issued":{"date-parts":[["2017"]]},"license":"arXiv.org perpetual, non-exclusive license","number":"arXiv:1705.06950","publisher":"arXiv","source":"DOI.org (Datacite)","title":"The Kinetics Human Action Video Dataset","type":"article","URL":"https://arxiv.org/abs/1705.06950","version":"1"},{"id":"keevallikHavingBallImmaterial2014","accessed":{"date-parts":[["2023",4,22]]},"author":[{"family":"Keevallik","given":"Leelo"}],"citation-key":"keevallikHavingBallImmaterial2014","container-title":"Interacting with Objects","DOI":"10.1075/z.186.11kee","editor":[{"family":"Nevile","given":"Maurice"},{"family":"Haddington","given":"Pentti"},{"family":"Heinemann","given":"Trine"},{"family":"Rauniomaa","given":"Mirka"}],"event-place":"Amsterdam","ISBN":"978-90-272-1213-9 978-90-272-6983-6","issued":{"date-parts":[["2014"]]},"language":"en","page":"249-268","publisher":"John Benjamins Publishing Company","publisher-place":"Amsterdam","source":"DOI.org (Crossref)","title":"Having a ball: Immaterial objects in dance instruction","title-short":"Having a ball","type":"chapter","URL":"https://benjamins.com/catalog/z.186.11kee"},{"id":"kelkarEvaluatingCollectionSoundtracing2018","author":[{"family":"Kelkar","given":"Tejaswinee"},{"family":"Roy","given":"Udit"},{"family":"Jensenius","given":"Alexander Refsum"}],"citation-key":"kelkarEvaluatingCollectionSoundtracing2018","container-title":"Proceedings of the 19th ISMIR Conference","event-place":"Paris, France","event-title":"19th International Society for Music Information Retrieval Conference","issued":{"date-parts":[["2018"]]},"page":"74-81","publisher-place":"Paris, France","title":"Evaluating a collection of sound-tracing data of melodic phrases","type":"paper-conference"},{"id":"kelseyASLJustWay2012","accessed":{"date-parts":[["2021",1,10]]},"author":[{"literal":"Kelsey"}],"citation-key":"kelseyASLJustWay2012","container-title":"YouTube","issued":{"date-parts":[["2012",7,17]]},"title":"ASL: Just the Way You Are","type":"webpage","URL":"https://www.youtube.com/watch?v=PjEw5NwaU1Q"},{"id":"kennyHeadSpace2017","accessed":{"date-parts":[["2021",1,19]]},"author":[{"family":"Kenny","given":"John"}],"citation-key":"kennyHeadSpace2017","container-title":"YouTube","issued":{"date-parts":[["2017",9,22]]},"title":"HeadSpace","type":"webpage","URL":"https://www.youtube.com/watch?v=Npg4SvIWsAc&feature=emb_logo"},{"id":"keoghDerivativeDynamicTime2001","abstract":"1 Introduction Time series are a ubiquitous form of data occurring in virtually every scientific discipline. A common task with time series data is comparing one sequence with another. In some domains a very simple distance measure, such as Euclidean distance will suffice. However, it is often the case that two sequences have the approximately the same overall component shapes, but these shapes do not line up in X-axis. Figure 1 shows this with a simple example. In order to find the similarity between such sequences, or as a preprocessing step before averaging them, we must ?warp? the time axis of one (or both) sequences to achieve a better alignment. Dynamic time warping (DTW), is a technique for efficiently achieving this warping. In addition to data mining (Keogh & Pazzani 2000, Yi et. al. 1998, Berndt & Clifford 1994), DTW has been used in gesture recognition (Gavrila & Davis 1995), robotics (Schmill et. al 1999), speech processing (Rabiner & Juang 1993), manufacturing (Gollmer & Posten 1995) and medicine (Caiani et. al 1998).","accessed":{"date-parts":[["2023",3,30]]},"author":[{"family":"Keogh","given":"Eamonn J."},{"family":"Pazzani","given":"Michael J."}],"citation-key":"keoghDerivativeDynamicTime2001","collection-title":"Proceedings","container-title":"Proceedings of the 2001 SIAM International Conference on Data Mining (SDM)","DOI":"10.1137/1.9781611972719.1","ISBN":"978-0-89871-495-1","issued":{"date-parts":[["2001",4,5]]},"page":"1-11","publisher":"Society for Industrial and Applied Mathematics","title":"Derivative Dynamic Time Warping","type":"paper-conference","URL":"https://doi.org/10.1137/1.9781611972719.1"},{"id":"keoghExactIndexingDynamic2005","accessed":{"date-parts":[["2023",3,27]]},"author":[{"family":"Keogh","given":"Eamonn"},{"family":"Ratanamahatana","given":"Chotirat Ann"}],"citation-key":"keoghExactIndexingDynamic2005","container-title":"Knowledge and Information Systems","container-title-short":"Knowl Inf Syst","DOI":"10.1007/s10115-004-0154-9","ISSN":"0219-1377, 0219-3116","issue":"3","issued":{"date-parts":[["2005",3]]},"language":"en","page":"358-386","source":"DOI.org (Crossref)","title":"Exact indexing of dynamic time warping","type":"article-journal","URL":"http://link.springer.com/10.1007/s10115-004-0154-9","volume":"7"},{"id":"keoghScalingDynamicTime2000","accessed":{"date-parts":[["2023",3,29]]},"author":[{"family":"Keogh","given":"Eamonn J."},{"family":"Pazzani","given":"Michael J."}],"citation-key":"keoghScalingDynamicTime2000","container-title":"Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining","DOI":"10.1145/347090.347153","event-place":"Boston Massachusetts USA","event-title":"KDD00: The Second Annual International Conference on Knowledge Discovery in Data","ISBN":"978-1-58113-233-5","issued":{"date-parts":[["2000",8]]},"language":"en","page":"285-289","publisher":"ACM","publisher-place":"Boston Massachusetts USA","source":"DOI.org (Crossref)","title":"Scaling up dynamic time warping for datamining applications","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/347090.347153"},{"id":"khanTakingBitterSwede2016","accessed":{"date-parts":[["2021",1,7]]},"author":[{"family":"Khan","given":"Imran"}],"citation-key":"khanTakingBitterSwede2016","container-title":"PopMatters","issued":{"date-parts":[["2016",9,7]]},"title":"Taking the Bitter With the Swede: Adam Tensta's Moody Hip-Hop Soul","type":"webpage","URL":"https://www.popmatters.com/taking-the-bitter-with-the-swede-adam-tenstas-moody-hip-hop-soul-2495418398.html"},{"id":"khoeiFlashlagEffectMotionbased2017","abstract":"Due to its inherent neural delays, the visual system has an outdated access to sensory information about the current position of moving objects. In contrast, living organisms are remarkably able to track and intercept moving objects under a large range of challenging environmental conditions. Physiological, behavioral and psychophysical evidences strongly suggest that position coding is extrapolated using an explicit and reliable representation of object’s motion but it is still unclear how these two representations interact. For instance, the so-called flash-lag effect supports the idea of a differential processing of position between moving and static objects. Although elucidating such mechanisms is crucial in our understanding of the dynamics of visual processing, a theory is still missing to explain the different facets of this visual illusion. Here, we reconsider several of the key aspects of the flash-lag effect in order to explore the role of motion upon neural coding of objects’ position. First, we formalize the problem using a Bayesian modeling framework which includes a graded representation of the degree of belief about visual motion. We introduce a motion-based prediction model as a candidate explanation for the perception of coherent motion. By including the knowledge of a fixed delay, we can model the dynamics of sensory information integration by extrapolating the information acquired at previous instants in time. Next, we simulate the optimal estimation of object position with and without delay compensation and compared it with human perception under a broad range of different psychophysical conditions. Our computational study suggests that the explicit, probabilistic representation of velocity information is crucial in explaining position coding, and therefore the flash-lag effect. We discuss these theoretical results in light of the putative corrective mechanisms that can be used to cancel out the detrimental effects of neural delays and illuminate the more general question of the dynamical representation at the present time of spatial information in the visual pathways.","author":[{"family":"Khoei","given":"M. A."},{"family":"Masson","given":"G."},{"family":"Perrinet","given":"Laurent Udo"}],"citation-key":"khoeiFlashlagEffectMotionbased2017","container-title":"PLoS Computational Biology","DOI":"10.1371/journal.pcbi.1005068","issued":{"date-parts":[["2017"]]},"note":"QID: Q36260905","page":"null","PMID":"28125585","title":"The flash-lag effect as a motion-based predictive shift","type":"article-journal","URL":"https://www.semanticscholar.org/paper/50e9311f27dd92ecba05c4bbecb9f618036021f3","volume":"13"},{"id":"killionEvaluationHighFidelityHearing1982","author":[{"family":"Killion","given":"Mead C."},{"family":"Tillman","given":"Tom W."}],"citation-key":"killionEvaluationHighFidelityHearing1982","container-title":"Journal of Speech, Language, and Hearing Research","container-title-short":"Journal of Speech, Language, and Hearing Research","ISSN":"1092-4388","issue":"1","issued":{"date-parts":[["1982"]]},"page":"15-25","publisher":"ASHA","title":"Evaluation of High-Fidelity Hearing Aids","type":"article-journal","volume":"25"},{"id":"killionHearingAidTransducers2016","abstract":"This volume will serve as the first Handbook of its kind in the area of hearing aid research, often the least-defined, least-understood, part of the multi-disciplinary research process. Most scientific training is very advanced within the particular disciplines but provides little opportunity for systematic introduction to the issues and obstacles that prevent effective hearing-aid related research. This area has emerged as one of critical importance, as signified by a single specialized meeting (the International Hearing Aid Conference, IHCON) that brings together specialists from the disparate disciplines involved, including both university and industry researchers. Identification of the key steps that enable high-impact basic science to ultimately result in significant clinical advances that improve patient outcome is critical. This volume will provide an overview of current key issues in hearing aid research from the perspective of many different disciplines, not only from the perspective of the key funding agencies, but also from the scientists and clinicians who are currently involved in hearing aid research. It will offer insight into the experience, current technology and future technology that can help improve hearing aids, as scientists and clinicians typically have little or no formal training over the whole range of the individual disciplines that are relevant. The selection and coverage of topics insures that it will have lasting impact, well beyond immediate, short-term, or parochial concerns.","accessed":{"date-parts":[["2021",1,20]]},"author":[{"family":"Killion","given":"Mead C."},{"family":"Van Halteren","given":"Aart"},{"family":"Stenfelt","given":"Stefan"},{"family":"Warren","given":"Daniel M."}],"citation-key":"killionHearingAidTransducers2016","collection-number":"56","collection-title":"Springer Handbook of Auditory Research","container-title":"Hearing Aids","editor":[{"family":"Popelka","given":"Gerald R."},{"family":"Moore","given":"Brian C. J."},{"family":"Fay","given":"Richard R."},{"family":"Popper","given":"Arthur N."}],"event-place":"Cham","ISBN":"978-3-319-33036-5","issued":{"date-parts":[["2016"]]},"language":"English","note":"OCLC: 984801900","page":"55 - 92","publisher":"Springer International Publishing : Imprint : Springer","publisher-place":"Cham","source":"Open WorldCat","title":"Hearing Aid Transducers","type":"chapter","URL":"https://doi.org/10.1007/978-3-319-33036-5"},{"id":"kimOxfordHandbookMusic2019","abstract":"The presence of the phenomenological body is central to music in all of its varieties and contradictions. With the explosion of scholarly works on the body in virtually every field in the humanities, the social as well as the biomedical sciences, the question of how such a complex understanding of the body is related to music, with its own complexity, has been investigated within specific disciplinary perspectives. The Oxford Handbook of Music and the Body brings together scholars from across these fields, providing a platform for the discussion of the multidimensional interfaces of music and the body. The book is organized into six sections, each discussing a topic that defines the field: the moving and performing body; the musical brain and psyche; embodied mind, embodied rhythm; the disabled and sexual body; music as medicine; and the multimodal body. Connecting a wide array of diverse perspectives and presenting a survey of research and practice, the Handbook provides an introduction into the rich world of music and the body","call-number":"ML3830 .O88 2019","citation-key":"kimOxfordHandbookMusic2019","editor":[{"family":"Kim","given":"Youn"},{"family":"Gilman","given":"Sander L."}],"event-place":"New York, NY","ISBN":"978-0-19-063623-4","issued":{"date-parts":[["2019"]]},"number-of-pages":"458","publisher":"Oxford University Press","publisher-place":"New York, NY","source":"Library of Congress ISBN","title":"The Oxford Handbook of Music and the Body","type":"book"},{"id":"kingmaAutoEncodingVariationalBayes2013","abstract":"How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.","accessed":{"date-parts":[["2022",4,21]]},"author":[{"family":"Kingma","given":"Diederik P"},{"family":"Welling","given":"Max"}],"citation-key":"kingmaAutoEncodingVariationalBayes2013","DOI":"10.48550/ARXIV.1312.6114","issued":{"date-parts":[["2013"]]},"license":"arXiv.org perpetual, non-exclusive license","publisher":"arXiv","source":"DOI.org (Datacite)","title":"Auto-Encoding Variational Bayes","type":"article-journal","URL":"https://arxiv.org/abs/1312.6114","version":"10"},{"id":"kingmaIntroductionVariationalAutoencoders2019","accessed":{"date-parts":[["2022",5,4]]},"author":[{"family":"Kingma","given":"Diederik P."},{"family":"Welling","given":"Max"}],"citation-key":"kingmaIntroductionVariationalAutoencoders2019","container-title":"Foundations and Trends® in Machine Learning","container-title-short":"FNT in Machine Learning","DOI":"10.1561/2200000056","ISSN":"1935-8237, 1935-8245","issue":"4","issued":{"date-parts":[["2019"]]},"language":"en","page":"307-392","source":"DOI.org (Crossref)","title":"An Introduction to Variational Autoencoders","type":"article-journal","URL":"http://www.nowpublishers.com/article/Details/MAL-056","volume":"12"},{"id":"kippEvaluatingTangibleInterface2006","abstract":"When using virtual characters in the human-computer interface the question arises of how useful this kind of interface is: whether the human user accepts, enjoys and profits from this form of interaction. Thorough system evaluations, however, are rarely done. We propose a post-questionnaire evaluation for a virtual character system that we apply to COHIBIT, an interactive museum exhibit with virtual characters. The evaluation study investigates the subjects’ experiences with the exhibit with regard to informativeness, entertainment and virtual character perception. Our subjects rated the exhibit both entertaining and informative and gave it a good overall mark. We discuss the detailed results and identify useful factors to consider when building and evaluating virtual character applications.","author":[{"family":"Kipp","given":"Michael"},{"family":"Kipp","given":"Kerstin H."},{"family":"Ndiaye","given":"Alassane"},{"family":"Gebhard","given":"Patrick"}],"citation-key":"kippEvaluatingTangibleInterface2006","container-title":"Intelligent Virtual Agents","editor":[{"family":"Gratch","given":"Jonathan"},{"family":"Young","given":"Michael"},{"family":"Aylett","given":"Ruth"},{"family":"Ballin","given":"Daniel"},{"family":"Olivier","given":"Patrick"}],"event-place":"Berlin, Heidelberg","ISBN":"978-3-540-37594-4","issued":{"date-parts":[["2006"]]},"page":"434-444","publisher":"Springer Berlin Heidelberg","publisher-place":"Berlin, Heidelberg","title":"Evaluating the Tangible Interface and Virtual Characters in the Interactive COHIBIT Exhibit","type":"paper-conference"},{"id":"kirchbergerDynamicRangeMusic2016","accessed":{"date-parts":[["2021",1,23]]},"author":[{"family":"Kirchberger","given":"Martin"},{"family":"Russo","given":"Frank A."}],"citation-key":"kirchbergerDynamicRangeMusic2016","container-title":"Trends in Hearing","container-title-short":"Trends in Hearing","DOI":"10.1177/2331216516630549","ISSN":"2331-2165, 2331-2165","issued":{"date-parts":[["2016",9]]},"language":"en","page":"1 - 16","source":"DOI.org (Crossref)","title":"Dynamic Range Across Music Genres and the Perception of Dynamic Compression in Hearing-Impaired Listeners","type":"article-journal","URL":"http://journals.sagepub.com/doi/10.1177/2331216516630549","volume":"20"},{"id":"kitagawaMoCapArtistsWorkflow2008","author":[{"family":"Kitagawa","given":"Midori"},{"family":"Windsor","given":"Brian"}],"call-number":"TR897.7 .K58 2008","citation-key":"kitagawaMoCapArtistsWorkflow2008","event-place":"Amsterdam ; Boston","ISBN":"978-0-240-81000-3","issued":{"date-parts":[["2008"]]},"note":"OCLC: ocn190620556","number-of-pages":"216","publisher":"Elsevier/Focal Press","publisher-place":"Amsterdam ; Boston","source":"Library of Congress ISBN","title":"MoCap for artists: workflow and techniques for motion capture","title-short":"MoCap for artists","type":"book"},{"id":"kitchenhamSystematicReviewSystematic2013","accessed":{"date-parts":[["2024",9,9]]},"author":[{"family":"Kitchenham","given":"Barbara"},{"family":"Brereton","given":"Pearl"}],"citation-key":"kitchenhamSystematicReviewSystematic2013","container-title":"Information and Software Technology","container-title-short":"Information and Software Technology","DOI":"10.1016/j.infsof.2013.07.010","ISSN":"09505849","issue":"12","issued":{"date-parts":[["2013",12]]},"language":"en","page":"2049-2075","source":"DOI.org (Crossref)","title":"A systematic review of systematic review process research in software engineering","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0950584913001560","volume":"55"},{"id":"kitsonInfluenceMovementExpertise2015","abstract":"There is increasing evidence of individual differences in spatial cognitive abilities and strategies, especially for simulated locomotion such as virtual realities. For example, Klatzky and colleagues observed two distinct response patterns in a \"point-to-origin\" task where participants pointed back to the origin of locomotion after a simulated 2-segment excursion. \"Turners\" responded as if succeeding to update their heading, whereas \"non-turners\" responded as if failing to update their heading - but why? Here, we investigated if one's real-world movement and movement analysis expertise (i.e., dancers versus Laban Movement Analysts) might affect one's virtual orientation behaviour. Using a virtual point-to-origin task, data showed that participants (N=39) with more extensive movement analysis expertise tended to be turners, and thus incorporate visually presented turns correctly. Conversely, dance students without Laban Movement Analysis expertise tended to be non-turners or used a mixed strategy. This suggests that reflecting about self-motion might be more conducive than movement experience, primarily dance, alone for enabling correct updating of simulated heading changes.","author":[{"family":"Kitson","given":"Alexandra"},{"family":"Riecke","given":"Bernhard E."},{"family":"Stepanova","given":"Ekaterina R."}],"citation-key":"kitsonInfluenceMovementExpertise2015","collection-title":"MOCO '15","container-title":"Proceedings of the 2nd international workshop on movement and computing","DOI":"10.1145/2790994.2791014","event-place":"Vancouver, British Columbia, Canada","ISBN":"978-1-4503-3457-0","issued":{"date-parts":[["2015"]]},"number-of-pages":"4","page":"100–103","publisher":"Association for Computing Machinery","publisher-place":"Vancouver, British Columbia, Canada","title":"Influence of movement expertise on a virtual point-to-origin task","type":"paper-conference","URL":"https://doi.org/10.1145/2790994.2791014"},{"id":"kjeldskovSpatialMixerCrossDevice2019","accessed":{"date-parts":[["2024",1,25]]},"author":[{"family":"Kjeldskov","given":"Jesper"},{"family":"Paay","given":"Jeni"},{"family":"Nilsson","given":"Aleksander"},{"family":"Plejdrup","given":"Kasper"},{"family":"Pedersen","given":"Mette"}],"citation-key":"kjeldskovSpatialMixerCrossDevice2019","container-title":"Proceedings of the 31st Australian Conference on Human-Computer-Interaction","DOI":"10.1145/3369457.3369465","event-place":"Fremantle WA Australia","event-title":"OZCHI'19: 31ST AUSTRALIAN CONFERENCE ON HUMAN-COMPUTER-INTERACTION","ISBN":"978-1-4503-7696-9","issued":{"date-parts":[["2019",12,2]]},"language":"en","page":"85-94","publisher":"ACM","publisher-place":"Fremantle WA Australia","source":"DOI.org (Crossref)","title":"Spatial Mixer: Cross-Device Interaction for Music Mixing","title-short":"Spatial Mixer","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3369457.3369465"},{"id":"kleinWhatArtisticResearch2017","accessed":{"date-parts":[["2023",4,24]]},"author":[{"family":"Klein","given":"Julian"}],"citation-key":"kleinWhatArtisticResearch2017","container-title":"Journal for Artistic Research","container-title-short":"JAR","DOI":"10.22501/jarnet.0004","ISSN":"22350225","issued":{"date-parts":[["2017",4,23]]},"source":"DOI.org (Crossref)","title":"What is artistic research?","type":"article-journal","URL":"https://jar-online.net/what-artistic-research"},{"id":"klyukanovPrinciplesInterculturalCommunication2020","abstract":"\"Now in a second edition, this book guides students in developing Intercultural Communication Competence through its accessible style and unique theoretical framework of ten interconnected principles. Thoroughly revised and updated with new case studies and examples and a sharper focus on practical application, the book engages students in active learning by showing them how these principles come to play in their intercultural journeys. It features detailed case studies that are accompanied by guiding questions that help students link theory to their daily lives. At the end of each chapter, the \"Side Trips\" discussion prompts encourage students to think more critically about the issues as they are presented. Suitable for upper-level or graduate intercultural communication courses within communication and linguistics departments\"--","author":[{"family":"Klyukanov","given":"Igor"}],"call-number":"HM1211 .K58 2020","citation-key":"klyukanovPrinciplesInterculturalCommunication2020","edition":"Second edition","event-place":"New York, NY","ISBN":"978-0-367-37388-7 978-0-367-37387-0","issued":{"date-parts":[["2020"]]},"publisher":"Routledge","publisher-place":"New York, NY","source":"Library of Congress ISBN","title":"Principles of Intercultural Communication","type":"book"},{"id":"kochEmbodiedEnactiveDance2011","abstract":"Dance/movement therapy may be conceptualized as an embodied and enactive form of psychotherapy. The embodied enactive approach looks at individuals as living systems characterized by plasticity and permeability (moment-to-moment adaptations within the self and toward the environment), autonomy, sense-making, emergence, experience, and striving for balance. Enaction and embodiment emphasize the roles that body motion and sensorimotor experience play in the formation of concepts and abstract thinking. A theoretical framework and a perspective on professional practice in dance/movement therapy are herein offered as influenced by interdisciplinary embodied and enactive approaches deriving from cognitive sciences and phenomenology. The authors assert that dance/movement therapy, enaction, and embodiment fruitfully contribute to one another.","author":[{"family":"Koch","given":"Sabine C."},{"family":"Fischman","given":"Diana"}],"citation-key":"kochEmbodiedEnactiveDance2011","container-title":"American Journal of Dance Therapy","container-title-short":"American Journal of Dance Therapy","DOI":"10.1007/s10465-011-9108-4","ISSN":"1573-3262","issue":"1","issued":{"date-parts":[["2011",6,1]]},"page":"57-72","title":"Embodied Enactive Dance/Movement Therapy","type":"article-journal","URL":"https://doi.org/10.1007/s10465-011-9108-4","volume":"33"},{"id":"kochkinMarkeTrakVIIIConsumer2010","abstract":"Based on more than 3000 responses from hearing aid wearers to the eighth MarkeTrak survey, Better Hearing Institute Executive Director Dr. Sergei Kochkin determined that 74% of hearing instrument users in 2008 were satisfied with their fittings. That was significantly higher than the 68% satisfaction rate found by MarkeTrak VII in 2004 and the best ever recorded.","author":[{"family":"Kochkin","given":"Sergei"}],"citation-key":"kochkinMarkeTrakVIIIConsumer2010","container-title":"The Hearing Journal","ISSN":"0745-7472","issue":"1","issued":{"date-parts":[["2010",1]]},"page":"19-20, 22, 24, 26, 28, 30-32","title":"MarkeTrak VIII: Consumer Satisfaction With Hearing Aids is Slowly Increasing","type":"article-journal","URL":"https://journals.lww.com/thehearingjournal/Fulltext/2010/01000/MarkeTrak_VIII__Consumer_satisfaction_with_hearing.4.aspx","volume":"63"},{"id":"kokOptimizationbasedApproachHuman2014","abstract":"In inertial human motion capture, a multitude of body segments are equipped with inertial measurement units, consisting of 3D accelerometers, 3D gyroscopes and 3D magnetometers. Relative position and orientation estimates can be obtained using the inertial data together with a biomechanical model. In this work we present an optimization-based solution to magnetometer-free inertial motion capture. It allows for natural inclusion of biomechanical constraints, for handling of nonlinearities and for using all data in obtaining an estimate. As a proof-of-concept we apply our algorithm to a lower body configuration, illustrating that the estimates are drift-free and match the joint angles from an optical reference system.","author":[{"family":"Kok","given":"Manon"},{"family":"Hol","given":"Jeroen D."},{"family":"Schön","given":"Thomas B."}],"citation-key":"kokOptimizationbasedApproachHuman2014","container-title":"19th IFAC World Congress","container-title-short":"IFAC Proceedings Volumes","DOI":"10.3182/20140824-6-ZA-1003.02252","ISSN":"1474-6670","issue":"3","issued":{"date-parts":[["2014",1,1]]},"page":"79-85","title":"An optimization-based approach to human body motion capture using inertial sensors","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S147466701641596X","volume":"47"},{"id":"kolykhalovaGraphrestrictedGameApproach2017","abstract":"A novel computational method for the analysis of expressive full-body movement qualities is introduced, which exploits concepts and tools from graph theory and game theory. The human skeletal structure is modeled as an undirected graph, where the joints are the vertices and the edge set contains both physical and non-physical links. Physical links correspond to connections between adjacent physical body joints (e.g., the forearm, which connects the elbow to the wrist). Nonphysical links act as \"bridges\" between parts of the body not directly connected by the skeletal structure, but sharing very similar feature values. The edge weights depend on features obtained by using Motion Capture data. Then, a mathematical game is constructed over the graph structure, where the vertices represent the players and the edges represent communication channels between them. Hence, the body movement is modeled in terms of a game built on the graph structure. Since the vertices and the edges contribute to the overall quality of the movement, the adopted game-theoretical model is of cooperative nature. A game-theoretical concept, called Shapley value, is exploited as a centrality index to estimate the contribution of each vertex to a shared goal (e.g., to the way a particular movement quality is transferred among the vertices). The proposed method is applied to a data set of Motion Capture data of subjects performing expressive movements, recorded in the framework of the H2020-ICT-2015 EU Project WhoLoDance, Project no. 688865. Preliminary results are presented.","author":[{"family":"Kolykhalova","given":"Ksenia"},{"family":"Gnecco","given":"Giorgio"},{"family":"Sanguineti","given":"Marcello"},{"family":"Camurri","given":"Antonio"},{"family":"Volpe","given":"Gualtiero"}],"citation-key":"kolykhalovaGraphrestrictedGameApproach2017","collection-title":"MOCO '17","container-title":"Proceedings of the 4th international conference on movement computing","DOI":"10.1145/3077981.3078030","event-place":"London, United Kingdom","ISBN":"978-1-4503-5209-3","issued":{"date-parts":[["2017"]]},"number-of-pages":"4","publisher":"Association for Computing Machinery","publisher-place":"London, United Kingdom","title":"Graph-restricted game approach for investigating human movement qualities","type":"paper-conference","URL":"https://doi.org/10.1145/3077981.3078030"},{"id":"komesaroffSurgicalConsentBioethics2007","citation-key":"komesaroffSurgicalConsentBioethics2007","editor":[{"family":"Komesaroff","given":"Linda R."}],"event-place":"Washington, D.C","ISBN":"978-1-56368-349-7 978-1-56368-583-5","issued":{"date-parts":[["2007"]]},"language":"en","note":"OCLC: 237135124","number-of-pages":"203","publisher":"Gallaudet Univ. Press","publisher-place":"Washington, D.C","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"Surgical consent: bioethics and cochlear implantation","title-short":"Surgical consent","type":"book"},{"id":"komplett.noSTLabUSB","accessed":{"date-parts":[["2022",11,26]]},"author":[{"literal":"komplett.no"}],"citation-key":"komplett.noSTLabUSB","container-title":"komplett.no","title":"ST Lab USB 3.0 HUB 4Port","type":"webpage","URL":"https://www.komplett.no/product/650595/pc-nettbrett/pc-tilbehoer/usb-hub/st-lab-usb-30-hub-4port#"},{"id":"kongMusicPerceptionTemporal2004","author":[{"family":"Kong","given":"Ying-Yee"},{"family":"Cruz","given":"Rachel"},{"family":"Jones","given":"J. Ackland"},{"family":"Zeng","given":"Fan-Gang"}],"citation-key":"kongMusicPerceptionTemporal2004","container-title":"Ear and Hearing","container-title-short":"Ear and Hearing","ISSN":"0196-0202","issue":"2","issued":{"date-parts":[["2004"]]},"page":"173-185","publisher":"LWW","title":"Music Perception with Temporal Cues in Acoustic and Electric Hearing","type":"article-journal","volume":"25"},{"id":"kongSpeechMelodyRecognition2005","author":[{"family":"Kong","given":"Ying-Yee"},{"family":"Stickney","given":"Ginger S."},{"family":"Zeng","given":"Fan-Gang"}],"citation-key":"kongSpeechMelodyRecognition2005","container-title":"The Journal of the Acoustical Society of America","container-title-short":"The Journal of the Acoustical Society of America","ISSN":"0001-4966","issue":"3","issued":{"date-parts":[["2005"]]},"page":"1351-1361","publisher":"Acoustical Society of America","title":"Speech and Melody Recognition in Binaurally Combined Acoustic and Electric Hearing","type":"article-journal","volume":"117"},{"id":"kozelCloserPerformanceTechnologies2008","abstract":"Susan Kozel draws on live performance practice, digital technologies & the philosophical approach of phenomenology. She places the human body at the centre of explorations of interactive interfaces, responsive systems & affective computing, asking what is to be discovered as we become closer to our computers?","author":[{"family":"Kozel","given":"Susan"}],"citation-key":"kozelCloserPerformanceTechnologies2008","event-place":"Cambridge, Mass.","ISBN":"978-0-262-27756-3","issued":{"date-parts":[["2008"]]},"language":"eng","note":"OCLC: 213296232","publisher":"MIT Press","publisher-place":"Cambridge, Mass.","source":"Open WorldCat","title":"Closer: performance, technologies, phenomenology","title-short":"Closer","type":"book"},{"id":"krautRecoveringHurstonReconsidering2006","accessed":{"date-parts":[["2023",1,3]]},"author":[{"family":"Kraut","given":"Anthea"}],"citation-key":"krautRecoveringHurstonReconsidering2006","container-title":"Women & Performance: a journal of feminist theory","container-title-short":"Women & Performance: a journal of feminist theory","DOI":"10.1080/07407700500515936","ISSN":"0740-770X, 1748-5819","issue":"1","issued":{"date-parts":[["2006",3]]},"language":"en","page":"71-90","source":"DOI.org (Crossref)","title":"Recovering hurston, reconsidering the choreographer","type":"article-journal","URL":"http://www.tandfonline.com/doi/abs/10.1080/07407700500515936","volume":"16"},{"id":"kristevaPowersHorror1982","author":[{"family":"Kristeva","given":"Julia"}],"citation-key":"kristevaPowersHorror1982","event-place":"New York","ISBN":"0-231-05346-0","issued":{"date-parts":[["1982"]]},"publisher":"Columbia University Press","publisher-place":"New York","title":"Powers of horror","type":"book"},{"id":"kroghBeatHybridMediation2018","abstract":"This article aims to discuss the notion of music as material practice from a perspective of mediation theory. It attempts a non-reductivist understanding of the role of things and material settings for processes of human action and interaction in the context of musical events. Having considered Tia DeNora's micro-sociological reconceptualisation of Adornian materialism (DeNora, T. 2003. After Adorno. Cambridge: Cambridge University Press), it invokes perspectives from actor-network theory, drawing in particular on the contribution made to music sociology by Antoine Hennion and the sociology of associations advanced by Bruno Latour. Moreover, considerations of time and temporality are added by reference to Georgina Born's work on mediation in cultural production. On these grounds, a reinterpretation of DeNora's model for understanding musical events is proposed and explored through a case study of a particular instance of music making as material practice, namely the production of beats by a Danish hip-hop deejay, Thorbjørn Schwarz (aka DJ Static).","author":[{"family":"Krogh","given":"Mads"}],"citation-key":"kroghBeatHybridMediation2018","container-title":"Contemporary music review","container-title-short":"CONTEMP MUSIC REV","DOI":"10.1080/07494467.2018.1575125","event-place":"ABINGDON","ISSN":"0749-4467","issue":"5-6","issued":{"date-parts":[["2018"]]},"page":"529-553","publisher":"ABINGDON: Routledge","publisher-place":"ABINGDON","title":"A Beat is a Hybrid: Mediation, ANT and Music as Material Practice","type":"article-journal","volume":"37"},{"id":"kruegerAffordancesMusicallyExtended2014","accessed":{"date-parts":[["2022",5,15]]},"author":[{"family":"Krueger","given":"Joel"}],"citation-key":"kruegerAffordancesMusicallyExtended2014","container-title":"Frontiers in Psychology","container-title-short":"Front. Psychol.","DOI":"10.3389/fpsyg.2013.01003","ISSN":"1664-1078","issued":{"date-parts":[["2014"]]},"source":"DOI.org (Crossref)","title":"Affordances and the musically extended mind","type":"article-journal","URL":"http://journal.frontiersin.org/article/10.3389/fpsyg.2013.01003/abstract","volume":"4"},{"id":"krzysztofcybulskiFEEDBACKSYNTH2015","accessed":{"date-parts":[["2022",12,9]]},"author":[{"literal":"Krzysztof Cybulski"}],"citation-key":"krzysztofcybulskiFEEDBACKSYNTH2015","container-title":"krzysztofcybulski.com","title":"FEEDBACK SYNTH /// 2015","type":"webpage","URL":"https://krzysztofcybulski.com/feedbacksynth.html"},{"id":"kuppersDisabilityContemporaryPerformance2004","author":[{"family":"Kuppers","given":"Petra"}],"call-number":"HV1568 .K87 2004","citation-key":"kuppersDisabilityContemporaryPerformance2004","event-place":"New York","ISBN":"978-0-415-30239-5 978-0-415-30238-8","issued":{"date-parts":[["2004"]]},"number-of-pages":"176","publisher":"Routledge","publisher-place":"New York","source":"Library of Congress ISBN","title":"Disability and Contemporary Performance: Bodies on Edge","title-short":"Disability and contemporary performance","type":"book"},{"id":"kvaleInterViewsLearningCraft2009","abstract":"\"The first edition of InterViews provided students and professionals in a wide variety of disciplines with the \"whys\" and \"hows\" of research interviewing, preparing students for learning interviewing by doing interviews and by studying examples of best practice. The thoroughly revised Second Edition retains its original seven stage structure, continuing to focus on the practical, epistemological, and ethical issues involved with interviewing. Authors Steinar Kvale and Svend Brinkmann also include coverage of newer developments in qualitative interviewing, discussion of interviewing as a craft, and a new chapter on linguistic modes of interview analysis. Practical and conceptual assignments, as well as new \"tool boxes,\" provide students with the means to dig deeper into the material presented and achieve a more meaningful level of understanding.\" \"This text is ideal for both novice and experienced interview researchers as well as graduate students taking courses in qualitative and research methods in the social sciences and health sciences, particularly in departments of education, nursing, sociology, psychology, and the media sciences.\"--Jacket","author":[{"family":"Kvale","given":"Steinar"},{"family":"Brinkmann","given":"Svend"}],"citation-key":"kvaleInterViewsLearningCraft2009","edition":"2. ed","event-place":"Los Angeles","ISBN":"978-0-7619-2542-2 978-0-7619-2541-5","issued":{"date-parts":[["2009"]]},"language":"eng","number-of-pages":"354","publisher":"Sage","publisher-place":"Los Angeles","source":"K10plus ISBN","title":"InterViews: learning the craft of qualitative research interviewing","title-short":"InterViews","type":"book"},{"id":"kvifteCoherentTerminologyModel2006","author":[{"family":"Kvifte","given":"Tellef"},{"family":"Jensenius","given":"Alexander"}],"citation-key":"kvifteCoherentTerminologyModel2006","issued":{"date-parts":[["2006",1,1]]},"number-of-pages":"220","page":"225","title":"Towards a Coherent Terminology and Model of Instrument Description and Design.","type":"book"},{"id":"laczkoReflectionsDevelopmentMusical2021","author":[{"family":"Laczkó","given":"Bálint"},{"family":"Jensenius","given":"Alexander Refsum"}],"citation-key":"laczkoReflectionsDevelopmentMusical2021","issued":{"date-parts":[["2021"]]},"publisher":"Aalborg University Copenhagen","title":"Reflections on the Development of the Musical Gestures Toolbox for Python","type":"article-journal","URL":"https://nordicsmc.create.aau.dk/wp-content/NordicSMC/Nordic_SMC_2021_paper_38.pdf"},{"id":"laddArtisticResearchTools1979","abstract":"[The topics of this paper are frequently-used, versatile research tools: subconscious mental processes (imagination and intuition), chance (including serendipity) and writing. Conditions that may stimulate subconscious mental processes to generate useful ideas are discussed. They are doubt, venturesome attitude, diversity, thorough preparation, tension, temporary abandonment, relaxation, writing, exchange with colleagues, freedom from distraction, and deadlines. Various forms of chance and their roles in research and problem solving are discussed. It is argued that writing is not only a research-reporting tool but is also valuable in performing research.]","accessed":{"date-parts":[["2023",4,26]]},"archive":"JSTOR","author":[{"family":"Ladd","given":"George W."}],"citation-key":"laddArtisticResearchTools1979","container-title":"American Journal of Agricultural Economics","DOI":"10.2307/1239494","ISSN":"00029092, 14678276","issue":"1","issued":{"date-parts":[["1979"]]},"page":"1-11","publisher":"[Agricultural & Applied Economics Association, Oxford University Press]","title":"Artistic Research Tools for Scientific Minds","type":"article-journal","URL":"http://www.jstor.org/stable/1239494","volume":"61"},{"id":"laddCochlearImplantationColonialism2007","abstract":"This chapter examines the issue of childhood cochlear implantation against the background of the situation for Deaf people in the United Kingdom (with reference to other countries where relevant). It is my belief that one reason for the lack of success in critiquing or challenging cochlear implantation is that Deaf discourses in general, and Deaf studies in particular, have been overwhelmingly inwardly focused; Deaf issues are discussed almost in intellectual isolation from the wider political patterns of world events. Thus, this chapter takes pains to extend the frame of reference for discussion of this issue. In particular, the concept of colonialism,1 as it pertains to signed language communities, is used to frame and evaluate issues related to cochlear implantation. I also introduce a new concept of \"positive\" and \"negative\" biology as a bridge to similar emergent concepts in other disciplines such as women's studies. Wrigley (1996) concisely frames the issue: What new colony in the name of communications technology is sited on the body of the Deaf? What discovery by a new \"Columbus\" is re-enacted on this new \"continent\" of language and communication? Did anyone notice any natives? (206).","author":[{"family":"Ladd","given":"Paddy"}],"citation-key":"laddCochlearImplantationColonialism2007","issued":{"date-parts":[["2007",1,1]]},"page":"1-29","title":"Cochlear implantation, colonialism, and deaf rights","type":"chapter"},{"id":"laddColonialismResistanceBrief2008","author":[{"family":"Ladd","given":"Paddy"}],"call-number":"HV2380 .D43 2002","citation-key":"laddColonialismResistanceBrief2008","container-title":"Colonialism and Resistance: A Brief History of Deafhood","editor":[{"family":"Bauman","given":"H.-Dirksen L."}],"event-place":"Minneapolis","ISBN":"978-0-8166-4618-0 978-0-8166-4619-7","issued":{"date-parts":[["2008"]]},"note":"OCLC: ocn167497734","page":"42 - 59","publisher":"University of Minnesota Press","publisher-place":"Minneapolis","source":"Library of Congress ISBN","title":"Colonialism and Resistance: A Brief History of Deafhood","type":"chapter"},{"id":"laddColonialismResistanceBrief2008a","author":[{"family":"Ladd","given":"Paddy"}],"call-number":"HV2380 .D43 2002","citation-key":"laddColonialismResistanceBrief2008a","container-title":"Open Your Eyes: Deaf Studies Talking","editor":[{"family":"Bauman","given":"H.-Dirksen L."}],"event-place":"Minneapolis","ISBN":"978-0-8166-4618-0 978-0-8166-4619-7","issued":{"date-parts":[["2008"]]},"note":"OCLC: ocn167497734","page":"42 - 59","publisher":"University of Minnesota Press","publisher-place":"Minneapolis","source":"Library of Congress ISBN","title":"Colonialism and Resistance: A Brief History of Deafhood","type":"chapter"},{"id":"laddUnderstandingDeafCulture2003","author":[{"family":"Ladd","given":"Paddy"}],"call-number":"HV2380 .L26 2003","citation-key":"laddUnderstandingDeafCulture2003","event-place":"Clevedon, England ; Buffalo","ISBN":"978-1-85359-546-2 978-1-85359-545-5","issued":{"date-parts":[["2003"]]},"number-of-pages":"502","publisher":"Multilingual Matters","publisher-place":"Clevedon, England ; Buffalo","source":"Library of Congress ISBN","title":"Understanding Deaf Culture: In Search of Deafhood","title-short":"Understanding deaf culture","type":"book"},{"id":"ladnerAccessibleTechnologyModels2010","author":[{"family":"Ladner","given":"Richard E."}],"call-number":"MLCM 2017/43366 (T)","citation-key":"ladnerAccessibleTechnologyModels2010","container-title":"Design and Use of Assistive Technology","editor":[{"family":"Oishi","given":"Meeko Mitsuko K."},{"family":"Mitchell","given":"Ian M."},{"family":"Van der Loos","given":"Hendrik F. Machiel"}],"event-place":"New York","ISBN":"978-1-4419-7030-5 978-1-4419-7031-2","issued":{"date-parts":[["2010"]]},"page":"25 -31","publisher":"Springer","publisher-place":"New York","source":"Library of Congress ISBN","title":"Accessible Technology and Models of Disability","type":"chapter"},{"id":"lahatMultimodalDataFusion2015","author":[{"family":"Lahat","given":"Dana"},{"family":"Adali","given":"Tülay"},{"family":"Jutten","given":"Christian"}],"citation-key":"lahatMultimodalDataFusion2015","container-title":"Proceedings of the IEEE","DOI":"10.1109/JPROC.2015.2460697","issue":"9","issued":{"date-parts":[["2015"]]},"page":"1449-1477","title":"Multimodal data fusion: An overview of methods, challenges, and prospects","type":"article-journal","volume":"103"},{"id":"lahavAcousticGapNICU2014","abstract":"The intrauterine environment allows the fetus to begin hearing low-frequency sounds in a protected fashion, ensuring initial optimal development of the peripheral and central auditory system. However, the auditory nursery provided by the womb vanishes once the preterm newborn enters the high-frequency (HF) noisy environment of the neonatal intensive care unit (NICU). The present article draws a concerning line between auditory system development and HF noise in the NICU, which we argue is not necessarily conducive to fostering this development. Overexposure to HF noise during critical periods disrupts the functional organization of auditory cortical circuits. As a result, we theorize that the ability to tune out noise and extract acoustic information in a noisy environment may be impaired, leading to increased risks for a variety of auditory, language, and attention disorders. Additionally, HF noise in the NICU often masks human speech sounds, further limiting quality exposure to linguistic stimuli. Understanding the impact of the sound environment on the developing auditory system is an important first step in meeting the developmental demands of preterm newborns undergoing intensive care.","author":[{"family":"Lahav","given":"Amir"},{"family":"Skoe","given":"Erika"}],"citation-key":"lahavAcousticGapNICU2014","container-title":"Frontiers In Neuroscience","container-title-short":"Frontiers In Neuroscience","DOI":"10.3389/fnins.2014.00381","issued":{"date-parts":[["2014",12,5]]},"page":"1 - 8","title":"An Acoustic Gap Between the NICU and Womb: A Potential Risk for Compromised Neuroplasticity of the Auditory System in Preterm Infants","type":"article-journal","volume":"8"},{"id":"lahusenOskarSchlemmerMechanical1986","accessed":{"date-parts":[["2023",2,28]]},"author":[{"family":"Lahusen","given":"Susanne"}],"citation-key":"lahusenOskarSchlemmerMechanical1986","container-title":"Dance Research","container-title-short":"Dance Research","DOI":"10.2307/1290727","ISSN":"0264-2875","issue":"2","issued":{"date-parts":[["1986",10,1]]},"page":"65-77","publisher":"Edinburgh University Press","title":"Oskar Schlemmer: Mechanical Ballets?","type":"article-journal","URL":"https://www.euppublishing.com/doi/abs/10.2307/1290727","volume":"4"},{"id":"lakoffMetaphorsWeLive2003","author":[{"family":"Lakoff","given":"George"},{"family":"Johnson","given":"Mark"}],"call-number":"P106 .L235 2003","citation-key":"lakoffMetaphorsWeLive2003","event-place":"Chicago","ISBN":"978-0-226-46801-3","issued":{"date-parts":[["2003"]]},"number-of-pages":"276","publisher":"University of Chicago Press","publisher-place":"Chicago","source":"Library of Congress ISBN","title":"Metaphors We Live By","type":"book"},{"id":"lakoffMetaphorsWeLive2003a","author":[{"family":"Lakoff","given":"George"},{"family":"Johnson","given":"Mark"}],"call-number":"P106 .L235 2003","citation-key":"lakoffMetaphorsWeLive2003a","event-place":"Chicago","ISBN":"978-0-226-46801-3","issued":{"date-parts":[["2003"]]},"number-of-pages":"276","publisher":"University of Chicago Press","publisher-place":"Chicago","source":"Library of Congress ISBN","title":"Metaphors We Live By","type":"book"},{"id":"lakoffWomenFireDangerous2012","author":[{"family":"Lakoff","given":"George"}],"citation-key":"lakoffWomenFireDangerous2012","edition":"paperback ed., [Nachdr.]","event-place":"Chicago","ISBN":"978-0-226-46804-4","issued":{"date-parts":[["2012"]]},"language":"eng","note":"OCLC: 935630820","number-of-pages":"614","publisher":"The Univ. of Chicago Press","publisher-place":"Chicago","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"Women, Fire, and Dangerous Things: What Categories Reveal About the Mind","title-short":"Women, fire, and dangerous things","type":"book"},{"id":"lancioniAssistiveTechnologyInterventions2013","author":[{"family":"Lancioni","given":"Giulio E"}],"citation-key":"lancioniAssistiveTechnologyInterventions2013","ISBN":"978-1-4899-9579-7","issued":{"date-parts":[["2013"]]},"language":"English","note":"OCLC: 1040565390","source":"Open WorldCat","title":"Assistive Technology: Interventions for Individuals with Severe/Profound and Multiple Disabilities","title-short":"Assistive technology","type":"book"},{"id":"landryParticipatoryDesignResearch2017","abstract":"Given that embodied interaction is widespread in Human-Computer Interaction, interests on the importance of body movements and emotions are gradually increasing. The present paper describes our process of designing and testing a dancer sonification system using a participatory design research methodology. The end goal of the dancer sonification project is to have dancers generate aesthetically pleasing music in real-time based on their dance gestures, instead of dancing to prerecorded music. The generated music should reflect both the kinetic activities and affective contents of the dancer’s movement. To accomplish these goals, expert dancers and musicians were recruited as domain experts in affective gesture and auditory communication. Much of the dancer sonification literature focuses exclusively on describing the final performance piece or the techniques used to process motion data into auditory control parameters. This paper focuses on the methods we used to identify, select, and test the most appropriate motion to sound mappings for a dancer sonification system.","accessed":{"date-parts":[["2023",11,13]]},"author":[{"family":"Landry","given":"Steven"},{"family":"Jeon","given":"Myounghoon"}],"citation-key":"landryParticipatoryDesignResearch2017","container-title":"Proceedings of the 23rd International Conference on Auditory Display - ICAD 2017","DOI":"10.21785/icad2017.069","event-place":"University Park Campus","event-title":"The 23rd International Conference on Auditory Display","ISBN":"978-0-9670904-4-3","issued":{"date-parts":[["2017",6]]},"language":"en","page":"182-187","publisher":"The International Community for Auditory Display","publisher-place":"University Park Campus","source":"DOI.org (Crossref)","title":"Participatory Design Research Methodologies: A Case Study in Dancer Sonification","title-short":"Participatory Design Research Methodologies","type":"paper-conference","URL":"http://hdl.handle.net/1853/58379"},{"id":"laneDeafExperienceClassics1984","call-number":"HV2736 .D43 1984","citation-key":"laneDeafExperienceClassics1984","editor":[{"family":"Lane","given":"Harlan L."}],"event-place":"Cambridge, Mass","ISBN":"978-0-674-19460-1","issued":{"date-parts":[["1984"]]},"language":"engfre","number-of-pages":"221","publisher":"Harvard University Press","publisher-place":"Cambridge, Mass","source":"Library of Congress ISBN","title":"The Deaf experience: classics in language and education","title-short":"The Deaf experience","type":"book"},{"id":"laneDeafExperienceClassics2006","call-number":"HV2736 .D43 2006","citation-key":"laneDeafExperienceClassics2006","collection-title":"Gallaudet classics in deaf studies","editor":[{"family":"Lane","given":"Harlan L."},{"family":"Philip","given":"Franklin"}],"event-place":"Washington, D.C","ISBN":"978-1-56368-286-5","issued":{"date-parts":[["2006"]]},"language":"eng","note":"OCLC: ocm63117058","number-of-pages":"221","publisher":"Gallaudet University Press","publisher-place":"Washington, D.C","source":"Library of Congress ISBN","title":"The Deaf Experience: Classics in Language and Education","title-short":"The deaf experience","type":"book"},{"id":"lanePeopleEyeDeaf2011","author":[{"family":"Lane","given":"Harlan"},{"family":"Pillard","given":"Richard"},{"family":"Hedberg","given":"Ulf"}],"call-number":"HV2530 .L36 2011","citation-key":"lanePeopleEyeDeaf2011","event-place":"New York","ISBN":"978-0-19-975929-3","issued":{"date-parts":[["2011"]]},"note":"OCLC: ocn643763052","number-of-pages":"269","publisher":"Oxford University Press","publisher-place":"New York","source":"Library of Congress ISBN","title":"The People of the Eye: Deaf Ethnicity and Ancestry","title-short":"The people of the eye","type":"book"},{"id":"lanePierreDesloges1984","call-number":"HV2736 .D43 2006","citation-key":"lanePierreDesloges1984","collection-title":"Gallaudet Classics in Deaf Studies","container-title":"The Deaf Experience: Classics in Language and Education","editor":[{"family":"Lane","given":"Harlan"}],"event-place":"Cam bridge, Massachusetts and London, England","ISBN":"0-674-19460-8","issued":{"date-parts":[["1984"]]},"language":"eng","note":"OCLC: ocm63117058","page":"28 - 48","publisher":"Harvard University Press","publisher-place":"Cam bridge, Massachusetts and London, England","source":"Library of Congress ISBN","title":"Pierre Desloges","translator":[{"family":"Philip","given":"Franklin"}],"type":"chapter"},{"id":"laneWhenMindHears1989","author":[{"family":"Lane","given":"Harlan"}],"call-number":"HV2367 .L36 1989","citation-key":"laneWhenMindHears1989","edition":"1st Vintage Books ed","event-place":"New York","ISBN":"978-0-679-72023-2","issued":{"date-parts":[["1989"]]},"number-of-pages":"537","publisher":"Vintage Books","publisher-place":"New York","source":"Library of Congress ISBN","title":"When the Mind Hears: A History of the Deaf","title-short":"When the mind hears","type":"book"},{"id":"larbouletteAmTreeEmbodiment2016","abstract":"Expressive representation of human movement has given rise to various static or dynamic artistic creations, whether they take into account specific postures or motion sequences. In this paper we are interested in the expressive qualities of motion and how these qualities influence the evolution of a 3D simulated system. The embodiment of this system takes the form of a non-anthropomorphic structure (non-human appearance) whose behavior expresses the emotional content of the original human motion. Expressive descriptors are extracted from a sequence of theatrical movements executed with different emotional states and used to dynamically control a mass-spring system coupled to a particle system as well as its rendering. The framework allows for the exploration of different sets of motion descriptors and mappings to the parameters of the 3D simulation. The resulting animations are discussed and evaluated through perceptual studies.","author":[{"family":"Larboulette","given":"Caroline"},{"family":"Gibet","given":"Sylvie"}],"citation-key":"larbouletteAmTreeEmbodiment2016","collection-title":"MOCO '16","container-title":"Proceedings of the 3rd international symposium on movement and computing","DOI":"10.1145/2948910.2948939","event-place":"Thessaloniki, GA, Greece","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Thessaloniki, GA, Greece","title":"I am a tree: Embodiment using physically based animation driven by expressive descriptors of motion","type":"paper-conference","URL":"https://doi.org/10.1145/2948910.2948939"},{"id":"larbouletteReviewComputableExpressive2015","abstract":"In this paper we present a review of computable descriptors of human motion. We first present low-level descriptors that compute quantities directly from the raw motion data. We then present higher level descriptors that use low-level ones to compute boolean, single value or continuous quantities that can be interpreted, automatically or manually, to qualify the meaning, style or expressiveness of a motion. We provide formulas inspired from the state of the art that can be applied to 3D motion capture data.","author":[{"family":"Larboulette","given":"Caroline"},{"family":"Gibet","given":"Sylvie"}],"citation-key":"larbouletteReviewComputableExpressive2015","collection-title":"MOCO '15","container-title":"Proceedings of the 2nd international workshop on movement and computing","DOI":"10.1145/2790994.2790998","event-place":"Vancouver, British Columbia, Canada","ISBN":"978-1-4503-3457-0","issued":{"date-parts":[["2015"]]},"number-of-pages":"8","page":"21–28","publisher":"Association for Computing Machinery","publisher-place":"Vancouver, British Columbia, Canada","title":"A review of computable expressive descriptors of human motion","type":"paper-conference","URL":"https://doi.org/10.1145/2790994.2790998"},{"id":"larsonMusicalForcesMotion2012","author":[{"family":"Larson","given":"Steve"}],"call-number":"ML3820 .L36 2012","citation-key":"larsonMusicalForcesMotion2012","collection-title":"Musical meaning & interpretation","event-place":"Bloomington","ISBN":"978-0-253-35682-6 978-0-253-00549-6","issued":{"date-parts":[["2012"]]},"note":"OCLC: ocn707212791","number-of-pages":"369","publisher":"Indiana University Press","publisher-place":"Bloomington","source":"Library of Congress ISBN","title":"Musical Forces: Motion, Metaphor, and Meaning in Music","title-short":"Musical forces","type":"book"},{"id":"lartillotDatasetNorwegianHardanger2023","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Lartillot","given":"Olivier"},{"family":"Johansson","given":"Mats Sigvard"},{"family":"Elowsson","given":"Anders"},{"family":"Monstad","given":"Lars Løberg"},{"family":"Cyvin","given":"Mattias"}],"citation-key":"lartillotDatasetNorwegianHardanger2023","container-title":"Transactions of the International Society for Music Information Retrieval","DOI":"10.5334/tismir.139","ISSN":"2514-3298","issue":"1","issued":{"date-parts":[["2023",12,13]]},"language":"en","page":"186-202","source":"DOI.org (Crossref)","title":"A Dataset of Norwegian Hardanger Fiddle Recordings with Precise Annotation of Note and Beat Onsets","type":"article-journal","URL":"https://transactions.ismir.net/articles/10.5334/tismir.139/","volume":"6"},{"id":"lartillotMatlabToolboxMusical2007","author":[{"family":"Lartillot","given":"Olivier"},{"family":"Toiviainen","given":"Petri"}],"citation-key":"lartillotMatlabToolboxMusical2007","container-title":"International conference on digital audio effects","issued":{"date-parts":[["2007"]]},"page":"244","title":"A Matlab toolbox for musical feature extraction from audio","type":"paper-conference","volume":"237"},{"id":"lathamOxfordCompanionMusic2002","call-number":"ML100 .S37 2002","citation-key":"lathamOxfordCompanionMusic2002","editor":[{"family":"Latham","given":"Alison"}],"event-place":"Oxford ; New York","ISBN":"978-0-19-866212-9","issued":{"date-parts":[["2002"]]},"note":"OCLC: ocm48532638","number-of-pages":"1434","publisher":"Oxford University Press","publisher-place":"Oxford ; New York","source":"Library of Congress ISBN","title":"The Oxford Companion to Music","type":"book"},{"id":"latourReassemblingSocialIntroduction2007","author":[{"family":"Latour","given":"Bruno"}],"citation-key":"latourReassemblingSocialIntroduction2007","collection-title":"Clarendon lectures in management studies","edition":"1. publ. in pbk","event-place":"Oxford","ISBN":"978-0-19-925605-1 978-0-19-925604-4","issued":{"date-parts":[["2007"]]},"language":"eng","number-of-pages":"301","publisher":"Oxford Univ. Press","publisher-place":"Oxford","source":"K10plus ISBN","title":"Reassembling the social: an introduction to Actor-Network-Theory","title-short":"Reassembling the social","type":"book"},{"id":"launerHearingAidSignal2016","abstract":"This volume will serve as the first Handbook of its kind in the area of hearing aid research, often the least-defined, least-understood, part of the multi-disciplinary research process. Most scientific training is very advanced within the particular disciplines but provides little opportunity for systematic introduction to the issues and obstacles that prevent effective hearing-aid related research. This area has emerged as one of critical importance, as signified by a single specialized meeting (the International Hearing Aid Conference, IHCON) that brings together specialists from the disparate disciplines involved, including both university and industry researchers. Identification of the key steps that enable high-impact basic science to ultimately result in significant clinical advances that improve patient outcome is critical. This volume will provide an overview of current key issues in hearing aid research from the perspective of many different disciplines, not only from the perspective of the key funding agencies, but also from the scientists and clinicians who are currently involved in hearing aid research. It will offer insight into the experience, current technology and future technology that can help improve hearing aids, as scientists and clinicians typically have little or no formal training over the whole range of the individual disciplines that are relevant. The selection and coverage of topics insures that it will have lasting impact, well beyond immediate, short-term, or parochial concerns.","accessed":{"date-parts":[["2021",1,20]]},"author":[{"family":"Launer","given":"Stefan"},{"family":"Zakis","given":"Justin A."},{"family":"Moore","given":"Brian C. J."}],"citation-key":"launerHearingAidSignal2016","collection-number":"56","collection-title":"Springer Handbook of Auditory Research","container-title":"Hearing Aids","editor":[{"family":"Popelka","given":"Gerald R."},{"family":"Moore","given":"Brian C. J."},{"family":"Fay","given":"Richard R."},{"family":"Popper","given":"Arthur N."}],"event-place":"Cham","ISBN":"978-3-319-33036-5","issued":{"date-parts":[["2016"]]},"language":"English","note":"OCLC: 984801900","page":"93 - 130","publisher":"Springer International Publishing : Imprint : Springer","publisher-place":"Cham","source":"Open WorldCat","title":"Hearing Aid Signal Processing","type":"chapter","URL":"https://doi.org/10.1007/978-3-319-33036-5"},{"id":"laviersBESSTSystemExplicating2022","abstract":"In order to develop interactive technology that interfaces more and more with humans and their full embodiment, robotics engineers need a means for reasoning about natural and artificial movement that is rooted in human experience. Movement studies – a broad field covering somatics and choreography – can act as a bridge to allow engineers to create technology that interacts with human movement in order to serve societal needs. An interesting, perhaps unanticipated result of this process is that applying movement studies to robotics requires a sharpening of the methodology. Thus, the branch of movement studies initiated by Laban and Bartenieff – sometimes described as Laban/Bartenieff Movement Studies (LBMS) – provides an important tool set for understanding movement patterns in context. This work is organized through four established components: Body, Effort, Shape, and Space (or the BESS System). The observation and movement-based workshop described in this extended abstract will share ideas about temporal patterns in movement, explicated as a new component, Time, establishing the BESST System. This component grows from working with machines, which must deal in user-specified and designed quantitative units of time, as a way to describe motion that is not quite as fluent as human motion. Some machines do not portray clear ideas about intent and relationship from their movement, but it is typically possible to measure the amount of time an action took and frequently phrasing is observed through stops and starts of different machine parts. Thus, while a particular example of artificial movement may not rise to the level of creating a clear dynamic quality, it does use elements collected in this component of Time, e.g., sequencing, duration, tempo, and phrasing. This workshop will offer an experiential inroad to these elements and their use inside of contemporary approaches to robotics.","author":[{"family":"Laviers","given":"Amy"},{"family":"Maguire","given":"Cat"}],"citation-key":"laviersBESSTSystemExplicating2022","collection-title":"MOCO '22","container-title":"Proceedings of the 8th international conference on movement and computing","DOI":"10.1145/3537972.3538023","event-place":"Chicago, IL, USA","ISBN":"978-1-4503-8716-3","issued":{"date-parts":[["2022"]]},"number-of-pages":"3","publisher":"Association for Computing Machinery","publisher-place":"Chicago, IL, USA","title":"The BESST system: Explicating a new component of time in Laban/Bartenieff movement studies through work with robots","type":"paper-conference","URL":"https://doi.org/10.1145/3537972.3538023"},{"id":"lealMusicPerceptionAdult2003","author":[{"family":"Leal","given":"Mariana C."},{"family":"Shin","given":"Young Je"},{"family":"Laborde","given":"Marie-laurence"},{"family":"Calmels","given":"Marie-noëlle"},{"family":"Verges","given":"Sebastien"},{"family":"Lugardon","given":"Stéphanie"},{"family":"Andrieu","given":"Sandrine"},{"family":"Deguine","given":"Olivier"},{"family":"Fraysse","given":"Bernard"}],"citation-key":"lealMusicPerceptionAdult2003","container-title":"Acta Oto-Laryngologica","container-title-short":"Acta Oto-Laryngologica","ISSN":"0001-6489","issue":"7","issued":{"date-parts":[["2003"]]},"page":"826-835","publisher":"Taylor & Francis","title":"Music Perception in Adult Cochlear Implant Recipients","type":"article-journal","volume":"123"},{"id":"leeAnalysisBasicExpressive2015","abstract":"Advances in sensing technology make the task of quantifying expressive human body movement more feasible than ever before. Success will enable breakthroughs in Human-computer interaction (HCI) and control paradigms. In most areas, however, expressivity remains vague and difficult to define. We examine the movements of instrumental conductors at an elementary level to define particular qualities of a beat. In our test case, we focus on the difference between sostenuto and staccato articulation styles as a base for expressive qualities. We show that it is possible to define generic low-level movement features, we call movement primitives, to quantify the qualitative aspects of these two different articulation styles across a range of different tempi. Our movement primitives include the mean and variance of the magnitude of velocity and acceleration, and measures of spatial curvature. Each of these is measured from the ictus of one beat through the ictus of the next beat in a standard 4/4 beat pattern. The discriminative power of these features is demonstrated by two-tail t-tests and verified through Naïve Bayes classification experiments. The results demonstrate that our use of movement primitives effectively describes characteristics of expression revealed in each beat of two different articulation styles.","author":[{"family":"Lee","given":"Kyungho"},{"family":"Junokas","given":"Michael J."},{"family":"Amanzadeh","given":"Mohammad"},{"family":"Garnett","given":"Guy E."}],"citation-key":"leeAnalysisBasicExpressive2015","collection-title":"MOCO '15","container-title":"Proceedings of the 2nd international workshop on movement and computing","DOI":"10.1145/2790994.2791005","event-place":"Vancouver, British Columbia, Canada","ISBN":"978-1-4503-3457-0","issued":{"date-parts":[["2015"]]},"number-of-pages":"8","page":"148–155","publisher":"Association for Computing Machinery","publisher-place":"Vancouver, British Columbia, Canada","title":"An analysis of basic expressive qualities in instrumental conducting","type":"paper-conference","URL":"https://doi.org/10.1145/2790994.2791005"},{"id":"leeGeometricallyCompensatingEffect2019","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Lee","given":"Injung"},{"family":"Kim","given":"Sunjun"},{"family":"Lee","given":"Byungjoo"}],"citation-key":"leeGeometricallyCompensatingEffect2019","container-title":"Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems","DOI":"10.1145/3290605.3300790","event-place":"Glasgow Scotland Uk","event-title":"CHI '19: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-5970-2","issued":{"date-parts":[["2019",5,2]]},"language":"en","page":"1-12","publisher":"ACM","publisher-place":"Glasgow Scotland Uk","source":"DOI.org (Crossref)","title":"Geometrically Compensating Effect of End-to-End Latency in Moving-Target Selection Games","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3290605.3300790"},{"id":"leekEnjoymentMusicElderly2008","author":[{"family":"Leek","given":"Marjorie R"},{"family":"Molis","given":"Michelle R"},{"family":"Kubli","given":"Lina R"},{"family":"Tufts","given":"Jennifer B"}],"citation-key":"leekEnjoymentMusicElderly2008","container-title":"Journal of the American Academy of Audiology","container-title-short":"Journal of the American Academy of Audiology","ISSN":"1050-0545","issue":"6","issued":{"date-parts":[["2008"]]},"page":"519-526","publisher":"American Academy of Audiology","title":"Enjoyment of Music by Elderly Hearing-Impaired Listeners","type":"article-journal","volume":"19"},{"id":"leeLowcost3DMotion2017","abstract":"This paper presents a low-cost 3D motion capture system using a single camera and passive optical markers. 3D motion capture systems usually demand multiple cameras. Thus, those systems require high-cost hardware devices and large computing power. However, such high-cost systems prevent personal or mobile systems using 3D motion capturing. To overcome this problem, we propose a low-cost motion capture system. The structure of our system is based on a single camera and passive optical markers, which enables the system to be low-cost. As the components of the proposed systems, we introduce 2D optical marker recognition, marker size recognition, and mapping for 3D data extraction. To show the effectiveness and efficiency, we conduct preliminary experiments in terms of accuracy and time-complexity. Experiment results indicate that the proposed system provides 3D motion capturing using a single camera enough to utilize it in 3D interaction.","author":[{"family":"Lee","given":"Yeonkyung"},{"family":"Yoo","given":"Hoon"}],"citation-key":"leeLowcost3DMotion2017","container-title":"Optik","container-title-short":"Optik","DOI":"10.1016/j.ijleo.2016.11.174","ISSN":"0030-4026","issued":{"date-parts":[["2017",2,1]]},"page":"1397-1407","title":"Low-cost 3D motion capture system using passive optical markers and monocular vision","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0030402616315108","volume":"130"},{"id":"leHumanPostureRecognition2013","accessed":{"date-parts":[["2024",4,21]]},"author":[{"family":"Le","given":"Thi-Lan"},{"family":"Nguyen","given":"Minh-Quoc"},{"family":"Nguyen","given":"Thi-Thanh-Mai"}],"citation-key":"leHumanPostureRecognition2013","container-title":"2013 International Conference on Computing, Management and Telecommunications (ComManTel)","DOI":"10.1109/ComManTel.2013.6482417","event-place":"Ho Chi Minh City, Vietnam","event-title":"2013 International Conference on Computing, Management and Telecommunications (ComManTel)","ISBN":"978-1-4673-2088-7 978-1-4673-2087-0 978-1-4673-2086-3","issued":{"date-parts":[["2013",1]]},"page":"340-345","publisher":"IEEE","publisher-place":"Ho Chi Minh City, Vietnam","source":"DOI.org (Crossref)","title":"Human posture recognition using human skeleton provided by Kinect","type":"paper-conference","URL":"http://ieeexplore.ieee.org/document/6482417/"},{"id":"lemanEmbodiedMusicCognition2008","author":[{"family":"Leman","given":"Marc"}],"call-number":"ML3800 .L57 2008","citation-key":"lemanEmbodiedMusicCognition2008","event-place":"Cambridge, Mass","ISBN":"978-0-262-12293-1","issued":{"date-parts":[["2008"]]},"note":"OCLC: ocm74915535","number-of-pages":"297","publisher":"MIT Press","publisher-place":"Cambridge, Mass","source":"Library of Congress ISBN","title":"Embodied music cognition and mediation technology","type":"book"},{"id":"lemanWhatEmbodiedMusic2018","accessed":{"date-parts":[["2022",2,16]]},"author":[{"family":"Leman","given":"Marc"},{"family":"Maes","given":"Pieter-Jan"},{"family":"Nijs","given":"Luc"},{"family":"Van Dyck","given":"Edith"}],"citation-key":"lemanWhatEmbodiedMusic2018","container-title":"Springer Handbook of Systematic Musicology","DOI":"10.1007/978-3-662-55004-5_34","editor":[{"family":"Bader","given":"Rolf"}],"event-place":"Berlin, Heidelberg","ISBN":"978-3-662-55002-1 978-3-662-55004-5","issued":{"date-parts":[["2018"]]},"page":"747-760","publisher":"Springer Berlin Heidelberg","publisher-place":"Berlin, Heidelberg","source":"DOI.org (Crossref)","title":"What Is Embodied Music Cognition?","type":"chapter","URL":"http://link.springer.com/10.1007/978-3-662-55004-5_34"},{"id":"lemanWhatEmbodiedMusic2018a","abstract":"Over the past decade, embodied music cognition has become an influential paradigm in music research. The paradigm holds that music cognition is strongly determined by corporeally mediated interactions with music. They determine the way in which music can be conceived in terms of goals, directions, targets, values, and reward. The chapter gives an overview of the ontological and epistemological foundations, and it introduces the core concepts that define the character of the paradigm. This is followed by an overview of some analytical and empirical studies, which illustrate contributions of the embodied music cognition approach to major topics in musical expression, timing, and prediction processing. The chapter gives a viewpoint on a music research paradigm that is in full development, both in view of the in-depth refinement of its foundations, as well as the broadening of its scope and applications.","accessed":{"date-parts":[["2024",12,9]]},"author":[{"family":"Leman","given":"Marc"},{"family":"Maes","given":"Pieter-Jan"},{"family":"Nijs","given":"Luc"},{"family":"Van Dyck","given":"Edith"}],"citation-key":"lemanWhatEmbodiedMusic2018a","container-title":"Springer Handbook of Systematic Musicology","DOI":"10.1007/978-3-662-55004-5_34","editor":[{"family":"Bader","given":"Rolf"}],"event-place":"Berlin, Heidelberg","ISBN":"978-3-662-55004-5","issued":{"date-parts":[["2018"]]},"language":"en","page":"747-760","publisher":"Springer","publisher-place":"Berlin, Heidelberg","source":"Springer Link","title":"What Is Embodied Music Cognition?","type":"chapter","URL":"https://doi.org/10.1007/978-3-662-55004-5_34"},{"id":"lemanWhyStudyMusical2010","author":[{"family":"Leman","given":"Marc"},{"family":"Godøy","given":"Rolf Inge"}],"citation-key":"lemanWhyStudyMusical2010","container-title":"Musical gestures: Sound, movement, and meaning","editor":[{"family":"Godøy","given":"Rolf Inge"},{"family":"Leman","given":"Marc"}],"event-place":"New York","ISBN":"978-0-415-99887-1","issued":{"date-parts":[["2010"]]},"page":"3-11","publisher":"Routledge","publisher-place":"New York","title":"Why study musical gestures?","type":"chapter"},{"id":"lenovoThinkCentreM70qTiny2022","accessed":{"date-parts":[["2022",11,26]]},"author":[{"literal":"Lenovo"}],"citation-key":"lenovoThinkCentreM70qTiny2022","container-title":"Lenovo","issued":{"date-parts":[["2022"]]},"title":"ThinkCentre M70q Tiny","type":"webpage","URL":"https://www.lenovo.com/us/en/p/desktops/thinkcentre/m-series-tiny/thinkcentre-m70q/11dt004gus"},{"id":"lerchMusicPerformanceAnalysis2019","abstract":"Music Information Retrieval (MIR) tends to focus on the analysis of audio signals. Often, a single music recording is used as representative of a \"song\" even though different performances of the same song may reveal different properties. A performance is distinct in many ways from a (arguably more abstract) representation of a \"song,\" \"piece,\" or musical score. The characteristics of the (recorded) performance -- as opposed to the score or musical idea -- can have a major impact on how a listener perceives music. The analysis of music performance, however, has been traditionally only a peripheral topic for the MIR research community. This paper surveys the field of Music Performance Analysis (MPA) from various perspectives, discusses its significance to the field of MIR, and points out opportunities for future research in this field.","accessed":{"date-parts":[["2022",3,7]]},"author":[{"family":"Lerch","given":"Alexander"},{"family":"Arthur","given":"Claire"},{"family":"Pati","given":"Ashis"},{"family":"Gururani","given":"Siddharth"}],"citation-key":"lerchMusicPerformanceAnalysis2019","DOI":"10.48550/ARXIV.1907.00178","issued":{"date-parts":[["2019"]]},"license":"Creative Commons Attribution 4.0 International","publisher":"arXiv","source":"DOI.org (Datacite)","title":"Music Performance Analysis: A Survey","title-short":"Music Performance Analysis","type":"article-journal","URL":"https://arxiv.org/abs/1907.00178","version":"1"},{"id":"lernerSoundingTheorizingDisability2006","call-number":"ML3920 .S728 2006","citation-key":"lernerSoundingTheorizingDisability2006","editor":[{"family":"Lerner","given":"Neil William"},{"family":"Straus","given":"Joseph Nathan"}],"event-place":"New York","ISBN":"978-0-415-97906-1 978-0-415-97907-8","issued":{"date-parts":[["2006"]]},"note":"OCLC: ocm64585773","number-of-pages":"295","publisher":"Routledge","publisher-place":"New York","source":"Library of Congress ISBN","title":"Sounding Off: Theorizing Disability in Music","title-short":"Sounding off","type":"book"},{"id":"levisohnTaggingMovementSomatic2014","abstract":"Movement researchers in HCI have begun to utilize theories from the field of Somatics to support their investigations into tangible, ubiquitous, and wearable computing systems. Despite recent advances in integrating movement theory within HCI, the practice of incorporating the associated Somatic methods and referencing this body-oriented epistemological perspective is often lacking from design ideation and development within movement interaction. The epistemological gap between somatic values and technological models of movement can constrain novel applications of somatic theories and their potential to inform embodied approaches to movement interaction. In this paper we discuss the value of Somatic epistemology and provide a case study exploring the use of movement to tag visual images. We describe a series of movement workshops structured to explore movement tagging of visual images, and illustrate the benefits of bridging Somatic theories and their associated methods to the design of novel movement applications.","author":[{"family":"Levisohn","given":"Aaron"},{"family":"Schiphorst","given":"Thecla"}],"citation-key":"levisohnTaggingMovementSomatic2014","collection-title":"MOCO '14","container-title":"Proceedings of the 2014 international workshop on movement and computing","DOI":"10.1145/2617995.2618003","event-place":"Paris, France","ISBN":"978-1-4503-2814-2","issued":{"date-parts":[["2014"]]},"number-of-pages":"6","page":"43–48","publisher":"Association for Computing Machinery","publisher-place":"Paris, France","title":"Tagging with movement: Somatic strategies for image classification","type":"paper-conference","URL":"https://doi.org/10.1145/2617995.2618003"},{"id":"levitinMusicalAbilitiesIndividuals1998","abstract":"We report evidence for relatively preserved musical rhythm processing in individuals with Williams syndrome, supporting the theory that musical ability constitutes an independent intelligence. Williams syndrome occurs in 1 out of 20,000 births and is associated with a defect in elastin production, impaired cognitive function, and poor spatial, quantitative, and reasoning abilities, coupled with excellent face processing and relatively strong language abilities in adolescents and adults. Previously, informal qualitative observations have revealed an unusual degree of musicality and engagement with musical stimuli in many individuals with Williams syndrome. In the present study, rhythm production was assessed for eight subjects with Williams syndrome and eight subjects in a comparison group by using an echo clapping task. Despite serious deficits in other cognitive domains and generally poor coordination, the subjects with Williams syndrome achieved accuracy scores equivalent to those of subjects in the comparison group and demonstrated equivalent abilities in meter change and beat maintenance. Most interestingly, when the subjects with Williams syndrome made errors in rhythm production, their errors were far more likely than comparison subjects' errors to form rhythmically compatible musical elaborations to the test items; that is, responses of subjects with Williams syndrome, when incorrect, tended to be creative extensions of the reference rhythm.","accessed":{"date-parts":[["2020",9,18]]},"author":[{"family":"Levitin","given":"Daniel J."},{"family":"Bellugi","given":"Ursula"}],"citation-key":"levitinMusicalAbilitiesIndividuals1998","container-title":"Music Perception","DOI":"10.2307/40300863","ISSN":"0730-7829","issue":"4","issued":{"date-parts":[["1998",7,1]]},"language":"en","page":"357-389","source":"DOI.org (Crossref)","title":"Musical Abilities in Individuals with Williams Syndrome","type":"article-journal","URL":"https://online.ucpress.edu/mp/article/15/4/357/62016/Musical-Abilities-in-Individuals-with-Williams","volume":"15"},{"id":"leymariePointbasedMedialnessMovement2014","abstract":"We introduce the idea of using a perception-based medial point description of a biological form (such as a 2D profile of a moving animal) as a basis for movement computing which delivers computational schemes to automatically annotate movement and be capable of producing meaningful qualitative descriptions. We distinguish interior from exterior shape representation. Interior medialness is used to characterise deformations from straightness, corners and necks, while exterior medialness identifies the main concavities and inlands which are useful to verify parts extent and reason about articulation and movement. We define an interior dominant point as a well localised peak value in medialness representation, while an exterior dominant point is evaluated by identifying a region of concavity sub-tended by a minimum angular support. Furthermore, significant convex points are extracted from the object's form to further characterise the elongation of parts. We propose that our evaluated feature points are sufficiently representative, as a basis for shape characterisation, to address many of the goals of movement computing.","author":[{"family":"Leymarie","given":"Frederic Fol"},{"family":"Aparajeya","given":"Prashant"},{"family":"MacGillivray","given":"Carol"}],"citation-key":"leymariePointbasedMedialnessMovement2014","collection-title":"MOCO '14","container-title":"Proceedings of the 2014 international workshop on movement and computing","DOI":"10.1145/2617995.2618001","event-place":"Paris, France","ISBN":"978-1-4503-2814-2","issued":{"date-parts":[["2014"]]},"number-of-pages":"6","page":"31–36","publisher":"Association for Computing Machinery","publisher-place":"Paris, France","title":"Point-based medialness for movement computing","type":"paper-conference","URL":"https://doi.org/10.1145/2617995.2618001"},{"id":"liCVPEComputerVision2023","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Li","given":"Xinyu"},{"family":"Yan","given":"Lixiang"},{"family":"Zhao","given":"Linxuan"},{"family":"Martinez-Maldonado","given":"Roberto"},{"family":"Gasevic","given":"Dragan"}],"citation-key":"liCVPEComputerVision2023","container-title":"LAK23: 13th International Learning Analytics and Knowledge Conference","DOI":"10.1145/3576050.3576145","event-place":"Arlington TX USA","event-title":"LAK 2023: 13th International Learning Analytics and Knowledge Conference","ISBN":"978-1-4503-9865-7","issued":{"date-parts":[["2023",3,13]]},"language":"en","page":"175-185","publisher":"ACM","publisher-place":"Arlington TX USA","source":"DOI.org (Crossref)","title":"CVPE: A Computer Vision Approach for Scalable and Privacy-Preserving Socio-spatial, Multimodal Learning Analytics","title-short":"CVPE","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3576050.3576145"},{"id":"liddellGrammarGestureMeaning2003","author":[{"family":"Liddell","given":"Scott K."}],"call-number":"HV2474 .L53 2003","citation-key":"liddellGrammarGestureMeaning2003","event-place":"Cambridge ; New York","ISBN":"978-0-521-81620-5 978-0-521-01650-6","issued":{"date-parts":[["2003"]]},"number-of-pages":"384","publisher":"Cambridge University Press","publisher-place":"Cambridge ; New York","source":"Library of Congress ISBN","title":"Grammar, gesture, and meaning in American Sign Language","type":"book"},{"id":"ligginsHandbookMultisensorData2009","citation-key":"ligginsHandbookMultisensorData2009","collection-number":"22","collection-title":"The electrical engineering and applied signal processing series","edition":"2nd ed","editor":[{"family":"Liggins","given":"Martin E."},{"family":"Hall","given":"David L."},{"family":"Llinas","given":"James"}],"event-place":"Boca Raton, Fla.","ISBN":"978-1-4200-5308-1","issued":{"date-parts":[["2009"]]},"language":"eng","number-of-pages":"849","publisher":"CRC Press","publisher-place":"Boca Raton, Fla.","source":"K10plus ISBN","title":"Handbook of multisensor data fusion: theory and practice","title-short":"Handbook of multisensor data fusion","type":"book"},{"id":"limbCurrentResearchMusic2012","author":[{"family":"Limb","given":"Charles J."},{"family":"Rubinstein","given":"Jay T."}],"citation-key":"limbCurrentResearchMusic2012","container-title":"Otolaryngologic Clinics of North America","container-title-short":"Otolaryngologic Clinics of North America","ISSN":"0030-6665","issue":"1","issued":{"date-parts":[["2012"]]},"page":"129-140","title":"Current Research on Music Perception in Cochlear Implant Users.","type":"article-journal","volume":"45"},{"id":"limbTechnologicalBiologicalAcoustical2014","author":[{"family":"Limb","given":"Charles J"},{"family":"Roy","given":"Alexis T"}],"citation-key":"limbTechnologicalBiologicalAcoustical2014","container-title":"Hearing research","container-title-short":"Hearing research","ISSN":"0378-5955","issued":{"date-parts":[["2014"]]},"page":"13-26","publisher":"Elsevier","title":"Technological, Biological, and Acoustical Constraints to Music Perception in Cochlear Implant Users","type":"article-journal","volume":"308"},{"id":"limFuzzyHumanMotion2015","abstract":"Human Motion Analysis (HMA) is currently one of the most popularly active research domains as such significant research interests are motivated by a number of real world applications such as video surveillance, sports analysis, healthcare monitoring and so on. However, most of these real world applications face high levels of uncertainties that can affect the operations of such applications. Hence, the fuzzy set theory has been applied and showed great success in the recent past. In this paper, we aim at reviewing the fuzzy set oriented approaches for HMA, individuating how the fuzzy set may improve the HMA, envisaging and delineating the future perspectives. To the best of our knowledge, there is not found a single survey in the current literature that has discussed and reviewed fuzzy approaches towards the HMA. For ease of understanding, we conceptually classify the human motion into three broad levels: Low-Level (LoL), Mid-Level (MiL), and High-Level (HiL) HMA.","author":[{"family":"Lim","given":"Chern Hong"},{"family":"Vats","given":"Ekta"},{"family":"Chan","given":"Chee Seng"}],"citation-key":"limFuzzyHumanMotion2015","container-title":"Pattern Recognition","container-title-short":"Pattern Recognition","DOI":"10.1016/j.patcog.2014.11.016","ISSN":"0031-3203","issue":"5","issued":{"date-parts":[["2015",5,1]]},"page":"1773-1796","title":"Fuzzy human motion analysis: A review","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0031320314004865","volume":"48"},{"id":"linkWorkReproductionMechanical2001","accessed":{"date-parts":[["2020",9,30]]},"archive":"JSTOR","author":[{"family":"Link","given":"Stan"}],"citation-key":"linkWorkReproductionMechanical2001","container-title":"Computer Music Journal","ISSN":"01489267, 15315169","issue":"1","issued":{"date-parts":[["2001"]]},"page":"34-47","publisher":"The MIT Press","title":"The Work of Reproduction in the Mechanical Aging of an Art: Listening to Noise","type":"article-journal","URL":"http://www.jstor.org/stable/3681633","volume":"25"},{"id":"liNovelTopicModel2013","abstract":"Automatic term extraction (ATE) aims at extracting domain-specific terms from a corpus of a certain domain. Termhood is one essential measure for judging whether a phrase is a term. Previous researches on termhood mainly depend on the word frequency information. In this paper, we propose to compute termhood based on semantic representation of words. A novel topic model, namely i-SWB, is developed to map the domain corpus into a latent semantic space, which is composed of some general topics, a background topic and a documents-specific topic. Experiments on four domains demonstrate that our approach outperforms the state-of-the-art ATE approaches.","author":[{"family":"Li","given":"Sujian"},{"family":"Li","given":"Jiwei"},{"family":"Song","given":"Tao"},{"family":"Li","given":"Wenjie"},{"family":"Chang","given":"Baobao"}],"citation-key":"liNovelTopicModel2013","collection-title":"Sigir '13","container-title":"Proceedings of the 36th international ACM SIGIR conference on research and development in information retrieval","DOI":"10.1145/2484028.2484106","event-place":"Dublin, Ireland","ISBN":"978-1-4503-2034-4","issued":{"date-parts":[["2013"]]},"number-of-pages":"4","page":"885–888","publisher":"Association for Computing Machinery","publisher-place":"Dublin, Ireland","title":"A novel topic model for automatic term extraction","type":"paper-conference","URL":"https://doi.org/10.1145/2484028.2484106"},{"id":"lintonClaimingDisabilityKnowledge1998","author":[{"family":"Linton","given":"Simi"}],"call-number":"HV1568.2 .L55 1998","citation-key":"lintonClaimingDisabilityKnowledge1998","collection-title":"Cultural front","event-place":"New York","ISBN":"978-0-8147-5133-6 978-0-8147-5134-3","issued":{"date-parts":[["1998"]]},"number-of-pages":"203","publisher":"New York University Press","publisher-place":"New York","source":"Library of Congress ISBN","title":"Claiming Disability: Knowledge and Identity","title-short":"Claiming disability","type":"book"},{"id":"linUntanglingDebateEthics2008","abstract":"Human enhancement, in which nanotechnology is expected to play a major role, continues to be a highly contentious ethical debate, with experts on both sides calling it the single most important issue facing science and society in this brave, new century. This paper is a broad introduction to the symposium herein that explores a range of perspectives related to that debate. We will discuss what human enhancement is and its apparent contrast to therapy; and we will begin to tease apart the myriad intertwined issues that arise in the debate: (1) freedom & autonomy, (2) health & safety, (3) fairness & equity, (4) societal disruption, and (5) human dignity.","author":[{"family":"Lin","given":"Patrick"},{"family":"Allhoff","given":"Fritz"}],"citation-key":"linUntanglingDebateEthics2008","container-title":"NanoEthics","container-title-short":"NanoEthics","DOI":"10.1007/s11569-008-0046-7","ISSN":"1871-4765","issue":"3","issued":{"date-parts":[["2008",11,18]]},"page":"251","title":"Untangling the Debate: The Ethics of Human Enhancement","type":"article-journal","URL":"https://doi.org/10.1007/s11569-008-0046-7","volume":"2"},{"id":"liontirisLowFrequencyFeedback2018","abstract":"This paper illustrates the development of a Feedback Resonating Double Bass. The instrument is essentially the augmentation of an acoustic double bass using positive feedback. The research aimed to reply the question of how to augment and convert a double bass into a feedback resonating one without following an invasive method. The conversion process illustrated here is applicable and adaptable to double basses of any size, without making irreversible alterations to the instruments.","accessed":{"date-parts":[["2023",1,15]]},"author":[{"family":"Liontiris","given":"Thanos Polymeneas"}],"citation-key":"liontirisLowFrequencyFeedback2018","DOI":"10.5281/ZENODO.1302605","issued":{"date-parts":[["2018",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"Low Frequency Feedback Drones: A Non-Invasive Augmentation Of The Double Bass","title-short":"Low Frequency Feedback Drones","type":"article-journal","URL":"https://zenodo.org/record/1302605"},{"id":"listmanJustWayYou2011","accessed":{"date-parts":[["2021",1,10]]},"author":[{"family":"Listman","given":"Jason"}],"citation-key":"listmanJustWayYou2011","container-title":"YouTube","issued":{"date-parts":[["2011",2,15]]},"title":"just the way you are - bruno mars (in ASL)","type":"webpage","URL":"https://www.youtube.com/watch?v=9vrboKNjpMk"},{"id":"liTechniquesApproachesStatic2016","abstract":"In this paper we present a state of the art of the current approaches to visualization of motion capture data. We discuss the data representation, pre-processing techniques, and the design of existing tools and systems. Next we outline the advantages and disadvantages of the systems, some of which are explicitly noted by the original authors. Lastly we conclude with an overall summary and future directions.","author":[{"family":"Li","given":"William"},{"family":"Bartram","given":"Lyn"},{"family":"Pasquier","given":"Philippe"}],"citation-key":"liTechniquesApproachesStatic2016","collection-title":"MOCO '16","container-title":"Proceedings of the 3rd international symposium on movement and computing","DOI":"10.1145/2948910.2948935","event-place":"Thessaloniki, GA, Greece","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Thessaloniki, GA, Greece","title":"Techniques and approaches in static visualization of motion capture data","type":"paper-conference","URL":"https://doi.org/10.1145/2948910.2948935"},{"id":"liuDataLevelFusionModel2013","accessed":{"date-parts":[["2024",8,24]]},"author":[{"family":"Liu","given":"Kaibo"},{"family":"Gebraeel","given":"Nagi Z."},{"family":"Shi","given":"Jianjun"}],"citation-key":"liuDataLevelFusionModel2013","container-title":"IEEE Transactions on Automation Science and Engineering","container-title-short":"IEEE Trans. Automat. Sci. Eng.","DOI":"10.1109/TASE.2013.2250282","ISSN":"1545-5955, 1558-3783","issue":"3","issued":{"date-parts":[["2013",7]]},"license":"https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html","page":"652-664","source":"DOI.org (Crossref)","title":"A Data-Level Fusion Model for Developing Composite Health Indices for Degradation Modeling and Prognostic Analysis","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/6496166/","volume":"10"},{"id":"liuImpactLatencyNavigation2022","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Liu","given":"Shengmei"},{"family":"Claypool","given":"Mark"}],"citation-key":"liuImpactLatencyNavigation2022","container-title":"CHI Conference on Human Factors in Computing Systems","DOI":"10.1145/3491102.3517660","event-place":"New Orleans LA USA","event-title":"CHI '22: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-9157-3","issued":{"date-parts":[["2022",4,27]]},"language":"en","page":"1-11","publisher":"ACM","publisher-place":"New Orleans LA USA","source":"DOI.org (Crossref)","title":"The Impact of Latency on Navigation in a First-Person Perspective Game","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3491102.3517660"},{"id":"liuLearningMovementHumancomputer2019","abstract":"Computers that are able to collaboratively improvise movement with humans could have an impact on a variety of application domains, ranging from improving procedural animation in game environments to fostering human-computer co-creativity. Enabling real-time movement improvisation requires equipping computers with strategies for learning and understanding movement. Most existing research focuses on gesture classification, which does not facilitate the learning of new gestures, thereby limiting the creative capacity of computers. In this paper, we explore how to develop a gesture clustering pipeline that facilitates reasoning about arbitrary novel movements in real-time. We describe the implementation of this pipeline within the context of LuminAI, a system in which humans can collaboratively improvise movements together with an AI agent. A preliminary evaluation indicates that our pipeline is capable of efficiently clustering similar gestures together, but further work is necessary to fully assess the pipeline's ability to meaningfully cluster complex movements.","author":[{"family":"Liu","given":"Lucas"},{"family":"Long","given":"Duri"},{"family":"Gujrania","given":"Swar"},{"family":"Magerko","given":"Brian"}],"citation-key":"liuLearningMovementHumancomputer2019","collection-title":"MOCO '19","container-title":"Proceedings of the 6th international conference on movement and computing","DOI":"10.1145/3347122.3347127","event-place":"Tempe, AZ, USA","ISBN":"978-1-4503-7654-9","issued":{"date-parts":[["2019"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Tempe, AZ, USA","title":"Learning movement through human-computer co-creative improvisation","type":"paper-conference","URL":"https://doi.org/10.1145/3347122.3347127"},{"id":"liuLowerBetterEffects2021","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Liu","given":"Shengmei"},{"family":"Claypool","given":"Mark"},{"family":"Kuwahara","given":"Atsuo"},{"family":"Sherman","given":"Jamie"},{"family":"Scovell","given":"James J"}],"citation-key":"liuLowerBetterEffects2021","container-title":"Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems","DOI":"10.1145/3411764.3445245","event-place":"Yokohama Japan","event-title":"CHI '21: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-8096-6","issued":{"date-parts":[["2021",5,6]]},"language":"en","page":"1-12","publisher":"ACM","publisher-place":"Yokohama Japan","source":"DOI.org (Crossref)","title":"Lower is Better? The Effects of Local Latencies on Competitive First-Person Shooter Game Players","title-short":"Lower is Better?","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3411764.3445245"},{"id":"liuNTURGB+D1202020","accessed":{"date-parts":[["2024",10,25]]},"author":[{"family":"Liu","given":"Jun"},{"family":"Shahroudy","given":"Amir"},{"family":"Perez","given":"Mauricio"},{"family":"Wang","given":"Gang"},{"family":"Duan","given":"Ling-Yu"},{"family":"Kot","given":"Alex C."}],"citation-key":"liuNTURGB+D1202020","container-title":"IEEE Transactions on Pattern Analysis and Machine Intelligence","container-title-short":"IEEE Trans. Pattern Anal. Mach. Intell.","DOI":"10.1109/TPAMI.2019.2916873","ISSN":"0162-8828, 2160-9292, 1939-3539","issue":"10","issued":{"date-parts":[["2020",10,1]]},"license":"https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html","page":"2684-2701","source":"DOI.org (Crossref)","title":"NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding","title-short":"NTU RGB+D 120","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/8713892/","volume":"42"},{"id":"liuSurveyHumanPose2015","abstract":"Estimating human pose from videos and image sequences is not only an important computer vision problem, but also plays very critical role in many real-world applications. Main challenges for human pose estimation are variation of body poses, complicated background and depth ambiguities. To solve these problems, considerable research efforts have been devoted to the related fields. In this survey, we focus our attention on the recent advances in vision-based human pose estimation. We first present a general framework of human pose estimation, and then go through the latest technical progress on each stage. Finally, we discuss the limitations of the existing approaches and foresee the future directions to be explored.","author":[{"family":"Liu","given":"Zhao"},{"family":"Zhu","given":"Jianke"},{"family":"Bu","given":"Jiajun"},{"family":"Chen","given":"Chun"}],"citation-key":"liuSurveyHumanPose2015","container-title":"Journal of Visual Communication and Image Representation","container-title-short":"Journal of Visual Communication and Image Representation","DOI":"10.1016/j.jvcir.2015.06.013","ISSN":"1047-3203","issued":{"date-parts":[["2015",10,1]]},"page":"10-19","title":"A survey of human pose estimation: The body parts parsing based methods","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S1047320315001121","volume":"32"},{"id":"lockyerExtendingComputationalModels2015","abstract":"The affectively rich expressive capacity of movement and motion is well established in art, performance, animation and visualization but research in perception, cognitive and social psychology provides only limited insight into the visual features that underpin this richness, and artistic principles are not amenable to computational modeling. Recent research has shown the communicative potential of simple abstract motions, absent of figure, to convey affect [23] based on a limited algorithmic model manipulating basic motion dimensions such as shape, speed and direction. Evidence suggests that descriptive frameworks of human movement expression, such as Laban Movement Analysis (LMA), are effective analytical tools with established principles and models; yet the benefits and challenges of incorporating these concepts into larger frameworks of motion and animation has not been rigorously explored. We present a computational model and prototype implementation that incorporates LMA core concepts and principles with established motion algorithms such that users can represent and explore LMA concepts using abstract motions. The model is the outcome of an indepth qualitative study with Certified Movement Analysts (CMAs) exploring, creating and analyzing the potential of low-level animation features to communicate expressive qualities of movement. A more comprehensive design space includes both new parameters for manipulation and a synthesis of lower-level dimensions into the more semantic concepts of Laban principles. In this paper, we discuss the evolution of the model to incorporate these principles of human movement, next steps, and relate the potential applicability of this research to applications in art, visualization and cognition.","author":[{"family":"Lockyer","given":"Matt"},{"family":"Bartram","given":"Lyn"},{"family":"Schiphorst","given":"Thecla"},{"family":"Studd","given":"Karen"}],"citation-key":"lockyerExtendingComputationalModels2015","collection-title":"MOCO '15","container-title":"Proceedings of the 2nd international workshop on movement and computing","DOI":"10.1145/2790994.2791008","event-place":"Vancouver, British Columbia, Canada","ISBN":"978-1-4503-3457-0","issued":{"date-parts":[["2015"]]},"number-of-pages":"8","page":"92–99","publisher":"Association for Computing Machinery","publisher-place":"Vancouver, British Columbia, Canada","title":"Extending computational models of abstract motion with movement qualities","type":"paper-conference","URL":"https://doi.org/10.1145/2790994.2791008"},{"id":"loebLetterEditor1993","author":[{"family":"Loeb","given":"Gerald"}],"citation-key":"loebLetterEditor1993","container-title":"Atlantic Monthly","edition":"December","issued":{"date-parts":[["1993",12]]},"title":"Letter to the Editor","type":"article-newspaper"},{"id":"loizouMimickingHumanEar1998","accessed":{"date-parts":[["2021",1,21]]},"author":[{"family":"Loizou","given":"P.C."}],"citation-key":"loizouMimickingHumanEar1998","container-title":"IEEE Signal Processing Magazine","container-title-short":"IEEE Signal Process. Mag.","DOI":"10.1109/79.708543","ISSN":"10535888","issue":"5","issued":{"date-parts":[["1998",9]]},"page":"101-130","source":"DOI.org (Crossref)","title":"Mimicking The Human Ear","type":"article-journal","URL":"http://ieeexplore.ieee.org/document/708543/","volume":"15"},{"id":"lokePerformermachineScoresChoreographing2015","abstract":"Recent advances in digital fabrication and computationally controlled environments have produced new forms of performative architecture that exhibit dynamic kinetic behaviours in physical space and time. This opens up the design process to choreographic thinking, in which patterns, compositions and dynamic qualities of movement are defined across heterogeneous elements of bodies, kinetic materials, spatial structures and software code. The generation of choreographic tools for exploring and notating movement in the design process poses the problem of representation and language translation across disciplines. Our contribution lies in a new tool to extend an existing design methodology. We propose the use of a performer-machine score, a choreographic tool which can be used in conjunction with many other choreographic and design tools, such as spatial diagrams and computer-aided design models and simulations, to aid the iterative creative process of designing the movement-based interaction, performance and behaviour of human performers and computationally controlled kinetic materials.","author":[{"family":"Loke","given":"Lian"},{"family":"Reinhardt","given":"Dagmar"},{"family":"McNeilly","given":"Jodie"}],"citation-key":"lokePerformermachineScoresChoreographing2015","collection-title":"MOCO '15","container-title":"Proceedings of the 2nd international workshop on movement and computing","DOI":"10.1145/2790994.2790999","event-place":"Vancouver, British Columbia, Canada","ISBN":"978-1-4503-3457-0","issued":{"date-parts":[["2015"]]},"number-of-pages":"8","page":"52–59","publisher":"Association for Computing Machinery","publisher-place":"Vancouver, British Columbia, Canada","title":"Performer-machine scores for choreographing bodies, interaction and kinetic materials","type":"paper-conference","URL":"https://doi.org/10.1145/2790994.2790999"},{"id":"longEffectsLocalLatency2019","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Long","given":"Michael"},{"family":"Gutwin","given":"Carl"}],"citation-key":"longEffectsLocalLatency2019","container-title":"Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems","DOI":"10.1145/3290605.3300438","event-place":"Glasgow Scotland Uk","event-title":"CHI '19: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-5970-2","issued":{"date-parts":[["2019",5,2]]},"language":"en","page":"1-12","publisher":"ACM","publisher-place":"Glasgow Scotland Uk","source":"DOI.org (Crossref)","title":"Effects of Local Latency on Game Pointing Devices and Game Pointing Tasks","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3290605.3300438"},{"id":"longoBeethovenNightmareTurn2012","accessed":{"date-parts":[["2021",1,4]]},"author":[{"family":"Longo","given":"Steve"}],"citation-key":"longoBeethovenNightmareTurn2012","container-title":"YouTube","issued":{"date-parts":[["2012",3,8]]},"title":"Beethoven's Nightmare - Turn It Up Louder in Sign Language and captions","type":"webpage","URL":"https://www.youtube.com/watch?v=2WkfI9GH_AI"},{"id":"longVisualizingImprovisationLuminAI2020","abstract":"LuminAI is an art installation in which participants can improvise movements with an AI dance partner. In this practice work, we will present the LuminAI installation as well as two visualization tools that interactively demonstrate how the LuminAI agent reasons about movement using both bottom-up learned knowledge and top-down domain knowledge. Participants will first be invited to interact with the LuminAI installation, where they can improvise movement with an AI agent projected onto a screen. They can then see how LuminAI learns relationships between gestures by interacting with MoViz, a visualization in which participants can explore the agent's gesture memory and qualitatively compare the efficacy of unsupervised learning algorithms at clustering gestures. Finally, participants will be invited to interact with a third tool, where they can explore how LuminAI applies top-down domain knowledge to gesture reasoning. Participants will be able to interactively explore how LuminAI uses Laban Movement Analysis's conception of Space to analyze learned movements in terms of the geometric properties of Laban's icosahedron and manipulate these properties to transform and generate new movements. The two visualization tools both represent novel approaches to understanding and analyzing improvisational movement in creative domains.","author":[{"family":"Long","given":"Duri"},{"family":"Liu","given":"Lucas"},{"family":"Gujrania","given":"Swar"},{"family":"Naomi","given":"Cassandra"},{"family":"Magerko","given":"Brian"}],"citation-key":"longVisualizingImprovisationLuminAI2020","collection-title":"MOCO '20","container-title":"Proceedings of the 7th international conference on movement and computing","DOI":"10.1145/3401956.3404258","event-place":"Jersey City/Virtual, NJ, USA","ISBN":"978-1-4503-7505-4","issued":{"date-parts":[["2020"]]},"number-of-pages":"2","publisher":"Association for Computing Machinery","publisher-place":"Jersey City/Virtual, NJ, USA","title":"Visualizing improvisation in LuminAI, an AI partner for co-creative dance","type":"paper-conference","URL":"https://doi.org/10.1145/3401956.3404258"},{"id":"looiComparisonsQualityRatings2007","author":[{"family":"Looi","given":"Valerie"},{"family":"McDermott","given":"Hugh"},{"family":"McKay","given":"Colette"},{"family":"Hickson","given":"Louise"}],"citation-key":"looiComparisonsQualityRatings2007","container-title":"Ear and hearing","container-title-short":"Ear and hearing","ISSN":"0196-0202","issue":"2","issued":{"date-parts":[["2007"]]},"page":"59S-61S","publisher":"LWW","title":"Comparisons of Quality Ratings for Music by Cochlear Implant and Hearing Aid Users","type":"article-journal","volume":"28"},{"id":"looiEffectCochlearImplantation2008","author":[{"family":"Looi","given":"Valerie"},{"family":"McDermott","given":"Hugh"},{"family":"McKay","given":"Colette"},{"family":"Hickson","given":"Louise"}],"citation-key":"looiEffectCochlearImplantation2008","container-title":"International Journal of Audiology","container-title-short":"International Journal of Audiology","ISSN":"1499-2027","issue":"5","issued":{"date-parts":[["2008"]]},"page":"257-268","publisher":"Taylor & Francis","title":"The Effect of Cochlear Implantation on Music Perception by Adults with Usable Pre-Operative Acoustic Hearing","type":"article-journal","volume":"47"},{"id":"looiMusicAppreciationTraining2012","author":[{"family":"Looi","given":"Valerie"},{"family":"Gfeller","given":"Kate"},{"family":"Driscoll","given":"Virginia"}],"citation-key":"looiMusicAppreciationTraining2012","event-title":"Seminars in hearing","issue":"4","issued":{"date-parts":[["2012"]]},"page":"307","publisher":"NIH Public Access","title":"Music Appreciation and Training for Cochlear Implant Recipients: A Review","type":"paper-conference","volume":"33"},{"id":"looiMusicPerceptionCochlear2008","author":[{"family":"Looi","given":"Valerie"},{"family":"McDermott","given":"Hugh"},{"family":"McKay","given":"Colette"},{"family":"Hickson","given":"Louise"}],"citation-key":"looiMusicPerceptionCochlear2008","container-title":"Ear and hearing","container-title-short":"Ear and hearing","ISSN":"0196-0202","issue":"3","issued":{"date-parts":[["2008"]]},"page":"421-434","publisher":"LWW","title":"Music Perception of Cochlear Implant Users Compared with that of Hearing Aid Users","type":"article-journal","volume":"29"},{"id":"looiPitchDiscriminationMelody2004","author":[{"family":"Looi","given":"Valerie"},{"family":"McDermott","given":"Hugh"},{"family":"McKay","given":"Colette"},{"family":"Hickson","given":"Louise"}],"citation-key":"looiPitchDiscriminationMelody2004","event-title":"International Congress Series","ISBN":"0531-5131","issued":{"date-parts":[["2004"]]},"page":"197-200","publisher":"Elsevier","title":"Pitch Discrimination and Melody Recognition by Cochlear Implant Users","type":"paper-conference","volume":"1273"},{"id":"lossio-venturaCombiningCvalueKeyword2013","author":[{"family":"Lossio-Ventura","given":"Juan Antonio"},{"family":"Jonquet","given":"Clement"},{"family":"Roche","given":"Mathieu"},{"family":"Teisseire","given":"Maguelonne"}],"citation-key":"lossio-venturaCombiningCvalueKeyword2013","container-title":"LBM’2013: International symposium on languages in biology and medicine","event-title":"LBM: languages in biology and medicine","issued":{"date-parts":[["2013"]]},"page":"45-49","title":"Combining c-value and keyword extraction methods for biomedical terms extraction","type":"paper-conference"},{"id":"loudhandsprojectLoudHandsAutistic2012","call-number":"RC553.A88 L68 2012","citation-key":"loudhandsprojectLoudHandsAutistic2012","editor":[{"family":"Loud Hands Project","given":""}],"event-place":"Washington, DC","ISBN":"978-1-938800-02-3","issued":{"date-parts":[["2012"]]},"note":"OCLC: ocn823510362","number-of-pages":"290","publisher":"The Autistic Press","publisher-place":"Washington, DC","source":"Library of Congress ISBN","title":"Loud Hands: Autistic People, Speaking","title-short":"Loud hands","type":"book"},{"id":"louppePoeticsContemporaryDance2010","author":[{"family":"Louppe","given":"Laurence"}],"citation-key":"louppePoeticsContemporaryDance2010","event-place":"Alton","ISBN":"978-1-85273-140-3","issued":{"date-parts":[["2010"]]},"language":"eng","number-of-pages":"285","publisher":"Dance Books","publisher-place":"Alton","source":"K10plus ISBN","title":"Poetics of contemporary dance","type":"book"},{"id":"louppePoetikZeitgenossischenTanzes2015","abstract":"Die »Poetik des zeitgenössischen Tanzes« gilt seit ihrem erstmaligen Erscheinen 1997 als Standardwerk der gegenwärtigen französischsprachigen Tanzforschung. Laurence Louppe verdichtet ästhetische und theoretische Elemente der Annäherung an verschiedene choreographische Entwicklungen des 20. Jahrhunderts. Als Poetik versteht sie ein Denken, das sie über das Aufkommen des zeitgenössischen Tanzes, seine Grundlagen und Lesarten entwickelt hat. Ihre Aktualität gewinnt die Untersuchung, die nun erstmals in deutscher Übersetzung vorliegt, durch den Rückgriff auf die Quellen der verschiedenen Tanzmodernen, die in ihren Fundamenten befragt werden, ebenso wie durch den spezifischen Standpunkt der Autorin, die sich - Beobachterin von und Eingebundene in die Praxis des zeitgenössischen Tanzes - ihrem Gegenstand auf außergewöhnliche Weise nähert","author":[{"family":"Louppe","given":"Laurence"}],"citation-key":"louppePoetikZeitgenossischenTanzes2015","event-place":"Place of publication not identified","ISBN":"978-3-8394-1068-4","issued":{"date-parts":[["2015"]]},"language":"de","note":"OCLC: 937424314","publisher":"Transcript-Verlag","publisher-place":"Place of publication not identified","source":"Open WorldCat","title":"Poetik des zeitgenossischen tanzes","type":"book"},{"id":"loyMusimathicsMathematicalFoundations2011","author":[{"family":"Loy","given":"Gareth"}],"citation-key":"loyMusimathicsMathematicalFoundations2011","edition":"1st MIT Press pbk. ed","event-place":"Cambridge, Mass.","ISBN":"978-0-262-51655-6 978-0-262-12282-5","issued":{"date-parts":[["2011"]]},"language":"eng","note":"OCLC: 935186089","number-of-pages":"482","publisher":"MIT Press","publisher-place":"Cambridge, Mass.","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"Musimathics: The Mathematical Foundations of Music. Vol. 1","title-short":"Musimathics","type":"book"},{"id":"lubetMusicDisabilitySociety2011","author":[{"family":"Lubet","given":"Alex"}],"call-number":"ML3820 .L83 2011","citation-key":"lubetMusicDisabilitySociety2011","event-place":"Philadelphia","ISBN":"978-1-4399-0025-3 978-1-4399-0026-0","issued":{"date-parts":[["2011"]]},"note":"OCLC: ocn610466892","number-of-pages":"199","publisher":"Temple University Press","publisher-place":"Philadelphia","source":"Library of Congress ISBN","title":"Music, Disability, and Society","type":"book"},{"id":"lubetTunesImpairmentEthnomusicology2004","abstract":"\"Tunes of Impairment:  An Ethnomusicology of Disability\" contemplates the theory and methodology of disability studies in music, a sub-field currently in only its earliest phase of development.  The article employs as its test case the field of Western art (\"classical\") music and examines the reasons for the near total exclusion from training and participation in music performance and composition by people with disabilities.  Among the issues around which the case is built are left-handedness as a disability; gender construction in classical music and its interface with disability; canon formation, the classical notion of artistic perfection and its analogy to the flawless (unimpaired) body; and technological and organizational accommodations in music-making present and future.","author":[{"family":"Lubet","given":"Alex"}],"citation-key":"lubetTunesImpairmentEthnomusicology2004","container-title":"Review of Disability Studies","ISSN":"1552-9215","issue":"1","issued":{"date-parts":[["2004",12,29]]},"publisher":"University of Hawaii at Manoa--Center on Disability Studies","title":"Tunes of Impairment: An Ethnomusicology of Disability","type":"article-journal","volume":"1"},{"id":"lucasbravoHumanMachineMusicPerformance2022","author":[{"family":"Lucas Bravo","given":"Pedro Pablo"}],"citation-key":"lucasbravoHumanMachineMusicPerformance2022","event-place":"Oslo","genre":"Master's Thesis","issued":{"date-parts":[["2022"]]},"publisher":"University of Oslo","publisher-place":"Oslo","title":"A Human-Machine Music Performance System based on Autonomous Agents","type":"thesis","URL":"https://www.duo.uio.no/handle/10852/96115"},{"id":"luoActivityBasedPersonIdentification2023","accessed":{"date-parts":[["2024",9,5]]},"author":[{"family":"Luo","given":"Fei"},{"family":"Khan","given":"Salabat"},{"family":"Huang","given":"Yandao"},{"family":"Wu","given":"Kaishun"}],"citation-key":"luoActivityBasedPersonIdentification2023","container-title":"IEEE Internet of Things Journal","container-title-short":"IEEE Internet Things J.","DOI":"10.1109/JIOT.2022.3209084","ISSN":"2327-4662, 2372-2541","issue":"2","issued":{"date-parts":[["2023",1,15]]},"license":"https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html","page":"1711-1723","source":"DOI.org (Crossref)","title":"Activity-Based Person Identification Using Multimodal Wearable Sensor Data","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/9900424/","volume":"10"},{"id":"luoLearningDisentangledRepresentations2019","author":[{"family":"Luo","given":"Yin-Jyun"},{"family":"Agres","given":"Kat"},{"family":"Herremans","given":"Dorien"}],"citation-key":"luoLearningDisentangledRepresentations2019","container-title":"arXiv preprint arXiv:1906.08152","container-title-short":"arXiv preprint arXiv:1906.08152","issued":{"date-parts":[["2019"]]},"title":"Learning disentangled representations of timbre and pitch for musical instrument sounds using gaussian mixture variational autoencoders","type":"article-journal"},{"id":"lysloffMusicTechnoculture2003","call-number":"ML197 .M78 2003","citation-key":"lysloffMusicTechnoculture2003","collection-title":"Music/culture","editor":[{"family":"Lysloff","given":"René T. A."},{"family":"Gay","given":"Leslie C."}],"event-place":"Middletown, Conn","ISBN":"978-0-8195-6513-6 978-0-8195-6514-3","issued":{"date-parts":[["2003"]]},"number-of-pages":"395","publisher":"Wesleyan University Press","publisher-place":"Middletown, Conn","source":"Library of Congress ISBN","title":"Music and Technoculture","type":"book"},{"id":"macionisSociology2011","author":[{"family":"Macionis","given":"John J"},{"family":"Gerber","given":"Linda Marie"}],"citation-key":"macionisSociology2011","event-place":"Toronto","ISBN":"978-0-13-700161-3 978-0-13-800270-1","issued":{"date-parts":[["2011"]]},"language":"English","note":"OCLC: 652430995","publisher":"Pearson Prentice Hall","publisher-place":"Toronto","source":"Open WorldCat","title":"Sociology","type":"book"},{"id":"madsenMusicHearingAids2014","abstract":"The signal processing and fitting methods used for hearing aids have mainly been designed to optimize the intelligibility of speech. Little attention has been paid to the effectiveness of hearing aids for listening to music. Perhaps as a consequence, many hearing-aid users complain that they are not satisfied with their hearing aids when listening to music. This issue inspired the Internet-based survey presented here. The survey was designed to identify the nature and prevalence of problems associated with listening to live and reproduced music with hearing aids. Responses from 523 hearing-aid users to 21 multiple-choice questions are presented and analyzed, and the relationships between responses to questions regarding music and questions concerned with information about the respondents, their hearing aids, and their hearing loss are described. Large proportions of the respondents reported that they found their hearing aids to be helpful for listening to both live and reproduced music, although less so for the former. The survey also identified problems such as distortion, acoustic feedback, insufficient or excessive gain, unbalanced frequency response, and reduced tone quality. The results indicate that the enjoyment of listening to music with hearing aids could be improved by an increase of the input and output dynamic range, extension of the low-frequency response, and improvement of feedback cancellation and automatic gain control systems.","author":[{"family":"Madsen","given":"Sara MK"},{"family":"Moore","given":"Brian C. J."}],"citation-key":"madsenMusicHearingAids2014","container-title":"Trends In Hearing","container-title-short":"Trends In Hearing","ISSN":"2331-2165","issued":{"date-parts":[["2014"]]},"page":"1 - 29","publisher":"SAGE Publications Sage CA: Los Angeles, CA","title":"Music and Hearing Aids","type":"article-journal","volume":"18"},{"id":"maelandMusicalDancersDancing2020","abstract":"[This article shows one way of researching and writing an ethno-choreomusicology. The article advocates for a triangular methodological approach. It is a triangulation between choreomusical analysis of recorded sound and movements, interviews and observations in the field, and the author’s own participatory skills in dancing and socialising in the field as well as her theoretical knowledge thereof. The text takes its departure from an ecstatic social dancing and musical moment with the couple dance pols in the valley Haltdalen, Norway. Two realisations of dancing and playing the pols are analysed and compared. The article demonstrates how working with choreomusicology may place dancing on an equal footing with musicking, and how choreomusical analysis may not only be linked to but shows how the choreomusical co-play creates a collective solidarity.]","accessed":{"date-parts":[["2023",12,21]]},"archive":"JSTOR","author":[{"family":"Mæland","given":"Siri"}],"citation-key":"maelandMusicalDancersDancing2020","container-title":"The World of Music","ISSN":"00438774","issue":"1","issued":{"date-parts":[["2020"]]},"page":"95-116","publisher":"[Florian Noetzel GmbH Verlag, VWB - Verlag für Wissenschaft und Bildung, Bärenreiter, Schott Music GmbH & Co. KG]","title":"Musical Dancers and Dancing Musicians, Who’s in Charge? Choreomusical Analysis of pols Performances in Haltdalen, Norway","type":"article-journal","URL":"https://www-jstor-org.ezproxy.uio.no/stable/26970257","volume":"9"},{"id":"magnussonDesigningConstraintsComposing2010","accessed":{"date-parts":[["2023",3,6]]},"archive":"JSTOR","author":[{"family":"Magnusson","given":"Thor"}],"citation-key":"magnussonDesigningConstraintsComposing2010","container-title":"Computer Music Journal","ISSN":"01489267, 15315169","issue":"4","issued":{"date-parts":[["2010"]]},"page":"62-73","publisher":"The MIT Press","title":"Designing Constraints: Composing and Performing with Digital Musical Systems","type":"article-journal","URL":"http://www.jstor.org/stable/40962941","volume":"34"},{"id":"magnussonReflexionsFeedback2022","accessed":{"date-parts":[["2023",10,11]]},"author":[{"family":"Magnusson","given":"Thor"},{"family":"Kiefer","given":"Chris"},{"family":"Ulfarsson","given":"Halldor"}],"citation-key":"magnussonReflexionsFeedback2022","container-title":"NIME 2022","DOI":"10.21428/92fbeb44.aa7de712","event-place":"The University of Auckland, New Zealand","event-title":"NIME 2022","issued":{"date-parts":[["2022",6,28]]},"publisher":"PubPub","publisher-place":"The University of Auckland, New Zealand","source":"DOI.org (Crossref)","title":"Reflexions upon Feedback","type":"paper-conference","URL":"https://nime.pubpub.org/pub/feedback"},{"id":"maki-patolaLatencyToleranceGesture2004","author":[{"family":"Mäki-patola","given":"Teemu"},{"family":"Hämäläinen","given":"Perttu"}],"citation-key":"maki-patolaLatencyToleranceGesture2004","container-title":"Proc. International Computer Music Conference (ICMC","issued":{"date-parts":[["2004"]]},"page":"1–5","title":"Latency Tolerance for Gesture Controlled Continuous Sound Instrument Without Tactile Feedback","type":"paper-conference"},{"id":"malerMusicalExpressionDeaf2016","author":[{"family":"Maler","given":"Anabel"}],"citation-key":"malerMusicalExpressionDeaf2016","container-title":"The Oxford Handbook of Music and Disability Studies","editor":[{"family":"Howe","given":"Blake"},{"family":"Jensen-Moulton","given":"Stephanie"},{"family":"Lerner","given":"Neil William"},{"family":"Straus","given":"Joseph Nathan"}],"event-place":"Oxford ; New York","ISBN":"978-0-19-933144-4 978-0-19-065060-5","issued":{"date-parts":[["2016"]]},"page":"54 - 72","publisher":"Oxford University Press","publisher-place":"Oxford ; New York","source":"Library of Congress ISBN","title":"Musical Expression among Deaf and Hearing Song Signers","type":"chapter"},{"id":"malerRhythmicTechniquesDeaf2021","abstract":"The art of signed music involves the use of rhythmicized signs from a signed language, such as American Sign Language (ASL), in a musical context. Signed music encompasses a variety of subgenres, including ASL hip hop or “dip hop.” A typical dip hop performance involves a Deaf or hard-of-hearing artist simultaneously performing vocalized and signed rapping over a looped background beat. Although dip hop emerged as a grassroots movement in the early 1990s, it has received little analytical attention in the scholarly literature on hip hop. In this paper, the authors combine techniques adapted from analyzing rhythm in non-signed rap music with techniques adapted from analyzing non-rapped signed music to analyze the rhythmic flow of tracks by dip hop artists Sean Forbes, Wawa, and Signmark. The authors demonstrate that dip hop artists have developed genre-specific rhythmic paradigms and tropes to convey the periodicity and rhyme that are fundamental to rap music. Specifically, we address the alignment of rhythm and meter in signed and vocal rap and the conveyance of a repeated “beat” through rhythmic signing. The analyses of dip hop tracks reveal important differences between dip hop and vocal rap, as well as differences between the conventions of dip hop and ASL poetry.","accessed":{"date-parts":[["2022",5,16]]},"author":[{"family":"Maler","given":"Anabel"},{"family":"Komaniecki","given":"Robert"}],"citation-key":"malerRhythmicTechniquesDeaf2021","container-title":"Music Theory Online","container-title-short":"MTO","DOI":"10.30535/mto.27.1.7","ISSN":"1067-3040","issue":"1","issued":{"date-parts":[["2021",3]]},"language":"en","source":"DOI.org (Crossref)","title":"Rhythmic Techniques in Deaf Hip Hop","type":"article-journal","URL":"https://mtosmt.org/issues/mto.21.27.1/mto.21.27.1.maler.html","volume":"27"},{"id":"malerSongsHandsAnalyzing2013","accessed":{"date-parts":[["2021",1,10]]},"author":[{"family":"Maler","given":"Anabel"}],"citation-key":"malerSongsHandsAnalyzing2013","container-title":"Music Theory Online","container-title-short":"Music Theory Online","issue":"1","issued":{"date-parts":[["2013"]]},"title":"Songs for Hands: Analyzing Interactions of Sign Language and Music","type":"article-journal","URL":"https://mtosmt.org/issues/mto.13.19.1/mto.13.19.1.maler.html","volume":"19"},{"id":"malmstromMoCompToolComparative2016","abstract":"We present MoComp, an interactive visualization tool that allows users to identify and understand differences in motion between two takes of motion capture data. In MoComp, the body part position and motion is visualized focusing on angles of the joints making up each body part. This makes the tool useful for between-take and even between-subject comparison of particular movements since the angle data is independent of the size of the captured subject.","author":[{"family":"Malmstrom","given":"Carl"},{"family":"Zhang","given":"Yaying"},{"family":"Pasquier","given":"Philippe"},{"family":"Schiphorst","given":"Thecla"},{"family":"Bartram","given":"Lyn"}],"citation-key":"malmstromMoCompToolComparative2016","collection-title":"MOCO '16","container-title":"Proceedings of the 3rd international symposium on movement and computing","DOI":"10.1145/2948910.2948932","event-place":"Thessaloniki, GA, Greece","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Thessaloniki, GA, Greece","title":"MoComp: A tool for comparative visualization between takes of motion capture data","type":"paper-conference","URL":"https://doi.org/10.1145/2948910.2948932"},{"id":"manningPoliticsTouchSense2007","author":[{"family":"Manning","given":"Erin"}],"call-number":"JA74.5 .M357 2007","citation-key":"manningPoliticsTouchSense2007","event-place":"Minneapolis","ISBN":"978-0-8166-4844-3 978-0-8166-4845-0","issued":{"date-parts":[["2007"]]},"note":"OCLC: ocm70062929","number-of-pages":"195","publisher":"University of Minnesota Press","publisher-place":"Minneapolis","source":"Library of Congress ISBN","title":"Politics of Touch: Sense, Movement, Sovereignty","title-short":"Politics of touch","type":"book"},{"id":"manningProstheticsMakingSense2006","author":[{"family":"Manning","given":"Erin"}],"citation-key":"manningProstheticsMakingSense2006","container-title":"Fibreculture Journal","container-title-short":"Fibreculture Journal","issued":{"date-parts":[["2006",1,1]]},"title":"Prosthetics Making Sense: Dancing the Technogenetic Body","type":"article-journal","URL":"http://nine.fibreculturejournal.org/fcj-055-prosthetics-making-sense-dancing-the-technogenetic-body/","volume":"9"},{"id":"manzoMaxMSPJitter2016","author":[{"family":"Manzo","given":"V. J."}],"call-number":"ML74.4.M39 M36 2016","citation-key":"manzoMaxMSPJitter2016","edition":"Second edition","event-place":"Oxford ; New York","ISBN":"978-0-19-024374-6 978-0-19-024373-9","issued":{"date-parts":[["2016"]]},"number-of-pages":"407","publisher":"Oxford University Press","publisher-place":"Oxford ; New York","source":"Library of Congress ISBN","title":"Max/MSP/Jitter for Music: A Practical Guide to Developing Interactive Music Systems for Education and More","title-short":"Max/MSP/Jitter for music","type":"book"},{"id":"marshallPhysicalInterfaceDesign2009","author":[{"family":"Marshall","given":"Mark"}],"citation-key":"marshallPhysicalInterfaceDesign2009","event-place":"Montreal","genre":"Ph.D Thesis","issued":{"date-parts":[["2009"]]},"publisher":"McGill University","publisher-place":"Montreal","title":"Physical interface design for digital musical instruments","type":"thesis","URL":"https://escholarship.mcgill.ca/concern/theses/h128ng18h"},{"id":"martinComposingEnsembleStandstill2018","abstract":"This paper describes the process of developing a standstill performance work using the Myo gesture control armband and the Bela embedded computing platform. The combination of Myo and Bela allows a portable and extensible version of the standstill performance concept while introducing muscle tension as an additional control parameter. We describe the technical details of our setup and introduce Myo-to-Bela and Myo-to-OSC software bridges that assist with prototyping compositions using the Myo controller.","accessed":{"date-parts":[["2023",10,18]]},"author":[{"family":"Martin","given":"Charles Patrick"},{"family":"Jensenius","given":"Alexander Refsum"},{"family":"Torresen","given":"Jim"}],"citation-key":"martinComposingEnsembleStandstill2018","DOI":"10.5281/ZENODO.1302543","issued":{"date-parts":[["2018",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"Composing An Ensemble Standstill Work For Myo And Bela","type":"article-journal","URL":"https://zenodo.org/record/1302543"},{"id":"martinez-maldonadoLessonsLearntMultimodal2023","abstract":"Multimodal Learning Analytics (MMLA) innovations make use of rapidly evolving sensing and artificial intelligence algorithms to collect rich data about learning activities that unfold in physical spaces. The analysis of these data is opening exciting new avenues for both studying and supporting learning. Yet, practical and logistical challenges commonly appear while deploying MMLA innovations “in-the-wild”. These can span from technical issues related to enhancing the learning space with sensing capabilities, to the increased complexity of teachers’ tasks. These practicalities have been rarely investigated. This article addresses this gap by presenting a set of lessons learnt from a 2-year human-centred MMLA in-the-wild study conducted with 399 students and 17 educators in the context of nursing education. The lessons learnt were synthesised into topics related to (i) technological/physical aspects of the deployment; (ii) multimodal data and interfaces; (iii) the design process; (iv) participation, ethics and privacy; and (v) sustainability of the deployment.","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Martinez-Maldonado","given":"Roberto"},{"family":"Echeverria","given":"Vanessa"},{"family":"Fernandez-Nieto","given":"Gloria"},{"family":"Yan","given":"Lixiang"},{"family":"Zhao","given":"Linxuan"},{"family":"Alfredo","given":"Riordan"},{"family":"Li","given":"Xinyu"},{"family":"Dix","given":"Samantha"},{"family":"Jaggard","given":"Hollie"},{"family":"Wotherspoon","given":"Rosie"},{"family":"Osborne","given":"Abra"},{"family":"Shum","given":"Simon Buckingham"},{"family":"Gašević","given":"Dragan"}],"citation-key":"martinez-maldonadoLessonsLearntMultimodal2023","container-title":"ACM Transactions on Computer-Human Interaction","container-title-short":"ACM Trans. Comput.-Hum. Interact.","DOI":"10.1145/3622784","ISSN":"1073-0516, 1557-7325","issue":"1","issued":{"date-parts":[["2023",11,29]]},"language":"en","page":"1-41","source":"DOI.org (Crossref)","title":"Lessons Learnt from a Multimodal Learning Analytics Deployment In-the-Wild","type":"article-journal","URL":"https://dl.acm.org/doi/10.1145/3622784","volume":"31"},{"id":"martinez-maldonadoWhatYouMean2021","abstract":"Using data to generate a deeper understanding of collaborative learning is not new, but automatically analyzing log data has enabled new means of identifying key indicators of effective collaboration and teamwork that can be used to predict outcomes and personalize feedback. Collaboration analytics is emerging as a new term to refer to computational methods for identifying salient aspects of collaboration from multiple group data sources for learners, educators, or other stakeholders to gain and act upon insights. Yet, it remains unclear how collaboration analytics go beyond previous work focused on modelling group interactions for the purpose of adapting instruction. This paper provides a conceptual model of collaboration analytics to help researchers and designers identify the opportunities enabled by such innovations to advance knowledge in, and provide enhanced support for, collaborative learning and teamwork. We argue that mapping from low-level data to higher-order constructs that are educationally meaningful, and that can be understood by educators and learners, is essential to assessing the validity of collaboration analytics. Through four cases, the paper illustrates the critical role of theory, task design, and human factors in the design of interfaces that inform actionable insights for improving collaboration and group learning.","accessed":{"date-parts":[["2024",12,9]]},"author":[{"family":"Martinez-Maldonado","given":"Roberto"},{"family":"Gašević","given":"Dragan"},{"family":"Echeverria","given":"Vanessa"},{"family":"Nieto","given":"Gloria Fernandez"},{"family":"Swiecki","given":"Zachari"},{"family":"Shum","given":"Simon Buckingham"}],"citation-key":"martinez-maldonadoWhatYouMean2021","container-title":"Journal of Learning Analytics","DOI":"10.18608/jla.2021.7227","ISSN":"1929-7750","issue":"1","issued":{"date-parts":[["2021",4,8]]},"language":"en","license":"Copyright (c) 2021 Journal of Learning Analytics","number":"1","page":"126-153","source":"learning-analytics.info","title":"What Do You Mean by Collaboration Analytics? A Conceptual Model","title-short":"What Do You Mean by Collaboration Analytics?","type":"article-journal","URL":"https://learning-analytics.info/index.php/JLA/article/view/7227","volume":"8"},{"id":"martinezSingleNetworkWholeBodyPose2019","accessed":{"date-parts":[["2024",4,21]]},"author":[{"family":"Martinez","given":"Gines Hidalgo"},{"family":"Raaj","given":"Yaadhav"},{"family":"Idrees","given":"Haroon"},{"family":"Xiang","given":"Donglai"},{"family":"Joo","given":"Hanbyul"},{"family":"Simon","given":"Tomas"},{"family":"Sheikh","given":"Yaser"}],"citation-key":"martinezSingleNetworkWholeBodyPose2019","container-title":"2019 IEEE/CVF International Conference on Computer Vision (ICCV)","DOI":"10.1109/ICCV.2019.00708","event-place":"Seoul, Korea (South)","event-title":"2019 IEEE/CVF International Conference on Computer Vision (ICCV)","ISBN":"978-1-7281-4803-8","issued":{"date-parts":[["2019",10]]},"license":"https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html","page":"6981-6990","publisher":"IEEE","publisher-place":"Seoul, Korea (South)","source":"DOI.org (Crossref)","title":"Single-Network Whole-Body Pose Estimation","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/9010752/"},{"id":"martinMechanismsControllingComplex2010","abstract":"Many musical instruments have interfaces which emphasisethe pitch of the sound produced over other perceptual characteristics, such as its timbre. This is at odds with the musical developments of the last century. In this paper, weintroduce a method for replacing the interface of musicalinstruments (both conventional and unconventional) witha more flexible interface which can present the intrument'savailable sounds according to variety of different perceptualcharacteristics, such as their brightness or roughness. Weapply this method to an instrument of our own design whichcomprises an electro-mechanically controlled electric guitarand amplifier configured to produce feedback tones.","accessed":{"date-parts":[["2023",1,16]]},"author":[{"family":"Martin","given":"Aengus"},{"family":"Ferguson","given":"Sam"},{"family":"Beilharz","given":"Kirsty"}],"citation-key":"martinMechanismsControllingComplex2010","DOI":"10.5281/ZENODO.1177841","issued":{"date-parts":[["2010",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"Mechanisms For Controlling Complex Sound Sources : Applications To Guitar Feedback Control","title-short":"Mechanisms For Controlling Complex Sound Sources","type":"article-journal","URL":"https://zenodo.org/record/1177841"},{"id":"mashinoBodyVisualisingMusic2020","abstract":"[For Balinese gender wayang musicians, seeing another musician’s body plays a pivotal role in shaping their own corporeality, allowing broad access to the corporeality and musical experience of others. With experience, the sight of others is integrated with the sound heard and the corresponding musician’s own body movement, so that the musician can easily collaborate or reference the other body as a rich store of knowledge and memory. In contrast, musicians in competitions are more concerned with being seen than with seeing each other and elaborately display their bodies to emphasise their excellence on stage. This article illustrates and analyses how the musicians utilise sight in producing and perceiving musical performance in both cases to share their corporeal experience and interact with each other.]","accessed":{"date-parts":[["2023",12,21]]},"archive":"JSTOR","author":[{"family":"Mashino","given":"Ako"}],"citation-key":"mashinoBodyVisualisingMusic2020","container-title":"The World of Music","ISSN":"00438774","issue":"1","issued":{"date-parts":[["2020"]]},"page":"47-66","publisher":"[Florian Noetzel GmbH Verlag, VWB - Verlag für Wissenschaft und Bildung, Bärenreiter, Schott Music GmbH & Co. KG]","title":"The Body Visualising the Music","type":"article-journal","URL":"https://www-jstor-org.ezproxy.uio.no/stable/26970254","volume":"9"},{"id":"mashinoCorporealitySoundMovement2020","abstract":"[We create music and dance with the body and perceive both through it. The performer’s body is moulded by the practice of music and/or dance, transforming it into a body with specific structure, competencies, and consciousness. The body of a performer is thus not any human body but a cultural body with particular physical skills and a heightened awareness of corporeality. Furthermore, dance and music often occur simultaneously and can intertwine to the point of being inseparable. Even when music occurs without dance, body movement is still involved in its performance, and dancers may also produce sound. This article investigates the bodily basis of music and dance as well as the significance of human corporeality in choreomusical interrelations. Drawing from interdisciplinary perspectives, it presents a cross-cultural approach for choreomusical analysis that does not a priori divide music and dance into two separate categories, but proceeds from the corporeal practices of music making and dancing.]","accessed":{"date-parts":[["2023",12,21]]},"archive":"JSTOR","author":[{"family":"Mashino","given":"Ako"},{"family":"Seye","given":"Elina"}],"citation-key":"mashinoCorporealitySoundMovement2020","container-title":"The World of Music","ISSN":"00438774","issue":"1","issued":{"date-parts":[["2020"]]},"page":"25-46","publisher":"[Florian Noetzel GmbH Verlag, VWB - Verlag für Wissenschaft und Bildung, Bärenreiter, Schott Music GmbH & Co. KG]","title":"The Corporeality of Sound and Movement in Performance","type":"article-journal","URL":"https://www-jstor-org.ezproxy.uio.no/stable/26970253","volume":"9"},{"id":"masuHowDancersWant2019","accessed":{"date-parts":[["2023",2,27]]},"author":[{"family":"Masu","given":"Raul"},{"family":"Correia","given":"Nuno N."},{"family":"Jurgens","given":"Stephan"},{"family":"Druzetic","given":"Ivana"},{"family":"Primett","given":"William"}],"citation-key":"masuHowDancersWant2019","container-title":"Proceedings of the 9th International Conference on Digital and Interactive Arts","DOI":"10.1145/3359852.3359869","event-place":"Braga Portugal","event-title":"ARTECH 2019: 9th International Conference on Digital and Interactive Arts","ISBN":"978-1-4503-7250-3","issued":{"date-parts":[["2019",10,23]]},"language":"en","page":"1-9","publisher":"ACM","publisher-place":"Braga Portugal","source":"DOI.org (Crossref)","title":"How do Dancers Want to Use Interactive Technology?: Appropriation and Layers of Meaning Beyond Traditional Movement Mapping","title-short":"How do Dancers Want to Use Interactive Technology?","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3359852.3359869"},{"id":"mathewsComputerMusicalInstrument1987","accessed":{"date-parts":[["2022",9,12]]},"archive":"JSTOR","author":[{"family":"Mathews","given":"Max V."},{"family":"Pierce","given":"John R."}],"citation-key":"mathewsComputerMusicalInstrument1987","container-title":"Scientific American","ISSN":"00368733, 19467087","issue":"2","issued":{"date-parts":[["1987"]]},"page":"126-133","publisher":"Scientific American, a division of Nature America, Inc.","title":"The Computer as a Musical Instrument","type":"article-journal","URL":"http://www.jstor.org/stable/24979324","volume":"256"},{"id":"matthewsHolographicABBAExamining2023","accessed":{"date-parts":[["2023",7,10]]},"author":[{"family":"Matthews","given":"Justin"},{"family":"Nairn","given":"Angelique"}],"citation-key":"matthewsHolographicABBAExamining2023","container-title":"Popular Music and Society","container-title-short":"Popular Music and Society","DOI":"10.1080/03007766.2023.2208048","ISSN":"0300-7766, 1740-1712","issue":"3","issued":{"date-parts":[["2023",5,27]]},"language":"en","page":"282-303","title":"Holographic ABBA: Examining Fan Responses to ABBA’s Virtual “Live” Concert","title-short":"Holographic ABBA","type":"article-journal","URL":"https://www.tandfonline.com/doi/full/10.1080/03007766.2023.2208048","volume":"46"},{"id":"matthiasm.deParticleTests152013","accessed":{"date-parts":[["2021",1,29]]},"author":[{"literal":"MatthiasM.de"}],"citation-key":"matthiasm.deParticleTests152013","container-title":"YouTube","issued":{"date-parts":[["2013",2,12]]},"title":"Particle tests (15) 3D Music Visualizer - Full HD","type":"webpage","URL":"https://www.youtube.com/watch?v=fpViZkhpPHk"},{"id":"matuskyShadowPuppetsDrums2017","author":[{"family":"Matusky","given":"Patricia"}],"citation-key":"matuskyShadowPuppetsDrums2017","collection-title":"SOAS musicology series","container-title":"Sounding the dance, moving the music : choreomusicology in maritime Southeast Asia","editor":[{"literal":"Mohd. Anis Md. Nor"},{"family":"Stepputat","given":"Kendra"}],"event-place":"Abingdon, Oxon","ISBN":"978-1-4724-6923-6","issued":{"date-parts":[["2017"]]},"publisher":"Routledge","publisher-place":"Abingdon, Oxon","title":"Shadow Puppets, Drums and Gongs: Movement-Music Relationships in a Theatrical Genre","type":"chapter"},{"id":"mausForwardDisplacementsFading2006","abstract":"S2 TL;DR: The results show that the 'disappearance threshold' for a moving object is lower than the detection threshold for the same object without a motion history, and this manipulation led to a forward displacement of the disappearance point by 175 ms.","author":[{"family":"Maus","given":"Gerrit W."},{"family":"Nijhawan","given":"Romi"}],"citation-key":"mausForwardDisplacementsFading2006","container-title":"Vision Research","DOI":"10.1016/j.visres.2006.08.028","issued":{"date-parts":[["2006"]]},"note":"QID: Q79256684","page":"4375-4381","PMID":"17045627","title":"Forward displacements of fading objects in motion: The role of transient signals in perceiving position","type":"article-journal","URL":"https://www.semanticscholar.org/paper/f65f7ef91c68eff7b60293f09a22d89b9b10331d","volume":"46"},{"id":"mausGoingGoingGone2009","abstract":"When a moving object abruptly disappears, this profoundly influences its localization by the visual system. In Experiment 1, 2 aligned objects moved across the screen, and 1 of them abruptly disappeared. Observers reported seeing the objects misaligned at the time of the offset, with the continuing object leading. Experiment 2 showed that the perceived forward displacement of the moving object depended on speed and that offsets were localized accurately. Two competing representations of position for moving objects are proposed: 1 based on a spatially extrapolated internal model, and the other based on transient signals elicited by sudden changes in the object trajectory that can correct the forward-shifted position. Experiment 3 measured forward displacements for moving objects that disappeared only for a short time or abruptly reduced contrast by various amounts. Manipulating the relative strength of the 2 position representations in this way resulted in intermediate positions being perceived, with weaker motion signals or stronger transients leading to less forward displacement. This 2-process mechanism is advantageous because it uses available information about object position to maximally reduce spatio-temporal localization errors.","author":[{"family":"Maus","given":"Gerrit W."},{"family":"Nijhawan","given":"Romi"}],"citation-key":"mausGoingGoingGone2009","container-title":"Journal of experimental psychology. Human perception and performance","DOI":"10.1037/a0012317","issued":{"date-parts":[["2009"]]},"note":"QID: Q51933569","page":"611-26","PMID":"19485681","title":"Going, going, gone: localizing abrupt offsets of moving objects.","type":"article-journal","URL":"https://www.semanticscholar.org/paper/ae7a6df5851d0d645d3839f5da03d5db55f54ca4","volume":"35 3"},{"id":"mausMotionExtrapolationBlind2008","abstract":"The flash-lag effect, in which a moving object is perceived ahead of a colocalized flash, has led to keen empirical and theoretical debates. To test the proposal that a predictive mechanism overcomes neural delays in vision by shifting objects spatially, we asked observers to judge the final position of a bar moving into the retinal blind spot. The bar was perceived to disappear in positions well inside the unstimulated area. Given that photoreceptors are absent in the blind spot, the perceived shift must be based on the history of the moving object. Such predictive overshoots are suppressed when a moving object disappears abruptly from the retina, triggering retinal transient signals. No such transient-driven suppression occurs when the object disappears by virtue of moving into the blind spot. The extrapolated position of the moving bar revealed in this manner provides converging support for visual prediction.","author":[{"family":"Maus","given":"Gerrit W."},{"family":"Nijhawan","given":"Romi"}],"citation-key":"mausMotionExtrapolationBlind2008","container-title":"Psychological Science","DOI":"10.1111/j.1467-9280.2008.02205.x","issued":{"date-parts":[["2008"]]},"note":"QID: Q46201295","page":"1087 - 1091","PMID":"19076478","title":"Motion extrapolation into the blind spot","type":"article-journal","URL":"https://www.semanticscholar.org/paper/23337ff6f1ee1f23aa51f3b4b6829fae4ddf8346","volume":"19"},{"id":"mccartneyRethinkingComputerMusic2002","accessed":{"date-parts":[["2024",5,15]]},"author":[{"family":"McCartney","given":"James"}],"citation-key":"mccartneyRethinkingComputerMusic2002","container-title":"Computer Music Journal","container-title-short":"Computer Music Journal","DOI":"10.1162/014892602320991383","ISSN":"0148-9267, 1531-5169","issue":"4","issued":{"date-parts":[["2002",12]]},"language":"en","page":"61-68","source":"DOI.org (Crossref)","title":"Rethinking the Computer Music Language: SuperCollider","title-short":"Rethinking the Computer Music Language","type":"article-journal","URL":"https://direct.mit.edu/comj/article/26/4/61-68/93775","volume":"26"},{"id":"mcclaryFeminineEndingsMusic2002","author":[{"family":"McClary","given":"Susan"}],"call-number":"ML82 .M38 2002","citation-key":"mcclaryFeminineEndingsMusic2002","event-place":"Minneapolis","ISBN":"978-0-8166-4189-5","issued":{"date-parts":[["2002"]]},"number-of-pages":"220","publisher":"University of Minnesota Press","publisher-place":"Minneapolis","source":"Library of Congress ISBN","title":"Feminine Endings: Music, Gender, and Sexuality","title-short":"Feminine endings","type":"book"},{"id":"mccormickTeachingDigitalPerforming2014","accessed":{"date-parts":[["2023",11,25]]},"author":[{"family":"McCormick","given":"John"},{"family":"Vincs","given":"Kim"},{"family":"Nahavandi","given":"Saeid"},{"family":"Creighton","given":"Douglas"},{"family":"Hutchison","given":"Steph"}],"citation-key":"mccormickTeachingDigitalPerforming2014","container-title":"Proceedings of the 2014 International Workshop on Movement and Computing","DOI":"10.1145/2617995.2618008","event-place":"Paris France","event-title":"MOCO '14: International Workshop on Movement and Computing","ISBN":"978-1-4503-2814-2","issued":{"date-parts":[["2014",6,16]]},"language":"en","page":"70-75","publisher":"ACM","publisher-place":"Paris France","source":"DOI.org (Crossref)","title":"Teaching a Digital Performing Agent: Artificial Neural Network and Hidden Markov Model for recognising and performing dance movement","title-short":"Teaching a Digital Performing Agent","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/2617995.2618008"},{"id":"mcdermottMusicPerception2011","author":[{"family":"McDermott","given":"Hugh"}],"call-number":"RF305 .A93 2011","citation-key":"mcdermottMusicPerception2011","collection-number":"39","collection-title":"Springer Handbook of Auditory Research","container-title":"Auditory Prostheses: New Horizons","editor":[{"family":"Zeng","given":"Fan-Gang"},{"family":"Popper","given":"Arthur N."},{"family":"Fay","given":"Richard R."}],"event-place":"New York","ISBN":"978-1-4419-9433-2 978-1-4419-9434-9","issued":{"date-parts":[["2011"]]},"note":"OCLC: ocn733239537","page":"305 - 340","publisher":"Springer Verlag","publisher-place":"New York","source":"Library of Congress ISBN","title":"Music Perception","type":"chapter"},{"id":"mcdermottMusicPerceptionCochlear2004","author":[{"family":"McDermott","given":"Hugh J"}],"citation-key":"mcdermottMusicPerceptionCochlear2004","container-title":"Trends in amplification","container-title-short":"Trends in amplification","ISSN":"1084-7138","issue":"2","issued":{"date-parts":[["2004"]]},"page":"49-82","publisher":"SAGE Publications Sage CA: Los Angeles, CA","title":"Music Perception with Cochlear Implants: A Review","type":"article-journal","volume":"8"},{"id":"mcdermottPerceptionComplexSignals2004","author":[{"family":"McDermott","given":"Hugh"},{"family":"Looi","given":"Valerie"}],"citation-key":"mcdermottPerceptionComplexSignals2004","event-title":"International Congress Series","ISBN":"0531-5131","issued":{"date-parts":[["2004"]]},"page":"201-204","publisher":"Elsevier","title":"Perception of Complex Signals, including Musical Sounds, with Cochlear Implants","type":"paper-conference","volume":"1273"},{"id":"mcdermottPitchRankingNonsimultaneous1994","author":[{"family":"McDermott","given":"Hugh"},{"family":"McKay","given":"Colette M."}],"citation-key":"mcdermottPitchRankingNonsimultaneous1994","container-title":"The Journal of the Acoustical Society of America","container-title-short":"The Journal of the Acoustical Society of America","ISSN":"0001-4966","issue":"1","issued":{"date-parts":[["1994"]]},"page":"155-162","publisher":"Acoustical Society of America","title":"Pitch Ranking with Nonsimultaneous Dual‐Electrode Electrical Stimulation of the Cochlea","type":"article-journal","volume":"96"},{"id":"mcdermottShouldMusicInteraction2013","accessed":{"date-parts":[["2022",9,6]]},"author":[{"family":"McDermott","given":"James"},{"family":"Gifford","given":"Toby"},{"family":"Bouwer","given":"Anders"},{"family":"Wagy","given":"Mark"}],"citation-key":"mcdermottShouldMusicInteraction2013","container-title":"Music and Human-Computer Interaction","DOI":"10.1007/978-1-4471-2990-5_2","editor":[{"family":"Holland","given":"Simon"},{"family":"Wilkie","given":"Katie"},{"family":"Mulholland","given":"Paul"},{"family":"Seago","given":"Allan"}],"event-place":"London","ISBN":"978-1-4471-2989-9 978-1-4471-2990-5","issued":{"date-parts":[["2013"]]},"page":"29-47","publisher":"Springer London","publisher-place":"London","source":"DOI.org (Crossref)","title":"Should Music Interaction Be Easy?","type":"chapter","URL":"http://link.springer.com/10.1007/978-1-4471-2990-5_2"},{"id":"mcfeeLibrosaAudioMusic2015","author":[{"family":"McFee","given":"Brian"},{"family":"Raffel","given":"Colin"},{"family":"Liang","given":"Dawen"},{"family":"Ellis","given":"Daniel P"},{"family":"McVicar","given":"Matt"},{"family":"Battenberg","given":"Eric"},{"family":"Nieto","given":"Oriol"}],"citation-key":"mcfeeLibrosaAudioMusic2015","container-title":"Proceedings of the 14th python in science conference","issued":{"date-parts":[["2015"]]},"page":"18–25","title":"librosa: Audio and music signal analysis in python","type":"paper-conference","volume":"8"},{"id":"mckayPitchMatchingAmplitude1995","author":[{"family":"McKay","given":"Colette M."},{"family":"McDermott","given":"Hugh"},{"family":"Clark","given":"Graeme M."}],"citation-key":"mckayPitchMatchingAmplitude1995","container-title":"The Journal of the Acoustical Society of America","container-title-short":"The Journal of the Acoustical Society of America","ISSN":"0001-4966","issue":"3","issued":{"date-parts":[["1995"]]},"page":"1777-1785","publisher":"Acoustical Society of America","title":"Pitch Matching of Amplitude‐Modulated Current Pulse Trains by Cochlear Implantees: The Effect of Modulation Depth","type":"article-journal","volume":"97"},{"id":"mckayPitchPerceptsAssociated1994","author":[{"family":"McKay","given":"Colette M."},{"family":"McDermott","given":"Hugh"},{"family":"Clark","given":"Graeme M."}],"citation-key":"mckayPitchPerceptsAssociated1994","container-title":"The Journal of the Acoustical Society of America","container-title-short":"The Journal of the Acoustical Society of America","ISSN":"0001-4966","issue":"5","issued":{"date-parts":[["1994"]]},"page":"2664-2673","publisher":"Acoustical Society of America","title":"Pitch Percepts Associated with Amplitude‐Modulated Current Pulse Trains in Cochlear Implantees","type":"article-journal","volume":"96"},{"id":"mckayPsychophysicsElectricalStimulation2004","abstract":"Cochlear implants have instigated a popular but controversial revolution in the treatment of deafness. This book discusses the physiological bases of using artificial devices to electrically stimulate the brain to interpret sounds. As the first successful device to restore neural function, the cochlear implant serves as a model for research in neuroscience and biomedical engineering. These and other auditory prostheses are discussed in the context of historical treatments, engineering, psychophysics and clinical issues as well as implications for speech, behavior, cognition and long-term effects on people.","accessed":{"date-parts":[["2021",1,20]]},"author":[{"family":"McKay","given":"Colette M."}],"citation-key":"mckayPsychophysicsElectricalStimulation2004","collection-number":"20","collection-title":"Springer Handbook of Auditory Research","container-title":"Cochlear Implants: Auditory Prostheses and Electric Hearing","editor":[{"family":"Zeng","given":"Fan-Gang"},{"family":"Popper","given":"Arthur N"},{"family":"Fay","given":"Richard R"}],"event-place":"New York","ISBN":"978-0-387-22585-2 978-1-4419-2346-2","issued":{"date-parts":[["2004"]]},"language":"English","note":"OCLC: 910559232","page":"286 - 333","publisher":"Springer","publisher-place":"New York","source":"Open WorldCat","title":"Psychophysics and Electrical Stimulation","type":"chapter","URL":"https://doi.org/10.1007/978-0-387-22585-2"},{"id":"mcmahanEvaluatingNaturalInteraction2010","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"McMahan","given":"Ryan P."},{"family":"Alon","given":"Alexander Joel D."},{"family":"Lazem","given":"Shaimaa"},{"family":"Beaton","given":"Robert J."},{"family":"Machaj","given":"David"},{"family":"Schaefer","given":"Michael"},{"family":"Silva","given":"Mara G."},{"family":"Leal","given":"Anamary"},{"family":"Hagan","given":"Robert"},{"family":"Bowman","given":"Doug A."}],"citation-key":"mcmahanEvaluatingNaturalInteraction2010","container-title":"2010 IEEE Symposium on 3D User Interfaces (3DUI)","DOI":"10.1109/3DUI.2010.5444727","event-place":"Waltham, MA, USA","event-title":"2010 IEEE Symposium on 3D User Interfaces (3DUI)","ISBN":"978-1-4244-6846-1","issued":{"date-parts":[["2010",3]]},"page":"11-14","publisher":"IEEE","publisher-place":"Waltham, MA, USA","source":"DOI.org (Crossref)","title":"Evaluating natural interaction techniques in video games","type":"paper-conference","URL":"http://ieeexplore.ieee.org/document/5444727/"},{"id":"mcruerCripTheoryCultural2006","author":[{"family":"McRuer","given":"Robert"}],"call-number":"HV1568 .M37 2006","citation-key":"mcruerCripTheoryCultural2006","collection-title":"Cultural front","event-place":"New York","ISBN":"978-0-8147-5712-3 978-0-8147-5713-0","issued":{"date-parts":[["2006"]]},"note":"OCLC: ocm62430884","number-of-pages":"283","publisher":"New York University Press","publisher-place":"New York","source":"Library of Congress ISBN","title":"Crip Theory: Cultural Signs of Queerness and Disability","title-short":"Crip theory","type":"book"},{"id":"meadorMixingDanceRealities2004","abstract":"An experimental dance performance featuring live-motion capture, real-time computer graphics, and multi-image projection was produced by a cross-departmental team of faculty and students at Purdue University. Dancers occupied and traversed performance mediums or \"frames,\" including a virtual performance frame occupied by a 3D character, driven by a dancer in motion-capture equipment. Developing and facilitating the relationships between the dancers in various performance frames became a primary focus for the project, but other areas, e.g., creating an artistically sound and technologically seamless performance, helping the various team members collaborate, and exploring the nature of the technology, were important focus points as well.","accessed":{"date-parts":[["2022",5,12]]},"author":[{"family":"Meador","given":"W. Scott"},{"family":"Rogers","given":"Timothy J."},{"family":"O'Neal","given":"Kevin"},{"family":"Kurt","given":"Eric"},{"family":"Cunningham","given":"Carol"}],"citation-key":"meadorMixingDanceRealities2004","container-title":"Computers in Entertainment","container-title-short":"Comput. Entertain.","DOI":"10.1145/1008213.1008233","ISSN":"1544-3574, 1544-3574","issue":"2","issued":{"date-parts":[["2004",4]]},"language":"en","page":"12-12","source":"DOI.org (Crossref)","title":"Mixing dance realities: collaborative development of live-motion capture in a performing arts environment","title-short":"Mixing dance realities","type":"article-journal","URL":"https://dl.acm.org/doi/10.1145/1008213.1008233","volume":"2"},{"id":"meadorMixingDanceRealities2004a","abstract":"An experimental dance performance featuring live-motion capture, real-time computer graphics, and multi-image projection was produced by a cross-departmental team of faculty and students at Purdue University. Dancers occupied and traversed performance mediums or \"frames,\" including a virtual performance frame occupied by a 3D character, driven by a dancer in motion-capture equipment. Developing and facilitating the relationships between the dancers in various performance frames became a primary focus for the project, but other areas, e.g., creating an artistically sound and technologically seamless performance, helping the various team members collaborate, and exploring the nature of the technology, were important focus points as well.","author":[{"family":"Meador","given":"W"},{"family":"Rogers","given":"Timothy"},{"family":"O'Neal","given":"Kevin"},{"family":"Kurt","given":"Eric"},{"family":"Cunningham","given":"Carol"}],"citation-key":"meadorMixingDanceRealities2004a","container-title":"Computers in Entertainment","DOI":"10.1145/1008213.1008233","event-place":"New York","ISSN":"1544-3574","issue":"2","issued":{"date-parts":[["2004"]]},"page":"12-12","publisher":"New York: ACM","publisher-place":"New York","title":"Mixing dance realities: collaborative development of live-motion capture in a performing arts environment","type":"article-journal","volume":"2"},{"id":"mecklenburgerWirelessTechnologiesHearing2016","abstract":"This volume will serve as the first Handbook of its kind in the area of hearing aid research, often the least-defined, least-understood, part of the multi-disciplinary research process. Most scientific training is very advanced within the particular disciplines but provides little opportunity for systematic introduction to the issues and obstacles that prevent effective hearing-aid related research. This area has emerged as one of critical importance, as signified by a single specialized meeting (the International Hearing Aid Conference, IHCON) that brings together specialists from the disparate disciplines involved, including both university and industry researchers. Identification of the key steps that enable high-impact basic science to ultimately result in significant clinical advances that improve patient outcome is critical. This volume will provide an overview of current key issues in hearing aid research from the perspective of many different disciplines, not only from the perspective of the key funding agencies, but also from the scientists and clinicians who are currently involved in hearing aid research. It will offer insight into the experience, current technology and future technology that can help improve hearing aids, as scientists and clinicians typically have little or no formal training over the whole range of the individual disciplines that are relevant. The selection and coverage of topics insures that it will have lasting impact, well beyond immediate, short-term, or parochial concerns.","accessed":{"date-parts":[["2021",1,20]]},"author":[{"family":"Mecklenburger","given":"Jill"},{"family":"Groth","given":"Torben"}],"citation-key":"mecklenburgerWirelessTechnologiesHearing2016","collection-number":"56","collection-title":"Springer Handbook of Auditory Research","container-title":"Hearing Aids","editor":[{"family":"Popelka","given":"Gerald R."},{"family":"Moore","given":"Brian C. J."},{"family":"Fay","given":"Richard R."},{"family":"Popper","given":"Arthur N."}],"event-place":"Cham","ISBN":"978-3-319-33036-5","issued":{"date-parts":[["2016"]]},"language":"English","note":"OCLC: 984801900","page":"131 - 149","publisher":"Springer International Publishing : Imprint : Springer","publisher-place":"Cham","source":"Open WorldCat","title":"Wireless Technologies and Hearing Aid Connectivity","type":"chapter","URL":"https://doi.org/10.1007/978-3-319-33036-5"},{"id":"medelListenHearMedEl2013","accessed":{"date-parts":[["2021",1,27]]},"author":[{"literal":"medel"}],"citation-key":"medelListenHearMedEl2013","container-title":"yumpu","issued":{"date-parts":[["2013"]]},"title":"Listen, Hear! - Med-El","type":"webpage","URL":"https://www.yumpu.com/en/document/read/3432280/listen-hear-med-el"},{"id":"mehtaMasteringPythonScientific2015","abstract":"A complete guide for Python programmers to master scientific computing using Python APIs and tools About This Book * The basics of scientific computing to advanced concepts involving parallel and large scale computation are all covered. * Most of the Python APIs and tools used in scientific computing are discussed in detail * The concepts are discussed with suitable example programs Who This Book Is For If you are a Python programmer and want to get your hands on scientific computing, this book is for you. The book expects you to have had exposure to various concepts of Python programming. What You Will Learn * Fundamentals and components of scientific computing * Scientific computing data management * Performing numerical computing using NumPy and SciPy * Concepts and programming for symbolic computing using SymPy * Using the plotting library matplotlib for data visualization * Data analysis and visualization using Pandas, matplotlib, and IPython * Performing parallel and high performance computing * Real-life case studies and best practices of scientific computing In Detail In today's world, along with theoretical and experimental work, scientific computing has become an important part of scientific disciplines. Numerical calculations, simulations and computer modeling in this day and age form the vast majority of both experimental and theoretical papers. In the scientific method, replication and reproducibility are two important contributing factors. A complete and concrete scientific result should be reproducible and replicable. Python is suitable for scientific computing. A large community of users, plenty of help and documentation, a large collection of scientific libraries and environments, great performance, and good support makes Python a great choice for scientific computing. At present Python is among the top choices for developing scientific workflow and the book targets existing Python developers to master this domain using Python. The main things to learn in the book are the concept of scientific workflow, managing scientific workflow data and performing computation on this data using Python. The book discusses NumPy, SciPy, SymPy, matplotlib, Pandas and IPython with several example programs. Style and approach This book follows a hands-on approach to explain the complex concepts related to scientific computing. It details various APIs using appropriate examples","author":[{"family":"Mehta","given":"Hemant"}],"citation-key":"mehtaMasteringPythonScientific2015","collection-title":"Community experience distilled","event-place":"Birmingham Mumbai","ISBN":"978-1-78328-882-3","issued":{"date-parts":[["2015"]]},"language":"eng","number-of-pages":"272","publisher":"Packt Publishing","publisher-place":"Birmingham Mumbai","source":"K10plus ISBN","title":"Mastering Python scientific computing: A complete guide for Python programmers to master scientific computing using Python APIs and tools","title-short":"Mastering Python scientific computing","type":"book"},{"id":"meijerSemanticApproachExtracting2014","abstract":"In this paper we present a framework for the automatic building of a domain taxonomy from text corpora, called Automatic Taxonomy Construction from Text (ATCT). This framework comprises four steps. First, terms are extracted from a corpus of documents. From these extracted terms the ones that are most relevant for a specific domain are selected using a filtering approach in the second step. Third, the selected terms are disambiguated by means of a word sense disambiguation technique and concepts are generated. In the final step, the broader–narrower relations between concepts are determined using a subsumption technique that makes use of concept co-occurrences in a text. For evaluation, we assess the performance of the ATCT framework using the semantic precision, semantic recall, and the taxonomic F-measure that take into account the concept semantics. The proposed framework is evaluated in the field of economics and management as well as the medical domain.","author":[{"family":"Meijer","given":"Kevin"},{"family":"Frasincar","given":"Flavius"},{"family":"Hogenboom","given":"Frederik"}],"citation-key":"meijerSemanticApproachExtracting2014","container-title":"Decision Support Systems","container-title-short":"Decision Support Systems","DOI":"10.1016/j.dss.2014.03.006","ISSN":"0167-9236","issued":{"date-parts":[["2014",6,1]]},"page":"78-93","title":"A semantic approach for extracting domain taxonomies from text","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0167923614001031","volume":"62"},{"id":"mekruksavanichLSTMNetworksUsing2021","abstract":"Human Activity Recognition (HAR) employing inertial motion data has gained considerable momentum in recent years, both in research and industrial applications. From the abstract perspective, this has been driven by an acceleration in the building of intelligent and smart environments and systems that cover all aspects of human life including healthcare, sports, manufacturing, commerce, etc. Such environments and systems necessitate and subsume activity recognition, aimed at recognizing the actions, characteristics, and goals of one or more individuals from a temporal series of observations streamed from one or more sensors. Due to the reliance of conventional Machine Learning (ML) techniques on handcrafted features in the extraction process, current research suggests that deep-learning approaches are more applicable to automated feature extraction from raw sensor data. In this work, the generic HAR framework for smartphone sensor data is proposed, based on Long Short-Term Memory (LSTM) networks for time-series domains. Four baseline LSTM networks are comparatively studied to analyze the impact of using different kinds of smartphone sensor data. In addition, a hybrid LSTM network called 4-layer CNN-LSTM is proposed to improve recognition performance. The HAR method is evaluated on a public smartphone-based dataset of UCI-HAR through various combinations of sample generation processes (OW and NOW) and validation protocols (10-fold and LOSO cross validation). Moreover, Bayesian optimization techniques are used in this study since they are advantageous for tuning the hyperparameters of each LSTM network. The experimental results indicate that the proposed 4-layer CNN-LSTM network performs well in activity recognition, enhancing the average accuracy by up to 2.24% compared to prior state-of-the-art approaches.","accessed":{"date-parts":[["2024",9,2]]},"author":[{"family":"Mekruksavanich","given":"Sakorn"},{"family":"Jitpattanakul","given":"Anuchit"}],"citation-key":"mekruksavanichLSTMNetworksUsing2021","container-title":"Sensors","container-title-short":"Sensors","DOI":"10.3390/s21051636","ISSN":"1424-8220","issue":"5","issued":{"date-parts":[["2021",2,26]]},"language":"en","license":"https://creativecommons.org/licenses/by/4.0/","page":"1636","source":"DOI.org (Crossref)","title":"LSTM Networks Using Smartphone Data for Sensor-Based Human Activity Recognition in Smart Homes","type":"article-journal","URL":"https://www.mdpi.com/1424-8220/21/5/1636","volume":"21"},{"id":"metkarMotionEstimationTechniques2013","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Metkar","given":"Shilpa"},{"family":"Talbar","given":"Sanjay"}],"citation-key":"metkarMotionEstimationTechniques2013","collection-title":"SpringerBriefs in Applied Sciences and Technology","DOI":"10.1007/978-81-322-1097-9","event-place":"India","ISBN":"978-81-322-1096-2 978-81-322-1097-9","issued":{"date-parts":[["2013"]]},"language":"en","license":"https://www.springernature.com/gp/researchers/text-and-data-mining","publisher":"Springer India","publisher-place":"India","source":"DOI.org (Crossref)","title":"Motion Estimation Techniques for Digital Video Coding","type":"book","URL":"https://link.springer.com/10.1007/978-81-322-1097-9"},{"id":"metkarMotionEstimationTechniques2013a","abstract":"The book deals with the development of a methodology to estimate the motion field between two frames for video coding applications. This book proposes an exhaustive study of the motion estimation process in the framework of a general video coder. The conceptual explanations are discussed in a simple language and with the use of suitable figures. The book will serve as a guide for new researchers working in the field of motion estimation techniques","author":[{"family":"Metkar","given":"Shilpa"},{"family":"Talbar","given":"Sanjay Nilkanth"}],"citation-key":"metkarMotionEstimationTechniques2013a","event-place":"New Delhi","ISBN":"978-81-322-1097-9","issued":{"date-parts":[["2013"]]},"language":"eng","note":"OCLC: 834401873","publisher":"Springer","publisher-place":"New Delhi","source":"Open WorldCat","title":"Motion estimation techniques for digital video coding","type":"book"},{"id":"miaskiewiczPersonasUsercenteredDesign2011","author":[{"family":"Miaskiewicz","given":"Tomasz"},{"family":"Kozar","given":"Kenneth A"}],"citation-key":"miaskiewiczPersonasUsercenteredDesign2011","container-title":"Design studies","container-title-short":"Design studies","ISSN":"0142-694X","issue":"5","issued":{"date-parts":[["2011"]]},"page":"417-430","publisher":"Elsevier","title":"Personas and user-centered design: How can personas benefit product design processes?","type":"article-journal","volume":"32"},{"id":"miceEmbodiedCognitionPerformers2021a","abstract":"We present The Large Instrument Performers Study, an interview-based exploration into how large scale acoustic instrument performers navigate the instrument’s size-related aesthetic features during the performance. Through the conceptual frameworks of embodied music cognition and affordance theory, we discuss how the themes that emerged in the interview data reveal the ways size-related aesthetic features of large acoustic instruments influence the instrument performer’s choices; how large scale acoustic instruments feature microscopic nuanced performance options; and how despite the preconception of large scale acoustic instruments being scaled up versions of the smaller instrument with the addition of a lower fundamental tone, the instruments offer different sonic and performative features to their smaller counterparts and require precise gestural control that is certainly not scaled up. This is followed by a discussion of how the study findings could influence design features in new large scale digital musical instruments to result in more nuanced control and timbrally rich instruments, and better understanding of how interfaces and instruments influence performers’ choices and as a result music repertoire and performance.","author":[{"family":"Mice","given":"Lia"},{"family":"McPherson","given":"Andrew P."}],"citation-key":"miceEmbodiedCognitionPerformers2021a","container-title":"Perception, Representations, Image, Sound, Music","editor":[{"family":"Kronland-Martinet","given":"Richard"},{"family":"Ystad","given":"Sølvi"},{"family":"Aramaki","given":"Mitsuko"}],"event-place":"Cham","ISBN":"978-3-030-70210-6","issued":{"date-parts":[["2021"]]},"page":"577-590","publisher":"Springer International Publishing","publisher-place":"Cham","title":"Embodied Cognition in Performers of Large Acoustic Instruments as a Method of Designing New Large Digital Musical Instruments","type":"paper-conference"},{"id":"michaelb.bakanBeingAppliedEthnomusicology2015","accessed":{"date-parts":[["2020",12,15]]},"author":[{"literal":"Michael B. Bakan"}],"citation-key":"michaelb.bakanBeingAppliedEthnomusicology2015","DOI":"10.1093/oxfordhb/9780199351701.013.11","editor":[{"family":"Pettan","given":"Svanibor"},{"family":"Titon","given":"Jeff Todd"}],"issued":{"date-parts":[["2015",8,1]]},"publisher":"Oxford University Press","source":"DOI.org (Crossref)","title":"Being Applied in the Ethnomusicology of Autism","type":"book","URL":"http://oxfordhandbooks.com/view/10.1093/oxfordhb/9780199351701.001.0001/oxfordhb-9780199351701-e-11"},{"id":"michelsantiOverviewDeeplearningbasedAudiovisual2021","author":[{"family":"Michelsanti","given":"Daniel"},{"family":"Tan","given":"Zheng-Hua"},{"family":"Zhang","given":"Shi-Xiong"},{"family":"Xu","given":"Yong"},{"family":"Yu","given":"Meng"},{"family":"Yu","given":"Dong"},{"family":"Jensen","given":"Jesper"}],"citation-key":"michelsantiOverviewDeeplearningbasedAudiovisual2021","container-title":"IEEE/ACM Transactions on Audio, Speech, and Language Processing","DOI":"10.1109/TASLP.2021.3066303","issued":{"date-parts":[["2021"]]},"page":"1368-1396","title":"An overview of deep-learning-based audio-visual speech enhancement and separation","type":"article-journal","volume":"29"},{"id":"millsTelematicsArtEvolution2019","accessed":{"date-parts":[["2021",8,30]]},"author":[{"family":"Mills","given":"Roger"}],"citation-key":"millsTelematicsArtEvolution2019","container-author":[{"family":"Mills","given":"Roger"}],"container-title":"Tele-Improvisation: Intercultural Interaction in the Online Global Music Jam Session","DOI":"10.1007/978-3-319-71039-6_2","event-place":"Cham","ISBN":"978-3-319-71038-9 978-3-319-71039-6","issued":{"date-parts":[["2019"]]},"page":"21-57","publisher":"Springer International Publishing","publisher-place":"Cham","source":"DOI.org (Crossref)","title":"Telematics, Art and the Evolution of Networked Music Performance","type":"chapter","URL":"http://link.springer.com/10.1007/978-3-319-71039-6_2"},{"id":"mineCharacterizationEndendDelays1993","author":[{"family":"Mine","given":"Mark R."}],"citation-key":"mineCharacterizationEndendDelays1993","event-place":"USA","issued":{"date-parts":[["1993"]]},"publisher":"University of North Carolina at Chapel Hill","publisher-place":"USA","title":"Characterization of end-to-end delays in head-mounted display systems","type":"report"},{"id":"mionScoreIndependentAudioFeatures2008","accessed":{"date-parts":[["2022",3,7]]},"author":[{"family":"Mion","given":"Luca"},{"family":"De Poli","given":"Giovanni"}],"citation-key":"mionScoreIndependentAudioFeatures2008","container-title":"IEEE Transactions on Audio, Speech, and Language Processing","container-title-short":"IEEE Trans. Audio Speech Lang. Process.","DOI":"10.1109/TASL.2007.913743","ISSN":"1558-7916","issue":"2","issued":{"date-parts":[["2008",2]]},"page":"458-466","source":"DOI.org (Crossref)","title":"Score-Independent Audio Features for Description of Music Expression","type":"article-journal","URL":"http://ieeexplore.ieee.org/document/4432649/","volume":"16"},{"id":"mirandaNewDigitalMusical2006","author":[{"family":"Miranda","given":"Eduardo Reck"},{"family":"Wanderley","given":"Marcelo M."}],"call-number":"ML1092 .M57 2006","citation-key":"mirandaNewDigitalMusical2006","collection-number":"v. 21","collection-title":"The computer music and digital audio series","event-place":"Middleton, Wis","ISBN":"978-0-89579-585-4","issued":{"date-parts":[["2006"]]},"note":"OCLC: ocm62533819","number-of-pages":"295","publisher":"A-R Editions","publisher-place":"Middleton, Wis","source":"Library of Congress ISBN","title":"New digital musical instruments: control and interaction beyond the keyboard","title-short":"New digital musical instruments","type":"book"},{"id":"mitaniMusicRecognitionMusic2007","author":[{"family":"Mitani","given":"Chisato"},{"family":"Nakata","given":"Takayuki"},{"family":"Trehub","given":"Sandra E"},{"family":"Kanda","given":"Yukihiko"},{"family":"Kumagami","given":"Hidetaka"},{"family":"Takasaki","given":"Kenji"},{"family":"Miyamoto","given":"Ikue"},{"family":"Takahashi","given":"Haruo"}],"citation-key":"mitaniMusicRecognitionMusic2007","container-title":"Ear and Hearing","container-title-short":"Ear and Hearing","ISSN":"0196-0202","issue":"2","issued":{"date-parts":[["2007"]]},"page":"29S-33S","publisher":"LWW","title":"Music Recognition, Music Listening, and Word Recognition by Deaf Children with Cochlear Implants","type":"article-journal","volume":"28"},{"id":"mitchellDataFusionConcepts2012","author":[{"family":"Mitchell","given":"H. B."}],"call-number":"004","citation-key":"mitchellDataFusionConcepts2012","event-place":"Berlin New York","ISBN":"978-3-642-27222-6","issued":{"date-parts":[["2012"]]},"language":"eng","publisher":"Springer","publisher-place":"Berlin New York","source":"BnF ISBN","title":"Data fusion: concepts and ideas","title-short":"Data fusion","type":"book"},{"id":"mitchellNarrativeProsthesisDisability2001","author":[{"family":"Mitchell","given":"David T."},{"family":"Snyder","given":"Sharon L."}],"call-number":"PN56.5.H35 M58 2000","citation-key":"mitchellNarrativeProsthesisDisability2001","collection-title":"Corporealities","event-place":"Ann Arbor","ISBN":"978-0-472-09748-7 978-0-472-06748-0","issued":{"date-parts":[["2001"]]},"number-of-pages":"211","publisher":"University of Michigan Press","publisher-place":"Ann Arbor","source":"Library of Congress ISBN","title":"Narrative Prosthesis: Disability and the Dependencies of Discourse","title-short":"Narrative prosthesis","type":"book"},{"id":"moeslundSurveyAdvancesVisionbased2006","abstract":"This survey reviews advances in human motion capture and analysis from 2000 to 2006, following a previous survey of papers up to 2000 [T.B. Moeslund, E. Granum, A survey of computer vision-based human motion capture, Computer Vision and Image Understanding, 81(3) (2001) 231–268.]. Human motion capture continues to be an increasingly active research area in computer vision with over 350 publications over this period. A number of significant research advances are identified together with novel methodologies for automatic initialization, tracking, pose estimation, and movement recognition. Recent research has addressed reliable tracking and pose estimation in natural scenes. Progress has also been made towards automatic understanding of human actions and behavior. This survey reviews recent trends in video-based human capture and analysis, as well as discussing open problems for future research to achieve automatic visual analysis of human movement.","author":[{"family":"Moeslund","given":"Thomas B."},{"family":"Hilton","given":"Adrian"},{"family":"Krüger","given":"Volker"}],"citation-key":"moeslundSurveyAdvancesVisionbased2006","container-title":"Special Issue on Modeling People: Vision-based understanding of a person’s shape, appearance, movement and behaviour","container-title-short":"Computer Vision and Image Understanding","DOI":"10.1016/j.cviu.2006.08.002","ISSN":"1077-3142","issue":"2","issued":{"date-parts":[["2006",11,1]]},"page":"90-126","title":"A survey of advances in vision-based human motion capture and analysis","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S1077314206001263","volume":"104"},{"id":"mogkDifferentBodiesEssays2013","abstract":"\"This is a collection of 19 new essays by 21 different authors. It focuses on contemporary film and television (1989 to the present). The essays are divided into three sections. The book as a whole is designed to be accessible to readers new to disability studies, while also contributing significantly to the field\"--","call-number":"PN1995.9.H34 D54 2013","citation-key":"mogkDifferentBodiesEssays2013","editor":[{"family":"Mogk","given":"Marja"}],"event-place":"Jefferson, North Carolina","ISBN":"978-0-7864-6535-4","issued":{"date-parts":[["2013"]]},"number-of-pages":"272","publisher":"McFarland & Company, Inc., Publishers","publisher-place":"Jefferson, North Carolina","source":"Library of Congress ISBN","title":"Different bodies: essays on disability in film and television","title-short":"Different bodies","type":"book"},{"id":"mohd.anismd.norSoundingDanceMoving2017","author":[{"literal":"Mohd. Anis Md. Nor"},{"family":"Stepputat","given":"Kendra"}],"citation-key":"mohd.anismd.norSoundingDanceMoving2017","collection-title":"SOAS musicology series","event-place":"Abingdon, Oxon","ISBN":"978-1-4724-6923-6","issued":{"date-parts":[["2017"]]},"publisher":"Routledge","publisher-place":"Abingdon, Oxon","title":"Sounding the dance, moving the music : choreomusicology in maritime Southeast Asia","type":"book"},{"id":"monsenVoiceQualitySpeech1983","abstract":"[Measures of the voice quality and speech intelligibility of deaf children are compared and related to articulatory and acoustic variables. It is shown that voice quality and speech intelligibility are closely related and that abnormalities of both phonation and articulation have a mutual negative effect on intelligibility and voice quality. A primary source of what is heard as the \"deaf voice\" may be inadequate vowel articulation, caused in part by insufficient tongue movements and by excess tension when speaking, which tends to constrict the pharynx and thereby further reduce the movements in frequency of the vowel resonances.]","accessed":{"date-parts":[["2021",1,4]]},"archive":"JSTOR","author":[{"family":"Monsen","given":"Randall B."}],"citation-key":"monsenVoiceQualitySpeech1983","container-title":"American Annals of the Deaf","ISSN":"0002726X, 15430375","issue":"1","issued":{"date-parts":[["1983"]]},"page":"12-19","publisher":"Gallaudet University Press","title":"Voice Quality and Speech Intelligibility Among Deaf Children","type":"article-journal","URL":"http://www.jstor.org/stable/44389171","volume":"128"},{"id":"mooneySonicImaginariesHow2021","author":[{"family":"Mooney","given":"James"},{"family":"Pinch","given":"Trevor"}],"citation-key":"mooneySonicImaginariesHow2021","container-title":"Rethinking Music through Science and Technology Studies","ISBN":"0-429-26883-1","issued":{"date-parts":[["2021"]]},"page":"113-149","publisher":"Routledge","title":"Sonic imaginaries: How Hugh Davies and David Van Koevering performed electronic music’s future","type":"chapter"},{"id":"mooreDysfunctionsMIDI1988","accessed":{"date-parts":[["2023",11,20]]},"author":[{"family":"Moore","given":"F. Richard"}],"citation-key":"mooreDysfunctionsMIDI1988","container-title":"Computer Music Journal","container-title-short":"Computer Music Journal","DOI":"10.2307/3679834","ISSN":"01489267","issue":"1","issued":{"season":1,"date-parts":[[1988]]},"page":"19","source":"DOI.org (Crossref)","title":"The Dysfunctions of MIDI","type":"article-journal","URL":"https://www.jstor.org/stable/3679834?origin=crossref","volume":"12"},{"id":"moorefieldProducerComposerShaping2010","author":[{"family":"Moorefield","given":"Virgil"}],"citation-key":"moorefieldProducerComposerShaping2010","ISBN":"0-262-51405-2","issued":{"date-parts":[["2010"]]},"publisher":"Mit Press","title":"The producer as composer: Shaping the sounds of popular music","type":"book"},{"id":"moorefieldProducerComposerShaping2010a","author":[{"family":"Moorefield","given":"Virgil"}],"call-number":"781.49","citation-key":"moorefieldProducerComposerShaping2010a","event-place":"Cambridge, Mass. London","ISBN":"978-0-262-51405-7","issued":{"date-parts":[["2010"]]},"language":"eng","publisher":"MIT Press","publisher-place":"Cambridge, Mass. London","source":"BnF ISBN","title":"The producer as composer: shaping the sounds of popular music","title-short":"The producer as composer","type":"book"},{"id":"mooreIntroductionHearingAids2016","abstract":"This volume will serve as the first Handbook of its kind in the area of hearing aid research, often the least-defined, least-understood, part of the multi-disciplinary research process. Most scientific training is very advanced within the particular disciplines but provides little opportunity for systematic introduction to the issues and obstacles that prevent effective hearing-aid related research. This area has emerged as one of critical importance, as signified by a single specialized meeting (the International Hearing Aid Conference, IHCON) that brings together specialists from the disparate disciplines involved, including both university and industry researchers. Identification of the key steps that enable high-impact basic science to ultimately result in significant clinical advances that improve patient outcome is critical. This volume will provide an overview of current key issues in hearing aid research from the perspective of many different disciplines, not only from the perspective of the key funding agencies, but also from the scientists and clinicians who are currently involved in hearing aid research. It will offer insight into the experience, current technology and future technology that can help improve hearing aids, as scientists and clinicians typically have little or no formal training over the whole range of the individual disciplines that are relevant. The selection and coverage of topics insures that it will have lasting impact, well beyond immediate, short-term, or parochial concerns.","accessed":{"date-parts":[["2021",1,20]]},"author":[{"family":"Moore","given":"Brian C. J."},{"family":"Popelka","given":"Gerald R."}],"citation-key":"mooreIntroductionHearingAids2016","collection-number":"56","collection-title":"Springer Handbook of Auditory Research","container-title":"Hearing Aids","editor":[{"family":"Popelka","given":"Gerald R."},{"family":"Moore","given":"Brian C. J."},{"family":"Fay","given":"Richard R."},{"family":"Popper","given":"Arthur N"}],"event-place":"Cham","ISBN":"978-3-319-33036-5","issued":{"date-parts":[["2016"]]},"language":"English","note":"OCLC: 984801900","page":"1 - 19","publisher":"Springer International Publishing : Imprint : Springer","publisher-place":"Cham","source":"Open WorldCat","title":"Introduction to Hearing Aids","type":"chapter","URL":"https://doi.org/10.1007/978-3-319-33036-5"},{"id":"mooreSpectroTemporalCharacteristicsSpeech2008","author":[{"family":"Moore","given":"Brian C. J."},{"family":"Stone","given":"Michael A."},{"family":"Füllgrabe","given":"Christian"},{"family":"Glasberg","given":"Brian R."},{"family":"Puria","given":"Sunil"}],"citation-key":"mooreSpectroTemporalCharacteristicsSpeech2008","container-title":"Ear and Hearing","container-title-short":"Ear and Hearing","issue":"6","issued":{"date-parts":[["2008"]]},"page":"907","publisher":"Europe PMC Funders","title":"Spectro-Temporal Characteristics of Speech at High Frequencies, and the Potential for Restoration of Audibility to People with Mild-to-Moderate Hearing Loss","type":"article-journal","volume":"29"},{"id":"Motive","citation-key":"Motive","publisher":"OptiTrak","title":"Motive","type":"software","version":"2.2.0"},{"id":"mulderChoiceGesturalConstraints2000","author":[{"family":"Mulder","given":"Axel G.E."}],"citation-key":"mulderChoiceGesturalConstraints2000","container-title":"Trends in Gestural Control of Music","container-title-short":"Trends in Gestural Control of Music","editor":[{"family":"Wanderley","given":"M.M"},{"family":"Battier","given":"M."}],"issued":{"date-parts":[["2000",1,1]]},"page":"315-335","title":"Towards a choice of gestural constraints for instrumental performers","type":"article-journal"},{"id":"mullerDTWBasedMotionComparison2007","abstract":"As we have seen in Chap. 4, dynamic time warping is a flexible tool for comparing time series in the presence of nonlinear time deformations. In this context, the choice of suitable local cost or distance measures is of crucial importance, since they determine the kind of (spatial) similarity between the elements (frames) of the two sequences to be aligned. For the mocap domain, we introduce two conceptually different local distance measures – one based on joint angle parameters and the other based on 3D coordinates – and discuss their respective strengths and weaknesses (Sect. 10.1). The importance of DTW is then illustrated by some synthesis and analysis applications (Sect. 10.2). By comparing a motion data stream to itself, one obtains a cost or distance matrix that exhibits self-similarities within the motion. In Sect. 10.3, we describe how this idea can be exploited for motion retrieval. Finally, in Sect. 10.4, we discuss some work related to DTW-based motion retrieval.","citation-key":"mullerDTWBasedMotionComparison2007","container-title":"Information Retrieval for Music and Motion","DOI":"10.1007/978-3-540-74048-3_10","editor":[{"family":"Müller","given":"Meinard"}],"event-place":"Berlin, Heidelberg","ISBN":"978-3-540-74048-3","issued":{"date-parts":[["2007"]]},"page":"211-226","publisher":"Springer Berlin Heidelberg","publisher-place":"Berlin, Heidelberg","title":"DTW-Based Motion Comparison and Retrieval","type":"chapter","URL":"https://doi.org/10.1007/978-3-540-74048-3_10"},{"id":"mullerDynamicTimeWarping2007","abstract":"Dynamic time warping (DTW) is a well-known technique to find an optimal alignment between two given (time-dependent) sequences under certain restrictions (Fig. 4.1). Intuitively, the sequences are warped in a nonlinear fashion to match each other. Originally, DTW has been used to compare different speech patterns in automatic speech recognition, see [170]. In fields such as data mining and information retrieval, DTW has been successfully applied to automatically cope with time deformations and different speeds associated with time-dependent data.","author":[{"family":"Müller","given":"Meinard"}],"citation-key":"mullerDynamicTimeWarping2007","container-title":"Information Retrieval for Music and Motion","DOI":"10.1007/978-3-540-74048-3_4","editor":[{"family":"Müller","given":"Meinard"}],"event-place":"Berlin, Heidelberg","ISBN":"978-3-540-74048-3","issued":{"date-parts":[["2007"]]},"page":"69-84","publisher":"Springer Berlin Heidelberg","publisher-place":"Berlin, Heidelberg","title":"Dynamic Time Warping","type":"chapter","URL":"https://doi.org/10.1007/978-3-540-74048-3_4"},{"id":"mullerEfficientMultiscaleApproach2006","author":[{"family":"Müller","given":"Meinard"},{"family":"Mattes","given":"Henning"},{"family":"Kurth","given":"Frank"}],"citation-key":"mullerEfficientMultiscaleApproach2006","event-title":"ISMIR","issued":{"date-parts":[["2006"]]},"page":"192-197","publisher":"Citeseer","title":"An efficient multiscale approach to audio synchronization.","type":"paper-conference","volume":"546"},{"id":"mullerFundamentalsMotionCapture2007","abstract":"The second part of this monograph deals with content-based analysis and retrieval of 3D motion capture data as used in computer graphics for animating virtual human characters. In this chapter, we provide the reader with some fundamental facts on motion representations. We start with a short introduction on motion capturing and introduce a mathematical model for the motion data as used throughout the subsequent chapters (Sect. 9.1).We continue with a detailed discussion of general similarity aspects that are crucial in view of motion comparison and retrieval (Sect. 9.2). Then, in Sect. 9.3, we formally introduce the concept of kinematic chains, which are generally used to model flexibly linked rigid bodies such as robot arms or human skeletons. Kinematic chains are parameterized by joint angles, which in turn can be represented in various ways. In Sect. 9.4, we describe and compare three important angle representations based on rotation matrices, Euler angles, and quaternions. Each of these representations has its strengths and weaknesses depending on the respective analysis or synthesis application.","author":[{"family":"Müller","given":"Meinard"}],"citation-key":"mullerFundamentalsMotionCapture2007","container-title":"Information Retrieval for Music and Motion","DOI":"10.1007/978-3-540-74048-3_9","event-place":"Berlin, Heidelberg","ISBN":"978-3-540-74048-3","issued":{"date-parts":[["2007"]]},"page":"187-209","publisher":"Springer Berlin Heidelberg","publisher-place":"Berlin, Heidelberg","title":"Fundamentals on Motion Capture Data","type":"chapter","URL":"https://doi.org/10.1007/978-3-540-74048-3_9"},{"id":"muMultimodalDataFusion2020","abstract":"Multimodal learning analytics (MMLA), which has become increasingly popular, can help provide an accurate understanding of learning processes. However, it is still unclear how multimodal data is integrated into MMLA. By following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, this paper systematically surveys 346 articles on MMLA published during the past three years. For this purpose, we first present a conceptual model for reviewing these articles from three dimensions: data types, learning indicators, and data fusion. Based on this model, we then answer the following questions: 1. What types of data and learning indicators are used in MMLA, together with their relationships; and 2. What are the classifications of the data fusion methods in MMLA. Finally, we point out the key stages in data fusion and the future research direction in MMLA. Our main findings from this review are (a) The data in MMLA are classified into digital data, physical data, physiological data, psychometric data, and environment data; (b) The learning indicators are behavior, cognition, emotion, collaboration, and engagement; (c) The relationships between multimodal data and learning indicators are one-to-one, one-to-any, and many-to-one. The complex relationships between multimodal data and learning indicators are the key for data fusion; (d) The main data fusion methods in MMLA are many-to-one, many-to-many and multiple validations among multimodal data; and (e) Multimodal data fusion can be characterized by the multimodality of data, multi-dimension of indicators, and diversity of methods.","accessed":{"date-parts":[["2024",12,10]]},"author":[{"family":"Mu","given":"Su"},{"family":"Cui","given":"Meng"},{"family":"Huang","given":"Xiaodi"}],"citation-key":"muMultimodalDataFusion2020","container-title":"Sensors","DOI":"10.3390/s20236856","ISSN":"1424-8220","issue":"23","issued":{"date-parts":[["2020",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"23","page":"6856","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Multimodal Data Fusion in Learning Analytics: A Systematic Review","title-short":"Multimodal Data Fusion in Learning Analytics","type":"article-journal","URL":"https://www.mdpi.com/1424-8220/20/23/6856","volume":"20"},{"id":"mundermannEvolutionMethodsCapture2006","abstract":"Abstract\n            Over the centuries the evolution of methods for the capture of human movement has been motivated by the need for new information on the characteristics of normal and pathological human movement. This study was motivated in part by the need of new clinical approaches for the treatment and prevention of diseases that are influenced by subtle changes in the patterns movement. These clinical approaches require new methods to measure accurately patterns of locomotion without the risk of artificial stimulus producing unwanted artifacts that could mask the natural patterns of motion. Most common methods for accurate capture of three-dimensional human movement require a laboratory environment and the attachment of markers or fixtures to the body's segments. These laboratory conditions can cause unknown experimental artifacts. Thus, our understanding of normal and pathological human movement would be enhanced by a method that allows the capture of human movement without the constraint of markers or fixtures placed on the body. In this paper, the need for markerless human motion capture methods is discussed and the advancement of markerless approaches is considered in view of accurate capture of three-dimensional human movement for biomechanical applications. The role of choosing appropriate technical equipment and algorithms for accurate markerless motion capture is critical. The implementation of this new methodology offers the promise for simple, time-efficient, and potentially more meaningful assessments of human movement in research and clinical practice. The feasibility of accurately and precisely measuring 3D human body kinematics for the lower limbs using a markerless motion capture system on the basis of visual hulls is demonstrated.","accessed":{"date-parts":[["2024",1,4]]},"author":[{"family":"Mündermann","given":"Lars"},{"family":"Corazza","given":"Stefano"},{"family":"Andriacchi","given":"Thomas P"}],"citation-key":"mundermannEvolutionMethodsCapture2006","container-title":"Journal of NeuroEngineering and Rehabilitation","container-title-short":"J NeuroEngineering Rehabil","DOI":"10.1186/1743-0003-3-6","ISSN":"1743-0003","issue":"1","issued":{"date-parts":[["2006",12]]},"language":"en","page":"6","source":"DOI.org (Crossref)","title":"The evolution of methods for the capture of human movement leading to markerless motion capture for biomechanical applications","type":"article-journal","URL":"https://jneuroengrehab.biomedcentral.com/articles/10.1186/1743-0003-3-6","volume":"3"},{"id":"munroClinicalVerificationHearing2016","abstract":"This volume will serve as the first Handbook of its kind in the area of hearing aid research, often the least-defined, least-understood, part of the multi-disciplinary research process. Most scientific training is very advanced within the particular disciplines but provides little opportunity for systematic introduction to the issues and obstacles that prevent effective hearing-aid related research. This area has emerged as one of critical importance, as signified by a single specialized meeting (the International Hearing Aid Conference, IHCON) that brings together specialists from the disparate disciplines involved, including both university and industry researchers. Identification of the key steps that enable high-impact basic science to ultimately result in significant clinical advances that improve patient outcome is critical. This volume will provide an overview of current key issues in hearing aid research from the perspective of many different disciplines, not only from the perspective of the key funding agencies, but also from the scientists and clinicians who are currently involved in hearing aid research. It will offer insight into the experience, current technology and future technology that can help improve hearing aids, as scientists and clinicians typically have little or no formal training over the whole range of the individual disciplines that are relevant. The selection and coverage of topics insures that it will have lasting impact, well beyond immediate, short-term, or parochial concerns.","accessed":{"date-parts":[["2021",1,20]]},"author":[{"family":"Munro","given":"Kevin J."},{"family":"Mueller","given":"H. Gustav"}],"citation-key":"munroClinicalVerificationHearing2016","collection-number":"56","collection-title":"Springer Handbook of Auditory Research","container-title":"Hearing Aids","editor":[{"family":"Popelka","given":"Gerald R."},{"family":"Moore","given":"Brian C. J."},{"family":"Fay","given":"Richard R."},{"family":"Popper","given":"Arthur N."}],"event-place":"Cham","ISBN":"978-3-319-33036-5","issued":{"date-parts":[["2016"]]},"language":"English","note":"OCLC: 984801900","page":"253 - 290","publisher":"Springer International Publishing : Imprint : Springer","publisher-place":"Cham","source":"Open WorldCat","title":"Clinical Verification of Hearing Aid Performance","type":"chapter","URL":"https://doi.org/10.1007/978-3-319-33036-5"},{"id":"muraroPortableInteractiveExplorations2020","abstract":"We present a mocap system designed with an aim towards understanding and incorporating the needs of contemporary dance choreographers and their integral relationship to somatics into interdisciplinary performance. Somatics here refers to the use of specific images and sensorial cognizance of physics principles in the human body which inform how the movement is created and performed. We apply these same somatics elements to the computational design and share the current state and our preliminary findings and results in using the system for a variety of site-specific dance performances.","author":[{"family":"Muraro","given":"Zjana"},{"family":"Higgs","given":"Colin"}],"citation-key":"muraroPortableInteractiveExplorations2020","collection-title":"MOCO '20","container-title":"Proceedings of the 7th international conference on movement and computing","DOI":"10.1145/3401956.3404255","event-place":"Jersey City/Virtual, NJ, USA","ISBN":"978-1-4503-7505-4","issued":{"date-parts":[["2020"]]},"number-of-pages":"2","publisher":"Association for Computing Machinery","publisher-place":"Jersey City/Virtual, NJ, USA","title":"Portable interactive explorations of motion data for choreographers","type":"paper-conference","URL":"https://doi.org/10.1145/3401956.3404255"},{"id":"murray-browneLatentMappingsGenerating2021","accessed":{"date-parts":[["2022",4,21]]},"author":[{"family":"Murray-Browne","given":"Tim"},{"family":"Tigas","given":"Panagiotis"}],"citation-key":"murray-browneLatentMappingsGenerating2021","container-title":"NIME 2021","DOI":"10.21428/92fbeb44.9d4bcd4b","event-place":"Shanghai, China","event-title":"NIME 2021","issued":{"date-parts":[["2021",6,1]]},"publisher":"PubPub","publisher-place":"Shanghai, China","source":"DOI.org (Crossref)","title":"Latent Mappings: Generating Open-Ended Expressive Mappings Using Variational Autoencoders","title-short":"Latent Mappings","type":"paper-conference","URL":"https://nime.pubpub.org/pub/latent-mappings"},{"id":"murrayAnalyzingInterculturalCommunication2011","author":[{"family":"Murray","given":"Alan"},{"family":"Sondhi","given":"Ranjit"},{"family":"Lallje","given":"Mansur"},{"family":"Apitzsch","given":"Gisela"}],"citation-key":"murrayAnalyzingInterculturalCommunication2011","ISBN":"3-11-087428-8","issued":{"date-parts":[["2011"]]},"publisher":"Walter de Gruyter","title":"Analyzing Intercultural Communication","type":"book","volume":"1"},{"id":"murrayPhysicalTheatresCritical2016","author":[{"family":"Murray","given":"Simon David"},{"family":"Keefe","given":"John"}],"citation-key":"murrayPhysicalTheatresCritical2016","edition":"Second edition","event-place":"London New York","ISBN":"978-1-138-78211-2 978-1-138-78210-5","issued":{"date-parts":[["2016"]]},"language":"eng","number-of-pages":"342","publisher":"Routledge","publisher-place":"London New York","source":"K10plus ISBN","title":"Physical theatres: a critical introduction","title-short":"Physical theatres","type":"book"},{"id":"musicalvibrationsMusicalVibrations","accessed":{"date-parts":[["2021",9,14]]},"author":[{"literal":"Musical Vibrations"}],"citation-key":"musicalvibrationsMusicalVibrations","container-title":"Musical Vibrations","title":"Musical Vibrations","type":"webpage","URL":"https://www.musicalvibrations.com/"},{"id":"musicalvibrationsMusicProductionSignKid","accessed":{"date-parts":[["2021",1,27]]},"author":[{"family":"Musical Vibrations","given":""}],"citation-key":"musicalvibrationsMusicProductionSignKid","container-title":"Musical Vibrations","title":"Music production: SignKid","type":"webpage","URL":"https://www.musicalvibrations.com/signkid/"},{"id":"musicalvibrationsWhatMusicalVibrations","accessed":{"date-parts":[["2021",1,29]]},"author":[{"literal":"Musical Vibrations"}],"citation-key":"musicalvibrationsWhatMusicalVibrations","container-title":"Musical Vibrations","title":"What is Musical Vibrations?","type":"webpage","URL":"https://www.musicalvibrations.com/whatismusvib/"},{"id":"musicandthedeafMusicDeaf2021","accessed":{"date-parts":[["2021",10,18]]},"author":[{"literal":"Music and the Deaf"}],"citation-key":"musicandthedeafMusicDeaf2021","container-title":"Music and the Deaf","issued":{"date-parts":[["2021"]]},"title":"Music and the Deaf","type":"webpage","URL":"https://www.matd.org.uk/"},{"id":"naccaratoCriticalAppropriationsBiosensors2017","accessed":{"date-parts":[["2023",2,26]]},"author":[{"family":"Naccarato","given":"Teoma J."},{"family":"MacCallum","given":"John"}],"citation-key":"naccaratoCriticalAppropriationsBiosensors2017","container-title":"Proceedings of the 4th International Conference on Movement Computing","DOI":"10.1145/3077981.3078053","event-place":"London United Kingdom","event-title":"MOCO '17: 4th International Conference on Movement Computing","ISBN":"978-1-4503-5209-3","issued":{"date-parts":[["2017",6,28]]},"language":"en","page":"1-7","publisher":"ACM","publisher-place":"London United Kingdom","title":"Critical Appropriations of Biosensors in Artistic Practice","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3077981.3078053"},{"id":"najafiHandbookElectronicAssistive2019","accessed":{"date-parts":[["2020",10,1]]},"author":[{"family":"Najafi","given":"Ladan"},{"family":"Cowan","given":"Donna"}],"citation-key":"najafiHandbookElectronicAssistive2019","ISBN":"978-0-12-812488-8","issued":{"date-parts":[["2019"]]},"language":"English","note":"OCLC: 1066741724","source":"Open WorldCat","title":"Handbook of Electronic Assistive Technology","type":"book","URL":"http://search.ebscohost.com/login.aspx?direct=true&scope=site&db=nlebk&db=nlabk&AN=1789645"},{"id":"nanayakkaraEnhancedMusicalExperience2009","abstract":"Music is a multi-dimensional experience informed by much more than hearing alone, and is thus accessible to people of all hearing abilities. In this paper we describe a prototype system designed to enrich the experience of music for the deaf by enhancing sensory input of information via channels other than in-air audio reception by the ear. The system has two main components-a vibrating 'Haptic Chair' and a computer display of informative visual effects that correspond to features of the music. The Haptic Chair provides sensory input of vibrations via touch. This system was developed based on an initial concept guided by information obtained from a background survey conducted with deaf people from multi-ethnic backgrounds and feedback received from two profoundly deaf musicians. A formal user study with 43 deaf participants suggested that the prototype system enhances the musical experience of a deaf person. All of the users preferred either the Haptic Chair alone (54%) or the Haptic Chair with the visual display (46%). The prototype system, especially the Haptic Chair was so enthusiastically received by our subjects that it is possible this system might significantly change the way the deaf community experiences music.","author":[{"family":"Nanayakkara","given":"Suranga"},{"family":"Taylor","given":"Elizabeth"},{"family":"Wyse","given":"Lonce"},{"family":"Ong","given":"S H."}],"citation-key":"nanayakkaraEnhancedMusicalExperience2009","collection-title":"CHI '09","container-title":"Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","DOI":"10.1145/1518701.1518756","event-place":"Boston, MA, USA","ISBN":"978-1-60558-246-7","issued":{"date-parts":[["2009"]]},"page":"337–346","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","title":"An Enhanced Musical Experience for the Deaf: Design and Evaluation of a Music Display and a Haptic Chair","type":"paper-conference","URL":"https://doi.org/10.1145/1518701.1518756"},{"id":"nanayakkaraHearingimpairedChildrenEnjoying2011","accessed":{"date-parts":[["2021",1,30]]},"author":[{"family":"Nanayakkara","given":"Suranga"}],"citation-key":"nanayakkaraHearingimpairedChildrenEnjoying2011","container-title":"YouTube","issued":{"date-parts":[["2011",7,24]]},"title":"Hearing-impaired children enjoying music!","type":"webpage","URL":"https://www.youtube.com/watch?v=g_ses3QLVQM"},{"id":"napierSpectralAnalysisDance2022","abstract":"While it is possible to quantify motion using various transforms or computational techniques, these representations may not be easy to interpret or reconstruct. In this paper, we focus on the problem of visualizing, querying, and manipulating dance components in the form of spectral features. Our first contribution is measuring the similarity of movements in a way that is robust to phase differences while identifying motions with similar pose frequencies. Our second contribution uses the similarity of pose spectra as a metric to drive the interpolation of a motion sequence towards target statistics. We identify the visual impact of these metrics on the characteristics of motion with input from experts in the dance field. These techniques are implemented to explore representations of dance that have the potential to be the basis of more intuitive choreography generation and educational tools for dance artists.","author":[{"family":"Napier","given":"Emily"},{"family":"Gray","given":"Gavin"},{"family":"Oore","given":"Sageev"}],"citation-key":"napierSpectralAnalysisDance2022","collection-title":"MOCO '22","container-title":"Proceedings of the 8th international conference on movement and computing","DOI":"10.1145/3537972.3537995","event-place":"Chicago, IL, USA","ISBN":"978-1-4503-8716-3","issued":{"date-parts":[["2022"]]},"number-of-pages":"7","publisher":"Association for Computing Machinery","publisher-place":"Chicago, IL, USA","title":"Spectral analysis for dance movement query and interpolation","type":"paper-conference","URL":"https://doi.org/10.1145/3537972.3537995"},{"id":"NatNetSDK","accessed":{"date-parts":[["2022",5,12]]},"citation-key":"NatNetSDK","publisher":"OptiTrak","title":"NatNet SDK","type":"software","URL":"https://optitrack.com/support/downloads/developer-tools.html#natnet-sdk","version":"4.4.0"},{"id":"nelsonElectrodeRankingPlace1995","author":[{"family":"Nelson","given":"David A."},{"family":"Van Tasell","given":"Dianne J."},{"family":"Schroder","given":"Anna C."},{"family":"Soli","given":"Sigfrid"},{"family":"Levine","given":"Samuel"}],"citation-key":"nelsonElectrodeRankingPlace1995","container-title":"The Journal of the Acoustical Society of America","container-title-short":"The Journal of the Acoustical Society of America","ISSN":"0001-4966","issue":"4","issued":{"date-parts":[["1995"]]},"page":"1987-1999","publisher":"Acoustical Society of America","title":"Electrode Ranking of ‘‘Place Pitch’’and Speech Recognition in Electrical Hearing","type":"article-journal","volume":"98"},{"id":"neumeyerDescriptionInterpretationFred2006","author":[{"family":"Neumeyer","given":"David"}],"citation-key":"neumeyerDescriptionInterpretationFred2006","container-title":"Music Analysis","ISSN":"0262-5245","issue":"1/2","issued":{"date-parts":[["2006"]]},"page":"201 - 230","title":"Description and Interpretation: Fred Lerdahl's\" Tonal Pitch Space\" and Linear Analysis","type":"article-journal","volume":"25"},{"id":"ngBlinkEyeInvestigating2014","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Ng","given":"Albert"},{"family":"Annett","given":"Michelle"},{"family":"Dietz","given":"Paul"},{"family":"Gupta","given":"Anoop"},{"family":"Bischof","given":"Walter F."}],"citation-key":"ngBlinkEyeInvestigating2014","container-title":"Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","DOI":"10.1145/2556288.2557037","event-place":"Toronto Ontario Canada","event-title":"CHI '14: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-2473-1","issued":{"date-parts":[["2014",4,26]]},"language":"en","page":"1103-1112","publisher":"ACM","publisher-place":"Toronto Ontario Canada","source":"DOI.org (Crossref)","title":"In the blink of an eye: investigating latency perception during stylus interaction","title-short":"In the blink of an eye","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/2556288.2557037"},{"id":"ngiamMultimodalDeepLearning2011","author":[{"family":"Ngiam","given":"Jiquan"},{"family":"Khosla","given":"Aditya"},{"family":"Kim","given":"Mingyu"},{"family":"Nam","given":"Juhan"},{"family":"Lee","given":"Honglak"},{"family":"Ng","given":"Andrew Y"}],"citation-key":"ngiamMultimodalDeepLearning2011","container-title":"Proceedings of the 28th international conference on machine learning (ICML-11)","event-title":"28th international conference on machine learning (ICML-11)","issued":{"date-parts":[["2011"]]},"page":"689-696","title":"Multimodal deep learning","type":"paper-conference"},{"id":"ngSpookerTrouperABBA2023","abstract":"This article analyses the ?live? virtual human in ABBA Voyage, the long-awaited concert reunion of the Swedish pop group ABBA, via Vilém Flusser?s concept of the digital apparition. It first argues for these virtual performers (dubbed ?ABBA-tars?) to be understood as externalized computational codes which shift the grounds of ownership over and consent to the use of one?s likeness. They are also key to disproportionate and as yet unaccountable power held by technology companies. Secondly, ABBA Voyage?s presentation of ABBA as their past selves places time in a capitalism of immateriality profiting from the protean temporality of bodies. This temporal discombobulation thwarts finitude and confounds time in meanings of life, death and growth. The article thus addresses urgent confrontations between actual and virtual humans placed in the same physical environment, and paves the way for thinking about how we are going to deal and live with their virtuality.","accessed":{"date-parts":[["2023",9,24]]},"author":[{"family":"Ng","given":"Jenna"},{"family":"Bax","given":"Nick"}],"citation-key":"ngSpookerTrouperABBA2023","container-title":"Paragraph","container-title-short":"Paragraph","DOI":"10.3366/para.2023.0427","ISSN":"0264-8334","issue":"2","issued":{"date-parts":[["2023",7,1]]},"page":"160-175","publisher":"Edinburgh University Press","title":"Spooker Trouper: ABBA Voyage, Virtual Humans and the Rise of the Digital Apparition","type":"article-journal","URL":"https://doi.org/10.3366/para.2023.0427","volume":"46"},{"id":"nguyenIMUbasedSpectrogramApproach2020","author":[{"family":"Nguyen","given":"Mau Dung"},{"family":"Mun","given":"Kyung-Ryoul"},{"family":"Jung","given":"Dawoon"},{"family":"Han","given":"Jooin"},{"family":"Park","given":"Mina"},{"family":"Kim","given":"Jeuk"},{"family":"Kim","given":"Jinwook"}],"citation-key":"nguyenIMUbasedSpectrogramApproach2020","container-title":"2020 IEEE international conference on consumer electronics (ICCE)","DOI":"10.1109/ICCE46568.2020.9042999","issued":{"date-parts":[["2020"]]},"page":"1-6","title":"IMU-based spectrogram approach with deep convolutional neural networks for gait classification","type":"paper-conference"},{"id":"nielsenIterativeUserinterfaceDesign1993","accessed":{"date-parts":[["2023",5,7]]},"author":[{"family":"Nielsen","given":"Jakob"}],"citation-key":"nielsenIterativeUserinterfaceDesign1993","container-title":"Computer","container-title-short":"Computer","DOI":"10.1109/2.241424","ISSN":"0018-9162","issue":"11","issued":{"date-parts":[["1993",11]]},"page":"32-41","source":"DOI.org (Crossref)","title":"Iterative user-interface design","type":"article-journal","URL":"http://ieeexplore.ieee.org/document/241424/","volume":"26"},{"id":"nijhawanNeuralDelaysVisual2002","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Nijhawan","given":"Romi"}],"citation-key":"nijhawanNeuralDelaysVisual2002","container-title":"Trends in Cognitive Sciences","container-title-short":"Trends in Cognitive Sciences","DOI":"10.1016/S1364-6613(02)01963-0","ISSN":"13646613","issue":"9","issued":{"date-parts":[["2002",9]]},"language":"en","license":"https://www.elsevier.com/tdm/userlicense/1.0/","note":"QID: Q74675434","page":"387-393","source":"DOI.org (Crossref)","title":"Neural delays, visual motion and the flash-lag effect","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S1364661302019630","volume":"6"},{"id":"nikolaiStillnessBreathSpine2015","abstract":"Highlights • Motion Capture offers perspectives towards dance composition between live and digital platforms. • Re-viewing motion capture movement data in dance carries an uncanny presence. • Motion capture of dance provides recognisable visualisation of essence relative to stillness, breath and articulation of the spine.","author":[{"family":"Nikolai","given":"Jennifer"},{"family":"Bennett","given":"Gregory"}],"citation-key":"nikolaiStillnessBreathSpine2015","container-title":"Performance enhancement & health (Oxford)","DOI":"10.1016/j.peh.2015.11.003","ISSN":"2211-2669","issue":"1-2","issued":{"date-parts":[["2015"]]},"page":"58-66","publisher":"Elsevier Ltd","title":"Stillness, breath and the spine - Dance performance enhancement catalysed by the interplay between 3D motion capture technology in a collaborative improvisational choreographic process","type":"article-journal","volume":"4"},{"id":"nogueiraMakingMusicMore2018","author":[{"family":"Nogueira","given":"Waldo"},{"family":"Nagathil","given":"Anil"},{"family":"Martin","given":"Rainer"}],"citation-key":"nogueiraMakingMusicMore2018","container-title":"IEEE Signal Processing Magazine","container-title-short":"IEEE Signal Processing Magazine","ISSN":"1053-5888","issue":"1","issued":{"date-parts":[["2018"]]},"page":"115-127","publisher":"IEEE","title":"Making Music More Accessible for Cochlear Implant Listeners: Recent Developments","type":"article-journal","volume":"36"},{"id":"nogueiraMusICMusicCochlear","accessed":{"date-parts":[["2021",1,27]]},"author":[{"family":"Nogueira","given":"Waldo"}],"citation-key":"nogueiraMusICMusicCochlear","container-title":"musIC 2.0 music for cochlear implants","title":"musIC 2.0 music for cochlear implants","type":"webpage","URL":"http://music-cochlearimplant2.weebly.com/"},{"id":"nogueiraMusICMusicCochleara","accessed":{"date-parts":[["2021",1,27]]},"author":[{"family":"Nogueira","given":"Waldo"}],"citation-key":"nogueiraMusICMusicCochleara","container-title":"musIC 3.0 music for cochlear implants","title":"musIC 3.0 music for cochlear implants","type":"webpage","URL":"https://music-cochlearimplant.weebly.com/"},{"id":"nogueiraMusICSeminarII2017","accessed":{"date-parts":[["2021",1,27]]},"author":[{"family":"Nogueira","given":"Waldo"}],"citation-key":"nogueiraMusICSeminarII2017","container-title":"musIC 3.0 music for cochlear implants","issued":{"date-parts":[["2017",10,9]]},"title":"musIC 3.0: Seminar II","type":"webpage","URL":"https://music-cochlearimplant.weebly.com/blog-english/music-30-seminar-ii"},{"id":"nogueiravasquez20versus232015","accessed":{"date-parts":[["2021",1,27]]},"author":[{"family":"NOGUEIRA VASQUEZ","given":"WALDO"}],"citation-key":"nogueiravasquez20versus232015","container-title":"YouTube","issued":{"date-parts":[["2015",5,6]]},"title":"20versus23","type":"webpage","URL":"https://www.youtube.com/watch?v=v8oClrqRlqE"},{"id":"nogueiravasquezLevit2015","accessed":{"date-parts":[["2021",1,27]]},"author":[{"family":"NOGUEIRA VASQUEZ","given":"WALDO"}],"citation-key":"nogueiravasquezLevit2015","container-title":"YouTube","issued":{"date-parts":[["2015",5,6]]},"title":"Levit","type":"webpage","URL":"https://www.youtube.com/watch?v=j_2I0byTGDg"},{"id":"nogueiravasquezMusICPerceptionDaria2017","accessed":{"date-parts":[["2021",1,27]]},"author":[{"family":"NOGUEIRA VASQUEZ","given":"WALDO"}],"citation-key":"nogueiravasquezMusICPerceptionDaria2017","container-title":"YouTube","issued":{"date-parts":[["2017",12,22]]},"title":"musIC 3.0: Perception by Daria Cheikh Sarraf","type":"webpage","URL":"https://www.youtube.com/watch?v=3PcwXbSLNjQ"},{"id":"nogueiravasquezSeminarPresentationWaldo2014","accessed":{"date-parts":[["2021",1,27]]},"author":[{"family":"NOGUEIRA VASQUEZ","given":"WALDO"}],"citation-key":"nogueiravasquezSeminarPresentationWaldo2014","container-title":"YouTube","issued":{"date-parts":[["2014",10,22]]},"title":"Seminar 1 Presentation Waldo","type":"webpage","URL":"https://www.youtube.com/watch?v=sFs0u4OXKlo"},{"id":"nogueiravasquezSlicing2015","accessed":{"date-parts":[["2021",1,27]]},"author":[{"family":"NOGUEIRA VASQUEZ","given":"WALDO"}],"citation-key":"nogueiravasquezSlicing2015","container-title":"YouTube","issued":{"date-parts":[["2015",5,6]]},"title":"slicing","type":"webpage","URL":"https://www.youtube.com/watch?v=R9fhlDgdjH8"},{"id":"normanDesignEverydayThings2013","abstract":"Even the smartest among us can feel inept as we try to figure out the shower control in a hotel or attempt to navigate an unfamiliar television set or stove. When The Design of Everyday Things was published in 1988, congnitive scientist Don Norman provocatively proposed that the fault lies not in ourselves but in design that ignores the needs and psychology of people. Alas, bad design is everywhere, but fortunately, it isn't difficult to design things that are understandable, usable, and enjoyable. Thoughtfully revised to keep the timeless principles of psychology up to date with ever-changing new technologies, The Design of Everyday Things is a powerful appeal for good design, and a reminder of how - and why - some products satisfy while others only disappoint","author":[{"family":"Norman","given":"Donald A"}],"citation-key":"normanDesignEverydayThings2013","collection-editor":[{"family":"Norman","given":"Donald A"}],"edition":"Revised and expanded edition.","event-place":"New York","ISBN":"978-0-465-05065-9","issued":{"date-parts":[["2013"]]},"publisher":"Basic Books","publisher-place":"New York","title":"The design of everyday things","type":"book"},{"id":"normanOskarSchlemmerProgrammatic2015","author":[{"family":"Norman","given":"Sally Jane"}],"call-number":"QP303 .C57 2015","citation-key":"normanOskarSchlemmerProgrammatic2015","collection-title":"Palgrave studies in performance and technology","container-title":"Digital movement: essays in motion technology and performance","editor":[{"family":"Sutil","given":"Nicolás Salazar"},{"family":"Popat","given":"Sita"}],"event-place":"Houndmills, Basingstoke Hampshire ; New York, NY","ISBN":"978-1-137-43040-3","issued":{"date-parts":[["2015"]]},"page":"21-34","publisher":"Palgrave Macmillan","publisher-place":"Houndmills, Basingstoke Hampshire ; New York, NY","source":"Library of Congress ISBN","title":"Oskar Schlemmer's Programmatic Gesture Research","type":"chapter"},{"id":"nymoenMethodsTechnologiesAnalysing2013","author":[{"family":"Nymoen","given":"Kristian"}],"citation-key":"nymoenMethodsTechnologiesAnalysing2013","event-place":"Oslo","genre":"Ph.D Thesis","issued":{"date-parts":[["2013"]]},"publisher":"Department of Informatics, Faculty of Mathematics and Natural Sciences, University of Oslo","publisher-place":"Oslo","title":"Methods and technologies for analysing links between musical sound and body motion","type":"thesis","URL":"https://www.duo.uio.no/handle/10852/34354","volume":"no. 1291"},{"id":"nymoenSoundSaberMotionCapture2011","abstract":"The paper presents the SoundSaber-a musical instrument based on motion capture technology. We present technical details of the instrument and discuss the design development process. The SoundSaber may be used as an example of how high-fidelity motion capture equipment can be used for prototyping musical instruments, and we illustrate this with an example of a low-cost implementation of our motion capture instrument.","author":[{"family":"Nymoen","given":"Kristian"},{"family":"Skogstad","given":"Ståle A."},{"family":"Jensenius","given":"Alexander Refsum"}],"citation-key":"nymoenSoundSaberMotionCapture2011","container-title":"Proceedings of the international conference on new interfaces for musical expression","DOI":"10.5281/zenodo.1178125","event-place":"Oslo, Norway","ISSN":"2220-4806","issued":{"date-parts":[["2011"]]},"page":"312–315","publisher-place":"Oslo, Norway","title":"SoundSaber – a motion capture instrument","type":"paper-conference","URL":"http://www.nime.org/proceedings/2011/nime2011_312.pdf"},{"id":"ogmenDifferentialLatenciesDynamics2004","abstract":"S2 TL;DR: To investigate the dynamics of the position computation process for a moving object in human vision, the response to a continuous change in position at a constant velocity (ramp-response) is measured using the flash-lag illusion.","author":[{"family":"Öğmen","given":"H."},{"family":"Patel","given":"Saumil S."},{"family":"Bedell","given":"H."},{"family":"Camuz","given":"Kaan"}],"citation-key":"ogmenDifferentialLatenciesDynamics2004","container-title":"Vision Research","DOI":"10.1016/j.visres.2004.04.003","issued":{"date-parts":[["2004"]]},"note":"QID: Q44926466","page":"2109-2128","PMID":"15183678","title":"Differential latencies and the dynamics of the position computation process for moving targets, assessed with the flash-lag effect","type":"article-journal","URL":"https://www.semanticscholar.org/paper/15f6afdcc8c15199e333955cdaa9f7ddbe6dad36","volume":"44"},{"id":"oishiDesignUseAssistive2010","call-number":"MLCM 2017/43366 (T)","citation-key":"oishiDesignUseAssistive2010","editor":[{"family":"Oishi","given":"Meeko Mitsuko K."},{"family":"Mitchell","given":"Ian M."},{"family":"Van der Loos","given":"Hendrik F. Machiel"}],"event-place":"New York","ISBN":"978-1-4419-7030-5 978-1-4419-7031-2","issued":{"date-parts":[["2010"]]},"number-of-pages":"117","publisher":"Springer","publisher-place":"New York","source":"Library of Congress ISBN","title":"Design and Use of Assistive Technology","type":"book"},{"id":"oliverosTelematicMusicSix2009","abstract":"See for the full article plus sound files and supplemental materials.\nTelematic Music: Six Perspectives covers the history, context, artistic and technical description of a network concert that the authors performed together on 16 November 2007. Performing live, the authors participated in the concert simultaneously, interactively, with high-quality low-latency software using Internet2 at Rensselaer Polytechnic Institute in Troy, New York; Stanford University in Palo Alto, California; and University of California San Diego in La Jolla. JackTrip, the audio software used for the interconnections, was developed by Chris Chafe at Stanford; the video software was Apple's iCHATav. The papers described below were presented during the Telematic Music panel at the International Society for Improvised Music (ISIM) conference organized by Sarah Weaver, ISIM Board director, and hosted at Northwestern University in Evanston, IL, 7 December 2007.\nPauline Oliveros. E-mail: .\nThis paper describes some qualities of my network performance characteristics, beginning in 1991 with a telephone bridge connecting six cities via video telephone and progressing through PictureTel videoconferencing with higher-quality DSL lines; Internet connection with 8-second delay and no video; iCHATav with compressed video and audio opening the Internet for performance; and CD- and DV-quality transmission via Internet2.\nSarah Weaver. E-mail: .\nThe paper begins with background on telematic music concerts in the year leading up to the 16 November 2007 performance of three pieces: TeleCello Concerto, Water Naught and Three Ways. The ensembles for the November 2007 performance were Tintinnabulate at Rennselaer Polytechnic Institute, VistaMuse at University of California San Diego and SoundWIRE at Stanford University. I conducted in this performance using the signing language Soundpainting. The paper outlines descriptions of the pieces and perspectives on telematic performance practice in areas such as attention modalities, audio and video delay, communication technology and the process of creating, rehearsing and performing in the medium.\nMark Dresser. E-mail: .\nIn fall 2007, three university-based telematic ensembles located on two coasts joined forces to co-produce a concert. The rehearsals used state-of-the-art software and a high-bandwidth network. In addition to the weekly rehearsals, a variety of consumer-level software was utilized, each with its particular tempo of communication. Three different types of structured improvisations were created, each with a conductor using the signing language Soundpainting. Surprising artistic and social dimensions emerged. The concert was evaluated on technical, administrative and artistic levels by all the participants as well as by local, remote and virtual audiences.\nJefferson Pitcher. E-mail: .\nYears ago, before the widespread use of Internet communication technologies, my closest friend moved to Greece, while I remained in California. After many months of letter-writing, we began sending audiotapes back and forth as a means of staying more connected. Eventually, we had the idea of recording these tapes at the same exact time an attempt at erasing the physical distance between us. Through the lens of this experience with breaking the time-space continuum, I examine the profound impact and immediacy of co-located performance and its ability to generate great humanity in people whose lives are lived in different parts of the world.\nJonas Braasch. E-mail: .\nThis paper focuses on the technological aspects of distributed music performances over the Internet, which have recently gained popularity. Although software exists to establish broadband telematic connections, current systems typically do not address the specific needs for distributed music performances. Three of the main existing challenges—insufficient bandwidth, transmission latency and echo feedback—are described here with their current solutions. In the paper, the telematic transmission scheme is treated as a musical instrument, allowing the comparison of current developments to the historic development of acoustical musical instruments such as the piano, and its influence on music traditions.","author":[{"family":"Oliveros","given":"Pauline"},{"family":"Weaver","given":"Sarah"},{"family":"Dresser","given":"Mark"},{"family":"Pitcher","given":"Jefferson"},{"family":"Braasch","given":"Jonas"},{"family":"Chafe","given":"Chris"}],"citation-key":"oliverosTelematicMusicSix2009","container-title":"Leonardo Music Journal","container-title-short":"Leonardo Music Journal","issued":{"date-parts":[["2009",1,1]]},"page":"95-96","title":"Telematic Music: Six Perspectives","type":"article-journal","volume":"19"},{"id":"olszewskiFamiliarMelodyRecognition2005","author":[{"family":"Olszewski","given":"Carol"},{"family":"Gfeller","given":"Kate"},{"family":"Froman","given":"Rebecca"},{"family":"Stordahl","given":"Julie"},{"family":"Tomblin","given":"Bruce"}],"citation-key":"olszewskiFamiliarMelodyRecognition2005","container-title":"Cochlear Implants International","container-title-short":"Cochlear Implants International","ISSN":"1467-0100","issue":"3","issued":{"date-parts":[["2005"]]},"page":"123-140","publisher":"Taylor & Francis","title":"Familiar Melody Recognition by Children and Adults Using Cochlear Implants and Normal Hearing Children","type":"article-journal","volume":"6"},{"id":"omara-evesTechniquesIdentifyingCrossdisciplinary2013","accessed":{"date-parts":[["2024",9,9]]},"author":[{"family":"O'Mara-Eves","given":"Alison"},{"family":"Brunton","given":"Ginny"},{"family":"McDaid","given":"David"},{"family":"Kavanagh","given":"Josephine"},{"family":"Oliver","given":"Sandy"},{"family":"Thomas","given":"James"}],"citation-key":"omara-evesTechniquesIdentifyingCrossdisciplinary2013","container-title":"Research Synthesis Methods","container-title-short":"Res. Syn. Meth.","DOI":"10.1002/jrsm.1094","ISSN":"17592879","issue":"1","issued":{"date-parts":[["2013"]]},"language":"en","license":"http://doi.wiley.com/10.1002/tdm_license_1.1","page":"50-59","source":"DOI.org (Crossref)","title":"Techniques for identifying cross-disciplinary and ‘hard-to-detect’ evidence for systematic review: Identifying Hard-to-Detect Evidence","title-short":"Techniques for identifying cross-disciplinary and ‘hard-to-detect’ evidence for systematic review","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1094","volume":"5"},{"id":"onsemiconducterInputDynamicRange2009","author":[{"literal":"ON Semiconducter"}],"citation-key":"onsemiconducterInputDynamicRange2009","issued":{"date-parts":[["2009"]]},"title":"Input Dynamic Range Extension of the Ezairo 5900 Series. Application Note AND8387/D (Rev 0)","type":"document"},{"id":"optitrackSkeletonTracking2022","accessed":{"date-parts":[["2023",7,10]]},"author":[{"literal":"OptiTrack"}],"citation-key":"optitrackSkeletonTracking2022","container-title":"OptiTrack Documentation","issued":{"date-parts":[["2022",11,18]]},"title":"Skeleton Tracking","type":"webpage","URL":"https://docs.optitrack.com/motive/skeleton-tracking"},{"id":"oramasMultimodalDeepLearning2018","accessed":{"date-parts":[["2024",8,19]]},"author":[{"family":"Oramas","given":"Sergio"},{"family":"Barbieri","given":"Francesco"},{"family":"Nieto","given":"Oriol"},{"family":"Serra","given":"Xavier"}],"citation-key":"oramasMultimodalDeepLearning2018","container-title":"Transactions of the International Society for Music Information Retrieval","DOI":"10.5334/tismir.10","ISSN":"2514-3298","issue":"1","issued":{"date-parts":[["2018",9,4]]},"language":"en","license":"http://creativecommons.org/licenses/by/4.0","page":"4-21","source":"DOI.org (Crossref)","title":"Multimodal Deep Learning for Music Genre Classification","type":"article-journal","URL":"http://transactions.ismir.net/articles/10.5334/tismir.10/","volume":"1"},{"id":"oreillyVodafoneGroupBrand2013","accessed":{"date-parts":[["2021",1,27]]},"author":[{"family":"O'Reilly","given":"Lara"}],"citation-key":"oreillyVodafoneGroupBrand2013","container-title":"MarketingWeek","issued":{"date-parts":[["2013",12,9]]},"title":"Vodafone Group brand director on becoming known as a ‘firsts’ company","type":"webpage","URL":"https://www.marketingweek.com/vodafone-group-brand-director-on-becoming-known-as-a-firsts-company/"},{"id":"otterbeinDanceMovementledResearch2022","abstract":"Movement research and practice in the context of wearable technologies and human-computer interaction (HCI) shifts the design paradigm to the lived body. Human movement is characterized by sense, intention and expressiveness. Designing HCI from this standpoint opens up new possibilities to make computational devices and applications more accessible and integrated. This work presents an iterative, collaborative, and cross-disciplinary approach using wearable sensor bands in an open-ended performative exploration in exchange with a professional dancer. The goal is to understand the benefits and challenges of using movement-centered tools originating from dance practice and movement research and how they might feed back into the design, development and evaluation process of embodied technologies to improve human-computer interactions. Movement analysis systems and motion computation models are reviewed and leveraged in an interactive audiovisual system, with focus on using force-sensing resistors for low-level motion descriptors and Laban Movement Analysis for higher-level movement features. The artistic methodology, which combines practice and research, results, discussion of the iterative and collaborative process, and the final system architecture are the main topics presented in the paper.","author":[{"family":"Otterbein","given":"Robin"},{"family":"Jochum","given":"Elizabeth"},{"family":"Overholt","given":"Daniel"},{"family":"Bai","given":"Shaoping"},{"family":"Dalsgaard","given":"Alex"}],"citation-key":"otterbeinDanceMovementledResearch2022","collection-title":"MOCO '22","container-title":"Proceedings of the 8th international conference on movement and computing","DOI":"10.1145/3537972.3537984","event-place":"Chicago, IL, USA","ISBN":"978-1-4503-8716-3","issued":{"date-parts":[["2022"]]},"number-of-pages":"9","publisher":"Association for Computing Machinery","publisher-place":"Chicago, IL, USA","title":"Dance and movement-led research for designing and evaluating wearable human-computer interfaces","type":"paper-conference","URL":"https://doi.org/10.1145/3537972.3537984"},{"id":"owensComposersWorkCraft1998","author":[{"family":"Owens","given":"Jessie Ann"}],"citation-key":"owensComposersWorkCraft1998","edition":"1. issued as paperback","event-place":"New York, NY","ISBN":"978-0-19-512904-5 978-0-19-509577-7","issued":{"date-parts":[["1998"]]},"language":"eng","note":"OCLC: 248490908","number-of-pages":"345","publisher":"Oxford Univ. Press","publisher-place":"New York, NY","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"Composers at Work: the Craft of Musical Composition 1450 - 1600","title-short":"Composers at work","type":"book"},{"id":"oyallon-koloskiEnhancingFilmChoreography2022","abstract":"Cinematography—aspect ratios, framing, and camera movement, especially—plays an essential role in film choreography. However, the camera’s capacity to expand the aesthetics of dance on film and contribute to the dynamism of figure movement is limited. In commercial (profit-oriented) cinematic practice, this limitation is bounded by the physical properties of the equipment, accessibility issues, limited time and financing for stylistic experimentation, and institutional memory loss of cinematic choreography techniques. The result in much of contemporary commercial dance on film is an emphasis on multi-camera coverage, tighter framings, and the use of editing to guide the dynamism of the figure movement in lieu of an emphasis on the relationship between the camera and the body. In this paper, we present theoretical frameworks and motion-capture driven utilities that empower the filmic choreographer beyond traditional, physical limits of the medium. We do so by providing digital representations and interactions using abstracted, artificial systems mimicking the live camera-dancer relationship that prioritize cinematic agency and movement as the principal subject material. This development parallels the growth of previsualization and camera motion control in the field of visual effects, linking us conceptually to existing industrial paradigms. Our initial foray into the expansion of this agency defines a progressive development of filmic choreography, escaping narrow limits of the traditional medium and provoking a more inclusive, accessible, and empowered form of creation through novel access of conventionally unmeasurable capability.","author":[{"family":"Oyallon-Koloski","given":"Jenny"},{"family":"Junokas","given":"Michael"}],"citation-key":"oyallon-koloskiEnhancingFilmChoreography2022","collection-title":"MOCO '22","container-title":"Proceedings of the 8th international conference on movement and computing","DOI":"10.1145/3537972.3537990","event-place":"Chicago, IL, USA","ISBN":"978-1-4503-8716-3","issued":{"date-parts":[["2022"]]},"number-of-pages":"5","publisher":"Association for Computing Machinery","publisher-place":"Chicago, IL, USA","title":"Enhancing film choreography through digital representation of camera movement and agency","type":"paper-conference","URL":"https://doi.org/10.1145/3537972.3537990"},{"id":"paddenDeafAmericaVoices1988","author":[{"family":"Padden","given":"Carol"},{"family":"Humphries","given":"Tom"}],"citation-key":"paddenDeafAmericaVoices1988","event-place":"Cambridge, Mass.","ISBN":"978-0-674-19424-3 978-0-674-19423-6","issued":{"date-parts":[["1988"]]},"language":"eng","note":"OCLC: 260169744","number-of-pages":"134","publisher":"Harvard University Press","publisher-place":"Cambridge, Mass.","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"Deaf in America: Voices from a Culture","title-short":"Deaf in America","type":"book"},{"id":"paddenDeafCulture2005","author":[{"family":"Padden","given":"Carol"},{"family":"Humphries","given":"Tom"}],"citation-key":"paddenDeafCulture2005","event-place":"Cambridge, Mass.","ISBN":"978-0-674-02252-2","issued":{"date-parts":[["2005"]]},"language":"eng","number-of-pages":"208","publisher":"Harvard University Press","publisher-place":"Cambridge, Mass.","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"Inside Deaf Culture","type":"book"},{"id":"paddenGrammarSpaceTwo2010","accessed":{"date-parts":[["2021",1,10]]},"author":[{"family":"Padden","given":"Carol"},{"family":"Meir","given":"Irit"},{"family":"Aronoff","given":"Mark"},{"family":"Sandler","given":"Wendy"}],"citation-key":"paddenGrammarSpaceTwo2010","issued":{"date-parts":[["2010"]]},"number-of-pages":"37","publisher":"na","title":"The Grammar of Space in Two New Sign Languages","type":"book","URL":"http://quote.ucsd.edu/padden/files/2013/01/Grammar-of-space.pdf"},{"id":"pagePRISMA2020Statement2021","accessed":{"date-parts":[["2024",12,10]]},"author":[{"family":"Page","given":"Matthew J."},{"family":"McKenzie","given":"Joanne E."},{"family":"Bossuyt","given":"Patrick M."},{"family":"Boutron","given":"Isabelle"},{"family":"Hoffmann","given":"Tammy C."},{"family":"Mulrow","given":"Cynthia D."},{"family":"Shamseer","given":"Larissa"},{"family":"Tetzlaff","given":"Jennifer M."},{"family":"Akl","given":"Elie A."},{"family":"Brennan","given":"Sue E."},{"family":"Chou","given":"Roger"},{"family":"Glanville","given":"Julie"},{"family":"Grimshaw","given":"Jeremy M."},{"family":"Hróbjartsson","given":"Asbjørn"},{"family":"Lalu","given":"Manoj M."},{"family":"Li","given":"Tianjing"},{"family":"Loder","given":"Elizabeth W."},{"family":"Mayo-Wilson","given":"Evan"},{"family":"McDonald","given":"Steve"},{"family":"McGuinness","given":"Luke A."},{"family":"Stewart","given":"Lesley A."},{"family":"Thomas","given":"James"},{"family":"Tricco","given":"Andrea C."},{"family":"Welch","given":"Vivian A."},{"family":"Whiting","given":"Penny"},{"family":"Moher","given":"David"}],"citation-key":"pagePRISMA2020Statement2021","container-title":"Systematic Reviews","container-title-short":"Syst Rev","DOI":"10.1186/s13643-021-01626-4","ISSN":"2046-4053","issue":"1","issued":{"date-parts":[["2021",3,29]]},"language":"en","page":"89","source":"Springer Link","title":"The PRISMA 2020 statement: an updated guideline for reporting systematic reviews","title-short":"The PRISMA 2020 statement","type":"article-journal","URL":"https://doi.org/10.1186/s13643-021-01626-4","volume":"10"},{"id":"pajala-assefaStudyMovementsoundExtended2019","abstract":"Skeleton Conductor (SC) is a cross-disciplinary research and development project that aims towards a new immersive and interactive VR experience, which positions the perceiver and one's body as an active agent within the virtual realm while creating and interacting with the displayed sensorial input in a head mounted display (HMD). We share the current state of the Skeleton Conductor project and reflect to the many research and technology development-geared questions this project has brought us to. The aim of the practice work is to present preliminary results from our user experience target groups and to reflect upon some of the key research areas which aim to explore the significance of embodied experience. We plan to further define the modes and characteristics of full body real-time interactivity within this virtual environment. In practical terms this would mean setting up a VR device (HTC Vive) and to allow a participant to enter the SC experience, while other participants watch this experience from a large monitor or video projector. With this practice-based work, we hope to enable knowledge exchange and feedback from our peers, artists and other researchers.","author":[{"family":"Pajala-Assefa","given":"Hanna"},{"family":"Erkut","given":"Cumhur"}],"citation-key":"pajala-assefaStudyMovementsoundExtended2019","collection-title":"MOCO '19","container-title":"Proceedings of the 6th international conference on movement and computing","DOI":"10.1145/3347122.3359604","event-place":"Tempe, AZ, USA","ISBN":"978-1-4503-7654-9","issued":{"date-parts":[["2019"]]},"number-of-pages":"4","publisher":"Association for Computing Machinery","publisher-place":"Tempe, AZ, USA","title":"A study of movement-sound within extended reality: Skeleton conductor","type":"paper-conference","URL":"https://doi.org/10.1145/3347122.3359604"},{"id":"pakrasiDesignMethodologyAbstracting2018","abstract":"Given the increase in robotic systems for the household, it is imperative to design the expressive modes of these systems, that in turn engender likability, animacy, acceptance, and trust. This paper approaches this problem by proposing a design methodology that can be used to abstract archetypal characters across the system, including form factor, user instructions, and interactive modalities. This approach uses Laban Movement Analysis paired with the Kansei Engineering iterative design approach to dissect movement and visual traits of archetypal characters and marry them to features of the robot. These character traits are explored in a product, channel, consumer framework and are realized through interface elements, such as color, animated eyes, and character specific motion profiles. Finally, the use of priming using familiar characters from popular culture as a means to enhance the recognition of character traits is explored. Results show that users associated traits specific to each character archetype that were consistent with the intended design and that an aggregate measure of interaction success went up with character priming. This was bolstered in the priming cases, where users rated these traits more strongly. Thus, this methodology serves as a tool to create meaningful design variations to robotic systems using character archetypes, allowing us to design user-specific personality traits and interactive elements.","author":[{"family":"Pakrasi","given":"Ishaan"},{"family":"Chakraborty","given":"Novoneel"},{"family":"LaViers","given":"Amy"}],"citation-key":"pakrasiDesignMethodologyAbstracting2018","collection-title":"MOCO '18","container-title":"Proceedings of the 5th international conference on movement and computing","DOI":"10.1145/3212721.3212809","event-place":"Genoa, Italy","ISBN":"978-1-4503-6504-8","issued":{"date-parts":[["2018"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Genoa, Italy","title":"A design methodology for abstracting character archetypes onto robotic systems","type":"paper-conference","URL":"https://doi.org/10.1145/3212721.3212809"},{"id":"palacioPianoampDancerInteractionDancer2017","abstract":"Piano&amp;Dancer is an interactive piece for a dancer and an electromechanical acoustic piano. The piece presents the dancer and the piano as two performers on stage whose bodily movements are mutually interdependent. This interdependence reveals a close relationship between physical and musical gestures. Accordingly, the realisation of the piece has been based on creative processes that merge choreographic and compositional methods. In order to relate the expressive movement qualities of a dancer to the creation of musical material, the piece employs a variety of techniques. These include methods for movement tracking and feature analysis, generative algorithms for creating musical structures, and the application of non-conventional scales and chord transformations to shape the modal characteristics of the music. The publication contextualises Piano&amp;Dancer by relating its creation to concepts of embodiment, interactivity and musical structure and by discussing opportunities for creative cross-fertilisation between dance choreography and musical composition. It also provides some details about the challenges and potentials of integrating a mechanical musical instrument into an interactive setting for a dance performance. Finally, the paper highlights some of the technical and aesthetic principles that were used in order to connect expressive qualities of body movements to the creation of music structures.","author":[{"family":"Palacio","given":"Pablo"},{"family":"Bisig","given":"Daniel"}],"citation-key":"palacioPianoampDancerInteractionDancer2017","collection-title":"MOCO '17","container-title":"Proceedings of the 4th international conference on movement computing","DOI":"10.1145/3077981.3078052","event-place":"London, United Kingdom","ISBN":"978-1-4503-5209-3","issued":{"date-parts":[["2017"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"London, United Kingdom","title":"Piano&amp;Dancer: Interaction between a dancer and an acoustic instrument","type":"paper-conference","URL":"https://doi.org/10.1145/3077981.3078052"},{"id":"palmerComparisonTwoHearing1995","author":[{"family":"Palmer","given":"Catherine V."},{"family":"Killion","given":"Mead C."},{"family":"Wilber","given":"Laura A."},{"family":"Ballad","given":"William J."}],"citation-key":"palmerComparisonTwoHearing1995","container-title":"Ear and hearing","container-title-short":"Ear and hearing","ISSN":"0196-0202","issue":"6","issued":{"date-parts":[["1995"]]},"page":"587-598","publisher":"Baltimore, Williams & Wilkins.","title":"Comparison of Two Hearing Aid Receiver-Amplifier Combinations Using Sound Quality Judgments","type":"article-journal","volume":"16"},{"id":"papadopoulouMovementNotationDigital2016","abstract":"UPDATED—9 June 2016. This paper presents some of the aspects from the creative process leading to the multimedia dance performance 'as far as abstract objects' ('afaao'). The creation of that stage work was at the same time an extensive experimental transdisciplinary research, a laboratory for movement analysis and movement composition. In particular, this paper will elaborate on the relation and collaboration between two of the fields involved, movement notation and media art. In 'afaao' fundamental principles from movement notation were paired with possibilities from modern media technology. The common ground they shared was the transformation process that movement undergoes when working with notation as well as when working with media art. The objective of this collaboration was to explore the complex phenomenon of movement and to create a work of art that would communicate the research revelations in a visually engaging way with the audience, offering alternative views on the movement's dynamic structures.","author":[{"family":"Papadopoulou","given":"Foteini"},{"family":"Schulte","given":"Martin"}],"citation-key":"papadopoulouMovementNotationDigital2016","collection-title":"MOCO '16","container-title":"Proceedings of the 3rd international symposium on movement and computing","DOI":"10.1145/2948910.2948929","event-place":"Thessaloniki, GA, Greece","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016"]]},"number-of-pages":"7","publisher":"Association for Computing Machinery","publisher-place":"Thessaloniki, GA, Greece","title":"Movement notation and digital media art in the contemporary dance practice: Aspects of the making of a multimedia dance performance","type":"paper-conference","URL":"https://doi.org/10.1145/2948910.2948929"},{"id":"paradisoElectronicMusicNew1997","author":[{"family":"Paradiso","given":"J.A."}],"citation-key":"paradisoElectronicMusicNew1997","container-title":"IEEE Spectrum","DOI":"10.1109/6.642965","issue":"12","issued":{"date-parts":[["1997"]]},"page":"18-30","title":"Electronic music: new ways to play","type":"article-journal","volume":"34"},{"id":"paraorchestraParaorchestra2021","accessed":{"date-parts":[["2021",1,18]]},"author":[{"literal":"Paraorchestra"}],"citation-key":"paraorchestraParaorchestra2021","container-title":"Paraorchestra","issued":{"date-parts":[["2021"]]},"title":"About Paraorchestra","type":"webpage","URL":"http://paraorchestra.com/about/"},{"id":"paraschiakosActivityRecognitionUsing2020","abstract":"A population group that is often overlooked in the recent revolution of self-tracking is the group of older people. This growing proportion of the general population is often faced with increasing health issues and discomfort. In order to come up with lifestyle advice towards the elderly, we need the ability to quantify their lifestyle, before and after an intervention. This research focuses on the task of activity recognition (AR) from accelerometer data. With that aim, we collect a substantial labelled dataset of older individuals wearing multiple devices simultaneously and performing a strict protocol of 16 activities (the GOTOV dataset, $$N=28$$). Using this dataset, we trained Random Forest AR models, under varying sensor set-ups and levels of activity description granularity. The model that combines ankle and wrist accelerometers (GENEActiv) produced the best results (accuracy $$>80\\%$$) for 16-class classification. At the same time, when additional physiological information is used, the accuracy increased ($$>85\\%$$). To further investigate the role of granularity in our predictions, we developed the LARA algorithm, which uses a hierarchical ontology that captures prior biological knowledge to increase or decrease the level of activity granularity (merge classes). As a result, a 12-class model in which the different paces of walking were merged showed a performance above $$93\\%$$. Testing this 12-class model in labelled free-living pilot data, the mean balanced accuracy appeared to be reasonably high, while using the LARA algorithm, we show that a 7-class model (lying down, sitting, standing, household, walking, cycling, jumping) was optimal for accuracy and granularity. Finally, we demonstrate the use of the latter model in unlabelled free-living data from a larger lifestyle intervention study. In this paper, we make the validation data as well as the derived prediction models available to the community.","author":[{"family":"Paraschiakos","given":"Stylianos"},{"family":"Cachucho","given":"Ricardo"},{"family":"Moed","given":"Matthijs"},{"family":"Heemst","given":"Diana","non-dropping-particle":"van"},{"family":"Mooijaart","given":"Simon"},{"family":"Slagboom","given":"Eline P."},{"family":"Knobbe","given":"Arno"},{"family":"Beekman","given":"Marian"}],"citation-key":"paraschiakosActivityRecognitionUsing2020","container-title":"User Modeling and User-Adapted Interaction","container-title-short":"User Modeling and User-Adapted Interaction","DOI":"10.1007/s11257-020-09268-2","ISSN":"1573-1391","issue":"3","issued":{"date-parts":[["2020",7,1]]},"page":"567-605","title":"Activity recognition using wearable sensors for tracking the elderly","type":"article-journal","URL":"https://doi.org/10.1007/s11257-020-09268-2","volume":"30"},{"id":"paraschiakosRecurrentNeuralNetwork2022","abstract":"Through the quantification of physical activity energy expenditure (PAEE), health care monitoring has the potential to stimulate vital and healthy ageing, inducing behavioural changes in older people and linking these to personal health gains. To be able to measure PAEE in a health care perspective, methods from wearable accelerometers have been developed, however, mainly targeted towards younger people. Since elderly subjects differ in energy requirements and range of physical activities, the current models may not be suitable for estimating PAEE among the elderly. Furthermore, currently available methods seem to be either simple but non-generalizable or require elaborate (manual) feature construction steps. Because past activities influence present PAEE, we propose a modeling approach known for its ability to model sequential data, the recurrent neural network (RNN). To train the RNN for an elderly population, we used the growing old together validation (GOTOV) dataset with 34 healthy participants of 60 years and older (mean 65 years old), performing 16 different activities. We used accelerometers placed on wrist and ankle, and measurements of energy counts by means of indirect calorimetry. After optimization, we propose an architecture consisting of an RNN with 3 GRU layers and a feedforward network combining both accelerometer and participant-level data. Our efforts included switching mean to standard deviation for down-sampling the input data and combining temporal and static data (person-specific details such as age, weight, BMI). The resulting architecture produces accurate PAEE estimations while decreasing training input and time by a factor of 10. Subsequently, compared to the state-of-the-art, it is capable to integrate longer activity data which lead to more accurate estimations of low intensity activities EE. It can thus be employed to investigate associations of PAEE with vitality parameters of older people related to metabolic and cognitive health and mental well-being.","author":[{"family":"Paraschiakos","given":"Stylianos"},{"family":"Sá","given":"Cláudio Rebelo","non-dropping-particle":"de"},{"family":"Okai","given":"Jeremiah"},{"family":"Slagboom","given":"P. Eline"},{"family":"Beekman","given":"Marian"},{"family":"Knobbe","given":"Arno"}],"citation-key":"paraschiakosRecurrentNeuralNetwork2022","container-title":"Data Mining and Knowledge Discovery","container-title-short":"Data Mining and Knowledge Discovery","DOI":"10.1007/s10618-021-00817-w","ISSN":"1573-756X","issue":"1","issued":{"date-parts":[["2022",1,1]]},"page":"477-512","title":"A recurrent neural network architecture to model physical activity energy expenditure in older people","type":"article-journal","URL":"https://doi.org/10.1007/s10618-021-00817-w","volume":"36"},{"id":"parkAutomaticGlossaryExtraction2002","author":[{"family":"Park","given":"Youngja"},{"family":"Byrd","given":"Roy J"},{"family":"Boguraev","given":"Branimir"}],"citation-key":"parkAutomaticGlossaryExtraction2002","container-title":"Proceedings of the 19th international conference on computational linguistics","event-title":"COLING","issued":{"date-parts":[["2002"]]},"page":"1-7","publisher":"Association for Computational Linguistics","title":"Automatic glossary extraction: Beyond terminology identification.","type":"paper-conference","volume":"10"},{"id":"parker-starbuckCyborgTheatreCorporeal2011","abstract":"Introduction : why cyborg theatre? -- Backspace : historical/theoretical intersections -- Shifting the balance : \"abject\" bodies -- \"Object of control\" : framing the fragments -- Entering the view : triangulating \"subject\" bodies -- Conclusion : remembering bodies, becoming-cyborg.","author":[{"family":"Parker-Starbuck","given":"Jennifer"}],"citation-key":"parker-starbuckCyborgTheatreCorporeal2011","event-place":"Houndmills, Basingstoke, Hampshire; New York","ISBN":"978-0-230-30652-3","issued":{"date-parts":[["2011"]]},"language":"English","note":"OCLC: 903286910","publisher":"Palgrave Macmillan","publisher-place":"Houndmills, Basingstoke, Hampshire; New York","source":"Open WorldCat","title":"Cyborg Theatre: Corporeal/Technological Intersections in Multimedia Performance","title-short":"Cyborg Theatre","type":"book"},{"id":"parker-starbuckCyborgTheatreCorporeal2014","abstract":"Investigates the role of bodies within the expanding field of multimedia performance. This innovative study articulates the first theoretical context for a \"cyborg theatre\" that metaphorically integrates onstage bodies with the technologized, digitized, or mediatized, to radically reimagine subjectivity in our posthuman age. The author covers a variety of provocative examples, both historical and contemporary, to propose new theoretical tools for understanding performance in our changing world. She offers a compelling feminist-inspired argument for the ways in which a range of bodies appearing onstage with new technologies serve to challenge notions of identity and destabilize historical binaries. Through a variety of critical lenses, she considers the ways in which bodies are already integrated with technology and the questions this raises in and through performance. The focus on the body is a necessary theorizing of this emergent field, which is often understood solely through the technology on stage.","author":[{"family":"Parker-Starbuck","given":"Jennifer"}],"citation-key":"parker-starbuckCyborgTheatreCorporeal2014","ISBN":"978-1-137-46641-9 978-0-230-24583-9","issued":{"date-parts":[["2014"]]},"language":"English","note":"OCLC: 881859388","source":"Open WorldCat","title":"Cyborg Theatre: Corporeal/Technological Intersections in Multimedia Performance","title-short":"Cyborg Theatre","type":"book"},{"id":"parker-starbuckShiftingStrengthsCyborg2005","author":[{"family":"Parker-Starbuck","given":"Jennifer"}],"call-number":"PN1590.H36 B63 2005","citation-key":"parker-starbuckShiftingStrengthsCyborg2005","collection-title":"Corporealities","container-title":"Bodies in Commotion: Disability & Performance","editor":[{"family":"Sandahl","given":"Carrie"},{"family":"Auslander","given":"Philip"}],"event-place":"Ann Arbor","ISBN":"978-0-472-09891-0 978-0-472-06891-3","issued":{"date-parts":[["2005"]]},"page":"95 - 108","publisher":"University of Michigan Press","publisher-place":"Ann Arbor","source":"Library of Congress ISBN","title":"Shifting Strengths: The Cyborg Theater of Cathy Weis","type":"chapter"},{"id":"pavlovychTradeoffSpatialJitter2009","accessed":{"date-parts":[["2023",12,7]]},"author":[{"family":"Pavlovych","given":"Andriy"},{"family":"Stuerzlinger","given":"Wolfgang"}],"citation-key":"pavlovychTradeoffSpatialJitter2009","container-title":"Proceedings of the 1st ACM SIGCHI symposium on Engineering interactive computing systems","DOI":"10.1145/1570433.1570469","event-place":"Pittsburgh PA USA","event-title":"EICS'09: Engineering Interactive Computing Systems","ISBN":"978-1-60558-600-7","issued":{"date-parts":[["2009",7,15]]},"language":"en","page":"187-196","publisher":"ACM","publisher-place":"Pittsburgh PA USA","source":"DOI.org (Crossref)","title":"The tradeoff between spatial jitter and latency in pointing tasks","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/1570433.1570469"},{"id":"pearsonsSpeechLevelsVarious1977","author":[{"family":"Pearsons","given":"K. S."},{"family":"Bennett","given":"R. L."},{"family":"Fidell","given":"S."}],"citation-key":"pearsonsSpeechLevelsVarious1977","event-place":"Washington, DC","issued":{"date-parts":[["1977"]]},"number":"EPA-600/1-77-025","publisher":"U.S. Environmental Protection Agency","publisher-place":"Washington, DC","title":"Speech Levels in various environments","type":"report"},{"id":"pedregosaScikitlearnMachineLearning2011","author":[{"family":"Pedregosa","given":"Fabian"},{"family":"Varoquaux","given":"Gaël"},{"family":"Gramfort","given":"Alexandre"},{"family":"Michel","given":"Vincent"},{"family":"Thirion","given":"Bertrand"},{"family":"Grisel","given":"Olivier"},{"family":"Blondel","given":"Mathieu"},{"family":"Prettenhofer","given":"Peter"},{"family":"Weiss","given":"Ron"},{"family":"Dubourg","given":"Vincent"},{"family":"Vanderplas","given":"Jake"},{"family":"Passos","given":"Alexandre"},{"family":"Cournapeau","given":"David"},{"family":"Brucher","given":"Matthieu"},{"family":"Perrot","given":"Matthieu"},{"family":"Duchesnay","given":"Édouard"}],"citation-key":"pedregosaScikitlearnMachineLearning2011","container-title":"Journal of Machine Learning Research","issue":"85","issued":{"date-parts":[["2011"]]},"page":"2825-2830","title":"Scikit-learn: Machine learning in python","type":"article-journal","URL":"http://jmlr.org/papers/v12/pedregosa11a.html","volume":"12"},{"id":"penasCorpusbasedTerminologyExtraction2001","author":[{"family":"Peñas","given":"Anselmo"},{"family":"Verdejo","given":"Felisa"},{"family":"Gonzalo","given":"Julio"}],"citation-key":"penasCorpusbasedTerminologyExtraction2001","event-title":"Proceedings of corpus linguistics","issued":{"date-parts":[["2001"]]},"page":"458","title":"Corpus-based terminology extraction applied to information access","type":"paper-conference","volume":"2001"},{"id":"penleyTechnoculture1991","abstract":"Case studies of groups including high-tech office workers, Star trek fans, Japanese technoporn producers, teenage hackers, AIDS activists, rap groups, and rock stars yield insights about the production and management of repressive technocultures, as well as new possibilities for the encouragement of technoliteracy, a requirement for the democratization of social communication. Annotation copyrighted by Book News, Inc., Portland, OR.","author":[{"family":"Penley","given":"Constance"},{"family":"Ross","given":"Andrew"}],"citation-key":"penleyTechnoculture1991","ISBN":"978-0-8166-8371-0 978-0-8166-1932-0","issued":{"date-parts":[["1991"]]},"language":"English","note":"OCLC: 704577634","source":"Open WorldCat","title":"Technoculture","type":"book"},{"id":"perlmutterWhatSignLanguage","accessed":{"date-parts":[["2020",10,3]]},"author":[{"family":"Perlmutter","given":"David M."}],"citation-key":"perlmutterWhatSignLanguage","container-title":"Linguistic Society of America","language":"English","title":"What is Sign Language?","type":"webpage","URL":"https://www.linguisticsociety.org/content/what-sign-language"},{"id":"petersBodilyExpressionElectronic2013","author":[{"family":"Peters","given":"Deniz"}],"citation-key":"petersBodilyExpressionElectronic2013","event-place":"London","ISBN":"978-0-415-74571-0","issued":{"date-parts":[["2013"]]},"language":"English","note":"OCLC: 870170264","publisher":"Taylor & Francis","publisher-place":"London","source":"Open WorldCat","title":"Bodily Expression in Electronic Music: Perspectives on Reclaiming Performativity","title-short":"Bodily expression in electronic music","type":"book"},{"id":"petersHomeDanceMediacy2009","accessed":{"date-parts":[["2021",1,9]]},"author":[{"family":"Peters","given":"Kathrin"},{"family":"Seier","given":"Andrea"}],"citation-key":"petersHomeDanceMediacy2009","container-title":"The YouTube Reader","container-title-short":"The YouTube Reader","issued":{"date-parts":[["2009"]]},"page":"187-203","publisher":"National Library of Sweden Stockholm","title":"Home dance: Mediacy and Aesthetics of the Self on YouTube","type":"article-journal","URL":"https://d1wqtxts1xzle7.cloudfront.net/37900199/HomeDancePeters_Seier.pdf?1434221398=&response-content-disposition=inline%3B+filename%3DHome_Dance_Aesthetics_of_the_Self_on_You.pdf&Expires=1610286758&Signature=BWv45FlR1gHgMT9PsK1QjKe8PeCzyRP21sphvqK~oA~AMXmTZEftcB6fOS1no4l0xPt7RDIW8acnUlC0x9HXkYUMiIZ~-x9jPMhjBKC5XQOCDvvY5XBaF-hELsGS8-6sKOeG8Hj8v7WrPxeJVz6QGBC6S9zr7hWAGKUU0nzId30--RBQAlXRPD7i3sglfEo8SrXFnl~ztBPSFKFLsW0pGppy9unvah8XA9FSp1Exg7OdvJU49nq4rAFfz3siEKprlWdEOgshX1nIf1ne-CjmkMnXI4sKdqx4Z04hDO-MlbbZTXDoZIpKrAUW29JyzaatDSTLB9y9vr52Z5LZA7psRQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA"},{"id":"petitmenginDescribingOneSubjective2006","accessed":{"date-parts":[["2023",11,1]]},"author":[{"family":"Petitmengin","given":"Claire"}],"citation-key":"petitmenginDescribingOneSubjective2006","container-title":"Phenomenology and the Cognitive Sciences","container-title-short":"Phenom Cogn Sci","DOI":"10.1007/s11097-006-9022-2","ISSN":"1568-7759, 1572-8676","issue":"3-4","issued":{"date-parts":[["2006",12,7]]},"language":"en","page":"229-269","source":"DOI.org (Crossref)","title":"Describing one’s subjective experience in the second person: An interview method for the science of consciousness","title-short":"Describing one’s subjective experience in the second person","type":"article-journal","URL":"http://link.springer.com/10.1007/s11097-006-9022-2","volume":"5"},{"id":"petryMuSSBitsSensorDisplayBlocks2016","abstract":"Hearing loss makes learning a musical instrument a challenging task. Prior work suggests that a universal sensory substitution system that works uniformly across all deaf users may not exist given the diversity within the deaf community. In this paper, we present Music Sensory Substitution (MuSS) Bits, wireless sensor-display pairs that enable exploration of musical sound as well as customization of visual and vibrotactile feedback to cater to individual requirements and preferences. MuSS-Bits are portable, easy to deploy on the user's body, on an instrument, or in the environment, and provide real-time feedback. We review existing music sensory substitution systems, discuss the design space for MuSS-Bits, present details of a prototypical implementation and illustrate interaction possibilities including initial user reactions.","author":[{"family":"Petry","given":"Benjamin"},{"family":"Illandara","given":"Thavishi"},{"family":"Nanayakkara","given":"Suranga"}],"citation-key":"petryMuSSBitsSensorDisplayBlocks2016","collection-title":"OzCHI '16","container-title":"Proceedings of the 28th Australian Conference on Computer-Human Interaction","DOI":"10.1145/3010915.3010939","event-place":"Launceston, Tasmania, Australia","ISBN":"978-1-4503-4618-4","issued":{"date-parts":[["2016"]]},"page":"72–80","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","title":"MuSS-Bits: Sensor-Display Blocks for Deaf People to Explore Musical Sounds","type":"paper-conference","URL":"https://doi.org/10.1145/3010915.3010939"},{"id":"pettanDeColonizationHeritageAdvocacy2019","call-number":"ML3799.2 .D4 2019","citation-key":"pettanDeColonizationHeritageAdvocacy2019","collection-title":"Oxford handbooks","editor":[{"family":"Pettan","given":"Svanibor"},{"family":"Titon","given":"Jeff Todd"}],"event-place":"New York, NY","ISBN":"978-0-19-088573-1","issued":{"date-parts":[["2019"]]},"number-of-pages":"346","publisher":"Oxford University Press","publisher-place":"New York, NY","source":"Library of Congress ISBN","title":"De-Colonization, Heritage, & Advocacy: An Oxford Handbook of Applied Ethnomusicology, Volume 2","title-short":"De-colonization, heritage, & advocacy","type":"book"},{"id":"pettanOxfordHandbookApplied2015","call-number":"ML3799.2 .O94 2015","citation-key":"pettanOxfordHandbookApplied2015","editor":[{"family":"Pettan","given":"Svanibor"},{"family":"Titon","given":"Jeff Todd"}],"event-place":"Oxford ; New York","ISBN":"978-0-19-935170-1","issued":{"date-parts":[["2015"]]},"number-of-pages":"836","publisher":"Oxford University Press","publisher-place":"Oxford ; New York","source":"Library of Congress ISBN","title":"The Oxford Handbook of Applied Ethnomusicology","type":"book"},{"id":"pfauNonmanualsTheirProsodic2010","author":[{"family":"Pfau","given":"Roland"},{"family":"Quer","given":"Josep"}],"citation-key":"pfauNonmanualsTheirProsodic2010","container-title":"Sign languages","issued":{"date-parts":[["2010"]]},"page":"381-402","publisher":"Cambridge University Press Cambridge","title":"Nonmanuals: Their Prosodic and Grammatical Roles","type":"chapter"},{"id":"phamPyaudioPortaudioV192006","author":[{"family":"Pham","given":"Hubert"}],"citation-key":"phamPyaudioPortaudioV192006","container-title":"URL: https://people. csail. mit. edu/hubert/pyaudio","container-title-short":"URL: https://people. csail. mit. edu/hubert/pyaudio","issued":{"date-parts":[["2006"]]},"title":"Pyaudio: Portaudio v19 python bindings","type":"article-journal"},{"id":"phillipsExploringMixHistorical2016","author":[{"family":"Phillips","given":"Martyn"}],"call-number":"ML3790 .H492 2017","citation-key":"phillipsExploringMixHistorical2016","collection-title":"Perspectives on music production","editor":[{"family":"Hepworth-Sawyer","given":"Russ"},{"family":"Hodgson","given":"Jay"}],"event-place":"New York ; London","ISBN":"978-1-138-18204-2 978-1-138-21873-4","issued":{"date-parts":[["2016"]]},"number-of-pages":"8-23","publisher":"Routledge","publisher-place":"New York ; London","source":"Library of Congress ISBN","title":"Exploring of the Mix: Historical milestones and expanded perspectives","type":"book"},{"id":"phonosAlmostNewPlaces2013","accessed":{"date-parts":[["2021",1,27]]},"author":[{"literal":"Phonos"}],"citation-key":"phonosAlmostNewPlaces2013","container-title":"YouTube","issued":{"date-parts":[["2013",2,21]]},"title":"Almost New Places by Sergio Naddei","type":"webpage","URL":"https://www.youtube.com/watch?v=nNM8uFg38XE"},{"id":"phonosAlmostNewSpaces2013","accessed":{"date-parts":[["2021",1,27]]},"author":[{"literal":"Phonos"}],"citation-key":"phonosAlmostNewSpaces2013","container-title":"YouTube","issued":{"date-parts":[["2013",2,21]]},"title":"Almost New Spaces by Sergio Naddei","type":"webpage","URL":"https://www.youtube.com/watch?v=LkcMWBKObZs"},{"id":"pianaMultimodalRepositoryExpressive2016","abstract":"In this paper, we present a new multimodal repository for the analysis of expressive movement qualities in dance. First, we discuss guidelines and methodology that we applied to create this repository. Next, the technical setup of recordings and the platform for capturing the synchronized audio-visual, physiological, and motion capture data are presented. The initial content of the repository consists of about 90 minutes of short dance performances movement sequences, and improvisations performed by four dancers, displaying three expressive qualities: Fluidity, Impulsivity, and Rigidity.","author":[{"family":"Piana","given":"Stefano"},{"family":"Coletta","given":"Paolo"},{"family":"Ghisio","given":"Simone"},{"family":"Niewiadomski","given":"Radoslaw"},{"family":"Mancini","given":"Maurizio"},{"family":"Sagoleo","given":"Roberto"},{"family":"Volpe","given":"Gualtiero"},{"family":"Camurri","given":"Antonio"}],"citation-key":"pianaMultimodalRepositoryExpressive2016","collection-title":"MOCO '16","container-title":"Proceedings of the 3rd international symposium on movement and computing","DOI":"10.1145/2948910.2948931","event-place":"Thessaloniki, GA, Greece","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Thessaloniki, GA, Greece","title":"Towards a multimodal repository of expressive movement qualities in dance","type":"paper-conference","URL":"https://doi.org/10.1145/2948910.2948931"},{"id":"piekutActorNetworksMusicHistory2014","author":[{"family":"Piekut","given":"Benjamin"}],"citation-key":"piekutActorNetworksMusicHistory2014","container-title":"Twentieth-Century Music","container-title-short":"Twentieth-Century Music","DOI":"10.1017/S147857221400005X","issued":{"date-parts":[["2014",9,1]]},"page":"191-215","title":"Actor-Networks in Music History: Clarifications and Critiques","type":"article-journal","volume":"11"},{"id":"pinknewsSaaraAltoSic2016","accessed":{"date-parts":[["2021",1,7]]},"author":[{"literal":"Pink News"}],"citation-key":"pinknewsSaaraAltoSic2016","container-title":"Pink News","issued":{"date-parts":[["2016",12,23]]},"title":"Saara Alto [sic] opens up about her sexuality as she poses in stunning new photo shoot","type":"webpage","URL":"https://www.pinknews.co.uk/2016/12/23/saara-alto-opens-up-about-her-sexuality-as-she-poses-in-stunning-new-photo-shoot/"},{"id":"pipinellisGitHubEssentialsUnleash2015","author":[{"family":"Pipinellis","given":"Achilleas"}],"citation-key":"pipinellisGitHubEssentialsUnleash2015","event-place":"Birmingham Mumbai","ISBN":"978-1-78355-371-6","issued":{"date-parts":[["2015"]]},"language":"eng","number-of-pages":"168","publisher":"Packt Publishing","publisher-place":"Birmingham Mumbai","source":"K10plus ISBN","title":"GitHub essentials: unleash the power of collaborative workflow development using GitHub, one step at a time","title-short":"GitHub essentials","type":"book"},{"id":"pisnerSupportVectorMachine2020","accessed":{"date-parts":[["2023",11,28]]},"author":[{"family":"Pisner","given":"Derek A."},{"family":"Schnyer","given":"David M."}],"citation-key":"pisnerSupportVectorMachine2020","container-title":"Machine Learning","DOI":"10.1016/B978-0-12-815739-8.00006-7","ISBN":"978-0-12-815739-8","issued":{"date-parts":[["2020"]]},"language":"en","page":"101-121","publisher":"Elsevier","source":"DOI.org (Crossref)","title":"Support vector machine","type":"chapter","URL":"https://linkinghub.elsevier.com/retrieve/pii/B9780128157398000067"},{"id":"plaeteABBAVoyageHigh2022","accessed":{"date-parts":[["2023",9,19]]},"author":[{"family":"Plaete","given":"Jo"},{"family":"Bradley","given":"Derek"},{"family":"Warner","given":"Paige"},{"family":"Zwartouw","given":"Anthony"}],"citation-key":"plaeteABBAVoyageHigh2022","container-title":"Special Interest Group on Computer Graphics and Interactive Techniques Conference Talks","DOI":"10.1145/3532836.3536260","event-place":"Vancouver BC Canada","event-title":"SIGGRAPH '22: Special Interest Group on Computer Graphics and Interactive Techniques Conference","ISBN":"978-1-4503-9371-3","issued":{"date-parts":[["2022",8,7]]},"language":"en","page":"1-2","publisher":"ACM","publisher-place":"Vancouver BC Canada","source":"DOI.org (Crossref)","title":"ABBA Voyage: High Volume Facial Likeness and Performance Pipeline","title-short":"ABBA Voyage","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3532836.3536260"},{"id":"plaeteABBAVoyageHigh2022a","abstract":"For the ABBA: Voyage concert experience, Industrial Light & Magic (ILM) was tasked with digitally time traveling the iconic band′s members Agnetha, Anni-Frida, Björn and Benny back to their prime time appearances. For the duration of this fully computer graphics generated concert four continuous photo-real digital human facial performances had to be synthesised driven by their original current day counterparts and stand-in young actors. This talk will dive into the extensive research and development that was undertaken to cater for high volume facial capture and processing, true-to-likeness face-retargeting and additional techniques for breaking through the uncanny valley.","author":[{"family":"Plaete","given":"Jo"},{"family":"Bradley","given":"Derek"},{"family":"Warner","given":"Paige"},{"family":"Zwartouw","given":"Anthony"}],"citation-key":"plaeteABBAVoyageHigh2022a","collection-title":"SIGGRAPH '22","container-title":"ACM SIGGRAPH 2022 talks","DOI":"10.1145/3532836.3536260","event-place":"Vancouver, BC, Canada","ISBN":"978-1-4503-9371-3","issued":{"date-parts":[["2022"]]},"number-of-pages":"2","publisher":"Association for Computing Machinery","publisher-place":"Vancouver, BC, Canada","title":"ABBA voyage: High volume facial likeness and performance pipeline","type":"paper-conference","URL":"https://doi.org/10.1145/3532836.3536260"},{"id":"poepelInterfaceExpressivityPlayerBased2005","abstract":"While many new interfaces for musical expression have been presented in the past, methods to evaluate these interfaces are rare.This paper presents a method and a study comparing the potentialfor musical expression of different string-instrument based musicalinterfaces. Cues for musical expression are defined based on results of research in musical expression and on methods for musicaleducation in instrumental pedagogy. Interfaces are evaluated according to how well they are estimated to allow players making useof their existing technique for the creation of expressive music.","accessed":{"date-parts":[["2023",1,20]]},"author":[{"family":"Poepel","given":"Cornelius"}],"citation-key":"poepelInterfaceExpressivityPlayerBased2005","DOI":"10.5281/ZENODO.1176802","issued":{"date-parts":[["2005",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"On Interface Expressivity: A Player-Based Study","title-short":"On Interface Expressivity","type":"article-journal","URL":"https://zenodo.org/record/1176802"},{"id":"pohlmannYouSpinMe2023","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Pöhlmann","given":"Katharina Margareta Theresa"},{"family":"Li","given":"Gang"},{"family":"Mcgill","given":"Mark"},{"family":"Markoff","given":"Reuben"},{"family":"Brewster","given":"Stephen Anthony"}],"citation-key":"pohlmannYouSpinMe2023","container-title":"Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems","DOI":"10.1145/3544548.3580966","event-place":"Hamburg Germany","event-title":"CHI '23: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-9421-5","issued":{"date-parts":[["2023",4,19]]},"language":"en","page":"1-16","publisher":"ACM","publisher-place":"Hamburg Germany","source":"DOI.org (Crossref)","title":"You spin me right round, baby, right round: Examining the Impact of Multi-Sensory Self-Motion Cues on Motion Sickness During a VR Reading Task","title-short":"You spin me right round, baby, right round","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3544548.3580966"},{"id":"pointalOsc4py3","accessed":{"date-parts":[["2022",5,12]]},"author":[{"family":"Pointal","given":"Laurent"}],"citation-key":"pointalOsc4py3","title":"osc4py3","type":"software","URL":"https://sourcesup.renater.fr/scm/viewvc.php/osc4py3/","version":"1.0.7"},{"id":"polakDjembeDanceMultimodalRhythm2023","accessed":{"date-parts":[["2023",12,23]]},"author":[{"family":"Polak","given":"Rainer"}],"citation-key":"polakDjembeDanceMultimodalRhythm2023","issued":{"date-parts":[["2023",11,29]]},"title":"DjembeDance: Multimodal rhythm in music and dance from West Africa","type":"document","URL":"https://www.uio.no/ritmo/english/projects/djembedance/djembedance_revised-project-description.pdf"},{"id":"popelkaHearingAids2016","abstract":"This volume will serve as the first Handbook of its kind in the area of hearing aid research, often the least-defined, least-understood, part of the multi-disciplinary research process. Most scientific training is very advanced within the particular disciplines but provides little opportunity for systematic introduction to the issues and obstacles that prevent effective hearing-aid related research. This area has emerged as one of critical importance, as signified by a single specialized meeting (the International Hearing Aid Conference, IHCON) that brings together specialists from the disparate disciplines involved, including both university and industry researchers. Identification of the key steps that enable high-impact basic science to ultimately result in significant clinical advances that improve patient outcome is critical. This volume will provide an overview of current key issues in hearing aid research from the perspective of many different disciplines, not only from the perspective of the key funding agencies, but also from the scientists and clinicians who are currently involved in hearing aid research. It will offer insight into the experience, current technology and future technology that can help improve hearing aids, as scientists and clinicians typically have little or no formal training over the whole range of the individual disciplines that are relevant. The selection and coverage of topics insures that it will have lasting impact, well beyond immediate, short-term, or parochial concerns.","accessed":{"date-parts":[["2021",1,20]]},"citation-key":"popelkaHearingAids2016","collection-number":"56","collection-title":"Springer Handbook of Auditory Research","editor":[{"family":"Popelka","given":"Gerald R."},{"family":"Moore","given":"Brian C. J."},{"family":"Fay","given":"Richard R."},{"family":"Popper","given":"Arthur N."}],"event-place":"Cham","ISBN":"978-3-319-33036-5","issued":{"date-parts":[["2016"]]},"language":"English","note":"OCLC: 984801900","publisher":"Springer International Publishing : Imprint : Springer","publisher-place":"Cham","source":"Open WorldCat","title":"Hearing Aids","type":"book","URL":"https://doi.org/10.1007/978-3-319-33036-5"},{"id":"poutaraudMetaEmbeddedClusteringMEC2024","abstract":"In recent years, ecoacoustics has offered an alternative to traditional biodiversity monitoring techniques with the development of passive acoustic monitoring (PAM) systems allowing, among others, to detect and identify species that are difficult to detect by human observers, automatically. PAM systems typically generate large audio datasets, but using these monitoring techniques to infer ecologically meaningful information remains challenging. In most cases, several thousand hours of recordings need to be manually labeled by experts limiting the operability of the systems. Based on recent developments of meta-learning algorithms and unsupervised learning techniques, we propose here Meta-Embedded Clustering (MEC), a new method with high potential for improving clustering quality in unlabeled bird sound datasets. MEC method is organized in two main steps, with: (a) fine-tuning of a pretrained convolutional neural network (CNN) backbone with different meta-learning algorithms using pseudo-labeled data, and (b) clustering of manually-labeled bird sounds in the latent space based on vector embeddings extracted from the fine-tuned CNN. The MEC method significantly enhanced average clustering performance from less than 1% to more than 80%, greatly outperforming the traditional approach of relying solely on CNN features extracted from a general neotropical audio database. However, this enhanced performance came with the cost of excluding a portion of the data categorized as noise. By improving the quality of clustering in unlabeled bird sound datasets, the MEC method should facilitate the work of ecoacousticians in managing acoustic units of bird song/call clustered according to their similarities, and in identifying potential clusters of species undetected using traditional approaches.","author":[{"family":"Poutaraud","given":"Joachim"},{"family":"Sueur","given":"Jérôme"},{"family":"Thébaud","given":"Christophe"},{"family":"Haupert","given":"Sylvain"}],"citation-key":"poutaraudMetaEmbeddedClusteringMEC2024","container-title":"Ecological Informatics","container-title-short":"Ecological Informatics","DOI":"10.1016/j.ecoinf.2024.102687","ISSN":"1574-9541","issued":{"date-parts":[["2024",9,1]]},"page":"102687","title":"Meta-Embedded Clustering (MEC): A new method for improving clustering quality in unlabeled bird sound datasets","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S1574954124002292","volume":"82"},{"id":"powerCharacterAnimationEmbodied2008","abstract":"This interdisciplinary investigation of aspects of 3D character animation synthesizes relevant research findings from diverse perspectives, including neuroscience, narratology, robotics, anthropology, cognitive psychology and philosophy of mind, and considers how they might be integrated as theory for animators and animation studies. The article focuses on the creative nature of character conception and creation in a 3D animated environment and on aspects of character ? narrative and style, in particular. It examines how findings from interdisciplinary research on the embodied mind?brain, including neuroscientific research with regard to mentalizing and simulation theory, can inform the creative animation process and might be gainfully synthesized in an animation studies context to inform both pedagogy and creative practice.","accessed":{"date-parts":[["2023",10,27]]},"author":[{"family":"Power","given":"Patrick"}],"citation-key":"powerCharacterAnimationEmbodied2008","container-title":"Animation","container-title-short":"Animation","DOI":"10.1177/1746847708088734","ISSN":"1746-8477","issue":"1","issued":{"date-parts":[["2008",3,1]]},"page":"25-48","publisher":"SAGE Publications","title":"Character Animation and the Embodied Mind—Brain","type":"article-journal","URL":"https://doi.org/10.1177/1746847708088734","volume":"3"},{"id":"pozdniakovHowTeachersUse2023","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Pozdniakov","given":"Stanislav"},{"family":"Martinez-Maldonado","given":"Roberto"},{"family":"Tsai","given":"Yi-Shan"},{"family":"Echeverria","given":"Vanessa"},{"family":"Srivastava","given":"Namrata"},{"family":"Gasevic","given":"Dragan"}],"citation-key":"pozdniakovHowTeachersUse2023","container-title":"LAK23: 13th International Learning Analytics and Knowledge Conference","DOI":"10.1145/3576050.3576063","event-place":"Arlington TX USA","event-title":"LAK 2023: 13th International Learning Analytics and Knowledge Conference","ISBN":"978-1-4503-9865-7","issued":{"date-parts":[["2023",3,13]]},"language":"en","page":"89-99","publisher":"ACM","publisher-place":"Arlington TX USA","source":"DOI.org (Crossref)","title":"How Do Teachers Use Dashboards Enhanced with Data Storytelling Elements According to their Data Visualisation Literacy Skills?","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3576050.3576063"},{"id":"pratzlichMemoryrestrictedMultiscaleDynamic2016","author":[{"family":"Prätzlich","given":"Thomas"},{"family":"Driedger","given":"Jonathan"},{"family":"Müller","given":"Meinard"}],"citation-key":"pratzlichMemoryrestrictedMultiscaleDynamic2016","container-title":"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","container-title-short":"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","DOI":"10.1109/ICASSP.2016.7471739","event-title":"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","ISBN":"2379-190X","issued":{"date-parts":[["2016",3,20],["2016",3,25]]},"page":"569-573","title":"Memory-restricted multiscale dynamic time warping","type":"paper-conference"},{"id":"proakisDigitalSignalProcessing2014","author":[{"family":"Proakis","given":"John G."},{"family":"Manolakis","given":"Dimitris G."}],"citation-key":"proakisDigitalSignalProcessing2014","collection-title":"Always learning","edition":"Fourth edition, Pearson new international edition","event-place":"Harlow","ISBN":"978-1-292-02573-5","issued":{"date-parts":[["2014"]]},"language":"eng","number-of-pages":"1013","publisher":"Pearson Education Limited","publisher-place":"Harlow","source":"K10plus ISBN","title":"Digital signal processing","type":"book"},{"id":"proakisDigitalSignalProcessing2021","abstract":"\"This book was developed based on our teaching of undergraduate- and graduate-level courses in digital signal processing over the past several years. In this book, we present the fundamentals of discrete-time signals, systems, and modern digital processing as well as applications for students in electrical engineering, computer engineering, and computer science. The book is suitable for either a one-semester or a two-semester undergraduate-level course in discrete systems and digital signal processing. It is also intended for use in a one-semester first-year graduate-level course in digital signal processing\"--","author":[{"family":"Proakis","given":"John G."},{"family":"Manolakis","given":"Dimitris G."}],"call-number":"TK5102.9 .P757 2021","citation-key":"proakisDigitalSignalProcessing2021","edition":"Fifth edition","event-place":"Hoboken, NJ","ISBN":"978-0-13-734861-9 978-0-13-734824-4","issued":{"date-parts":[["2021"]]},"publisher":"Pearson Education","publisher-place":"Hoboken, NJ","source":"Library of Congress ISBN","title":"Digital signal processing","type":"book"},{"id":"puckettePureData","accessed":{"date-parts":[["2022",5,12]]},"author":[{"family":"Puckette","given":"Miller"}],"citation-key":"puckettePureData","title":"Pure Data","type":"software","URL":"https://puredata.info/","version":"0.52-1"},{"id":"purserBeingYourBody2017","abstract":"Sports studies is currently dominated by the intellectualist approach to understanding skill and expertise, meaning that questions about the phenomenological nature of skilled performance in sport have generally been overshadowed by the emphasis on the cognitive. By contrast, this article responds to calls for a phenomenology of sporting embodiment by opening up a philosophical exploration of the nature of athletic being-in-the-world. In particular, the paper explores the conceptualisation of immanence and transcendence in relation to the embodied practice of dance, engaging with Merleau-Ponty’s important insight that the body can be a source of transcendence. I also draw on data from in-depth qualitative interviews with professional contemporary dancers to explore dancers’ concepts of ‘being in your body’ and ‘being in the moment’, and to suggest that during the actual embodied practice of dance, dancers do not experience transcendence and immanence as they are conceptualised in philosophy. Rather, I argue, dancers experience a third mode of being that is somehow in-between these two binary terms. I have called this ‘inhabited transcendence’.","author":[{"family":"Purser","given":"Aimie C. E."}],"citation-key":"purserBeingYourBody2017","container-title":"Journal of the Philosophy of Sport","DOI":"10.1080/00948705.2017.1408018","issue":"1","issued":{"date-parts":[["2017"]]},"page":"37-52","publisher":"Routledge","title":"‘Being in your body’ and ‘being in the moment’: the dancing body-subject and inhabited transcendence","type":"article-journal","URL":"https://doi.org/10.1080/00948705.2017.1408018","volume":"45"},{"id":"Pygame","accessed":{"date-parts":[["2022",5,12]]},"citation-key":"Pygame","title":"pygame","type":"software","URL":"https://github.com/pygame/pygame/","version":"2.1.2"},{"id":"Pythonosc","accessed":{"date-parts":[["2022",5,12]]},"citation-key":"Pythonosc","title":"python-osc","type":"software","URL":"https://github.com/attwad/python-osc","version":"1.7.7"},{"id":"qinDomainGeneralizationActivity2022","abstract":"Human activity recognition requires the efforts to build a generalizable model using the training datasets with the hope to achieve good performance in test datasets. However, in real applications, the training and testing datasets may have totally different distributions due to various reasons such as different body shapes, acting styles, and habits, damaging the model’s generalization performance. While such a distribution gap can be reduced by existing domain adaptation approaches, they typically assume that the test data can be accessed in the training stage, which is not realistic. In this article, we consider a more practical and challenging scenario: domain-generalized activity recognition (DGAR) where the test dataset cannot be accessed during training. To this end, we propose Adaptive Feature Fusion for Activity Recognition&nbsp;(AFFAR), a domain generalization approach that learns to fuse the domain-invariant and domain-specific representations to improve the model’s generalization performance. AFFAR takes the best of both worlds where domain-invariant representations enhance the transferability across domains and domain-specific representations leverage the model discrimination power from each domain. Extensive experiments on three public HAR datasets show its effectiveness. Furthermore, we apply AFFAR to a real application, i.e., the diagnosis of Children’s Attention Deficit Hyperactivity Disorder&nbsp;(ADHD), which also demonstrates the superiority of our approach.","author":[{"family":"Qin","given":"Xin"},{"family":"Wang","given":"Jindong"},{"family":"Chen","given":"Yiqiang"},{"family":"Lu","given":"Wang"},{"family":"Jiang","given":"Xinlong"}],"citation-key":"qinDomainGeneralizationActivity2022","container-title":"ACM Transactions on Intelligent Systems and Technology","container-title-short":"ACM Trans. Intell. Syst. Technol.","DOI":"10.1145/3552434","event-place":"New York, NY, USA","ISSN":"2157-6904","issue":"1","issued":{"date-parts":[["2022",11]]},"number-of-pages":"21","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","title":"Domain generalization for activity recognition via adaptive feature fusion","type":"article-journal","URL":"https://doi.org/10.1145/3552434","volume":"14"},{"id":"qiuMultisensorInformationFusion2022","accessed":{"date-parts":[["2024",8,24]]},"author":[{"family":"Qiu","given":"Sen"},{"family":"Zhao","given":"Hongkai"},{"family":"Jiang","given":"Nan"},{"family":"Wang","given":"Zhelong"},{"family":"Liu","given":"Long"},{"family":"An","given":"Yi"},{"family":"Zhao","given":"Hongyu"},{"family":"Miao","given":"Xin"},{"family":"Liu","given":"Ruichen"},{"family":"Fortino","given":"Giancarlo"}],"citation-key":"qiuMultisensorInformationFusion2022","container-title":"Information Fusion","container-title-short":"Information Fusion","DOI":"10.1016/j.inffus.2021.11.006","ISSN":"15662535","issued":{"date-parts":[["2022",4]]},"language":"en","page":"241-265","source":"DOI.org (Crossref)","title":"Multi-sensor information fusion based on machine learning for real applications in human activity recognition: State-of-the-art and research challenges","title-short":"Multi-sensor information fusion based on machine learning for real applications in human activity recognition","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S1566253521002311","volume":"80"},{"id":"qualisysQualisysMarkerless2021","accessed":{"date-parts":[["2023",10,5]]},"author":[{"literal":"Qualisys"}],"citation-key":"qualisysQualisysMarkerless2021","issued":{"date-parts":[["2021",2,16]]},"publisher":"Qualisys","title":"Qualisys Markerless","type":"document","URL":"https://cdn-content.qualisys.com/2021/02/AN_Qualisys-Markerless.pdf"},{"id":"QualysisTrackManager2021","citation-key":"QualysisTrackManager2021","issued":{"date-parts":[["2021",1]]},"publisher":"Qualysis","title":"Qualysis Track Manager","type":"software","version":"2021.1"},{"id":"quigleyChoreomusicalInteractionsHierarchical2020","abstract":"[This article makes the case for an explicit ethno-choreomusicology. We propose a research methodology that deploys a set of complementary techniques: detailed formal analyses of specific choreomusical genres; analyses of features that link movement and sound articulation based on detailed sound and movement documentation of specific realisations; discourse analysis to reveal concepts that inform both music and dance ethnotheory and aesthetics; video-elicitation and guided interviews to bring forward participants’ movement and sound experience; ethnographic documentation to support analysis of social situations as choreomusical phenomena; oral history and narrative analysis of interview material to broaden the interpretations of choreomusical interaction beyond specific performance situations.]","accessed":{"date-parts":[["2023",12,21]]},"archive":"JSTOR","author":[{"family":"Quigley","given":"Colin"},{"family":"Mæland","given":"Siri"}],"citation-key":"quigleyChoreomusicalInteractionsHierarchical2020","container-title":"The World of Music","ISSN":"00438774","issue":"1","issued":{"date-parts":[["2020"]]},"page":"83-94","publisher":"[Florian Noetzel GmbH Verlag, VWB - Verlag für Wissenschaft und Bildung, Bärenreiter, Schott Music GmbH & Co. KG]","title":"Choreomusical Interactions, Hierarchical Structures, and Social Relations","type":"article-journal","URL":"https://www-jstor-org.ezproxy.uio.no/stable/26970256","volume":"9"},{"id":"quigleyPeasantDancersGypsy2020","abstract":"[This article looks back to dance and music practice in villages of the Transylvanian Plain throughout the long twentieth century in which the potential for conflict between Roma musicians and village dancers was carefully managed through long established customary practice. We apply an ethnochoreological approach to investigate the ways in which moments of choreomusical performance intimacy offer a possibility for social repositioning. The focus of previous studies has been on the formal analysis of music and dance in their own terms as parallel systems, only occasionally on the relationship of these to one another, and almost never on the production of social meaning in their joint performance. We aim to redress this imbalance, arguing that an ethno-choreomusical focus is needed to examine the complex field of social interaction among these groups, that informs these dance events]","accessed":{"date-parts":[["2023",12,21]]},"archive":"JSTOR","author":[{"family":"Quigley","given":"Colin"},{"family":"Varga","given":"Sándor"}],"citation-key":"quigleyPeasantDancersGypsy2020","container-title":"The World of Music","ISSN":"00438774","issue":"1","issued":{"date-parts":[["2020"]]},"page":"117-138","publisher":"[Florian Noetzel GmbH Verlag, VWB - Verlag für Wissenschaft und Bildung, Bärenreiter, Schott Music GmbH & Co. KG]","title":"Peasant Dancers and Gypsy Musicians","type":"article-journal","URL":"https://www-jstor-org.ezproxy.uio.no/stable/26970258","volume":"9"},{"id":"quinnMinimalChallengesProcess2006","author":[{"family":"Quinn","given":"Ian"}],"citation-key":"quinnMinimalChallengesProcess2006","container-title":"Contemporary Music Review","container-title-short":"Contemporary Music Review","ISSN":"0749-4467","issue":"3","issued":{"date-parts":[["2006"]]},"page":"283-294","publisher":"Taylor & Francis","title":"Minimal challenges: Process Music and the Uses of Formalist Analysis","type":"article-journal","volume":"25"},{"id":"rabinowIntroduction2020","author":[{"family":"Rabinow","given":"Paul"}],"citation-key":"rabinowIntroduction2020","container-title":"The Foucault Reader","event-place":"Place of publication not identified","ISBN":"978-0-241-43514-4","issued":{"date-parts":[["2020"]]},"language":"English","note":"OCLC: 1130361542","page":"3 -29","publisher":"Penguin Books","publisher-place":"Place of publication not identified","source":"Open WorldCat","title":"Introduction","type":"chapter"},{"id":"rajkoGeoculturalPrecaritiesCanonizing2022","abstract":"This paper conducts a thorough mapping study and rhetorical analysis of computing research involving dance. Research investigates: 1) who conducts computing research involving dance; 2) how dance is described in computing research publications; and 3) how geoculturally-specific forms of embodied dance knowledge become normalised over time. The study's publication corpus is extracted from the Association of Computing Machinery (ACM) Digital Library and includes 135 papers returned in a database query using the general keyword search term “dancer.” Results illustrate the geocultural specificity of computing research involving dance and identify rhetorical trends that treat embodied knowledge and methods deriving from western concert dance as the unofficial norm of dance-based movement expertise in computing contexts. The paper's summaries and discussion consider the effects treating embodied knowledge deriving from western concert dance as universally applicable across geoculturally diverse movement analysis efforts. Here, I particularly address the unintended erasure of embodied knowledge deriving from non-western dance forms and discuss what we might learn in terms of best practices from existing trends in computing research involving non-western dance forms.","author":[{"family":"Rajko","given":"Jessica"}],"citation-key":"rajkoGeoculturalPrecaritiesCanonizing2022","collection-title":"MOCO '22","container-title":"Proceedings of the 8th international conference on movement and computing","DOI":"10.1145/3537972.3537988","event-place":"Chicago, IL, USA","ISBN":"978-1-4503-8716-3","issued":{"date-parts":[["2022"]]},"number-of-pages":"14","publisher":"Association for Computing Machinery","publisher-place":"Chicago, IL, USA","title":"Geocultural precarities in canonizing computing research involving dance: The effects of treating western, EuroAmerican concert dance as universally applicable across geoculturally diverse movement computing research efforts","type":"paper-conference","URL":"https://doi.org/10.1145/3537972.3537988"},{"id":"ramachandranMotionCaptureAnisotropy1987","abstract":"Two uncorrelated random dot patterns were superimposed and alternated to produce dynamic incoherent noise. When a low spatial frequency sine wave grating was optically superimposed on this noise and moved in step with the alternation of the two frames, the incoherent motion was masked and all the dots were seen to adhere to the grating and to move with it as a single rigid sheet (“Motion Capture”). Over a wide range of displacements subjects could not discriminate uncorrelated noise which was “captured” from correlated noise patterns which moved physically in the same direction as the grating. In fact the motion signal from the low frequency grating was even strong enough to overcome signals from twocorrelated random dot patterns which moved in the opposite direction. Capture was not as strong if the direction of dot motion was orthogonal to the direction of grating motion. We conclude that in any dynamic visual scene the motion of certain salient features in the image tends to dominate our perceptual experience. The signal from low frequencies masks or inhibits the signal from the high frequencies. Since the latter now have no motion signal of their own they are assumed to move with the low frequencies. Thus, motion capture suggests an important biological role for long-range apparent motion: the process serves to preserve continuity of object identity while at the same time eliminating spurious motion signals that arise from finer image features. In this manner the visual system solves the “correspondence problem” without benefit from either computation or cognition.","author":[{"family":"Ramachandran","given":"V.S."},{"family":"Cavanagh","given":"Patrick"}],"citation-key":"ramachandranMotionCaptureAnisotropy1987","container-title":"Vision Research","container-title-short":"Vision Research","DOI":"10.1016/0042-6989(87)90146-5","ISSN":"0042-6989","issue":"1","issued":{"date-parts":[["1987",1,1]]},"page":"97-106","title":"Motion capture anisotropy","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/0042698987901465","volume":"27"},{"id":"ramsdenCochlearImplantsBrain2002","abstract":"This chapter describes the development of two implantable prosthetic neurostimulators which, in the last 20 years, have revolutionised the management of severe-to-profound sensorineural deafness. We have witnessed their rapid evolution from the realms of esoteric laboratory abstraction, with many critics and little perceived clinical use, to a routine treatment which is safe, effective and, indeed, cost effective. It is one of the great triumphs of biomedical and surgical collaboration, and is without any doubt the greatest ever advance in the treatment of deafness.","accessed":{"date-parts":[["2021",1,21]]},"author":[{"family":"Ramsden","given":"Richard T"}],"citation-key":"ramsdenCochlearImplantsBrain2002","container-title":"British Medical Bulletin","container-title-short":"British Medical Bulletin","DOI":"10.1093/bmb/63.1.183","ISSN":"0007-1420","issue":"1","issued":{"date-parts":[["2002",10,1]]},"page":"183-193","title":"Cochlear Implants and Brain Stem Implants","type":"article-journal","URL":"https://doi.org/10.1093/bmb/63.1.183","volume":"63"},{"id":"ranMultitaskLearningLaban2015","abstract":"This paper presents the results of a multitask learning method for recognition of Laban Movement Analysis (LMA) qualities from a markerless motion capture camera. LMA is a well-accepted method for describing, interpreting and documenting human movement which can be advantageous over kinematic description for capturing qualitative aspects as well as quantitative ones. Its specific language can be understood across disciplines. Thus, in recent years, LMA is increasingly becoming the preferred method for movement analysis. Many applications that use motion capture data might be significantly leveraged by automatic recognition of Laban Movement qualities. A data set of 550 video clips of different combinations of LMA qualities were recorded from markerless motion capture skeletal recordings demonstrated on the output of Microsoft's Kinect V2 sensor and on video. A sample of these clips were tagged by 2 Certified Movement Analysts as a multi-label training set to develop the Machine Learning (ML) algorithms. This approach obtained an improvement in recall and precision rate of about 60%— 4% more than single-task machine learning previous approach by Bertstein et al. on single-task learning, was validated by analysis of non trained people moving general actions. Results show improved handling of noisy sensory data with an in-home setup, a method for automatic recognition of markerless movement in different situations, postures and tasks, and moderate improvements in quantification of subtle qualities for which a well defined quantification had previously not been found.","author":[{"family":"Ran","given":"Bernstein"},{"family":"Tal","given":"Shafir"},{"family":"Rachelle","given":"Tsachor"},{"family":"Karen","given":"Studd"},{"family":"Assaf","given":"Schuster"}],"citation-key":"ranMultitaskLearningLaban2015","collection-title":"MOCO '15","container-title":"Proceedings of the 2nd international workshop on movement and computing","DOI":"10.1145/2790994.2791009","event-place":"Vancouver, British Columbia, Canada","ISBN":"978-1-4503-3457-0","issued":{"date-parts":[["2015"]]},"number-of-pages":"8","page":"37–44","publisher":"Association for Computing Machinery","publisher-place":"Vancouver, British Columbia, Canada","title":"Multitask learning for laban movement analysis","type":"paper-conference","URL":"https://doi.org/10.1145/2790994.2791009"},{"id":"ratanamahatanaEverythingYouKnow2004","author":[{"family":"Ratanamahatana","given":"Chotirat Ann"},{"family":"Keogh","given":"Eamonn"}],"citation-key":"ratanamahatanaEverythingYouKnow2004","event-title":"Third workshop on mining temporal and sequential data","issued":{"date-parts":[["2004"]]},"publisher":"Citeseer","title":"Everything you know about dynamic time warping is wrong","type":"paper-conference","volume":"32"},{"id":"ratanamahatanaMakingTimeseriesClassification2004","abstract":"Abstract It has long been known that Dynamic Time Warping (DTW) is superior to Euclidean distance for classification and clustering of time series. However, until lately, most research has utilized Euclidean distance because it is more efficiently calculated. A recently introduced technique that greatly mitigates DTWs demanding CPU time has sparked a flurry of research activity. However, the technique and its many extensions still only allow DTW to be applied to moderately large datasets. In addition, almost all of the research on DTW has focused exclusively on speeding up its calculation; there has been little work done on improving its accuracy. In this work, we target the accuracy aspect of DTW performance and introduce a new framework that learns arbitrary constraints on the warping path of the DTW calculation. Apart from improving the accuracy of classification, our technique as a side effect speeds up DTW by a wide margin as well. We show the utility of our approach on datasets from diverse domains and demonstrate significant gains in accuracy and efficiency.","accessed":{"date-parts":[["2023",3,30]]},"author":[{"family":"Ratanamahatana","given":"Chotirat Ann"},{"family":"Keogh","given":"Eamonn"}],"citation-key":"ratanamahatanaMakingTimeseriesClassification2004","collection-title":"Proceedings","container-title":"Proceedings of the 2004 SIAM International Conference on Data Mining (SDM)","DOI":"10.1137/1.9781611972740.2","ISBN":"978-0-89871-568-2","issued":{"date-parts":[["2004",4,22]]},"page":"11-22","publisher":"Society for Industrial and Applied Mathematics","title":"Making Time-series Classification More Accurate Using Learned Constraints","type":"paper-conference","URL":"https://doi.org/10.1137/1.9781611972740.2"},{"id":"ratcliffeHandFingerMotionControlled2014","abstract":"This paper presents a control surface interface for music mixing using real time computer vision. Two input sensors are considered: the Leap Motion and the Microsoft Kinect. The author presents significant design considerations, including improving of the user's sense of depth and panorama, maintaining broad accessibility by integrating the system with Digital Audio Workstation (DAW) software, and implementing a system that is portable and affordable. To provide the user with a heightened sense of sound spatialization over the traditional channel strip, the concept of depth is addressed directly using the stage metaphor. Sound sources are represented as colored spheres in a graphical user interface to provide the user with visual feedback. Moving sources back and forward controls volume, while left to right controls panning. To provide broader accessibility, the interface is configured to control mixing within the Ableton Live DAW. The author also discusses future plans to expand functionality and evaluate the system.","accessed":{"date-parts":[["2024",1,25]]},"author":[{"family":"Ratcliffe","given":"Jarrod"}],"citation-key":"ratcliffeHandFingerMotionControlled2014","container-title":"Proceedings of the International Conference on New Interfaces for Musical Expression","DOI":"10.5281/ZENODO.1178911","issued":{"date-parts":[["2014",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","page":"136--139","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"Hand And Finger Motion-Controlled Audio Mixing Interface","type":"paper-conference","URL":"https://zenodo.org/record/1178911"},{"id":"reich19EarlyWorks19652004","abstract":"This chapter presents Steve Reich's personal accounts about several of his early works. These include It's Gonna Rain (1965), Come Out (1966), Melodica (1966), Piano Phase (1967), Violin Phase (1967), Slow Motion Sound (1967), My Name Is (1967), and Pendulum Music (1968).","author":[{"family":"Reich","given":"Steve"}],"citation-key":"reich19EarlyWorks19652004","container-title":"Writings on Music 1965–2000: 1965-2000","DOI":"10.1093/acprof:oso/9780195151152.003.0002","ISBN":"978-0-19-515115-2","issued":{"date-parts":[["2004",10]]},"publisher":"Oxford University Press","title":"19Early Works (1965–68)","type":"chapter","URL":"https://doi.org/10.1093/acprof:oso/9780195151152.003.0002"},{"id":"reichWritingsMusic19652004","abstract":"In the mid-1960s, Steve Reich radically renewed the musical landscape with a back-to-basics sound that came to be called minimalism. These early works, characterized by a relentless pulse and static harmony, focused single-mindedly on the process of gradual rhythmic change. Throughout his career, Reich has continued to reinvigorate the music world, drawing from a wide array of classical, popular, sacred, and non-western idioms. His works reflect the steady evolution of an original musical mind. This book documents the creative journey of this thoughtful, groundbreaking composer. These sixty-four short pieces include Reich's 1968 essay “Music as a Gradual Process,” widely considered one of the most influential pieces of music theory in the second half of the 20th century. Subsequent essays, articles, and interviews treat Reich's early work with tape and phase shifting, showing its development into more recent work with speech melody and instrumental music. Other essays recount his exposure to non-western music—African drumming, Balinese gamelan, Hebrew cantillation—and the influence of these musics as structures and not as sounds. The writings include Reich's reactions to and appreciations of the works of his contemporaries (John Cage, Luciano Berio, Morton Feldman, Gyorgy Ligeti) and older influences (Kurt Weill, Schoenberg). Each major work of the composer's career is also explored through notes written for performances and recordings.","accessed":{"date-parts":[["2023",5,1]]},"author":[{"family":"Reich","given":"Steve"}],"citation-key":"reichWritingsMusic19652004","DOI":"10.1093/acprof:oso/9780195151152.001.0001","editor":[{"family":"Hillier","given":"Paul"}],"ISBN":"978-0-19-515115-2","issued":{"date-parts":[["2004",10,28]]},"publisher":"Oxford University Press","title":"Writings on Music 1965–2000: 1965-2000","type":"book","URL":"https://doi.org/10.1093/acprof:oso/9780195151152.001.0001"},{"id":"reillyBlendingArtEvents2014","abstract":"We present experiences as artists and Human-Computer Interaction (HCI) researchers exhibiting an interactive artwork called Tweetris at a public event, and its simultaneous research evaluation. We describe the unique opportunities a public art event offered for achieving our research goals, then discuss three key challenges we encountered: tensions between creative and research goals before the event, ethical considerations during the event and in analysis, and obstacles complicating subsequent evaluation as the work has evolved. We offer observations throughout that are important to consider when conducting HCI research at public art events.","author":[{"family":"Reilly","given":"Derek"},{"family":"Chevalier","given":"Fanny"},{"family":"Freeman","given":"Dustin"}],"citation-key":"reillyBlendingArtEvents2014","collection-title":"Springer Series on Cultural Computing","DOI":"10.1007/978-3-319-04510-8_11","event-place":"Cham","ISBN":"2195-9056","issued":{"date-parts":[["2014"]]},"page":"153-168","publisher":"Cham: Springer International Publishing","publisher-place":"Cham","title":"Blending Art Events and HCI Research","type":"chapter"},{"id":"renzoTechnologicallyMediatedTransparency2017","abstract":"AbstractThis article argues that several recent developments in popular music make the artist?s production process more transparent to listeners. By using loop pedals, by releasing the recorded stems of songs, or by uploading performative instructional videos on YouTube, producers ?reveal? techniques used during the production process. Such revelations partly deconstruct earlier concerns from rock fans regarding the (lack of) authenticity of particular musics. Furthermore, we argue that these developments have a history in earlier forms of popular music, such as the ?extended version? of 12-inch singles from the 1970s and 1980s. Here, songs were frequently stripped down to their core, making specific parts (and, by extension, specific arrangement techniques) more accessible to listeners.","author":[{"family":"Renzo","given":"Adrian"},{"family":"Collins","given":"Steve"}],"citation-key":"renzoTechnologicallyMediatedTransparency2017","container-title":"Popular Music and Society","container-title-short":"Popular Music and Society","DOI":"10.1080/03007766.2015.1121643","ISSN":"0300-7766","issue":"4","issued":{"date-parts":[["2017",8,8]]},"page":"406-421","publisher":"Routledge","title":"Technologically Mediated Transparency in Music Production","type":"article-journal","URL":"https://doi.org/10.1080/03007766.2015.1121643","volume":"40"},{"id":"revelleTangibleUserInterfaces2005","abstract":"Tangible user interfaces, which provide interactivity using real physical objects, hold enormous promise for children. Exploring and manipulating physical objects is a key component of young children's learning. The educational power of digital technology for children has typically been limited by the fact that users explore and manipulate abstract two-dimensional screen-based representations, and not real physical objects. Embedding interactivity into physical objects, therefore, allows the \"best of both worlds\" - supporting traditional exploratory play with physical objects that can be extended and enhanced by the interactive power of digital technology. Participants in this SIG are invited to share ideas regarding the design and development of tangible interfaces, and to bring demos or slides/videos showing work in this area. Participants will review as many examples as time allows, and discuss the issues surrounding design and development of such interfaces. A primary goal of this SIG is to foster the development of a community of researchers and practitioners who are focused on designing and developing tangible interfaces for children.","author":[{"family":"Revelle","given":"Glenda"},{"family":"Zuckerman","given":"Oren"},{"family":"Druin","given":"Allison"},{"family":"Bolas","given":"Mark"}],"citation-key":"revelleTangibleUserInterfaces2005","collection-title":"CHI EA '05","container-title":"CHI '05 Extended Abstracts on Human Factors in Computing Systems","DOI":"10.1145/1056808.1057095","event-place":"Portland, OR, USA","ISBN":"1-59593-002-7","issued":{"date-parts":[["2005"]]},"page":"2051–2052","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","title":"Tangible User Interfaces for Children","type":"paper-conference","URL":"https://doi.org/10.1145/1056808.1057095"},{"id":"reynoldsNormate2019","accessed":{"date-parts":[["2022",5,12]]},"author":[{"family":"Reynolds","given":"Joel Michael"}],"citation-key":"reynoldsNormate2019","container-title":"50 Concepts for a Critical Phenomenology","DOI":"10.2307/j.ctvmx3j22","editor":[{"family":"Weiss","given":"Gail"},{"family":"Murphy","given":"Ann V."},{"family":"Salamon","given":"Gayle"}],"ISBN":"978-0-8101-4116-2 978-0-8101-4115-5","issued":{"date-parts":[["2019",11,15]]},"page":"243-248","publisher":"Northwestern University Press","title":"The Normate","type":"chapter","URL":"http://www.jstor.org/stable/10.2307/j.ctvmx3j22"},{"id":"richardsonH264AdvancedVideo2010","abstract":"H.264 Advanced Video Coding or MPEG-4 Part 10 is fundamental to a growing range of markets such as high definition broadcasting, internet video sharing, mobile video and digital surveillance. This book reflects the growing importance and implementation of H.264 video technology. Offering a detailed overview of the system, it explains the syntax, tools and features of H.264 and equips readers with practical advice on how to get the most out of the standard. Packed with clear examples and illustrations to explain H.264 technology in an accessible and practical way. Covers basic video coding concepts, video formats and visual quality. Explains how to measure and optimise the performance of H.264 and how to balance bitrate, computation and video quality. Analyses recent work on scalable and multi-view versions of H.264, case studies of H.264 codecs and new technological developments such as the popular High Profile extensions. An invaluable companion for developers, broadcasters, system integrators, academics and students who want to master this burgeoning state-of-the-art technology. \"[This book] unravels the mysteries behind the latest H.264 standard and delves deeper into each of the operations in the codec. The reader can implement (simulate, design, evaluate, optimize) the codec with all profiles and levels. The book ends with extensions and directions (such as SVC and MVC) for further research.\" Professor K. R. Rao, The University of Texas at Arlington, co-inventor of the Discrete Cosine Transform","author":[{"family":"Richardson","given":"Iain E. G."}],"citation-key":"richardsonH264AdvancedVideo2010","edition":"2nd ed","event-place":"Hoboken, NJ","ISBN":"978-0-470-51692-8","issued":{"date-parts":[["2010"]]},"language":"eng","number-of-pages":"1","publisher":"Wiley","publisher-place":"Hoboken, NJ","source":"K10plus ISBN","title":"The H.264 advanced video compression standard","type":"book"},{"id":"riedelsheimerTouchSound2004","citation-key":"riedelsheimerTouchSound2004","dimensions":"1:39:00","director":[{"family":"Riedelsheimer","given":"Thomas"}],"issued":{"date-parts":[["2004",11,4]]},"publisher":"Piffl Medien GmbH","title":"Touch the Sound","type":"motion_picture"},{"id":"risoudSoundSourceLocalization2018","abstract":"Sound source localization is paramount for comfort of life, determining the position of a sound source in 3 dimensions: azimuth, height and distance. It is based on 3 types of cue: 2 binaural (interaural time difference and interaural level difference) and 1 monaural spectral cue (head-related transfer function). These are complementary and vary according to the acoustic characteristics of the incident sound. The objective of this report is to update the current state of knowledge on the physical basis of spatial sound localization.","author":[{"family":"Risoud","given":"M."},{"family":"Hanson","given":"J.-N."},{"family":"Gauvrit","given":"F."},{"family":"Renard","given":"C."},{"family":"Lemesre","given":"P.-E."},{"family":"Bonne","given":"N.-X."},{"family":"Vincent","given":"C."}],"citation-key":"risoudSoundSourceLocalization2018","container-title":"European Annals of Otorhinolaryngology, Head and Neck Diseases","container-title-short":"European Annals of Otorhinolaryngology, Head and Neck Diseases","DOI":"10.1016/j.anorl.2018.04.009","ISSN":"1879-7296","issue":"4","issued":{"date-parts":[["2018",8,1]]},"page":"259-264","title":"Sound source localization","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S187972961830067X","volume":"135"},{"id":"rizviMovementDesignVirtual2019","abstract":"As robots are progressively introduced in public spaces, it is crucial to develop systems that move appropriately to convey variable internal state and context responsiveness. In this paper, we present six variations of a virtual robot designed after characters from pop-culture. The motion of each character is examined using movement analysis techniques, and the appropriate features are designed for an aerial robot platform in virtual reality. This work is meant to be a foundation for future user studies that investigates how these robot movements are perceived by humans and if varying context changes that perception.","author":[{"family":"Rizvi","given":"Wali"},{"family":"LaViers","given":"Amy"},{"family":"Pakrasi","given":"Ishaan"}],"citation-key":"rizviMovementDesignVirtual2019","collection-title":"MOCO '19","container-title":"Proceedings of the 6th international conference on movement and computing","DOI":"10.1145/3347122.3359601","event-place":"Tempe, AZ, USA","ISBN":"978-1-4503-7654-9","issued":{"date-parts":[["2019"]]},"number-of-pages":"6","publisher":"Association for Computing Machinery","publisher-place":"Tempe, AZ, USA","title":"Movement design of virtual aerial robots with distinct affective labels","type":"paper-conference","URL":"https://doi.org/10.1145/3347122.3359601"},{"id":"roadsComputerMusicTutorial1996","author":[{"family":"Roads","given":"Curtis"}],"call-number":"MT56 .R6 1995","citation-key":"roadsComputerMusicTutorial1996","event-place":"Cambridge, Mass","ISBN":"978-0-262-18158-7 978-0-262-68082-0","issued":{"date-parts":[["1996"]]},"number-of-pages":"1234","publisher":"MIT Press","publisher-place":"Cambridge, Mass","source":"Library of Congress ISBN","title":"The computer music tutorial","type":"book"},{"id":"roadsMicrosound2004","author":[{"family":"Roads","given":"Curtis"}],"citation-key":"roadsMicrosound2004","ISBN":"0-262-68154-4","issued":{"date-parts":[["2004"]]},"publisher":"The MIT Press","title":"Microsound","type":"book"},{"id":"robertsHierarchicalVariationalAutoencoders2017","author":[{"family":"Roberts","given":"Adam"},{"family":"Engel","given":"Jesse"},{"family":"Eck","given":"Douglas"}],"citation-key":"robertsHierarchicalVariationalAutoencoders2017","event-title":"NIPS Workshop on Machine Learning for Creativity and Design","issued":{"date-parts":[["2017"]]},"title":"Hierarchical variational autoencoders for music","type":"paper-conference","volume":"3"},{"id":"robertsonRealtimeInteractiveMusical2006","author":[{"family":"Robertson","given":"AN"},{"family":"Plumbley","given":"MD"}],"citation-key":"robertsonRealtimeInteractiveMusical2006","container-title":"Proceedings of the Digital Music Research Network Doctoral Research Conference","event-title":"Proceedings of the Digital Music Research Network Doctoral Research Conference","issued":{"date-parts":[["2006"]]},"title":"Real-time interactive musical systems: An overview","type":"paper-conference"},{"id":"rosenboomBiofeedbackArtsResults1976","call-number":"BF319.5.B5 B555 1976","citation-key":"rosenboomBiofeedbackArtsResults1976","edition":"2d ed","editor":[{"family":"Rosenboom","given":"David"}],"event-place":"Vancouver, B.C","ISBN":"978-0-88985-002-6","issued":{"date-parts":[["1976"]]},"number-of-pages":"162","publisher":"Aesthetic Research Centre of Canada","publisher-place":"Vancouver, B.C","source":"Library of Congress ISBN","title":"Biofeedback and the arts, results of early experiments","type":"book"},{"id":"rosenVerdiRequiem1995","author":[{"family":"Rosen","given":"David"}],"call-number":"ML410.V4 R73 1995","citation-key":"rosenVerdiRequiem1995","collection-title":"Cambridge music handbooks","event-place":"Cambridge, [England] ; New York","ISBN":"978-0-521-39448-2 978-0-521-39767-4","issued":{"date-parts":[["1995"]]},"number-of-pages":"115","publisher":"Cambridge University Press","publisher-place":"Cambridge, [England] ; New York","source":"Library of Congress ISBN","title":"Verdi, Requiem","type":"book"},{"id":"rossettiStudyingPerceptionSound2020","accessed":{"date-parts":[["2021",11,29]]},"author":[{"family":"Rossetti","given":"Danilo"},{"family":"Manzolli","given":"Jônatas"}],"citation-key":"rossettiStudyingPerceptionSound2020","container-title":"OPUS","container-title-short":"OPUS - Rev. Elet. Anppom","DOI":"10.20504/opus2020b2610","ISSN":"15177017, 01037412","issue":"2","issued":{"date-parts":[["2020",10,1]]},"page":"1","source":"DOI.org (Crossref)","title":"Studying the Perception of Sound in Space: Granular Sounds Spatialized in a High-Order Ambisonics System","title-short":"Studying the Perception of Sound in Space","type":"article-journal","URL":"https://www.anppom.com.br/revista/index.php/opus/article/view/opus2020b2610","volume":"26"},{"id":"rossingScienceSound2014","author":[{"family":"Rossing","given":"Thomas D."},{"family":"Moore","given":"F. Richard"},{"family":"Wheeler","given":"Paul"}],"citation-key":"rossingScienceSound2014","collection-title":"Always Learning","edition":"3. ed., Pearson New Internat. ed","event-place":"Harlow","ISBN":"978-1-292-03957-2","issued":{"date-parts":[["2014"]]},"language":"eng","note":"OCLC: 931444258","number-of-pages":"764","publisher":"Pearson Education","publisher-place":"Harlow","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"The Science of Sound","type":"book"},{"id":"rowntreeStatisticsTearsIntroduction2018","author":[{"family":"Rowntree","given":"Derek"}],"citation-key":"rowntreeStatisticsTearsIntroduction2018","collection-title":"Penguin mathematics","edition":"Updated edition","event-place":"London","ISBN":"978-0-14-198749-1","issued":{"date-parts":[["2018"]]},"language":"eng","number-of-pages":"199","publisher":"Penguin Books","publisher-place":"London","source":"K10plus ISBN","title":"Statistics without tears: an introduction for non-mathematicians","title-short":"Statistics without tears","type":"book"},{"id":"roysterSoundExposuresHearing1991","author":[{"family":"Royster","given":"Julia Doswell"},{"family":"Royster","given":"Larry H"},{"family":"Killion","given":"Mead C"}],"citation-key":"roysterSoundExposuresHearing1991","container-title":"The Journal of the Acoustical Society of America","container-title-short":"The Journal of the Acoustical Society of America","ISSN":"0001-4966","issue":"6","issued":{"date-parts":[["1991"]]},"page":"2793-2803","publisher":"Acoustical Society of America","title":"Sound Exposures and Hearing Thresholds of Symphony Orchestra Musicians","type":"article-journal","volume":"89"},{"id":"ryanDigitalSignalProcessor2009","author":[{"family":"Ryan","given":"J"},{"family":"Tewari","given":"S"}],"citation-key":"ryanDigitalSignalProcessor2009","container-title":"Hearing Review","container-title-short":"Hearing Review","issue":"2","issued":{"date-parts":[["2009"]]},"page":"38-41","title":"A Digital Signal Processor for Musicians and Audiophiles","type":"article-journal","volume":"16"},{"id":"sakoeDynamicProgrammingAlgorithm1978","abstract":"This paper reports on an optimum dynamic progxamming (DP) based time-normalization algorithm for spoken word recognition. First, a general principle of time-normalization is given using time-warping function. Then, two time-normalized distance definitions, called symmetric and asymmetric forms, are derived from the principle. These two forms are compared with each other through theoretical discussions and experimental studies. The symmetric form algorithm superiority is established. A new technique, called slope constraint, is successfully introduced, in which the warping function slope is restricted so as to improve discrimination between words in different categories. The effective slope constraint characteristic is qualitatively analyzed, and the optimum slope constraint condition is determined through experiments. The optimized algorithm is then extensively subjected to experimental comparison with various DP-algorithms, previously applied to spoken word recognition by different research groups. The experiment shows that the present algorithm gives no more than about two-thirds errors, even compared to the best conventional algorithm.","author":[{"family":"Sakoe","given":"Hiroaki"},{"family":"Chiba","given":"Seibi"}],"citation-key":"sakoeDynamicProgrammingAlgorithm1978","container-title":"IEEE Transactions on Acoustics, Speech, and Signal Processing","container-title-short":"IEEE Transactions on Acoustics, Speech, and Signal Processing","DOI":"10.1109/TASSP.1978.1163055","ISSN":"0096-3518","issue":"1","issued":{"date-parts":[["1978",2]]},"page":"43-49","title":"Dynamic programming algorithm optimization for spoken word recognition","type":"article-journal","volume":"26"},{"id":"salvadorAccurateDynamicTime2007","abstract":"Dynamic Time Warping (DTW) has a quadratic time and space complexity that limits its use to small time series. In this paper we introduce FastDTW, an approximation of DTW that has a linear time and space complexity. FastDTW uses a multilevel approach that recursively projects a solution from a coarser resolution and refines the projected solution. We prove the linear time and space complexity of FastDTW both theoretically and empirically. We also analyze the accuracy of FastDTW by comparing it to two other types of existing approximate DTW algorithms: constraints (such as Sakoe-Chiba Bands) and abstraction. Our results show a large improvement in accuracy over existing methods.","author":[{"family":"Salvador","given":"Stan"},{"family":"Chan","given":"Philip"}],"citation-key":"salvadorAccurateDynamicTime2007","container-title":"Intelligent Data Analysis","DOI":"10.3233/IDA-2007-11508","ISSN":"1571-4128","issue":"5","issued":{"date-parts":[["2007"]]},"page":"561-580","publisher":"IOS Press","title":"Toward accurate dynamic time warping in linear time and space","type":"article-journal","volume":"11"},{"id":"sanchez-colbergAlteredStatesSubliminal1996","accessed":{"date-parts":[["2023",11,3]]},"author":[{"family":"Sanchez-Colberg","given":"Ana"}],"citation-key":"sanchez-colbergAlteredStatesSubliminal1996","container-title":"Performance Research","container-title-short":"Performance Research","DOI":"10.1080/13528165.1996.10871489","ISSN":"1352-8165, 1469-9990","issue":"2","issued":{"date-parts":[["1996",1]]},"language":"en","page":"40-56","source":"DOI.org (Crossref)","title":"Altered States and Subliminal Spaces: Charting the Road towards a Physical Theatre","title-short":"Altered States and Subliminal Spaces","type":"article-journal","URL":"https://www.tandfonline.com/doi/full/10.1080/13528165.1996.10871489","volume":"1"},{"id":"sandahlBodiesCommotionDisability2005","call-number":"PN1590.H36 B63 2005","citation-key":"sandahlBodiesCommotionDisability2005","collection-title":"Corporealities","editor":[{"family":"Sandahl","given":"Carrie"},{"family":"Auslander","given":"Philip"}],"event-place":"Ann Arbor","ISBN":"978-0-472-09891-0 978-0-472-06891-3","issued":{"date-parts":[["2005"]]},"number-of-pages":"339","publisher":"University of Michigan Press","publisher-place":"Ann Arbor","source":"Library of Congress ISBN","title":"Bodies in Commotion: Disability & Performance","title-short":"Bodies in commotion","type":"book"},{"id":"sandenLivenessModernMusic2017","author":[{"family":"Sanden","given":"Paul"}],"citation-key":"sandenLivenessModernMusic2017","collection-number":"5","collection-title":"Routledge research in music","event-place":"New York London","ISBN":"978-1-138-10797-7 978-0-415-89540-8","issued":{"date-parts":[["2017"]]},"language":"eng","number-of-pages":"206","publisher":"Routledge, Taylor & Francis Group","publisher-place":"New York London","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"Liveness in Modern Music: Musicians, Technology, and the Perception of Performance","title-short":"Liveness in modern music","type":"book"},{"id":"sandlerSignLanguageLinguistic2006","author":[{"family":"Sandler","given":"Wendy"},{"family":"Lillo-Martin","given":"Diane C."}],"call-number":"HV2474 .S28 2006","citation-key":"sandlerSignLanguageLinguistic2006","event-place":"Cambridge, UK ; New York","ISBN":"978-0-521-48248-6 978-0-521-48395-7","issued":{"date-parts":[["2006"]]},"note":"OCLC: ocm61425229","number-of-pages":"547","publisher":"Cambridge University Press","publisher-place":"Cambridge, UK ; New York","source":"Library of Congress ISBN","title":"Sign Language and Linguistic Universals","type":"book"},{"id":"sanfilippoFeedbackSystemsAnalytical2013","abstract":"The use of feedback-based systems in the music domain dates back to the 1960s. Their applications span from music composition and sound organization to audio synthesis and processing, as the interest in feedback resulted both from theoretical reflection on cybernetics and system theory, and from practical experimentation on analog circuits. The advent of computers has made possible the implementation of complex theoretical systems in audio-domain oriented applications, in some sense bridging the gap between theory and practice in the analog domain, and further increasing the range of audio and musical applications of feedback systems. In this article we first sketch a minimal history of feedback in music; second, we briefly introduce feedback systems from a theoretical point of view; then we propose a set of features that characterize them from the perspective of music applications; finally, we propose a typology targeted at feedback systems used in the audio/musical domain and discuss some relevant examples.","accessed":{"date-parts":[["2023",1,16]]},"author":[{"family":"Sanfilippo","given":"Dario"},{"family":"Valle","given":"Andrea"}],"citation-key":"sanfilippoFeedbackSystemsAnalytical2013","container-title":"Computer Music Journal","container-title-short":"Computer Music Journal","DOI":"10.1162/COMJ_a_00176","ISSN":"0148-9267","issue":"2","issued":{"date-parts":[["2013",6,1]]},"page":"12-27","title":"Feedback Systems: An Analytical Framework","type":"article-journal","URL":"https://doi.org/10.1162/COMJ_a_00176","volume":"37"},{"id":"santosYouAreBeat2018","abstract":"Rhythm is the most basic skill for people learning to dance. Beginners need practice but also close coaching and constant feedback. However, in most dance classes teachers often find challenging to provide attention to each student. A possible solution to this problem would be to automate the provision of feedback to students by objectively assessing rhythm from their movement data. But how effective would a fully automated approach be compared to dance experts in evaluating dance performance? We conducted a study aimed at exploring this by 'measuring' dance rhythm from accelerometer data streams and contrasting the algorithm results with expert human judgement. We developed RiMoDe, an algorithm that tracks bodily rhythmic skills, and gathered a dataset that includes 282 independent evaluations made by expert dance teachers on 94 dance exercises performed by 7 dance students. Our findings revealed major gaps between a purely algorithmic approach and how experts evaluate dance rhythm. We identified 6 themes that are important when assessing rhythm. We discuss how these themes should be considered and incorporated into future systems aimed at supporting people learning to dance.","author":[{"family":"Santos","given":"Augusto Dias Pereira","dropping-particle":"dos"},{"family":"Tang","given":"Lie Ming"},{"family":"Loke","given":"Lian"},{"family":"Martinez-Maldonado","given":"Roberto"}],"citation-key":"santosYouAreBeat2018","collection-title":"MOCO '18","container-title":"Proceedings of the 5th international conference on movement and computing","DOI":"10.1145/3212721.3212724","event-place":"Genoa, Italy","ISBN":"978-1-4503-6504-8","issued":{"date-parts":[["2018"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Genoa, Italy","title":"You are off the beat! Is accelerometer data enough for measuring dance rhythm?","type":"paper-conference","URL":"https://doi.org/10.1145/3212721.3212724"},{"id":"sarjiHandTalkAssistiveTechnology2008","abstract":"One of the many areas in which embedded systems show great promise is assistive technologies, which address the special needs of those with impairments. This article presents HandTalk, a \"smart glove\" that can recognize basic hand gestures and convert them into speech using low-cost, commercial off-the-shelf (COTS) components. A low-cost, portable gesture-to-speech glove prototype demonstrates that embedded systems don't have to be expensive to be effective.","author":[{"family":"Sarji","given":"D. K."}],"citation-key":"sarjiHandTalkAssistiveTechnology2008","container-title":"Computer","container-title-short":"Computer","DOI":"10.1109/MC.2008.226","ISSN":"1558-0814","issue":"7","issued":{"date-parts":[["2008",7]]},"page":"84-86","title":"HandTalk: Assistive Technology for the Deaf","type":"article-journal","volume":"41"},{"id":"satorestudioHaitaSatoreStudio2022","accessed":{"date-parts":[["2023",10,9]]},"author":[{"literal":"Satore Studio"}],"citation-key":"satorestudioHaitaSatoreStudio2022","container-title":"Satore Studio","issued":{"date-parts":[["2022"]]},"title":"Háita - Satore Studio","type":"webpage","URL":"https://satorestudio.com/portfolio_page/haita-at-sonar-lisboa/"},{"id":"scariSeeWhatSaying2010","citation-key":"scariSeeWhatSaying2010","director":[{"family":"Scari","given":"Hilari"}],"issued":{"date-parts":[["2010"]]},"publisher":"Wordplay","title":"See What I'm Saying: The Deaf Entertainers Documentary","type":"motion_picture"},{"id":"schacherAmbisonicsSpatializationTools2006a","author":[{"family":"Schacher","given":"Jan C"},{"family":"Kocher","given":"Philippe"}],"citation-key":"schacherAmbisonicsSpatializationTools2006a","container-title":"Omni","container-title-short":"Omni","issue":"1","issued":{"date-parts":[["2006"]]},"title":"Ambisonics spatialization tools for max/msp","type":"article-journal","volume":"500"},{"id":"schacherGestureinksoundLinkingCalligraphy2019","abstract":"In calligraphy, a brush stroke is rooted in an inner image, breath and the uninterrupted flow of movement. The same can be said of a bow stroke on a string instrument or a note sounded on a wind instrument. This article documents the encounter between a specific, two-person form of calligraphic performance, movement analysis techniques, and the mapping of brush gestures to sound processes. It shows how, based on data obtained in motion-capture sessions, the link between gesture and sound is established. This enables different models of sound processes, their specific mode of operation, and the understanding of what makes a stroke. Questions and issues arising from this concrete work are collected and a reflective analysis is carried out via a diagrammatic process. A discussion of critical limitations and possible extensions in this configuration concludes the article.","author":[{"family":"Schacher","given":"Jan"},{"family":"Wei","given":"Lia"}],"citation-key":"schacherGestureinksoundLinkingCalligraphy2019","collection-title":"MOCO '19","container-title":"Proceedings of the 6th international conference on movement and computing","DOI":"10.1145/3347122.3347136","event-place":"Tempe, AZ, USA","ISBN":"978-1-4503-7654-9","issued":{"date-parts":[["2019"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Tempe, AZ, USA","title":"Gesture-ink-sound: Linking calligraphy performance with sound","type":"paper-conference","URL":"https://doi.org/10.1145/3347122.3347136"},{"id":"schacherMovingMusicExploring2016","abstract":"Relating movement to sound in an artistic context demands an understanding of the foundations of perception of both domains and the elaboration of techniques that effectively creates a link with technical means from body to sound. This article explores the strategies necessary in interactive dance work to successfully link movement to sound processes. This is done by reducing the dimensions of the observed elements to the fundamentals and at the same time identifying target dimensions that allow the recreation of an equivalent expression. A categorisation helps to elucidate those elements and characteristics that can be applied and looks at how they are perceived by the audience. The asymmetry that arises when using technical links to generate sound in interactive dance poses the question of dependency and exposes limits and challenges of using technology in this performing arts practice.","author":[{"family":"Schacher","given":"Jan C."}],"citation-key":"schacherMovingMusicExploring2016","collection-title":"MOCO '16","container-title":"Proceedings of the 3rd international symposium on movement and computing","DOI":"10.1145/2948910.2948940","event-place":"Thessaloniki, GA, Greece","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Thessaloniki, GA, Greece","title":"Moving music: Exploring movement-to-sound relationships","type":"paper-conference","URL":"https://doi.org/10.1145/2948910.2948940"},{"id":"schacherMusicMeansMovement2015","abstract":"This article addresses the intersection of technical, analytical and artistic approaches to perceiving and measuring musical movement. The point of view taken is situated between the development and application of technological tools, the design and running of exploratory experiments, and the musical performance moment, where perception of the body and its movements constitutes an integral part of the experience. Through a use-case that is shared with other artists and researchers, a wide range of necessary developments, both conceptually and in software is shown. The tools and the methods generated are juxtaposed with the realisation that movement analysis is merely one possible usage of acquired data. Artistic translations provide alternate ways of generating meaning from movement data, in particular when translating musical actions to pieces that span multiple modalities. With the proposed multi-perspective methodology, ways and means are sketched out that address the inherent multiplicity of domains involved in music performance and perception.","author":[{"family":"Schacher","given":"Jan C."}],"citation-key":"schacherMusicMeansMovement2015","collection-title":"MOCO '15","container-title":"Proceedings of the 2nd international workshop on movement and computing","DOI":"10.1145/2790994.2791001","event-place":"Vancouver, British Columbia, Canada","ISBN":"978-1-4503-3457-0","issued":{"date-parts":[["2015"]]},"number-of-pages":"8","page":"132–139","publisher":"Association for Computing Machinery","publisher-place":"Vancouver, British Columbia, Canada","title":"Music means movement: Musings on methods for movement analysis in music","type":"paper-conference","URL":"https://doi.org/10.1145/2790994.2791001"},{"id":"schacherWatchThisExpressive2014","abstract":"How does bodily awareness relate to instrumental action, how is movement perceived and what role does it play in music performance with technology? This article investigates such questions in the light of the application of concepts and models for machine-based gesture recognition. The problematic relationship between paradigms of control and the notion of 'inter-action' in the technically mediated art-form of electronic music is revealed. The concepts used when applying gesture-recognition display a problematic limited scope as well. The challenge in using these advanced algorithms is to be able to detect and translate salient and expressive aspects of a movement-based music performance. Acknowledging this as a goal exposes the need for a unified high-level descriptive system for expressive movements or gestures in music and dance performance.","author":[{"family":"Schacher","given":"Jan C."},{"family":"Bisig","given":"Daniel"}],"citation-key":"schacherWatchThisExpressive2014","collection-title":"MOCO '14","container-title":"Proceedings of the 2014 international workshop on movement and computing","DOI":"10.1145/2617995.2618014","event-place":"Paris, France","ISBN":"978-1-4503-2814-2","issued":{"date-parts":[["2014"]]},"number-of-pages":"6","page":"106–111","publisher":"Association for Computing Machinery","publisher-place":"Paris, France","title":"Watch this! Expressive movement in electronic music performance","type":"paper-conference","URL":"https://doi.org/10.1145/2617995.2618014"},{"id":"schacherWhatQualityPerforming2018","abstract":"This article investigates fundamental questions and methodological issues concerning research on movement and computing. Through a process of mapping of the various approaches and phases of research in this domain, it attempts to construct a coherent picture and overview of the research field. A series of questions arise that are discussed with the intent of anchoring and directing future research across different disciplines. In order to better apprehend the complexity of movement, gesture, action, and physical performance, and their role as topic of scientific, scholarly as well artistic research practices, an extension of the disciplinary and methodological framework is proposed. The juxtaposition of the diverse approaches and goals, and the extension of the research can indicate novel axes for generating techniques, methods, and ultimately knowledge. Based on this insight, a reflection on the potential of a wider cross-mediating research practice concludes this article.","author":[{"family":"Schacher","given":"Jan"}],"citation-key":"schacherWhatQualityPerforming2018","collection-title":"MOCO '18","container-title":"Proceedings of the 5th international conference on movement and computing","DOI":"10.1145/3212721.3212834","event-place":"Genoa, Italy","ISBN":"978-1-4503-6504-8","issued":{"date-parts":[["2018"]]},"number-of-pages":"9","publisher":"Association for Computing Machinery","publisher-place":"Genoa, Italy","title":"What quality? Performing research on movement and computing","type":"paper-conference","URL":"https://doi.org/10.1145/3212721.3212834"},{"id":"schlagEyeSlowlyDelays2002","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Schlag","given":"John"},{"family":"Schlag-Rey","given":"Madeleine"}],"citation-key":"schlagEyeSlowlyDelays2002","container-title":"Nature Reviews Neuroscience","container-title-short":"Nat Rev Neurosci","DOI":"10.1038/nrn750","ISSN":"1471-003X, 1471-0048","issue":"3","issued":{"date-parts":[["2002",3]]},"language":"en","license":"http://www.springer.com/tdm","note":"QID: Q34627255","page":"191-191","source":"DOI.org (Crossref)","title":"Through the eye, slowly; Delays and localization errors in the visual system","type":"article-journal","URL":"https://www.nature.com/articles/nrn750","volume":"3"},{"id":"schlemmerManArtFigure1987","author":[{"family":"Schlemmer","given":"Oskar"}],"call-number":"791","citation-key":"schlemmerManArtFigure1987","collection-title":"Wesleyan paperbacks","container-title":"The Theater of the Bauhaus","editor":[{"family":"Gropius","given":"Walter"},{"family":"Wensinger","given":"Arthur S."}],"event-place":"Middletown (Conn.)","ISBN":"978-0-8195-6020-9","issued":{"date-parts":[["1987"]]},"language":"eng","note":"Original work published 1961","page":"19-46","publisher":"Wesleyan university press","publisher-place":"Middletown (Conn.)","source":"BnF ISBN","title":"Man and Art Figure","type":"chapter"},{"id":"schlemmerManArtFigure2014","author":[{"family":"Schlemmer","given":"Oskar"}],"call-number":"PN1584 .T84 2014","citation-key":"schlemmerManArtFigure2014","container-title":"The Twentieth Century Performance Reader","edition":"3rd edition","editor":[{"family":"Brayshaw","given":"Teresa"},{"family":"Witts","given":"Noel"}],"event-place":"London ; New York","ISBN":"978-0-415-69664-7 978-0-415-69665-4 978-0-203-12523-6","issued":{"date-parts":[["2014"]]},"page":"413-424","publisher":"Routledge","publisher-place":"London ; New York","source":"Library of Congress ISBN","title":"Man and Art Figure","type":"chapter"},{"id":"schlemmerTheaterBauhaus1987","author":[{"family":"Schlemmer","given":"Oskar"},{"family":"Moholy-Nagy","given":"László"},{"family":"Molnár","given":"Farkas"}],"call-number":"791","citation-key":"schlemmerTheaterBauhaus1987","collection-title":"Wesleyan paperbacks","editor":[{"family":"Gropius","given":"Walter"},{"family":"Wensinger","given":"Arthur S."}],"event-place":"Middletown (Conn.)","ISBN":"978-0-8195-6020-9","issued":{"date-parts":[["1987"]]},"language":"eng","note":"Original work published 1961","number-of-pages":"109","publisher":"Wesleyan university press","publisher-place":"Middletown (Conn.)","source":"BnF ISBN","title":"The theater of the Bauhaus","type":"book"},{"id":"schmidQuantifyingSpinalGait2016","accessed":{"date-parts":[["2023",7,10]]},"author":[{"family":"Schmid","given":"Stefan"},{"family":"Studer","given":"Daniel"},{"family":"Hasler","given":"Carol-Claudius"},{"family":"Romkes","given":"Jacqueline"},{"family":"Taylor","given":"William R."},{"family":"Lorenzetti","given":"Silvio"},{"family":"Brunner","given":"Reinald"}],"citation-key":"schmidQuantifyingSpinalGait2016","container-title":"Gait & Posture","container-title-short":"Gait & Posture","DOI":"10.1016/j.gaitpost.2015.12.036","ISSN":"09666362","issued":{"date-parts":[["2016",2]]},"language":"en","page":"231-237","title":"Quantifying spinal gait kinematics using an enhanced optical motion capture approach in adolescent idiopathic scoliosis","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0966636215010048","volume":"44"},{"id":"schmidtMusiciansHearingAid2012","author":[{"family":"Schmidt","given":"Mark"}],"citation-key":"schmidtMusiciansHearingAid2012","container-title":"Trends in amplification","container-title-short":"Trends in amplification","ISSN":"1084-7138","issue":"3","issued":{"date-parts":[["2012"]]},"page":"140-145","publisher":"Sage Publications Sage CA: Los Angeles, CA","title":"Musicians and Hearing Aid Design—Is Your Hearing Instrument Being Overworked?","type":"article-journal","volume":"16"},{"id":"schmittMusicMusicCochlear2016","accessed":{"date-parts":[["2021",1,27]]},"author":[{"family":"Schmitt","given":"Annegret Erna"}],"citation-key":"schmittMusicMusicCochlear2016","container-title":"silo.tips","issued":{"date-parts":[["2016",9,11]]},"title":"music 2.0: music for Cochlear Implants","type":"webpage","URL":"https://silo.tips/download/music-20-music-for-cochlear-implants"},{"id":"schmitzMeasurementVivoJoint2015","abstract":"Markerless motion capture may have the potential to make motion capture technology widely clinically practical. However, the ability of a single markerless camera system to quantify clinically relevant, lower extremity joint angles has not been studied in vivo. Therefore, the goal of this study was to compare in vivo joint angles calculated using a marker-based motion capture system and a Microsoft Kinect during a squat. Fifteen individuals participated in the study: 8 male, 7 female, height 1.702±0.089m, mass 67.9±10.4kg, age 24±4 years, BMI 23.4±2.2kg/m2. Marker trajectories and Kinect depth map data of the leg were collected while each subject performed a slow squat motion. Custom code was used to export virtual marker trajectories for the Kinect data. Each set of marker trajectories was utilized to calculate Cardan knee and hip angles. The patterns of motion were similar between systems with average absolute differences of <5 deg. Peak joint angles showed high between-trial reliability with ICC>0.9 for both systems. The peak angles calculated by the marker-based and Kinect systems were largely correlated (r>0.55). These results suggest the data from the Kinect can be post processed in way that it may be a feasible markerless motion capture system that can be used in the clinic.","author":[{"family":"Schmitz","given":"Anne"},{"family":"Ye","given":"Mao"},{"family":"Boggess","given":"Grant"},{"family":"Shapiro","given":"Robert"},{"family":"Yang","given":"Ruigang"},{"family":"Noehren","given":"Brian"}],"citation-key":"schmitzMeasurementVivoJoint2015","container-title":"Gait & Posture","container-title-short":"Gait & Posture","DOI":"10.1016/j.gaitpost.2015.01.028","ISSN":"0966-6362","issue":"2","issued":{"date-parts":[["2015",2,1]]},"page":"694-698","title":"The measurement of in vivo joint angles during a squat using a single camera markerless motion capture system as compared to a marker based system","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0966636215000314","volume":"41"},{"id":"schneiderSystematicMusicologyHistorical2018","abstract":"A brief account of the historical development of systematic musicology as a field of interdisciplinary research is given that spans from Greek antiquity to the present. Selected topics cover the rise of music theory from the Renaissance to modern times, the issue of harmonic dualism from Zarlino and Rameau to the 20th century and the controversy about physicalism versus musical logic in music theory. Sections of this chapter further relate to the notion of a system and the concept of systematic research (which is exemplified with respect to the work of Chladni, Helmholtz, Stumpf, and Riemann), and to the concept of Gestalt quality that spawned contributions to music perception from Gestalt psychology. In addition, some developments in music psychology outside the Gestalt movement as well as in the sociology of music are sketched, followed by a paragraph on modern research trends, which include semiotic, computational, and linguistic approaches to music perception and cognition as well as contributions from the neurosciences. A final paragraph provides some of the background that led to establishing systematic musicology as an academic discipline around 1870–1910, from where further disciplinary and scientific developments defined the field in the 20th century.","accessed":{"date-parts":[["2024",12,9]]},"author":[{"family":"Schneider","given":"Albrecht"}],"citation-key":"schneiderSystematicMusicologyHistorical2018","container-title":"Springer Handbook of Systematic Musicology","DOI":"10.1007/978-3-662-55004-5_1","editor":[{"family":"Bader","given":"Rolf"}],"event-place":"Berlin, Heidelberg","ISBN":"978-3-662-55004-5","issued":{"date-parts":[["2018"]]},"language":"en","page":"1-24","publisher":"Springer","publisher-place":"Berlin, Heidelberg","source":"Springer Link","title":"Systematic Musicology: A Historical Interdisciplinary Perspective","title-short":"Systematic Musicology","type":"chapter","URL":"https://doi.org/10.1007/978-3-662-55004-5_1"},{"id":"schubertContinuousSelfreportMethods2010","abstract":"An undeniable, fundamental properly of music is that it requires time to exist. Any definition of music must include this properly, even if by implication. For example, the well-worn definition of music being 'organized sound' does not explicitly mention time dependence, but sound requires the projection of energy through space and time as an absolute minimum. Emotion also requires time to unfold, but this is not mandatory to its definition, since an emotion can be detected in a static image or object such as a photograph. However, given the intricate connection between music and emotion, it stands to reason that emotions occurring in response to unfolding music should also be time dependent. While this may be obvious, it is true too that, of all the research in music perception and cognition, only a small fraction has focused on the fundamental nature of time in music and the emotion it produces. In the last 80 years, there has been the implicit assumption that music emotion can be understood by collecting (emotional) responses or assessments after a musical stimulus has been sounded, the so-called 'postperformance' response. Since the first important English-language experiments on the topic, the reasons for such an approach can be identified as pragmatism and tradition. Collecting self-report responses continuously requires careful synchronization of each response with the time in the music at which the response occurred. Frequent sampling of responses over time can produce large sets of data, too. Apart from a few ingenious solutions, this methodology needed significant computational power, something that would not be widespread until the 1990s. As researchers began to explore this time-dependent mode of data collection, they were faced with the problem of how to interpret the huge data sets accumulated. Indeed, there are now several methods of data collection and analysis of continuous emotional responses to music, many of them quite recent developments. In this chapter, I will discuss some of these (measurement and analysis methods) after defining continuous response. I will conclude by briefly discussing some of the current issues in continuous-response method in connection with emotion and music, and speculate on some future directions and challenges. (PsycInfo Database Record (c) 2020 APA, all rights reserved)","author":[{"family":"Schubert","given":"Emery"}],"citation-key":"schubertContinuousSelfreportMethods2010","collection-title":"Series in affective science.","container-title":"Handbook of music and emotion: Theory, research, applications.","event-place":"New York,  NY,  US","ISBN":"0-19-923014-5 (Hardcover); 978-0-19-923014-3 (Hardcover)","issued":{"date-parts":[["2010"]]},"page":"223-253","publisher":"Oxford University Press","publisher-place":"New York,  NY,  US","title":"Continuous self-report methods.","type":"chapter"},{"id":"schubertRelationshipLapsingScaling2010","accessed":{"date-parts":[["2024",4,8]]},"author":[{"family":"Schubert","given":"Emery"},{"family":"Stevens","given":"Catherine"},{"family":"Ferguson","given":"Sam"}],"citation-key":"schubertRelationshipLapsingScaling2010","container-title":"Proceedings of the 9th Conference of the Australasian Society for Cognitive Science","DOI":"10.5096/ASCS200947","event-place":"Macquary University, Sydney, Australia","event-title":"9th Conference of the Australasian Society for Cognitive Science","ISBN":"978-0-646-52918-9","issued":{"date-parts":[["2010"]]},"language":"en","page":"311-315","publisher":"Macquarie Centre for Cognitive Science","publisher-place":"Macquary University, Sydney, Australia","source":"DOI.org (Crossref)","title":"The relationship between lapsing and scaling: Explaining timing variations in a contemporary dance performance","title-short":"The relationship between lapsing and scaling","type":"paper-conference","URL":"http://www.maccs.mq.edu.au/news/conferences/2009/ASCS2009/schubert.html"},{"id":"scottHealthcareApplicationsSingle2022","abstract":"Background\n              Single camera markerless motion capture has the potential to facilitate at home movement assessment due to the ease of setup, portability, and affordable cost of the technology. However, it is not clear what the current healthcare applications of single camera markerless motion capture are and what information is being collected that may be used to inform clinical decision making. This review aims to map the available literature to highlight potential use cases and identify the limitations of the technology for clinicians and researchers interested in the collection of movement data.\n            \n            \n              Survey Methodology\n              Studies were collected up to 14 January 2022 using Pubmed, CINAHL and SPORTDiscus using a systematic search. Data recorded included the description of the markerless system, clinical outcome measures, and biomechanical data mapped to the International Classification of Functioning, Disability and Health Framework (ICF). Studies were grouped by patient population.\n            \n            \n              Results\n              A total of 50 studies were included for data collection. Use cases for single camera markerless motion capture technology were identified for Neurological Injury in Children and Adults; Hereditary/Genetic Neuromuscular Disorders; Frailty; and Orthopaedic or Musculoskeletal groups. Single camera markerless systems were found to perform well in studies involving single plane measurements, such as in the analysis of infant general movements or spatiotemporal parameters of gait, when evaluated against 3D marker-based systems and a variety of clinical outcome measures. However, they were less capable than marker-based systems in studies requiring the tracking of detailed 3D kinematics or fine movements such as finger tracking.\n            \n            \n              Conclusions\n              Single camera markerless motion capture offers great potential for extending the scope of movement analysis outside of laboratory settings in a practical way, but currently suffers from a lack of accuracy where detailed 3D kinematics are required for clinical decision making. Future work should therefore focus on improving tracking accuracy of movements that are out of plane relative to the camera orientation or affected by occlusion, such as supination and pronation of the forearm.","accessed":{"date-parts":[["2023",10,5]]},"author":[{"family":"Scott","given":"Bradley"},{"family":"Seyres","given":"Martin"},{"family":"Philp","given":"Fraser"},{"family":"Chadwick","given":"Edward K."},{"family":"Blana","given":"Dimitra"}],"citation-key":"scottHealthcareApplicationsSingle2022","container-title":"PeerJ","DOI":"10.7717/peerj.13517","ISSN":"2167-8359","issued":{"date-parts":[["2022",5,26]]},"language":"en","page":"e13517","source":"DOI.org (Crossref)","title":"Healthcare applications of single camera markerless motion capture: a scoping review","title-short":"Healthcare applications of single camera markerless motion capture","type":"article-journal","URL":"https://peerj.com/articles/13517","volume":"10"},{"id":"scullyDisabilityBioethicsMoral2008","author":[{"family":"Scully","given":"Jackie Leach"}],"call-number":"HV1568 .S388 2008","citation-key":"scullyDisabilityBioethicsMoral2008","collection-title":"Feminist constructions","event-place":"Lanham","ISBN":"978-0-7425-5122-0 978-0-7425-6457-2","issued":{"date-parts":[["2008"]]},"note":"OCLC: ocn214065664","number-of-pages":"203","publisher":"Rowman & Littlefield","publisher-place":"Lanham","source":"Library of Congress ISBN","title":"Disability Bioethics: Moral Bodies, Moral Difference","title-short":"Disability bioethics","type":"book"},{"id":"seidmanInterviewingQualitativeResearch2006","author":[{"family":"Seidman","given":"Irving"}],"call-number":"H61.28 .S45 2006","citation-key":"seidmanInterviewingQualitativeResearch2006","edition":"3rd ed","event-place":"New York","ISBN":"978-0-8077-4666-0","issued":{"date-parts":[["2006"]]},"note":"OCLC: ocm61285766","number-of-pages":"162","publisher":"Teachers College Press","publisher-place":"New York","source":"Library of Congress ISBN","title":"Interviewing as Qualitative Research: A Guide for Researchers in Education and the Social Sciences","title-short":"Interviewing as qualitative research","type":"book"},{"id":"seyeCorporealDynamicsChoreomusical2020","abstract":"[The sabar dancing and drumming in Senegal takes several forms, but in most performance contexts improvisatory dancing and the interaction of dance and music are central. Both dancers and musicians refer to the knowledge about the tradition, the dance rhythms in particular, as the common ground for dance-music interactions. However, what appears to be central is also a certain kind of tension, or “intensity” to use Nketia’s (1988) term, which enables and motivates this connection, in addition to the shared knowledge of dance movements, their accompanying rhythms and the habitual relations between certain movement patterns and musical solo phrases. This article thus explores the use of energy, the dynamics of tension and release, as a possible factor that connects sabar dancing and drumming. For this purpose, the analysis here focuses on the corporeal dynamics of individual dance solos, their points of connection to the dynamics of the music, as well as the dynamics of the whole dance event.]","accessed":{"date-parts":[["2023",12,21]]},"archive":"JSTOR","author":[{"family":"Seye","given":"Elina"}],"citation-key":"seyeCorporealDynamicsChoreomusical2020","container-title":"The World of Music","ISSN":"00438774","issue":"1","issued":{"date-parts":[["2020"]]},"page":"67-82","publisher":"[Florian Noetzel GmbH Verlag, VWB - Verlag für Wissenschaft und Bildung, Bärenreiter, Schott Music GmbH & Co. KG]","title":"The Corporeal Dynamics of Choreomusical Interactions in sabar Dance Events","type":"article-journal","URL":"https://www-jstor-org.ezproxy.uio.no/stable/26970255","volume":"9"},{"id":"shafferTutorialEpistemicNetwork2016","abstract":"This paper provides a tutorial on epistemic network analysis (ENA), a novel method for identifying and quantifying connections among elements in coded data and representing them in dynamic network models. Such models illustrate the structure of connections and measure the strength of association among elements in a network, and they quantify changes in the composition and strength of connections over time. Importantly, ENA enables comparison of networks both directly and via summary statistics, so the method can be used to explore a wide range of qualitative and quantitative research questions in situations where patterns of association in data are hypothesized to be meaningful. While ENA was originally developed to model cognitive networks—the patterns of association between knowledge, skills, values, habits of mind, and other elements that characterize complex thinking—ENA is a robust method that can be used to model patterns of association in any system characterized by a complex network of dynamic relationships among a relatively small, fixed set of elements.","accessed":{"date-parts":[["2024",6,18]]},"author":[{"family":"Shaffer","given":"David Williamson"},{"family":"Collier","given":"Wesley"},{"family":"Ruis","given":"A. R."}],"citation-key":"shafferTutorialEpistemicNetwork2016","container-title":"Journal of Learning Analytics","container-title-short":"Learning Analytics","DOI":"10.18608/jla.2016.33.3","ISSN":"1929-7750","issue":"3","issued":{"date-parts":[["2016",12,19]]},"page":"9-45","source":"DOI.org (Crossref)","title":"A Tutorial on Epistemic Network Analysis: Analyzing the Structure of Connections in Cognitive, Social, and Interaction Data","title-short":"A Tutorial on Epistemic Network Analysis","type":"article-journal","URL":"https://learning-analytics.info/index.php/JLA/article/view/4329","volume":"3"},{"id":"shakespeareDisabilityResearchToday2015","call-number":"HV1568 .D56944 2015","citation-key":"shakespeareDisabilityResearchToday2015","editor":[{"family":"Shakespeare","given":"Tom"}],"event-place":"London ; New York","ISBN":"978-0-415-74843-8 978-0-415-74844-5","issued":{"date-parts":[["2015"]]},"number-of-pages":"254","publisher":"Routledge, Taylor & Francis Group","publisher-place":"London ; New York","source":"Library of Congress ISBN","title":"Disability research today: international perspectives","title-short":"Disability research today","type":"book"},{"id":"shakespeareSocialModelDisability2006","author":[{"family":"Shakespeare","given":"Tom"}],"citation-key":"shakespeareSocialModelDisability2006","container-title":"The disability studies reader","container-title-short":"The disability studies reader","issued":{"date-parts":[["2006"]]},"page":"197-204","title":"The social model of disability","type":"article-journal","volume":"2"},{"id":"shakespeareSocialModelDisability2017","author":[{"family":"Shakespeare","given":"Tom"}],"call-number":"HV1568 .D5696 2017","citation-key":"shakespeareSocialModelDisability2017","container-title":"The Disability Studies Reader","edition":"Fifth edition","editor":[{"family":"Davis","given":"Lennard J."}],"event-place":"New York","ISBN":"978-1-138-93022-3 978-1-138-93023-0","issued":{"date-parts":[["2017"]]},"page":"190 - 199","publisher":"Routledge, Taylor & Francis Group","publisher-place":"New York","source":"Library of Congress ISBN","title":"The Social Model of Disability","type":"chapter"},{"id":"sharmaTrendsAudioSignal2020","abstract":"Audio signal processing algorithms generally involves analysis of signal, extracting its properties, predicting its behaviour, recognizing if any pattern is present in the signal, and how a particular signal is correlated to another similar signals. Audio signal includes music, speech and environmental sounds. Over the last few decades, audio signal processing has grown significantly in terms of signal analysis and classification. And it has been proven that solutions of many existing issues can be solved by integrating the modern machine learning (ML) algorithms with the audio signal processing techniques. The performance of any ML algorithm depends on the features on which the training and testing is done. Hence feature extraction is one of the most vital part of a machine learning process. The aim of this study is to summarize the literature of the audio signal processing specially focusing on the feature extraction techniques. In this survey the temporal domain, frequency domain, cepstral domain, wavelet domain and time-frequency domain features are discussed in detail.","author":[{"family":"Sharma","given":"Garima"},{"family":"Umapathy","given":"Kartikeyan"},{"family":"Krishnan","given":"Sridhar"}],"citation-key":"sharmaTrendsAudioSignal2020","container-title":"Applied Acoustics","container-title-short":"Applied Acoustics","DOI":"10.1016/j.apacoust.2019.107020","ISSN":"0003-682X","issued":{"date-parts":[["2020",1,15]]},"page":"107020","title":"Trends in audio signal feature extraction methods","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0003682X19308795","volume":"158"},{"id":"sharmaUseMotionCapture2019","author":[{"family":"Sharma","given":"Shubham"},{"family":"Verma","given":"Shubhankar"},{"family":"Kumar","given":"Mohit"},{"family":"Sharma","given":"Lavanya"}],"citation-key":"sharmaUseMotionCapture2019","container-title":"2019 international conference on machine learning, big data, cloud and parallel computing (COMITCon)","DOI":"10.1109/COMITCon.2019.8862448","issued":{"date-parts":[["2019"]]},"page":"289-294","title":"Use of motion capture in 3D animation: Motion capture systems, challenges, and recent trends","type":"paper-conference"},{"id":"shepherdWhatDoesMusic2012","author":[{"family":"Shepherd","given":"Ian"}],"citation-key":"shepherdWhatDoesMusic2012","container-title":"California Copyright Conference Newsletter","issued":{"date-parts":[["2012",10]]},"title":"What does a music producer do, anyway","type":"article-journal","URL":"https://theccc.org/wp-content/uploads/Oct-9-2012-Newletter.pdf"},{"id":"shiMotionExtrapolationCentral2012","abstract":"Neural transmission latency would introduce a spatial lag when an object moves across the visual field, if the latency was not compensated. A visual predictive mechanism has been proposed, which overcomes such spatial lag by extrapolating the position of the moving object forward. However, a forward position shift is often absent if the object abruptly stops moving (motion-termination). A recent “correction-for-extrapolation” hypothesis suggests that the absence of forward shifts is caused by sensory signals representing ‘failed’ predictions. Thus far, this hypothesis has been tested only for extra-foveal retinal locations. We tested this hypothesis using two foveal scotomas: scotoma to dim light and scotoma to blue light. We found that the perceived position of a dim dot is extrapolated into the fovea during motion-termination. Next, we compared the perceived position shifts of a blue versus a green moving dot. As predicted the extrapolation at motion-termination was only found with the blue moving dot. The results provide new evidence for the correction-for-extrapolation hypothesis for the region with highest spatial acuity, the fovea.","author":[{"family":"Shi","given":"Zhuanghua"},{"family":"Nijhawan","given":"Romi"}],"citation-key":"shiMotionExtrapolationCentral2012","container-title":"PLoS ONE","DOI":"10.1371/journal.pone.0033651","issued":{"date-parts":[["2012"]]},"note":"QID: Q27306517","page":"null","PMID":"22438976","title":"Motion extrapolation in the central fovea","type":"article-journal","URL":"https://www.semanticscholar.org/paper/d161e83a1b33bfee586c9f8abf5975ecc5f5146c","volume":"7"},{"id":"siebersDisabilityTheory2008","author":[{"family":"Siebers","given":"Tobin"}],"call-number":"HV1568.2","citation-key":"siebersDisabilityTheory2008","collection-title":"Corporealities","event-place":"Ann Arbor","ISBN":"978-0-472-12222-6","issued":{"date-parts":[["2008"]]},"number-of-pages":"1","publisher":"University of Michigan Press","publisher-place":"Ann Arbor","source":"Library of Congress ISBN","title":"Disability Theory","type":"book"},{"id":"siegelDancingMusicInteractive2009","author":[{"family":"Siegel","given":"Wayne"}],"citation-key":"siegelDancingMusicInteractive2009","container-title":"The Oxford Handbook of Computer Music","editor":[{"family":"Dean","given":"Roger T."}],"event-place":"New York","issued":{"date-parts":[["2009"]]},"page":"191 -213","publisher":"Oxford University Press","publisher-place":"New York","title":"Dancing the Music: Interactive Dance and Music","type":"chapter"},{"id":"signkidSignkidLlFight2019","accessed":{"date-parts":[["2022",5,15]]},"author":[{"literal":"Signkid"}],"citation-key":"signkidSignkidLlFight2019","container-title":"The Big Issue","issued":{"date-parts":[["2019",5,1]]},"title":"Signkid: ‘I’ll fight deaf people’s right to space in the music industry’","type":"webpage","URL":"https://www.bigissue.com/opinion/signkid-ill-fight-deaf-peoples-right-to-space-in-the-music-industry/"},{"id":"signmark-topicDeafManBlues2014","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Signmark - Topic"}],"citation-key":"signmark-topicDeafManBlues2014","container-title":"YouTube","issued":{"date-parts":[["2014",11,21]]},"title":"Deaf Man's Blues","type":"webpage","URL":"https://www.youtube.com/watch?v=hmV1uzXOa9k"},{"id":"signmark-topicMissRhythm2014","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Signmark - Topic"}],"citation-key":"signmark-topicMissRhythm2014","container-title":"YouTube","issued":{"date-parts":[["2014",11,21]]},"title":"Miss Rhythm","type":"webpage","URL":"https://www.youtube.com/watch?v=uqvHJ1FS8do"},{"id":"signmarkBio2010","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Signmark"}],"citation-key":"signmarkBio2010","container-title":"Signmark (Accessed over the Internet Archive Wayback Machine)","issued":{"date-parts":[["2010",4,24]]},"title":"Bio","type":"webpage","URL":"https://web.archive.org/web/20100424082210/http://www.signmark.biz/site/en/bio"},{"id":"signmarkDeafManBlues2010","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Signmark"}],"citation-key":"signmarkDeafManBlues2010","composer":[{"family":"Bauer","given":"B"},{"family":"Vuoriheimo","given":"M"},{"family":"Aalto","given":"S"}],"dimensions":"3:43","issued":{"date-parts":[["2010",4,21]]},"medium":"Streaming","publisher":"Warner Music Finland","title":"Deaf Man's Blues","type":"song","URL":"https://open.spotify.com/track/7k2ZxIjFvG36tpUAq56aBM?si=OkWo7-OMSLadM2or8hV2Rg"},{"id":"signmarkMissRhythm2010","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Signmark"}],"citation-key":"signmarkMissRhythm2010","composer":[{"family":"Aalto","given":"A."},{"family":"Sariola","given":"A."},{"family":"Bauer","given":"B."},{"family":"Vuoriheimo","given":"M."},{"family":"Ikonen","given":"O."}],"dimensions":"3:23","issued":{"date-parts":[["2010",4,21]]},"publisher":"Warner Music Finland","title":"Miss Rhythm","type":"song","URL":"https://open.spotify.com/track/6j292R64mq8rW6PTcHzHgi?si=61eL3883QSC63iB--5me7Q"},{"id":"signmarkSignmarkFeatAdam2014","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Signmark"}],"citation-key":"signmarkSignmarkFeatAdam2014","container-title":"YouTube","issued":{"date-parts":[["2014",4,8]]},"title":"Signmark feat. Adam Tensta & Saara Aalto - Impossible is my thing","type":"webpage","URL":"https://www.youtube.com/watch?v=bTAk_HQ9Tu4"},{"id":"signmarkSignmarkFighting2014","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Signmark"}],"citation-key":"signmarkSignmarkFighting2014","container-title":"YouTube","issued":{"date-parts":[["2014",4,4]]},"title":"Signmark - Fighting","type":"webpage","URL":"https://www.youtube.com/watch?v=gfNoMJ1GYzM"},{"id":"signmarkSignmarkSmellsVictory2009","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Signmark"}],"citation-key":"signmarkSignmarkSmellsVictory2009","container-title":"YouTube","issued":{"date-parts":[["2009",10,12]]},"title":"Signmark - Smells Like Victory","type":"webpage","URL":"https://www.youtube.com/watch?v=oUtM8_DOVUI"},{"id":"signmarkSignmarkTalkHand2014","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Signmark"}],"citation-key":"signmarkSignmarkTalkHand2014","container-title":"YouTube","issued":{"date-parts":[["2014",2,12]]},"title":"Signmark - Talk To The Hand","type":"webpage","URL":"https://www.youtube.com/watch?v=AZF0vZS8kKE"},{"id":"signmarkSignmarkTalkTalk2017","accessed":{"date-parts":[["2021",1,6]]},"author":[{"literal":"Signmark"}],"citation-key":"signmarkSignmarkTalkTalk2017","container-title":"YouTube","issued":{"date-parts":[["2017",8,13]]},"title":"Signmark - Talk The Talk","type":"webpage","URL":"https://www.youtube.com/watch?v=ZMBhhMYASss"},{"id":"silaghiLocalGlobalSkeleton1998","abstract":"Identifying a precise anatomic skeleton is important in order to ensure high quality motion capture. In this paper we discuss two skeleton fitting techniques based on 3D optical marker data. First a local technique is proposed based on relative marker trajectories. Then it is compared to a global optimization of a skeleton model. Various proposals are made to handle the skin deformation problem. Index Terms—skeleton fitting, motion capture, optical markers.","author":[{"family":"Silaghi","given":"Marius-CĂlin"},{"family":"Plänkers","given":"Ralf"},{"family":"Boulic","given":"Ronan"},{"family":"Fua","given":"Pascal"},{"family":"Thalmann","given":"Daniel"}],"citation-key":"silaghiLocalGlobalSkeleton1998","container-title":"Modelling and Motion Capture Techniques for Virtual Environments","editor":[{"family":"Magnenat-Thalmann","given":"Nadia"},{"family":"Thalmann","given":"Daniel"}],"event-place":"Berlin, Heidelberg","ISBN":"978-3-540-49384-6","issued":{"date-parts":[["1998"]]},"page":"26-40","publisher":"Springer Berlin Heidelberg","publisher-place":"Berlin, Heidelberg","title":"Local and Global Skeleton Fitting Techniques for Optical Motion Capture","type":"paper-conference"},{"id":"sileomodhrainFrameworkEvaluationDigital2011","abstract":"If performance is considered to be a valid means of evaluating a musical instrument, then it follows that, for the field of digital music design (DMI), a much broader definition of the term \"evaluation\" than that typically used in human-computer interactionis required to reflect the fact that there are a number of stakeholders involved in the design and evaluation of DMIs.","author":[{"literal":"Sile O'Modhrain"}],"citation-key":"sileomodhrainFrameworkEvaluationDigital2011","container-title":"Computer music journal","container-title-short":"COMPUT MUSIC J","DOI":"10.1162/COMJ_a_00038","event-place":"55 Hayward St., Cambridge, MA 02142-1315, USA","ISSN":"0148-9267","issue":"1","issued":{"date-parts":[["2011"]]},"page":"28-42","publisher":"55 Hayward St., Cambridge, MA 02142-1315, USA: MIT Press","publisher-place":"55 Hayward St., Cambridge, MA 02142-1315, USA","title":"A Framework for the Evaluation of Digital Musical Instruments","type":"article-journal","volume":"35"},{"id":"silvaSpeedingAllPairwiseDynamic2016","abstract":"Abstract Dynamic Time Warping (DTW) is certainly the most relevant distance for time series analysis. However, its quadratic time complexity may hamper its use, mainly in the analysis of large time series data. All the recent advances in speeding up the exact DTW calculation are confined to similarity search. However, there is a significant number of important algorithms including clustering and classification that require the pairwise distance matrix for all time series objects. The only techniques available to deal with this issue are constraint bands and DTW approximations. In this paper, we propose the first exact approach for speeding up the all-pairwise DTW matrix calculation. Our method is exact and may be applied in conjunction with constraint bands. We demonstrate that our algorithm reduces the runtime in approximately 50% on average and up to one order of magnitude in some datasets.","accessed":{"date-parts":[["2023",3,30]]},"author":[{"family":"Silva","given":"Diego F."},{"family":"Batista","given":"Gustavo E. A. P. A."}],"citation-key":"silvaSpeedingAllPairwiseDynamic2016","collection-title":"Proceedings","container-title":"Proceedings of the 2016 SIAM International Conference on Data Mining (SDM)","DOI":"10.1137/1.9781611974348.94","issued":{"date-parts":[["2016",6,30]]},"page":"837-845","publisher":"Society for Industrial and Applied Mathematics","title":"Speeding Up All-Pairwise Dynamic Time Warping Matrix Calculation","type":"paper-conference","URL":"https://doi.org/10.1137/1.9781611974348.94"},{"id":"simonsenRoutledgeInternationalHandbook2013","abstract":"\"Participatory Design is about the direct involvement of people in the co-design of the technologies they use. Its central concern is how collaborative design processes can be driven by the participation of the people affected by the technology designed. Embracing a diverse collection of principles and practices aimed at making technologies, tools, environments, businesses, and social institutions more responsive to human needs, the International Handbook of Participatory Design is a state-of-the-art reference handbook for the subject. The Handbook brings together a multidisciplinary and international group of highly recognized and experienced experts to present an authoritative overview of the field and its history and discuss contributions and challenges of the pivotal issues in Participatory Design, including heritage, ethics, ethnography, methods, tools and techniques and community involvement. The book also highlights three large-scale case studies which show how Participatory Design has been used to bring about outstanding changes in different organisations. The book shows why Participatory Design is an important, highly relevant and rewarding area for research and practice. It will be an invaluable resource for students, researchers, scholars and professionals in Participatory Design\"--","call-number":"QA76.9.S88 R675 2013","citation-key":"simonsenRoutledgeInternationalHandbook2013","editor":[{"family":"Simonsen","given":"Jesper"},{"family":"Robertson","given":"Toni"}],"event-place":"New York","ISBN":"978-0-415-69440-7 978-0-203-10854-3 978-1-136-26619-5","issued":{"date-parts":[["2013"]]},"number-of-pages":"294","publisher":"Routledge","publisher-place":"New York","source":"Library of Congress ISBN","title":"Routledge international handbook of participatory design","type":"book"},{"id":"singhalTimeTimeAgain2021","abstract":"Abstract Temporality and the feeling of ‘now’ is a fundamental property of consciousness. Different conceptualizations of time-consciousness have argued that both the content of our experiences and the representations of those experiences evolve in time, or neither have temporal extension, or only content does. Accounting for these different positions, we propose a nested hierarchical model of multiple timescales that accounts for findings on timing of cognition and phenomenology of temporal experience. This framework hierarchically combines the three major philosophical positions on time-consciousness (i.e. cinematic, extensional and retentional) and presents a common basis for temporal experience. We detail the properties of these hierarchical levels and speculate how they could coexist mechanistically. We also place several findings on timing and temporal experience at different levels in this hierarchy and show how they can be brought together. Finally, the framework is used to derive novel predictions for both timing of our experiences and time perception. The theoretical framework offers a novel dynamic space that can bring together sub-fields of cognitive science like perception, attention, action and consciousness research in understanding and describing our experiences both in and of time.","author":[{"family":"Singhal","given":"Ishank"},{"family":"Srinivasan","given":"N."}],"citation-key":"singhalTimeTimeAgain2021","container-title":"Neuroscience of Consciousness","DOI":"10.1093/nc/niab020","issued":{"date-parts":[["2021"]]},"page":"null","PMID":"34394957","title":"Time and time again: a multi-scale hierarchical framework for time-consciousness and timing of cognition","type":"article-journal","URL":"https://www.semanticscholar.org/paper/22f85204b0d02de5eff01aea3915494de316cf17","volume":"2021"},{"id":"singhCochlearImplantMelody2009","author":[{"family":"Singh","given":"Sonya"},{"family":"Kong","given":"Ying-Yee"},{"family":"Zeng","given":"Fan-Gang"}],"citation-key":"singhCochlearImplantMelody2009","container-title":"Ear and Hearing","container-title-short":"Ear and Hearing","issue":"2","issued":{"date-parts":[["2009"]]},"page":"160 - 168","publisher":"NIH Public Access","title":"Cochlear Implant Melody Recognition as a Function of Melody Frequency Range, Harmonicity, and Number of Electrodes","type":"article-journal","volume":"30"},{"id":"skuseCreatingOnlineEnsemble21","abstract":"The project takes a Universal Design approach to exploring the possibility of creating a software platform to facilitate a Networked Ensemble for Disabled musicians. In accordance with the Nothing About Us Without Us (Charlton, 1998) principle I worked with a group of 15 professional musicians who are also disabled. The group gave interviews as to their perspectives and needs around networked music practices and this data was then analysed to look at how software design could be developed to make it more accessible. We also identified key messages for the wider design of digital musical instrument makers, performers and event organisers to improve practice around working with and for disabled musicians.","author":[{"family":"Skuse","given":"Amble H C"},{"family":"Knotts","given":"Shelly"}],"citation-key":"skuseCreatingOnlineEnsemble21","container-title":"Proceedings of the International Conference on New Interfaces for Musical Expression","ISSN":"2220-4806","issued":{"date-parts":[["21"],["2020",7,25]]},"page":"115 -120","title":"Creating an Online Ensemble for Home Based Disabled Musicians: Why Disabled People Must be at the Heart of Developing Technology","type":"article-journal","URL":"https://www.nime.org/proceedings/2020/nime2020_paper22.pdf"},{"id":"smallMusickingMeaningsPerforming1998","author":[{"family":"Small","given":"Christopher"}],"call-number":"ML3845 .S628 1998","citation-key":"smallMusickingMeaningsPerforming1998","collection-title":"Music/culture","event-place":"Hanover","ISBN":"978-0-8195-2256-6 978-0-8195-2257-3","issued":{"date-parts":[["1998"]]},"number-of-pages":"230","publisher":"University Press of New England","publisher-place":"Hanover","source":"Library of Congress ISBN","title":"Musicking: The Meanings of Performing and Listening","title-short":"Musicking","type":"book"},{"id":"smithSocialJusticeDisability2009","author":[{"family":"Smith","given":"Steven R."}],"citation-key":"smithSocialJusticeDisability2009","container-title":"Arguing about disability","event-place":"New York","issued":{"date-parts":[["2009"]]},"page":"15 - 29","publisher":"Routledge","publisher-place":"New York","title":"Social Justice and Disability: Competing Interpretations of the Medical and Social Models","type":"chapter"},{"id":"snyderCulturalLocationsDisability2006","author":[{"family":"Snyder","given":"Sharon L."},{"family":"Mitchell","given":"David T."}],"call-number":"HV1568 .S69 2006","citation-key":"snyderCulturalLocationsDisability2006","event-place":"Chicago","ISBN":"978-0-226-76731-4 978-0-226-76732-1","issued":{"date-parts":[["2006"]]},"note":"OCLC: ocm61151535","number-of-pages":"245","publisher":"University of Chicago Press","publisher-place":"Chicago","source":"Library of Congress ISBN","title":"Cultural Locations of Disability","type":"book"},{"id":"snyderDisabilityStudiesEnabling2002","call-number":"HV1568.2 .D594 2002","citation-key":"snyderDisabilityStudiesEnabling2002","editor":[{"family":"Snyder","given":"Sharon L."},{"family":"Brueggemann","given":"Brenda Jo"},{"family":"Garland-Thomson","given":"Rosemarie"}],"event-place":"New York","ISBN":"978-0-87352-980-8 978-0-87352-981-5","issued":{"date-parts":[["2002"]]},"number-of-pages":"386","publisher":"Modern Language Association of America","publisher-place":"New York","source":"Library of Congress ISBN","title":"Disability Studies: Enabling the Humanities","title-short":"Disability studies","type":"book"},{"id":"snyderFeedbackTromboneControlling2018","abstract":"This paper presents research on control of electronic signal feedback in brass instruments through the development of a new augmented musical instrument, the Feedback Trombone. The Feedback Trombone (FBT) extends the traditional acoustic trombone interface with a speaker, microphone, and custom analog and digital hardware.","accessed":{"date-parts":[["2023",1,8]]},"author":[{"family":"Snyder","given":"Jeff"},{"family":"Mulshine","given":"Michael R"},{"family":"Erramilli","given":"Rajeev S"}],"citation-key":"snyderFeedbackTromboneControlling2018","DOI":"10.5281/ZENODO.1302629","issued":{"date-parts":[["2018",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"The Feedback Trombone: Controlling Feedback In Brass Instruments","title-short":"The Feedback Trombone","type":"article-journal","URL":"https://zenodo.org/record/1302629"},{"id":"soderbergMusicAidCollaborative2016","abstract":"This paper explores the possibility of breaking the barrier between deaf and hearing people when it comes to the subject of making music. Suggestions on how deaf and hearing people can collaborate in creating music together, are presented. The conducted research will focus on deaf people with a general interest in music as well as hearing musicians as target groups. Through reviewing different related research areas, it is found that visualization of sound along with a haptic feedback can help deaf people interpret and interact with music. With this in mind, three variations of a collaborative user interface are presented, in which deaf and hearing people are meant to collaborate in creating short beats and melody sequences. Through evaluating the three prototypes, with two deaf people and two hearing musicians, it is found that the target groups can collaborate to some extent in creating beats. However, in order for the target groups to create melodic sequences together in a satisfactory manner, more detailed visualization and distributed haptic output is necessary, mostly due to the fact that the deaf test participants struggle in distinguishing between higher pitch and timbre.","accessed":{"date-parts":[["2020",10,7]]},"author":[{"family":"Söderberg","given":"Ene Alicia"},{"family":"Odgaard","given":"Rasmus Emil"},{"family":"Bitsch","given":"Sarah"},{"family":"Höeg-Jensen","given":"Oliver"},{"family":"Christensen","given":"Nikolaj Schildt"},{"family":"Poulsen","given":"Sören Dahl"},{"family":"Gelineck","given":"Steven"}],"citation-key":"soderbergMusicAidCollaborative2016","DOI":"10.5281/ZENODO.1176112","issued":{"date-parts":[["2016",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"Music Aid---Towards A Collaborative Experience For Deaf And Hearing People In Creating Music","type":"article-journal","URL":"https://zenodo.org/record/1176112"},{"id":"sofianidisSomatosensoryDrivenInterpersonal2012","accessed":{"date-parts":[["2022",5,16]]},"author":[{"family":"Sofianidis","given":"George"},{"family":"Hatzitaki","given":"Vassilia"},{"family":"Grouios","given":"George"},{"family":"Johannsen","given":"Leif"},{"family":"Wing","given":"Alan"}],"citation-key":"sofianidisSomatosensoryDrivenInterpersonal2012","container-title":"Human Movement Science","container-title-short":"Human Movement Science","DOI":"10.1016/j.humov.2011.07.007","ISSN":"01679457","issue":"3","issued":{"date-parts":[["2012",6]]},"language":"en","page":"553-566","source":"DOI.org (Crossref)","title":"Somatosensory driven interpersonal synchrony during rhythmic sway","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0167945711001138","volume":"31"},{"id":"solnitWanderlustHistoryWalking2014","abstract":"Drawing together many histories-of anatomical evolution and city design, of treadmills and labyrinths, of walking clubs and sexual mores-Rebecca Solnit creates a fascinating portrait of the range of possibilities presented by walking. Arguing that the history of walking includes walking for pleasure as well as for political, aesthetic, and social meaning, Solnit focuses on the walkers whose everyday and extreme acts have shaped our culture, from philosophers to poets to mountaineers. She profiles some of the most significant walkers in history and fiction-from Wordsworth to Gary Snyder, from Jane Austen's Elizabeth Bennet to Andre Breton's Nadja-finding a profound relationship between walking and thinking and walking and culture. Solnit argues for the necessity of preserving the time and space in which to walk in our ever more car-dependent and accelerated world","author":[{"family":"Solnit","given":"Rebecca"}],"citation-key":"solnitWanderlustHistoryWalking2014","event-place":"New York","ISBN":"978-1-101-19955-8","issued":{"date-parts":[["2014"]]},"language":"eng","note":"OCLC: 883361637","publisher":"Penguin Books","publisher-place":"New York","source":"Open WorldCat","title":"Wanderlust: a history of walking","title-short":"Wanderlust","type":"book"},{"id":"sorginiHapticAssistiveTechnologiesAudition2018","abstract":"AbstractPurpose: The aim of this review is to analyze haptic sensory substitution technologies for deaf, blind and deaf?blind individuals.Method: The literature search has been performed in Scopus, PubMed and Google Scholar databases using selected keywords, analyzing studies from 1960s to present. Search on databases for scientific publications has been accompanied by web search for commercial devices. Results have been classified by sensory disability and functionality, and analyzed by assistive technology. Complementary analyses have also been carried out on websites of public international agencies, such as the World Health Organization (WHO), and of associations representing sensory disabled persons.Results: The reviewed literature provides evidences that sensory substitution aids are able to mitigate in part the deficits in language learning, communication and navigation for deaf, blind and deaf?blind individuals, and that the tactile sense can be a means of communication to provide some kind of information to sensory disabled individuals.Conclusions: A lack of acceptance emerged from the discussion of capabilities and limitations of haptic assistive technologies. Future researches shall go towards miniaturized, custom-designed and low-cost haptic interfaces and integration with personal devices such as smartphones for a major diffusion of sensory aids among disabled.Implications for rehabilitationSystematic review of state of the art of haptic assistive technologies for vision and audition sensory disabilities.Sensory substitution systems for visual and hearing disabilities have a central role in the transmission of information for patients with sensory impairments, enabling users to interact with the not disabled community in daily activities.Visual and auditory inputs are converted in haptic feedback via different actuation technologies. The information is presented in the form of static or dynamic stimulation of the skin.Their effectiveness and ease of use make haptic sensory substitution systems suitable for patients with different levels of disabilities. They constitute a cheaper and less invasive alternative to implantable partial sensory restitution systems.Future researches are oriented towards the optimization of the stimulation parameters together with the development of miniaturized, custom-designed and low-cost aids operating in synergy in networks, aiming to increase patients? acceptability of these technologies.","author":[{"family":"Sorgini","given":"Francesca"},{"family":"Caliò","given":"Renato"},{"family":"Carrozza","given":"Maria Chiara"},{"family":"Oddo","given":"Calogero Maria"}],"citation-key":"sorginiHapticAssistiveTechnologiesAudition2018","container-title":"Disability and Rehabilitation: Assistive Technology","container-title-short":"null","DOI":"10.1080/17483107.2017.1385100","ISSN":"1748-3107","issue":"4","issued":{"date-parts":[["2018",5,19]]},"page":"394-421","publisher":"Taylor & Francis","title":"Haptic-Assistive Technologies for Audition and Vision Sensory Disabilities","type":"article-journal","URL":"https://doi.org/10.1080/17483107.2017.1385100","volume":"13"},{"id":"sosciPrivacyProtectionOnline2019","accessed":{"date-parts":[["2021",1,29]]},"author":[{"literal":"soSci"}],"citation-key":"sosciPrivacyProtectionOnline2019","container-title":"soSci","issued":{"date-parts":[["2019",11,14]]},"title":"Privacy Protection in the Online Survey","type":"webpage","URL":"https://www.soscisurvey.de/help/doku.php/en:general:privacy"},{"id":"spagnolVikingHRTFDataset2019","author":[{"family":"Spagnol","given":"Simone"},{"family":"Purkhús","given":"Kristján Bjarki"},{"family":"Unnthórsson","given":"Rúnar"},{"family":"Björnsson","given":"Sverrir Karl"}],"citation-key":"spagnolVikingHRTFDataset2019","container-title":"Proceedings of the 16th Sound & Music Computing Conference (SMC 2019)","event-place":"Malaga, Spain","event-title":"16th Sound and music computing conference","ISBN":"978-84-09-08518-7","issued":{"date-parts":[["2019",5,28]]},"page":"55-60","publisher":"Sound and Music Computing Network","publisher-place":"Malaga, Spain","title":"The Viking HRTF dataset","type":"paper-conference"},{"id":"sparckjonesStatisticalInterpretationTerm1972","accessed":{"date-parts":[["2024",9,24]]},"author":[{"family":"Sparck Jones","given":"Karen"}],"citation-key":"sparckjonesStatisticalInterpretationTerm1972","container-title":"Journal of Documentation","container-title-short":"Journal of Documentation","DOI":"10.1108/eb026526","ISSN":"0022-0418","issue":"1","issued":{"date-parts":[["1972",1]]},"language":"en","page":"11-21","source":"DOI.org (Crossref)","title":"A statistical interpretation of term specificity and its application in retrieval","type":"article-journal","URL":"https://www.emerald.com/insight/content/doi/10.1108/eb026526/full/html","volume":"28"},{"id":"stachClinicalAudiologyIntroduction1998","author":[{"family":"Stach","given":"Brad A."}],"citation-key":"stachClinicalAudiologyIntroduction1998","event-place":"San Diego, Calif.","ISBN":"978-1-56593-346-0","issued":{"date-parts":[["1998"]]},"language":"eng","note":"OCLC: 245843423","number-of-pages":"585","publisher":"Singular Publ. Group","publisher-place":"San Diego, Calif.","source":"Gemeinsamer Bibliotheksverbund ISBN","title":"Clinical Audiology: An Introduction","title-short":"Clinical audiology","type":"book"},{"id":"staddonScientificMethodHow2024","author":[{"family":"Staddon","given":"John"}],"citation-key":"staddonScientificMethodHow2024","edition":"2nd ed","event-place":"Oxford","ISBN":"978-1-032-65771-4 978-1-040-03316-6","issued":{"date-parts":[["2024"]]},"language":"eng","number-of-pages":"1","publisher":"Taylor & Francis Group","publisher-place":"Oxford","source":"K10plus ISBN","title":"Scientific Method: How Science Works, Fails to Work, and Pretends to Work","title-short":"Scientific Method","type":"book"},{"id":"stanleyCaseStudy22015","abstract":"This chapter provides a case study in how objectives can hold back progress in a particular field of scientific research. The field of artificial intelligence (AI) focuses on the ambitious aim of creating a human-level computer intelligence, an objective which is fascinating for the profound implications it entails if is ever achieved. Interestingly, viewing the dominant approaches to AI through the myth of the objective illustrates the insidious potential for objectives to deceive even scientific experts. In particular, AI research is guided by perceived progress towards the objective of human-level AI, and the criteria for publishing AI papers are themselves driven by performance and theoretical objectives. While on their surface these incentives seem to make sense, there’s no reason to suspect that the quest for AI is fundamentally different from other systems of innovation or achievement. Thus the chapter suggests non-objective criteria that might productively unseat traditional objective-based incentives in AI research.","accessed":{"date-parts":[["2024",11,29]]},"author":[{"family":"Stanley","given":"Kenneth O."},{"family":"Lehman","given":"Joel"}],"citation-key":"stanleyCaseStudy22015","container-title":"Why Greatness Cannot Be Planned: The Myth of the Objective","DOI":"10.1007/978-3-319-15524-1_11","editor":[{"family":"Stanley","given":"Kenneth O."},{"family":"Lehman","given":"Joel"}],"event-place":"Cham","ISBN":"978-3-319-15524-1","issued":{"date-parts":[["2015"]]},"language":"en","page":"119-135","publisher":"Springer International Publishing","publisher-place":"Cham","source":"Springer Link","title":"Case Study 2: Objectives and the Quest for AI","title-short":"Case Study 2","type":"chapter","URL":"https://doi.org/10.1007/978-3-319-15524-1_11"},{"id":"stanleyWhyGreatnessCannot2015","accessed":{"date-parts":[["2024",11,29]]},"author":[{"family":"Stanley","given":"Kenneth O."},{"family":"Lehman","given":"Joel"}],"citation-key":"stanleyWhyGreatnessCannot2015","DOI":"10.1007/978-3-319-15524-1","event-place":"Cham","ISBN":"978-3-319-15523-4 978-3-319-15524-1","issued":{"date-parts":[["2015"]]},"language":"en","license":"https://www.springernature.com/gp/researchers/text-and-data-mining","publisher":"Springer International Publishing","publisher-place":"Cham","source":"DOI.org (Crossref)","title":"Why Greatness Cannot Be Planned: The Myth of the Objective","title-short":"Why Greatness Cannot Be Planned","type":"book","URL":"https://link.springer.com/10.1007/978-3-319-15524-1"},{"id":"starkeylaboratoriesinc.CompressionHandbookn.d.","accessed":{"date-parts":[["2021",1,24]]},"author":[{"literal":"Starkey Laboratories, Inc."}],"citation-key":"starkeylaboratoriesinc.CompressionHandbookn.d.","edition":"Fourth Edition","issued":{"literal":"n.d."},"publisher":"Starkey Laboratories, Inc.","title":"The Compression Handbook","type":"book","URL":"https://starkeypro.com/pdfs/The_Compression_Handbook.pdf"},{"id":"stauffertKaBoomVisuallyExploring2021","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Stauffert","given":"Jan-Philipp"},{"family":"Korwisi","given":"Kristof"},{"family":"Niebling","given":"Florian"},{"family":"Latoschik","given":"Marc Erich"}],"citation-key":"stauffertKaBoomVisuallyExploring2021","container-title":"Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems","DOI":"10.1145/3411763.3450379","event-place":"Yokohama Japan","event-title":"CHI '21: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-8095-9","issued":{"date-parts":[["2021",5,8]]},"language":"en","page":"1-9","publisher":"ACM","publisher-place":"Yokohama Japan","source":"DOI.org (Crossref)","title":"Ka-Boom!!! Visually Exploring Latency Measurements for XR","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3411763.3450379"},{"id":"steedSimpleMethodEstimating2008","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Steed","given":"Anthony"}],"citation-key":"steedSimpleMethodEstimating2008","container-title":"Proceedings of the 2008 ACM symposium on Virtual reality software and technology","DOI":"10.1145/1450579.1450606","event-place":"Bordeaux France","event-title":"VRST08: The ACM Symposium on Virtual Reality Software and Technology","ISBN":"978-1-59593-951-7","issued":{"date-parts":[["2008",10,27]]},"language":"en","page":"123-129","publisher":"ACM","publisher-place":"Bordeaux France","source":"DOI.org (Crossref)","title":"A simple method for estimating the latency of interactive, real-time graphics simulations","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/1450579.1450606"},{"id":"steedSimpleMethodEstimating2008a","abstract":"One of the critical determinants of the effectiveness and usability of interactive graphics simulations is the latency with which visual updates can be made based on input from interaction devices. High latency can diminish performance and can lead to simulator sickness. We demonstrate a new method for measuring latency using a standard video camera. The method is simple to configure, sensitive and rapid to use. This is in contrast to previous methods which required specialized equipment, were laborious or could only determine gross changes in latency. We attach a tracker to a pendulum and move a simulated image on the screen using the tracker positions. We video both the pendulum and simulated image together, and fit two sine curves, one to centre of motion of pendulum and one to the centre of motion of the simulated image. From the phase difference between these two sine curves we can determine latency changes significantly less than the frame rate of the camera. We demonstrate the method by comparing the latency of a two different systems for a CAVE™-like display.","author":[{"family":"Steed","given":"Anthony"}],"citation-key":"steedSimpleMethodEstimating2008a","collection-title":"VRST '08","container-title":"Proceedings of the 2008 ACM symposium on virtual reality software and technology","DOI":"10.1145/1450579.1450606","event-place":"Bordeaux, France","ISBN":"978-1-59593-951-7","issued":{"date-parts":[["2008"]]},"number-of-pages":"7","page":"123–129","publisher":"Association for Computing Machinery","publisher-place":"Bordeaux, France","title":"A simple method for estimating the latency of interactive, real-time graphics simulations","type":"paper-conference","URL":"https://doi.org/10.1145/1450579.1450606"},{"id":"stepputatIntroductionChoreomusicalPerspectives2020","abstract":"[This article introduces the theme and contents of this double issue on choreomusicology. It summarizes the historical development of research focusing on the relationship of music and dance, or sound and movement, especially within music and dance studies, but also in other disciplines. The authors advocate the term choreomusicology as an umbrella term for the various approaches used to investigate music-dance interrelations and related topics such as embodied music interaction. The focus is on combining views from ethnomusicology and ethnochoreology, which offer new potential to choreomusical research with their culturally sensitive insights based on ethnographic fieldwork, often including practical understanding of the traditions studied.]","accessed":{"date-parts":[["2023",12,21]]},"archive":"JSTOR","author":[{"family":"Stepputat","given":"Kendra"},{"family":"Seye","given":"Elina"}],"citation-key":"stepputatIntroductionChoreomusicalPerspectives2020","container-title":"The World of Music","ISSN":"00438774","issue":"1","issued":{"date-parts":[["2020"]]},"page":"7-24","publisher":"[Florian Noetzel GmbH Verlag, VWB - Verlag für Wissenschaft und Bildung, Bärenreiter, Schott Music GmbH & Co. KG]","title":"Introduction: Choreomusical Perspectives","type":"article-journal","URL":"https://www-jstor-org.ezproxy.uio.no/stable/26970252","volume":"9"},{"id":"stergiouImageryMetaphorsMovement2019","abstract":"Imagery is a commonly used practice that is applied in areas such as sports, rehabilitation, therapy and dance. Especially in dance, students of all ages are encouraged by their teachers to use imagery to improve their performance or clearly understand the form and quality of a movement. Mental imagery aims to stimulate thinking with the body, mostly with metaphoric pictures, that usually trigger the sense of sight. These visual or kinaestetic images may include handling imaginary objects, imagining being in particular environments and many other possible imaginary bodily states and shapes. Nowadays motion sensing, augmented and virtual reality technologies offer powerful tools for implementing interactive and real-time visualizations, merging the two worlds of mental imagery and immersive technology into a new range of opportunities. In this work, we raise the question of how design and transition of certain types of imagery into digital experiences might assist dance training. Within an embodied interactive experience, through visual or other modalities, a mental imagery metaphor can be transformed into a visual or other kind of representation consisting an effective and/or creative feedback. In this work, first, we examine the existing imagery approaches in movement practices and we discuss their characteristics. Secondly, we study the existing applications that are proposed by researchers in the field of interactive dance and categorize them in terms of the modalities that they use and the type of metaphors that they are related to. Based on existing literature on augmented performances and reported metaphors, we propose a practical map for implementing self practice tools, reflection tools and learning environments.","author":[{"family":"Stergiou","given":"Marina"},{"family":"El Raheb","given":"Katerina"},{"family":"Ioannidis","given":"Yannis"}],"citation-key":"stergiouImageryMetaphorsMovement2019","collection-title":"MOCO '19","container-title":"Proceedings of the 6th international conference on movement and computing","DOI":"10.1145/3347122.3347141","event-place":"Tempe, AZ, USA","ISBN":"978-1-4503-7654-9","issued":{"date-parts":[["2019"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Tempe, AZ, USA","title":"Imagery and metaphors: From movement practices to digital and immersive environments","type":"paper-conference","URL":"https://doi.org/10.1145/3347122.3347141"},{"id":"sterneAudibleCulturalOrigins2003","author":[{"family":"Sterne","given":"Jonathan"}],"call-number":"TK7881.4 .S733 2003","citation-key":"sterneAudibleCulturalOrigins2003","event-place":"Durham","ISBN":"978-0-8223-3013-4 978-0-8223-3004-2","issued":{"date-parts":[["2003"]]},"number-of-pages":"450","publisher":"Duke University Press","publisher-place":"Durham","source":"Library of Congress ISBN","title":"The audible past: cultural origins of sound reproduction","title-short":"The audible past","type":"book"},{"id":"sterneDiminishedFacultiesPolitical2021","abstract":"\"In Diminished Faculties Jonathan Sterne offers a sweeping cultural study and theorization of impairment. Drawing on his personal history with thyroid cancer and a paralyzed vocal cord, Sterne undertakes a political phenomenology of impairment in which experience is understood from the standpoint of a subject that is not fully able to account for itself. He conceives of impairment as a fundamental dimension of human experience, examining it as both political and physical. While some impairments are enshrined as normal in international standards, others are treated as causes or effects of illness or disability. Alongside his fractured account of experience, Sterne provides a tour of alternative vocal technologies and practices; a study of \"normal\" hearing loss as a cultural practice rather than a medical problem; and an intertwined history and phenomenology of fatigue that follows the concept as it careens from people, to materials science, to industrial management, to spoons. Sterne demonstrates how impairment is a problem, opportunity, and occasion for approaching larger questions about disability, subjectivity, power, technology, and experience in new ways. Diminished Faculties ends with a practical user's guide to impairment theory\"--","author":[{"family":"Sterne","given":"Jonathan"}],"call-number":"HV1568","citation-key":"sterneDiminishedFacultiesPolitical2021","event-place":"Durham","ISBN":"978-1-4780-2232-9","issued":{"date-parts":[["2021"]]},"number-of-pages":"1","publisher":"Duke University Press","publisher-place":"Durham","source":"Library of Congress ISBN","title":"Diminished faculties: a political phenomenology of impairment","title-short":"Diminished faculties","type":"book"},{"id":"sterneMediateAuscultationStethoscope2001","abstract":"The practice of mediate auscultation—listening to the body through a stethoscope—was at the center of new articulations of medical thought and practice in the 19th century. During that period, the stethoscope became the hallmark of medical modernity. This article offers a detailed examination of the work of RTH Laennec and other important writings on the stethoscope in order to argue for the centrality of a distinctive orientation toward listening in modern medicine. The development of mediate auscultation applied medical and scientific reason to listening, just as a particular practice of hearing the body became integral to everyday functioning of medicine. Mediate auscultation was thus an artifact of a new approach to reason and the senses, one based in a scientific mindset and a logic of mediation.","author":[{"family":"Sterne","given":"Jonathan"}],"citation-key":"sterneMediateAuscultationStethoscope2001","container-title":"Journal of Medical Humanities","container-title-short":"Journal of Medical Humanities","DOI":"10.1023/A:1009067628620","ISSN":"1573-3645","issue":"2","issued":{"date-parts":[["2001",6,1]]},"page":"115-136","title":"Mediate Auscultation, the Stethoscope, and the “Autopsy of the Living”: Medicine's Acoustic Culture","type":"article-journal","URL":"https://doi.org/10.1023/A:1009067628620","volume":"22"},{"id":"stevanceResearchcreationMusicCollaborative2018","author":[{"family":"Stévance","given":"Sophie"},{"family":"Lacasse","given":"Serge"}],"call-number":"MT18 .R47 2018","citation-key":"stevanceResearchcreationMusicCollaborative2018","collection-title":"SEMPRE studies in the psychology of music","event-place":"Abingdon, Oxon ; New York, NY","ISBN":"978-1-4724-8607-3","issued":{"date-parts":[["2018"]]},"number-of-pages":"177","publisher":"Routledge","publisher-place":"Abingdon, Oxon ; New York, NY","source":"Library of Congress ISBN","title":"Research-creation in music: towards a collaborative interdiscipline","title-short":"Research-creation in music","type":"book"},{"id":"stevensMovingMusicScaling2009","abstract":"TIME-KEEPING AMONG DANCERS WAS INVESTIGATED by measuring a dancer's movement in the presence and absence of music. If an internal clock was at work, then change from the ideal would manifest as scaling---consistently faster or slower unaccompanied performance; if time differences were due to lapsing, then sections from the with-music condition would be deleted, or material would be inserted into the no-music condition. Motion was recorded during ensemble performances of a four-minute choreographed piece with and without music. The median of 24 markers in the height dimension was analyzed for scaling and lapsing. Twenty percent of the variance was accounted for by sporadic scaling. Lapses---insertions and deletions---accounted for nearly all the speeding up---10.45 of 14 s. As in musical performance of memorized material, lapsing rather than scaling accounted for timing variations. Automation of lapsing and scaling detection has application in the analysis of music and dance time series data.","accessed":{"date-parts":[["2024",4,8]]},"author":[{"family":"Stevens","given":"Catherine J."},{"family":"Schubert","given":"Emery"},{"family":"Wang","given":"Shuai"},{"family":"Kroos","given":"Christian"},{"family":"Halovic","given":"Shaun"}],"citation-key":"stevensMovingMusicScaling2009","container-title":"Music Perception","DOI":"10.1525/mp.2009.26.5.451","ISSN":"0730-7829, 1533-8312","issue":"5","issued":{"date-parts":[["2009",6,1]]},"language":"en","note":"QID: Q63431449","page":"451-464","source":"DOI.org (Crossref)","title":"Moving with and Without Music: Scaling and Lapsing in Time in the Performance of Contemporary Dance","title-short":"Moving with and Without Music","type":"article-journal","URL":"https://online.ucpress.edu/mp/article/26/5/451/62434/Moving-with-and-Without-Music-Scaling-and-Lapsing","volume":"26"},{"id":"stevensMusicPerceptionCognition2012","abstract":"Abstract\n            Experimental investigations of cross‐cultural music perception and cognition reported during the past decade are described. As globalization and Western music homogenize the world musical environment, it is imperative that diverse music and musical contexts are documented. Processes of music perception include grouping and segmentation, statistical learning and sensitivity to tonal and temporal hierarchies, and the development of tonal and temporal expectations. The interplay of auditory, visual, and motor modalities is discussed in light of synchronization and the way music moves via emotional response. Further research is needed to test deep‐rooted psychological assumptions about music cognition with diverse materials and groups in dynamic contexts. Although empirical musicology provides keystones to unlock musical structures and organization, the psychological reality of those theorized structures for listeners and performers, and the broader implications for theories of music perception and cognition, awaits investigation.","accessed":{"date-parts":[["2024",1,11]]},"author":[{"family":"Stevens","given":"Catherine J."}],"citation-key":"stevensMusicPerceptionCognition2012","container-title":"Topics in Cognitive Science","container-title-short":"Topics in Cognitive Science","DOI":"10.1111/j.1756-8765.2012.01215.x","ISSN":"1756-8757, 1756-8765","issue":"4","issued":{"date-parts":[["2012",10]]},"language":"en","page":"653-667","source":"DOI.org (Crossref)","title":"Music Perception and Cognition: A Review of Recent Cross‐Cultural Research","title-short":"Music Perception and Cognition","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/10.1111/j.1756-8765.2012.01215.x","volume":"4"},{"id":"stevensUniversalsMusicProcessing2016","accessed":{"date-parts":[["2022",1,5]]},"author":[{"family":"Stevens","given":"Catherine"},{"family":"Byron","given":"Tim"}],"citation-key":"stevensUniversalsMusicProcessing2016","DOI":"10.1093/oxfordhb/9780198722946.013.6","editor":[{"family":"Hallam","given":"Susan"},{"family":"Cross","given":"Ian"},{"family":"Thaut","given":"Michael"}],"issued":{"date-parts":[["2016",1,1]]},"publisher":"Oxford University Press","source":"DOI.org (Crossref)","title":"Universals in Music Processing","type":"book","URL":"http://oxfordhandbooks.com/view/10.1093/oxfordhb/9780198722946.001.0001/oxfordhb-9780198722946-e-6"},{"id":"stikerHistoryDisability1999","author":[{"family":"Stiker","given":"Henri-Jacques"}],"call-number":"HV1552 .S8413 1999","citation-key":"stikerHistoryDisability1999","collection-title":"Corporealities","event-place":"Ann Arbor","ISBN":"978-0-472-11063-6 978-0-472-08626-9","issued":{"date-parts":[["1999"]]},"language":"eng","number-of-pages":"239","publisher":"University of Michigan Press","publisher-place":"Ann Arbor","source":"Library of Congress ISBN","title":"A History of Disability","type":"book"},{"id":"stokoeSignLanguageStructure2005","abstract":"It is approaching a half century since Bill Stokoe published his revolutionary monograph, Sign Language Structure: An Outline of the Visual Communication Systems of the American Deaf. It is rare for a work of innovative scholarship to spark a social as well as an intellectual revolution, but that is just what Stokoe's 1960 paper did. And it is indicative both of Stokoe's genius and of his commitment that he did not simply publish his groundbreaking work and then sit back to watch the revolutions unfold. He actively promoted important changes in at least three areas of social and intellectual life. First, and perhaps most important, his work, that was ultimately generally accepted as showing the signing of deaf people to be linguistic, supported significant changes in the way deaf children are educated around the globe. Second, his work led to a general rethinking of what is fundamental about human language; and, third, it helped to reenergize the moribund field of language origin studies. This truly revolutionary paper has been reprinted at least twice, in revised and original versions, since its initial release in 1960, and now, five years after Bill's death, it is good to see it once again brought before the general public. – David F. Armstrong, Gallaudet University","accessed":{"date-parts":[["2020",12,28]]},"author":[{"family":"Stokoe","given":"William C.","suffix":"Jr."}],"citation-key":"stokoeSignLanguageStructure2005","container-title":"The Journal of Deaf Studies and Deaf Education","container-title-short":"The Journal of Deaf Studies and Deaf Education","DOI":"10.1093/deafed/eni001","ISSN":"1081-4159","issue":"1","issued":{"date-parts":[["2005",1,1]]},"page":"3-37","title":"Sign Language Structure: An Outline of the Visual Communication Systems of the American Deaf","type":"article-journal","URL":"https://doi.org/10.1093/deafed/eni001","volume":"10"},{"id":"stoneInformationTheoryTutorial2015","author":[{"family":"Stone","given":"James V."}],"citation-key":"stoneInformationTheoryTutorial2015","edition":"First edition","event-place":"Sheffield, UK","ISBN":"978-0-9563728-5-7","issued":{"date-parts":[["2015"]]},"language":"eng","number-of-pages":"243","publisher":"Sebtel Press","publisher-place":"Sheffield, UK","source":"K10plus ISBN","title":"Information theory: a tutorial introduction","title-short":"Information theory","type":"book"},{"id":"strachanSonicTechnologiesPopular2017","author":[{"family":"Strachan","given":"Robert"}],"call-number":"ML3876 .S77 2017","citation-key":"strachanSonicTechnologiesPopular2017","event-place":"New York, NY","ISBN":"978-1-5013-1061-4 978-1-5013-1062-1","issued":{"date-parts":[["2017"]]},"number-of-pages":"194","publisher":"Bloomsbury Academic","publisher-place":"New York, NY","source":"Library of Congress ISBN","title":"Sonic technologies: popular music, digital culture and the creative process","title-short":"Sonic technologies","type":"book"},{"id":"strasSubhumanSuperhumanMusical2016","author":[{"family":"Stras","given":"Laurie"}],"citation-key":"strasSubhumanSuperhumanMusical2016","container-title":"The Oxford Handbook of Music and Disability Studies","editor":[{"family":"Howe","given":"Blake"},{"family":"Jensen-Moulton","given":"Stephanie"},{"family":"Lerner","given":"Neil William"},{"family":"Straus","given":"Joseph Nathan"}],"event-place":"Oxford ; New York","ISBN":"978-0-19-933144-4 978-0-19-065060-5","issued":{"date-parts":[["2016"]]},"page":"54 - 72","publisher":"Oxford University Press","publisher-place":"Oxford ; New York","source":"Library of Congress ISBN","title":"Subhuman or Superhuman: (Musical) Assistive Technology, Performance Enhancement, and the Aesthetic/Moral Debate","type":"chapter"},{"id":"strausAutismCulture2013","author":[{"family":"Straus","given":"Joseph N."}],"citation-key":"strausAutismCulture2013","container-title":"The Disability Studies Reader","editor":[{"family":"Davis","given":"Lennard J."}],"event-place":"New York","issued":{"date-parts":[["2013"]]},"page":"460-84","publisher":"Routledge New York","publisher-place":"New York","title":"Autism as Culture","type":"chapter","volume":"4"},{"id":"strausExtraordinaryMeasuresDisability2011","author":[{"family":"Straus","given":"Joseph N."}],"call-number":"ML3800 .S885 2011","citation-key":"strausExtraordinaryMeasuresDisability2011","event-place":"New York","ISBN":"978-0-19-976645-1 978-0-19-976646-8","issued":{"date-parts":[["2011"]]},"note":"OCLC: ocn609101212","number-of-pages":"212","publisher":"Oxford University Press","publisher-place":"New York","source":"Library of Congress ISBN","title":"Extraordinary Measures: Disability in Music","title-short":"Extraordinary measures","type":"book"},{"id":"strausNormalizingAbnormalDisability2006","abstract":"Abstract The emerging interdisciplinary field of disability studies takes as its subject matter the historical, social, and cultural construction of disability. After a brief introduction to disability studies, this article explores the interconnected histories of disability and music as they are manifested in three theoretical approaches to late eighteenth- and early nineteenth-century Western art music (the musical Formenlehre and the tonal theories of Schoenberg and Schenker) and in three works by Beethoven and Schubert. Around the turn of the nineteenth century in Western Europe, disability began to be understood not as something natural and permanent but rather as a deviation from a normative standard, and thus subject to possible remediation. In the same time and place, art music also underwent a significant shift (reflected in the more recent theoretical traditions that have grown up around it), one that involved an increasing interest in rhetorically marked deviations from diatonic and formal normativity, and the possibility of their narrative recuperation. The article describes ways in which language about music and music itself may be understood both to represent and construct disability. More generally, it suggests that disability should take its place alongside nationality, ethnicity, class, gender, and sexual orientation as a significant category for cultural analysis, including the analysis of music.","archive":"JSTOR","author":[{"family":"Straus","given":"Joseph N."}],"citation-key":"strausNormalizingAbnormalDisability2006","container-title":"Journal of the American Musicological Society","DOI":"10.1525/jams.2006.59.1.113","ISSN":"00030139, 15473848","issue":"1","issued":{"date-parts":[["2006"]]},"page":"113-184","publisher":"[University of California Press, American Musicological Society]","title":"Normalizing the Abnormal: Disability in Music and Music Theory","type":"article-journal","URL":"http://www.jstor.org/stable/10.1525/jams.2006.59.1.113","volume":"59"},{"id":"struttSimpleToolRemote2022","author":[{"family":"Strutt","given":"Dan"}],"citation-key":"struttSimpleToolRemote2022","container-title":"Critical Stages/Scènes critiques","container-title-short":"Critical Stages/Scènes critiques","ISSN":"2409-7411","issued":{"date-parts":[["2022"]]},"publisher":"International Association of Theatre Critics (IATC)","title":"A Simple Tool for Remote Real-Time Dance Interaction in Virtual Spaces, Or “Dancing in the Metaverse”","type":"article-journal","URL":"https://www.critical-stages.org/25/a-simple-tool-for-remote-real-time-dance-interaction-in-virtual-spaces-or-dancing-in-the-metaverse/","volume":"25"},{"id":"strzysch-siebeckBrockhausMusikPersonen2001","call-number":"ML100 .B4845 2001","citation-key":"strzysch-siebeckBrockhausMusikPersonen2001","edition":"2., völlig neu bearbeitete Aufl","editor":[{"family":"Strzysch-Siebeck","given":"Marianne"}],"event-place":"Mannheim","ISBN":"978-3-7653-0374-6","issued":{"date-parts":[["2001"]]},"number-of-pages":"896","publisher":"Brockhaus","publisher-place":"Mannheim","source":"Library of Congress ISBN","title":"Der Brockhaus Musik: Personen, Epochen, Sachbegriffe","title-short":"Der Brockhaus Musik","type":"book"},{"id":"subramaniyanAbbreviatedTitleNeural2015","abstract":"null","author":[{"family":"Subramaniyan","given":"Manivannan"},{"family":"Ecker","given":"Alexander S."},{"family":"Patel","given":"Saumil S."},{"family":"Cotton","given":"R."},{"family":"Berens","given":"Philipp"},{"family":"Tolias","given":"A."}],"citation-key":"subramaniyanAbbreviatedTitleNeural2015","issued":{"date-parts":[["2015"]]},"title":"Abbreviated title: Neural correlates of flash lag illusion","type":"article-journal","URL":"https://www.semanticscholar.org/paper/e05d2c0da2e10e251c62cd5c356b2b1c8d8cbfd4"},{"id":"subramaniyanFasterProcessingMoving2018","abstract":"When the brain has determined the position of a moving object, because of anatomical and processing delays the object will have already moved to a new location. Given the statistical regularities present in natural motion, the brain may have acquired compensatory mechanisms to minimize the mismatch between the perceived and real positions of moving objects. A well-known visual illusion-the flash lag effect-points toward such a possibility. Although many psychophysical models have been suggested to explain this illusion, their predictions have not been tested at the neural level, particularly in a species of animal known to perceive the illusion. To this end, we recorded neural responses to flashed and moving bars from primary visual cortex (V1) of awake, fixating macaque monkeys. We found that the response latency to moving bars of varying speed, motion direction, and luminance was shorter than that to flashes, in a manner that is consistent with psychophysical results. At the level of V1, our results support the differential latency model positing that flashed and moving bars have different latencies. As we found a neural correlate of the illusion in passively fixating monkeys, our results also suggest that judging the instantaneous position of the moving bar at the time of flash-as required by the postdiction/motion-biasing model-may not be necessary for observing a neural correlate of the illusion. Our results also suggest that the brain may have evolved mechanisms to process moving stimuli faster and closer to real time compared with briefly appearing stationary stimuli. NEW & NOTEWORTHY We report several observations in awake macaque V1 that provide support for the differential latency model of the flash lag illusion. We find that the equal latency of flash and moving stimuli as assumed by motion integration/postdiction models does not hold in V1. We show that in macaque V1, motion processing latency depends on stimulus luminance, speed and motion direction in a manner consistent with several psychophysical properties of the flash lag illusion.","author":[{"family":"Subramaniyan","given":"Manivannan"},{"family":"Ecker","given":"Alexander S."},{"family":"Patel","given":"Saumil S."},{"family":"Cotton","given":"R."},{"family":"Bethge","given":"M."},{"family":"Pitkow","given":"X."},{"family":"Berens","given":"Philipp"},{"family":"Tolias","given":"A."}],"citation-key":"subramaniyanFasterProcessingMoving2018","container-title":"Journal of neurophysiology","DOI":"10.1152/jn.00792.2017","issued":{"date-parts":[["2018"]]},"note":"QID: Q58560962","page":"2430-2452","PMID":"30133378","title":"Faster processing of moving compared with flashed bars in awake macaque V1 provides a neural correlate of the flash lag illusion.","type":"article-journal","URL":"https://www.semanticscholar.org/paper/3084afdcc8772e0eae8a3511d954cfcd8fc05e0a","volume":"120 5"},{"id":"subramaniyanMacaqueMonkeysPerceive2013","abstract":"Transmission of neural signals in the brain takes time due to the slow biological mechanisms that mediate it. During such delays, the position of moving objects can change substantially. The brain could use statistical regularities in the natural world to compensate neural delays and represent moving stimuli closer to real time. This possibility has been explored in the context of the flash lag illusion, where a briefly flashed stimulus in alignment with a moving one appears to lag behind the moving stimulus. Despite numerous psychophysical studies, the neural mechanisms underlying the flash lag illusion remain poorly understood, partly because it has never been studied electrophysiologically in behaving animals. Macaques are a prime model for such studies, but it is unknown if they perceive the illusion. By training monkeys to report their percepts unbiased by reward, we show that they indeed perceive the illusion qualitatively similar to humans. Importantly, the magnitude of the illusion is smaller in monkeys than in humans, but it increases linearly with the speed of the moving stimulus in both species. These results provide further evidence for the similarity of sensory information processing in macaques and humans and pave the way for detailed neurophysiological investigations of the flash lag illusion in behaving macaques.","author":[{"family":"Subramaniyan","given":"Manivannan"},{"family":"Ecker","given":"Alexander S."},{"family":"Berens","given":"Philipp"},{"family":"Tolias","given":"A."}],"citation-key":"subramaniyanMacaqueMonkeysPerceive2013","container-title":"PLoS ONE","DOI":"10.1371/journal.pone.0058788","issued":{"date-parts":[["2013"]]},"note":"QID: Q34634286","page":"null","PMID":"23527024","title":"Macaque monkeys perceive the flash lag illusion","type":"article-journal","URL":"https://www.semanticscholar.org/paper/885a343c4b6418f377349e0e6dbccde8c4a8281d","volume":"8"},{"id":"sucherBimodalStimulationBenefits2009","author":[{"family":"Sucher","given":"Catherine M."},{"family":"McDermott","given":"Hugh"}],"citation-key":"sucherBimodalStimulationBenefits2009","container-title":"Cochlear Implants International","container-title-short":"Cochlear Implants International","ISSN":"1467-0100","issue":"S1","issued":{"date-parts":[["2009"]]},"page":"96-99","publisher":"Wiley Online Library","title":"Bimodal Stimulation: Benefits for Music Perception and Sound Quality","type":"article-journal","volume":"10"},{"id":"sucherPitchRankingComplex2007","author":[{"family":"Sucher","given":"Catherine M."},{"family":"McDermott","given":"Hugh"}],"citation-key":"sucherPitchRankingComplex2007","container-title":"Hearing Research","container-title-short":"Hearing Research","ISSN":"0378-5955","issue":"1-2","issued":{"date-parts":[["2007"]]},"page":"80-87","publisher":"Elsevier","title":"Pitch Ranking of Complex Tones by Normally Hearing Subjects and Cochlear Implant Users","type":"article-journal","volume":"230"},{"id":"suitsElementsSport2007","author":[{"family":"Suits","given":"Bernard"}],"citation-key":"suitsElementsSport2007","container-title":"Ethics in sport","container-title-short":"Ethics in sport","issued":{"date-parts":[["2007"]]},"page":"9-19","publisher":"Human Kinetics Champaign, IL","title":"The Elements of Sport","type":"article-journal","volume":"2"},{"id":"sukhanovDynamicPatternMatching2020","accessed":{"date-parts":[["2023",3,30]]},"author":[{"family":"Sukhanov","given":"S."},{"family":"Wu","given":"R."},{"family":"Debes","given":"C."},{"family":"Zoubir","given":"A.M."}],"citation-key":"sukhanovDynamicPatternMatching2020","container-title":"Signal Processing","container-title-short":"Signal Processing","DOI":"10.1016/j.sigpro.2019.107402","ISSN":"01651684","issued":{"date-parts":[["2020",6]]},"language":"en","page":"107402","source":"DOI.org (Crossref)","title":"Dynamic pattern matching with multiple queries on large scale data streams","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0165168419304542","volume":"171"},{"id":"sutilDigitalMovementEssays2015","call-number":"QP303 .C57 2015","citation-key":"sutilDigitalMovementEssays2015","collection-title":"Palgrave studies in performance and technology","editor":[{"family":"Sutil","given":"Nicolás Salazar"},{"family":"Popat","given":"Sita"}],"event-place":"Houndmills, Basingstoke Hampshire ; New York, NY","ISBN":"978-1-137-43040-3","issued":{"date-parts":[["2015"]]},"number-of-pages":"317","publisher":"Palgrave Macmillan","publisher-place":"Houndmills, Basingstoke Hampshire ; New York, NY","source":"Library of Congress ISBN","title":"Digital movement: essays in motion technology and performance","title-short":"Digital movement","type":"book"},{"id":"sutilIntroduction2015","author":[{"family":"Sutil","given":"Nicolás Salazar"},{"family":"Popat","given":"Sita"}],"call-number":"QP303 .C57 2015","citation-key":"sutilIntroduction2015","collection-title":"Palgrave studies in performance and technology","container-title":"Digital movement: essays in motion technology and performance","editor":[{"family":"Sutil","given":"Nicolás Salazar"},{"family":"Popat","given":"Sita"}],"event-place":"Houndmills, Basingstoke Hampshire ; New York, NY","ISBN":"978-1-137-43040-3","issued":{"date-parts":[["2015"]]},"page":"1-17","publisher":"Palgrave Macmillan","publisher-place":"Houndmills, Basingstoke Hampshire ; New York, NY","source":"Library of Congress ISBN","title":"Introduction","type":"chapter"},{"id":"sutilMathematicsMotionComparative2014","abstract":"This essay looks at the seminal work of Bauhaus practitioners Wassily Kandinksy and Oskar Schlemmer in terms of their multidisciplinary approach to the performing arts, and the dance in particular. Whilst their contribution has been widely recognized in terms of a cross-pollination of ideas from the fine arts to the performing arts, this essay also addresses the influence that compositional methods, based on techniques derived from figural drawing, as well as the study of form and geometry, might have had in their choreographic practice. I argue that despite stylistic similarities, these works present a divergent approach to the question of a geometrized motion design, which Schlemmer called ?mathematics in motion?. I discuss the concept of ?abstract dance? promoted by Kandinsky, in terms of a visualistic method, where movement is rendered both as a succession of still images and as an imaginary process. Schlemmer, on the other hand, promoted a synthesis of abstract and physical, as part of a model for live performance known as ?balletic mathematics?. I expand on this distinction in terms of a differential sense schematic approach to movement, one being visual, the other proprioceptive. Landmark works produced by these artists during the Bauhaus years (1922?1933) are called upon as case studies, including Kandinsky's Dance Curves (after Gret Palucca), and Schlemmer's renowned Stäbetanz.","accessed":{"date-parts":[["2023",2,28]]},"author":[{"family":"Sutil","given":"Nicolas Salazar"}],"citation-key":"sutilMathematicsMotionComparative2014","container-title":"Dance Research","container-title-short":"Dance Research","DOI":"10.3366/drs.2014.0085","ISSN":"0264-2875","issue":"1","issued":{"date-parts":[["2014",5,1]]},"page":"23-42","publisher":"Edinburgh University Press","title":"Mathematics in Motion: A Comparative Analysis of the Stage Works of Schlemmer and Kandinsky at the Bauhaus","type":"article-journal","URL":"https://doi.org/10.3366/drs.2014.0085","volume":"32"},{"id":"tanakaComparisonExergamingInterfaces2012","author":[{"family":"Tanaka","given":"Kazumoto"},{"family":"Parker","given":"JR"},{"family":"Baradoy","given":"Graham"},{"family":"Sheehan","given":"Dwayne"},{"family":"Holash","given":"John R"},{"family":"Katz","given":"Larry"}],"citation-key":"tanakaComparisonExergamingInterfaces2012","container-title":"Loading...","container-title-short":"Loading...","ISSN":"1923-2691","issue":"9","issued":{"date-parts":[["2012"]]},"title":"A comparison of exergaming interfaces for use in rehabilitation programs and research","type":"article-journal","volume":"6"},{"id":"tanakaGesturalMusicalAffordances2012","abstract":"In this paper a comparative study gestural interaction with musical sound, to gain insight into the notion of musical affordance on interactive music systems. We conducted an interview base user study trialing three accelerometer based devices, an iPhone, a Wii-mote, and an Axivity Wax prototype, with four kinds of musical sound, including percussion, stringed instruments, and voice recordings. The accelerometers from the devices were mapped to computer based sound synthesis parameters. By using consistent mappings across different source sounds, and performing them from the three different devices, users experienced forms of physical, sonic, and cultural affordance, that combine to form what we term musical affordance.","author":[{"family":"Tanaka","given":"Atau"},{"family":"Altavilla","given":"Alessandro"},{"family":"Spowage","given":"N."}],"citation-key":"tanakaGesturalMusicalAffordances2012","container-title":"Proceedings of the 9th Sound and Music Computing Conference, SMC 2012","container-title-short":"Proceedings of the 9th Sound and Music Computing Conference, SMC 2012","issued":{"date-parts":[["2012",1,1]]},"title":"Gestural musical affordances","type":"article-journal"},{"id":"tangInteractiveDancingGame2011","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Tang","given":"Jeff K. T."},{"family":"Chan","given":"Jacky C. P."},{"family":"Leung","given":"Howard"}],"citation-key":"tangInteractiveDancingGame2011","container-title":"Proceedings of the 5th International Conference on Ubiquitous Information Management and Communication","DOI":"10.1145/1968613.1968674","event-place":"Seoul Korea","event-title":"ICUIMC '11: The 5th International Conference on Ubiquitous Information Management and Communication","ISBN":"978-1-4503-0571-6","issued":{"date-parts":[["2011",2,21]]},"language":"en","page":"1-9","publisher":"ACM","publisher-place":"Seoul Korea","source":"DOI.org (Crossref)","title":"Interactive dancing game with real-time recognition of continuous dance moves from 3D human motion capture","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/1968613.1968674"},{"id":"tanPerceptionNonlinearDistortion2008","author":[{"family":"Tan","given":"Chin-Tuan"},{"family":"Moore","given":"Brian C. J."}],"citation-key":"tanPerceptionNonlinearDistortion2008","container-title":"International Journal of Audiology","container-title-short":"International Journal of Audiology","ISSN":"1499-2027","issue":"5","issued":{"date-parts":[["2008"]]},"page":"246-256","publisher":"Taylor & Francis","title":"Perception of Nonlinear Distortion by Hearing-Impaired People","type":"article-journal","volume":"47"},{"id":"tatarLatentTimbreSynthesis2021","author":[{"family":"Tatar","given":"Kıvanç"},{"family":"Bisig","given":"Daniel"},{"family":"Pasquier","given":"Philippe"}],"citation-key":"tatarLatentTimbreSynthesis2021","container-title":"Neural Computing and Applications","container-title-short":"Neural Computing and Applications","ISSN":"1433-3058","issue":"1","issued":{"date-parts":[["2021"]]},"page":"67-84","publisher":"Springer","title":"Latent timbre synthesis","type":"article-journal","volume":"33"},{"id":"tatarMusicalAgentsTypology2019","abstract":"ABSTRACTMusical agents are artificial agents that tackle musical creative tasks, partially or completely. This review of musical agents combines the terminology of Generative Arts (artistic practice) and the scientific literature of Computational Creativity, Multi-Agent Systems (MAS), and Artificial Intelligence. We define Musical Metacreation as a field that studies the partial or complete automation of musical tasks. We survey seventy-eight musical agent systems, and present a typology of musical agents. After examining the evaluation methodologies of musical agents, we propose possible future steps while mentioning ongoing discussions in the field.","author":[{"family":"Tatar","given":"Kıvanç"},{"family":"Pasquier","given":"Philippe"}],"citation-key":"tatarMusicalAgentsTypology2019","container-title":"Journal of New Music Research","container-title-short":"null","DOI":"10.1080/09298215.2018.1511736","ISSN":"0929-8215","issue":"1","issued":{"date-parts":[["2019",1,1]]},"page":"56-105","publisher":"Routledge","title":"Musical agents: A typology and state of the art towards Musical Metacreation","type":"article-journal","URL":"https://doi.org/10.1080/09298215.2018.1511736","volume":"48"},{"id":"taylorInfluenceContinuousAffect2021","abstract":"We aim to increase user engagement in unfamiliar music. We investigated listening duration for 100 unfamiliar art music items from the Australian Music Centre (AMC) library, presented under four different exposure conditions: a continuous affect response task, text/photographic information, text only, and no information. Participants could skip each item, and provided post-excerpt liking or familiarity ratings. Time-series analysis models of listening duration, liking, and familiarity, showed no increase in successive item liking or familiarity, although user liking and familiarity, positively predicted listening duration. The data confirm that directing listeners’ attention to discerning affect can enhance their engagement with unfamiliar music.","accessed":{"date-parts":[["2021",10,4]]},"author":[{"family":"Taylor","given":"John R."},{"family":"Dean","given":"Roger T."}],"citation-key":"taylorInfluenceContinuousAffect2021","container-title":"Journal of New Music Research","container-title-short":"Journal of New Music Research","DOI":"10.1080/09298215.2020.1867588","ISSN":"0929-8215, 1744-5027","issue":"3","issued":{"date-parts":[["2021",5,27]]},"language":"en","page":"242-258","source":"DOI.org (Crossref)","title":"Influence of a continuous affect ratings task on listening time for unfamiliar art music","type":"article-journal","URL":"https://www.tandfonline.com/doi/full/10.1080/09298215.2020.1867588","volume":"50"},{"id":"tedHowTrulyListen2007","accessed":{"date-parts":[["2021",1,12]]},"author":[{"literal":"TED"}],"citation-key":"tedHowTrulyListen2007","container-title":"YouTube","issued":{"date-parts":[["2007",5,14]]},"title":"How to truly listen | Evelyn Glennie","type":"webpage","URL":"https://www.youtube.com/watch?v=IU3V6zNER4g"},{"id":"teruggiMusiqueConcreteToday2015","abstract":"Musique concrète has become a well-known word and concept. The history of the concept permits us to understand how it evolved and how its inventor, Pierre Schaeffer, felt about it and its impact. The terms have gone through several transformations, the main one being that into the term acousmatique, which implied a change of perspective in the reach of the concept. Today musique concrète is an active concept, not generally applied to describe contemporary musical creation, however embedded in musical thought and theory.","archive":"Cambridge Core","author":[{"family":"Teruggi","given":"Daniel"}],"citation-key":"teruggiMusiqueConcreteToday2015","container-title":"Organised Sound","DOI":"10.1017/S1355771814000429","edition":"2015/03/05","ISSN":"1355-7718","issue":"1","issued":{"date-parts":[["2015"]]},"page":"51-59","publisher":"Cambridge University Press","source":"Cambridge University Press","title":"Musique Concrète Today: Its reach, evolution of concepts and role in musical thought","type":"article-journal","URL":"https://www.cambridge.org/core/article/musique-concrete-today-its-reach-evolution-of-concepts-and-role-in-musical-thought/EECE2B87DA05CC0984EF62C0A8602B7B","volume":"20"},{"id":"thiedeTapDanceMedium2020","abstract":"While there are sources for preserving and documenting movement, there are not many clear options for memorization and disseminating notation for tap dance. Two sources are more widely known: Labanotation and Kahnotation. The former attempts to use a diagram of the human body to express how it should move over time. The latter uses images sequentially to convey movement. Labanotation is typically used for more classical and modern genres like ballet and contemporary dance. Kahnotation was devised specifically for tap dance. While both are no more complex than music notation, they are vastly different and do not crossover into how a musician understands reading music. This paper aims to comprehensively analyze both notation systems by comparing and contrasting with modern music notation. Additionally, I propose a new form of notation for both tap dancers and musicians which is inspired by elements of rudiments for percussion. Ultimately, I apply three suggested methods for composing for tap dance in addition to creating a unique Max 4 Live device which allows tap dancers to actively interact with the computer (Ableton) and change tempo with effortless precision.","author":[{"family":"Thiede","given":"Jacob"}],"citation-key":"thiedeTapDanceMedium2020","collection-title":"MOCO '20","container-title":"Proceedings of the 7th international conference on movement and computing","DOI":"10.1145/3401956.3404230","event-place":"Jersey City/Virtual, NJ, USA","ISBN":"978-1-4503-7505-4","issued":{"date-parts":[["2020"]]},"number-of-pages":"9","publisher":"Association for Computing Machinery","publisher-place":"Jersey City/Virtual, NJ, USA","title":"Tap dance as medium for composition: Notation and technology","type":"paper-conference","URL":"https://doi.org/10.1145/3401956.3404230"},{"id":"thomasMusicTechnologySpecial2013","accessed":{"date-parts":[["2021",1,18]]},"author":[{"family":"Thomas","given":"Pete"}],"citation-key":"thomasMusicTechnologySpecial2013","container-title":"Sound On Sound","issued":{"date-parts":[["2013",1]]},"title":"Music Technology & Special Needs: Part 2 Assist & Adapt","type":"webpage","URL":"https://www.soundonsound.com/techniques/music-technology-special-needs-part-2"},{"id":"thorsenCanMachineLearning2024","abstract":"As the world of competitive sports increasingly embraces data-driven techniques, our research explores the potential of machine learning in distinguishing elite from semi-elite beach volleyball players. This study is motivated by the need to understand the subtle yet crucial differences in player movements that contribute to high-level performance in beach volleyball. Utilizing advanced machine learning techniques, we analyzed specific movement patterns of the motion of the torso during spikes, captured through vest-mounted accelerometers. Our approach offers novel insights into the nuanced dynamics of elite play, revealing that certain movement patterns are distinctly characteristic of higher skill levels. One of our key contributions is the ability to classify spiking movements at different skill levels with an accuracy rate as high as 87%. This current research provides a foundation of what separates elite players from their semi-elite counterparts.","accessed":{"date-parts":[["2024",10,11]]},"author":[{"family":"Thorsen","given":"Ola"},{"family":"Esema","given":"Emmanuel"},{"family":"Hemaz","given":"Said"},{"family":"Ellefsen","given":"Kai Olav"},{"family":"Herrebrøden","given":"Henrik"},{"family":"Arnim","given":"Hugh A","non-dropping-particle":"von"},{"family":"Torresen","given":"Jim"}],"citation-key":"thorsenCanMachineLearning2024","container-title":"Proceedings of the 14th Scandinavian Conference on Artificial Intelligence SCAI 2024","DOI":"10.3384/ecp208007","event-place":"Jönköping, Sweden","event-title":"14th Scandinavian Conference on Artificial Intelligence SCAI 2024","issued":{"date-parts":[["2024",6,14]]},"license":"https://creativecommons.org/licenses/by/4.0/","page":"57-66","publisher":"Swedish Artificial Intelligence Society","publisher-place":"Jönköping, Sweden","source":"DOI.org (Crossref)","title":"Can machine learning help reveal the competitive advantage of elite beach volleyball players?","type":"paper-conference","URL":"https://ecp.ep.liu.se/index.php/sais/article/view/999"},{"id":"tikhonovMusicGenerationVariational2017","author":[{"family":"Tikhonov","given":"Alexey"},{"family":"Yamshchikov","given":"Ivan P"}],"citation-key":"tikhonovMusicGenerationVariational2017","container-title":"arXiv preprint arXiv:1705.05458","container-title-short":"arXiv preprint arXiv:1705.05458","issued":{"date-parts":[["2017"]]},"title":"Music generation with variational recurrent autoencoder supported by history","type":"article-journal"},{"id":"timmASLMusicVideo2012","accessed":{"date-parts":[["2021",1,10]]},"author":[{"family":"Timm","given":"Rosa Lee"}],"citation-key":"timmASLMusicVideo2012","container-title":"YouTube","issued":{"date-parts":[["2012",10,28]]},"title":"ASL Music Video: Blown Away by Carrie Underwood","type":"webpage","URL":"https://www.youtube.com/watch?v=e_SbM9Ci_0k"},{"id":"tingStudy3DStereoscopic2022","accessed":{"date-parts":[["2023",2,28]]},"author":[{"family":"Ting","given":"Yi-Wen"},{"family":"Lin","given":"Po-Hsien"},{"family":"Lin","given":"Rungtai"},{"family":"Shi","given":"Ming-Hong"}],"citation-key":"tingStudy3DStereoscopic2022","container-title":"Cross-Cultural Design. Applications in Learning, Arts, Cultural Heritage, Creative Industries, and Virtual Reality","DOI":"10.1007/978-3-031-06047-2_20","editor":[{"family":"Rau","given":"Pei-Luen Patrick"}],"event-place":"Cham","ISBN":"978-3-031-06046-5 978-3-031-06047-2","issued":{"date-parts":[["2022"]]},"language":"en","page":"283-293","publisher":"Springer International Publishing","publisher-place":"Cham","source":"DOI.org (Crossref)","title":"A Study of 3D Stereoscopic Image Production of “Triadic Ballet” of the Theater of the Bauhaus","type":"chapter","URL":"https://link.springer.com/10.1007/978-3-031-06047-2_20","volume":"13312"},{"id":"tingStudyApplyingBauhaus2021","accessed":{"date-parts":[["2023",2,28]]},"author":[{"family":"Ting","given":"Yi-Wen"},{"family":"Lin","given":"Po-Hsien"},{"family":"Lin","given":"Rungtai"}],"citation-key":"tingStudyApplyingBauhaus2021","container-title":"Cross-Cultural Design. Applications in Arts, Learning, Well-being, and Social Development","DOI":"10.1007/978-3-030-77077-8_6","editor":[{"family":"Rau","given":"Pei-Luen Patrick"}],"event-place":"Cham","ISBN":"978-3-030-77076-1 978-3-030-77077-8","issued":{"date-parts":[["2021"]]},"language":"en","page":"65-83","publisher":"Springer International Publishing","publisher-place":"Cham","source":"DOI.org (Crossref)","title":"A Study of Applying Bauhaus Design Idea into the Reproduction of the Triadic Ballet","type":"chapter","URL":"https://link.springer.com/10.1007/978-3-030-77077-8_6","volume":"12772"},{"id":"titchkoskyCulturalMapsWhich2002","author":[{"family":"Titchkosky","given":"Tanya"}],"citation-key":"titchkoskyCulturalMapsWhich2002","container-title":"Disability/postmodernity: Embodying disability theory","container-title-short":"Disability/postmodernity: Embodying disability theory","issued":{"date-parts":[["2002"]]},"page":"101-111","publisher":"Continuum, London","title":"Cultural maps: Which Way to Disability","type":"article-journal"},{"id":"titchkoskyNotYetTimeDisabilityBureaucratization2010","author":[{"family":"Titchkosky","given":"Tanya"}],"citation-key":"titchkoskyNotYetTimeDisabilityBureaucratization2010","container-title":"Disability Studies Quarterly","ISSN":"2159-8371 (Online); 1041-5718 (Print)","issue":"3/4","issued":{"date-parts":[["2010"]]},"title":"The Not-Yet-Time of Disability in the Bureaucratization of University Life","type":"article-journal","URL":"https://dsq-sds.org/article/view/1295/1331","volume":"30"},{"id":"titsNovelToolMotion2016","abstract":"The recent arise of Motion Capture (MoCap) technologies provides new possibilities, but also new challenges in human motion analysis. Indeed, the analysis of a motion database is a complex task, due to the high dimensionality of motion data, and the number of independent factors that can affect movements. We addressed the first issue in some of our earlier work by developing MotionMachine, a framework helping to overcome the problem of motion data interpretation through feature extraction and interactive visualization [20]. In this paper, we address the question of the relations between movements and some of the various factors (social, psychological, physiological, etc.) that can influence them. To that end, we propose a tool for rapid factor analysis of a MoCap database. This tool allows statistical exploration of the effect of any factor of the database on motion features. As a use case of this work, we present the analysis of a database of improvised contemporary dance, showing the capabilities and interest of our tool.","author":[{"family":"Tits","given":"Mickaël"},{"family":"Tilmanne","given":"Joëlle"},{"family":"Alessandro","given":"Nicolas","non-dropping-particle":"d'"}],"citation-key":"titsNovelToolMotion2016","collection-title":"MOCO '16","container-title":"Proceedings of the 3rd international symposium on movement and computing","DOI":"10.1145/2948910.2948923","event-place":"Thessaloniki, GA, Greece","ISBN":"978-1-4503-4307-7","issued":{"date-parts":[["2016"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Thessaloniki, GA, Greece","title":"A novel tool for motion capture database factor statistical exploration","type":"paper-conference","URL":"https://doi.org/10.1145/2948910.2948923"},{"id":"tolleneerAthleticEnhancementHuman2012","citation-key":"tolleneerAthleticEnhancementHuman2012","editor":[{"family":"Tolleneer","given":"Jan"},{"family":"Sterckx","given":"Sigrid"},{"family":"Bonte","given":"Pieter"}],"event-place":"Dordrecht","issued":{"date-parts":[["2012"]]},"language":"English","note":"OCLC: 941492931","publisher":"Springer","publisher-place":"Dordrecht","source":"Open WorldCat","title":"Athletic Enhancement, Human Nature and Ethics: Threats and Opportunities of Doping Technologies","title-short":"Athletic enhancement, human nature and ethics","type":"book"},{"id":"tolleneerSelfOtherPlay2013","author":[{"family":"Tolleneer","given":"Jan"},{"family":"Schotsmans","given":"Paul"}],"citation-key":"tolleneerSelfOtherPlay2013","container-title":"Athletic Enhancement, Human Nature and Ethics: Threats and Opportunities of Doping Technologies","editor":[{"family":"Tolleneer","given":"Jan"},{"family":"Sterckx","given":"Sigrid"},{"family":"Bonte","given":"Pieter"}],"event-place":"Dordrecht","issued":{"date-parts":[["2013"]]},"language":"English","note":"OCLC: 941492931","page":"21 -43","publisher":"Springer","publisher-place":"Dordrecht","source":"Open WorldCat","title":"Self, Other, Play, Display, and Humanity: Development of a Five-Level Model for the Analysis of Ethical Arguemnts in the Athletic Enhancement Debate","type":"chapter"},{"id":"tongPsychophysicalStudiesTwo1982","author":[{"family":"Tong","given":"Y. C."},{"family":"Clark","given":"Graeme M."},{"family":"Blamey","given":"P. J."},{"family":"Busby","given":"P. A."},{"family":"Dowell","given":"R. C."}],"citation-key":"tongPsychophysicalStudiesTwo1982","container-title":"The Journal of the Acoustical Society of America","container-title-short":"The Journal of the Acoustical Society of America","ISSN":"0001-4966","issue":"1","issued":{"date-parts":[["1982"]]},"page":"153-160","publisher":"Acoustical Society of America","title":"Psychophysical Studies for Two Multiple‐Channel Cochlear Implant Patients","type":"article-journal","volume":"71"},{"id":"torrencen.d.","accessed":{"date-parts":[["2021",1,10]]},"author":[{"family":"Torrence","given":"Stephen"}],"citation-key":"torrencen.d.","container-title":"Facebook","issued":{"literal":"n.d."},"title":"About","type":"webpage","URL":"https://www.facebook.com/pg/captainvalor/about/?ref=page_internal"},{"id":"townshendPitchPerceptionCochlear1987","author":[{"family":"Townshend","given":"Brent"},{"family":"Cotter","given":"Neil"},{"family":"Van Compernolle","given":"Dirk"},{"family":"White","given":"R. L."}],"citation-key":"townshendPitchPerceptionCochlear1987","container-title":"The Journal of the Acoustical Society of America","container-title-short":"The Journal of the Acoustical Society of America","ISSN":"0001-4966","issue":"1","issued":{"date-parts":[["1987"]]},"page":"106-115","publisher":"Acoustical Society of America","title":"Pitch Perception by Cochlear Implant Subjects","type":"article-journal","volume":"82"},{"id":"tragtenbergConceptDigitalDance2019","author":[{"family":"Tragtenberg","given":"João"},{"family":"Calegario","given":"Filipe"},{"family":"Cabral","given":"Giordano"},{"family":"Ramalho","given":"Geber L"}],"citation-key":"tragtenbergConceptDigitalDance2019","container-title":"Proceedings of the International Conference on New Interfaces for Musical Expression","DOI":"10.5281/zenodo.3672878","event-place":"Porto Alegre, Brazil","event-title":"NIME","issued":{"date-parts":[["2019"]]},"page":"89-94","publisher":"UFRGS","publisher-place":"Porto Alegre, Brazil","title":"Towards the Concept of Digital Dance and Music Instruments.","type":"paper-conference","URL":"http://www.nime.org/proceedings/2019/nime2019_paper018.pdf","volume":"19"},{"id":"tragtenbergConceptDigitalDance2019a","abstract":"This paper discusses the creation of instruments in which music is intentionally generated by dance. We introduce the conceptual framework of Digital Dance and Music Instruments (DDMI). Several DDMI have already been created, but they have been developed isolatedly, and there is still a lack of a common process of ideation and development. Knowledge about Digital Musical Instruments (DMIs) and Interactive Dance Systems (IDSs) can contribute to the design of DDMI, but the former brings few contributions to the body's expressiveness, and the latter brings few references to an instrumental relationship with music. Because of those different premises, the integration between both paradigms can be an arduous task for the designer of DDMI. The conceptual framework of DDMI can also serve as a bridge between DMIs and IDSs, serving as a lingua franca between both communities and facilitating the exchange of knowledge. The conceptual framework has shown to be a promising analytical tool for the design, development, and evaluation of new digital dance and music instrument.","accessed":{"date-parts":[["2023",10,11]]},"author":[{"family":"Tragtenberg","given":"Joao Nogueira"},{"family":"Calegario","given":"Filipe"},{"family":"Cabral","given":"Giordano"},{"family":"Ramalho","given":"Geber L."}],"citation-key":"tragtenbergConceptDigitalDance2019a","DOI":"10.5281/ZENODO.3672878","issued":{"date-parts":[["2019",6,1]]},"license":"Creative Commons Attribution 4.0 International, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"Towards the Concept of Digital Dance and Music Instruments","type":"article-journal","URL":"https://zenodo.org/record/3672878"},{"id":"tremainFoucaultGovernmentDisability2015","call-number":"HV1568 .F68 2015","citation-key":"tremainFoucaultGovernmentDisability2015","collection-title":"Corporealities : Discourses of disability","edition":"Enlarged and revised edition","editor":[{"family":"Tremain","given":"Shelley"}],"event-place":"Ann Arbor","ISBN":"978-0-472-03638-7","issued":{"date-parts":[["2015"]]},"note":"OCLC: ocn915718962","number-of-pages":"440","publisher":"University of Michigan Press","publisher-place":"Ann Arbor","source":"Library of Congress ISBN","title":"Foucault and the Government of Disability","type":"book"},{"id":"tsuchidaAISTDanceVideo2019","author":[{"family":"Tsuchida","given":"Shuhei"},{"family":"Fukayama","given":"Satoru"},{"family":"Hamasaki","given":"Masahiro"},{"family":"Goto","given":"Masataka"}],"citation-key":"tsuchidaAISTDanceVideo2019","container-title":"Proceedings of the 20th international society for music information retrieval conference","DOI":"10.5281/zenodo.3527854","event-place":"Delft, The Netherlands","issued":{"date-parts":[["2019",11]]},"page":"501-510","publisher":"ISMIR","publisher-place":"Delft, The Netherlands","title":"AIST dance video database: Multi-genre, multi- dancer, and multi-camera database for dance information processing","type":"paper-conference","URL":"https://doi.org/10.5281/zenodo.3527854"},{"id":"ulfarssonHalldorophoneOngoingInnovation2018","abstract":"This paper reports upon the process of innovation of a new instrument. The author has developed the halldorophone a new electroacoustic string instrument which makes use of positive feedback as a key element in generating its sound. An important objective of the project has been to encourage its use by practicing musicians. After ten years of use, the halldorophone has a growing repertoire of works by prominent composers and performers. During the development of the instrument, the question has been asked: \"why do musicians want to use this instrument?\" and answers have been found through on-going (informal) user studies and feedback. As the project progresses, a picture emerges of what qualities have led to a culture of acceptance and use around this new instrument. This paper describes the halldorophone and presents the rationale for its major design features and ergonomic choices, as they relate to the overarching objective of nurturing a culture of use and connects it to wider trends.","accessed":{"date-parts":[["2023",1,16]]},"author":[{"family":"Úlfarsson","given":"Halldór"}],"citation-key":"ulfarssonHalldorophoneOngoingInnovation2018","DOI":"10.5281/ZENODO.1302579","issued":{"date-parts":[["2018",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"The Halldorophone: The Ongoing Innovation Of A Cello-Like Drone Instrument","title-short":"The Halldorophone","type":"article-journal","URL":"https://zenodo.org/record/1302579"},{"id":"ulloaScikitMaadOpen2021","abstract":"Abstract\n            \n              \n                \n                  Passive acoustic monitoring is increasingly being applied to terrestrial, marine and freshwater environments, providing cost‐efficient methods for surveying biodiversity. However, processing the avalanche of audio recordings remains challenging, and represents nowadays a major bottleneck that slows down its application in research and conservation.\n                \n                \n                  We present scikit‐maad, an open‐source Python package dedicated to the analysis of environmental audio recordings. This package was designed to (a) load and process digital audio, (b) segment and find regions of interest, (c) compute acoustic features and (d) estimate sound pressure levels. The package also provides field recordings and a comprehensive online documentation that includes practical examples with step‐by‐step instructions for beginners and advanced users.\n                \n                \n                  scikit‐maad opens the possibility to efficiently scan large audio datasets and easily integrate additional machine learning Python packages into the analysis, allowing to measure acoustic properties and identify key patterns in all kinds of soundscapes. To support reproducible research, the package is released under the BSD open‐source licence, which allows unrestricted redistribution for commercial and private use.\n                \n                \n                  This development will create synergies between the community of ecoacousticians, such as engineers, data scientists, ecologists, biologists and conservation practitioners, to explore and understand the processes underlying the acoustic diversity of ecological systems.\n                \n              \n            \n          , \n            Resumen\n            \n              \n                \n                  El monitoreo acústico pasivo se está aplicando cada vez más en ambientes terrestres, marinos y de agua dulce, proporcionando métodos costo‐eficientes para estudiar la biodiversidad. Sin embargo, procesar la avalancha de grabaciones colectadas sigue siendo un desafío y representa hoy en día un importante cuello de botella que ralentiza su aplicación en la investigación y la conservación.\n                \n                \n                  Presentamos scikit‐maad, un paquete de Python de código abierto dedicado al análisis de grabaciones de audio ambientales. Este paquete fue diseñado para (1) cargar y procesar grabaciones de audio digital, (2) segmentar y encontrar regiones de interés, (3) calcular características acústicas y (4) estimar niveles de presión sonora. Integrado al paquete, proporcionamos muestras de grabaciones de campo y una documentación en línea que incluye ejemplos prácticos con instrucciones paso a paso para principiantes y usuarios avanzados.\n                \n                \n                  scikit‐maad abre la posibilidad de analizar de manera eficiente grandes conjuntos de datos de audio e integrar paquetes complementarios de Python de aprendizaje automático en el flujo de análisis, lo que permite medir las propiedades acústicas e identificar patrones clave en todo tipo de paisajes sonoros. Para apoyar la investigación reproducible, el paquete se publica bajo la licencia de código abierto BSD, que permite la redistribución sin restricciones para uso comercial y privado.\n                \n                \n                  Este desarrollo creará sinergias entre la comunidad de investigadores en ecoacústica, como ingenieros, científicos de datos, ecólogos, biólogos y profesionales en conservación, para explorar y comprender los procesos subyacentes que dan origen a la diversidad acústica de los sistemas ecológicos.","accessed":{"date-parts":[["2023",11,28]]},"author":[{"family":"Ulloa","given":"Juan Sebastián"},{"family":"Haupert","given":"Sylvain"},{"family":"Latorre","given":"Juan Felipe"},{"family":"Aubin","given":"Thierry"},{"family":"Sueur","given":"Jérôme"}],"citation-key":"ulloaScikitMaadOpen2021","container-title":"Methods in Ecology and Evolution","container-title-short":"Methods Ecol Evol","DOI":"10.1111/2041-210X.13711","ISSN":"2041-210X, 2041-210X","issue":"12","issued":{"date-parts":[["2021",12]]},"language":"en","page":"2334-2340","source":"DOI.org (Crossref)","title":"scikit‐maad: An open‐source and modular toolbox for quantitative soundscape analysis in Python","title-short":"scikit‐maad","type":"article-journal","URL":"https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13711","volume":"12"},{"id":"uysDevelopmentMusicPerception2011","author":[{"family":"Uys","given":"Marinda"},{"family":"Dijk","given":"Catherine-Anne","non-dropping-particle":"van"}],"citation-key":"uysDevelopmentMusicPerception2011","container-title":"South African Journal of Communication Disorders","ISSN":"0379-8046","issued":{"date-parts":[["2011"]]},"page":"19 - 47","publisher":"South African Speech-Language-Hearing Association","title":"Development of a Music Perception Test for Adult Hearing-Aid Users","type":"article-journal","volume":"58"},{"id":"valenteAudiologyAnswersOtolaryngologists2017","author":[{"family":"Valente","given":"Michael"},{"family":"Fernandez","given":"Elizabeth"},{"family":"Monroe","given":"Heather"},{"family":"Valente","given":"Maureen"},{"family":"Cadieux","given":"Jamie"}],"call-number":"RF291.3 .V35 2017","citation-key":"valenteAudiologyAnswersOtolaryngologists2017","edition":"2nd edition","event-place":"Stuttgart ; New York","ISBN":"978-1-62623-796-4","issued":{"date-parts":[["2017"]]},"number-of-pages":"178","publisher":"Thieme","publisher-place":"Stuttgart ; New York","source":"Library of Congress ISBN","title":"Audiology Answers for Otolaryngologists","type":"book"},{"id":"vallisShiftIterativeOpenSource2010","abstract":"The aim of this paper is to define the process of iterative interface design as it pertains to musical performance. Embodying this design approach, the Monome OSC/MIDI USB controller represents a minimalist, open-source hardware device. The open-source nature of the device has allowed for a small group of Monome users to modify the hardware, firmware, and software associated with the interface. These user driven modifications have allowed the re-imagining of the interface for new and novel purposes, beyond even that of the device's original intentions. With development being driven by a community of users, a device can become several related but unique generations of musical controllers, each one focused on a specific set of needs.","accessed":{"date-parts":[["2023",5,7]]},"author":[{"family":"Vallis","given":"Owen"},{"family":"Hochenbaum","given":"Jordan"},{"family":"Kapur","given":"Ajay"}],"citation-key":"vallisShiftIterativeOpenSource2010","DOI":"10.5281/ZENODO.1177919","issued":{"date-parts":[["2010",6,1]]},"license":"Creative Commons Attribution 4.0, Open Access","publisher":"Zenodo","source":"DOI.org (Datacite)","title":"A Shift Towards Iterative And Open-Source Design For Musical Interfaces","type":"article-journal","URL":"https://zenodo.org/record/1177919"},{"id":"vancleveDeafHistoryReader2007","call-number":"HV2530 .D43 2007","citation-key":"vancleveDeafHistoryReader2007","editor":[{"family":"Van Cleve","given":"John V."}],"event-place":"Washington, DC","ISBN":"978-1-56368-359-6","issued":{"date-parts":[["2007"]]},"number-of-pages":"217","publisher":"Gallaudet University Press","publisher-place":"Washington, DC","source":"Library of Congress ISBN","title":"The Deaf History Reader","type":"book"},{"id":"vandyckImpactBassDrum2013","abstract":"The present study aims to gain better insight into the connection between music and dance by examining the dynamic effects of the bass drum on a dancing audience in a club-like environment. One hundred adult participants moved freely in groups of five to a musical sequence that comprised six songs. Each song consisted of one section that was repeated three times, each time with a different sound pressure level of the bass drum. Hip and head movements were recorded using motion capture and motion sensing. The study demonstrates that people modify their bodily behavior according to the dynamic level of the bass drum when moving to contemporary dance music in a social context. Participants moved more actively and displayed a higher degree of tempo entrainment as the sound pressure level of the bass drum increased. These results indicate that the prominence of the bass drum in contemporary dance music serves not merely as a stylistic element; indeed, it has a strong influence on dancing itself.","accessed":{"date-parts":[["2022",2,16]]},"author":[{"family":"Van Dyck","given":"Edith"},{"family":"Moelants","given":"Dirk"},{"family":"Demey","given":"Michiel"},{"family":"Deweppe","given":"Alexander"},{"family":"Coussement","given":"Pieter"},{"family":"Leman","given":"Marc"}],"citation-key":"vandyckImpactBassDrum2013","container-title":"Music Perception","DOI":"10.1525/mp.2013.30.4.349","ISSN":"0730-7829, 1533-8312","issue":"4","issued":{"date-parts":[["2013",4,1]]},"language":"en","page":"349-359","source":"DOI.org (Crossref)","title":"The Impact of the Bass Drum on Human Dance Movement","type":"article-journal","URL":"https://online.ucpress.edu/mp/article/30/4/349/62563/The-Impact-of-the-Bass-Drum-on-Human-Dance","volume":"30"},{"id":"vaneckAirElectricityMicrophones2017","author":[{"family":"Eck","given":"Cathy","non-dropping-particle":"van"}],"citation-key":"vaneckAirElectricityMicrophones2017","collection-title":"Music & sound studies","event-place":"New York London Oxford New Delhi Sydney","ISBN":"978-1-5013-4471-8 978-1-5013-2760-5 978-1-5013-2761-2","issued":{"date-parts":[["2017"]]},"language":"eng","number-of-pages":"198","publisher":"Bloomsbury Academic","publisher-place":"New York London Oxford New Delhi Sydney","source":"K10plus ISBN","title":"Between air and electricity: microphones and loudspeakers as musical instruments","title-short":"Between air and electricity","type":"book"},{"id":"vanheusdenPredictiveCodingVisual2019","abstract":"Neural processing of sensory input in the brain takes time, and for that reason our awareness of visual events lags behind their actual occurrence. One way the brain might compensate to minimize the impact of the resulting delays is through extrapolation. Extrapolation mechanisms have been argued to underlie perceptual illusions in which moving and static stimuli are mislocalised relative to one another (such as the flash-lag and related effects). However, where in the visual hierarchy such extrapolation processes take place remains unknown. Here, we address this question by identifying monocular and binocular contributions to the flash-grab illusion. In this illusion, a brief target is flashed on a moving background that reverses direction. As a result, the perceived position of the target is shifted in the direction of the reversal. We show that the illusion is attenuated, but not eliminated, when the motion reversal and the target are presented dichoptically to separate eyes. This reveals extrapolation mechanisms at both monocular and binocular processing stages contribute to the illusion. We interpret the results in a hierarchical predictive coding framework, and argue that prediction errors in this framework manifest directly as perceptual illusions.","author":[{"family":"Heusden","given":"E.","non-dropping-particle":"van"},{"family":"Harris","given":"A."},{"family":"Garrido","given":"M."},{"family":"Hogendoorn","given":"Hinze"}],"citation-key":"vanheusdenPredictiveCodingVisual2019","container-title":"Journal of vision","DOI":"10.1167/19.1.3","issued":{"date-parts":[["2019"]]},"note":"QID: Q90985587","page":"3","PMID":"30630191","title":"Predictive coding of visual motion in both monocular and binocular human visual processing.","type":"article-journal","URL":"https://www.semanticscholar.org/paper/57244e467f44a01ced2008d1666df0ea6583f54e","volume":"19 1"},{"id":"vannoordenFunctionalRoleBiokinetics2010","author":[{"family":"Van Noorden","given":"Leon"}],"citation-key":"vannoordenFunctionalRoleBiokinetics2010","container-title":"Musical gestures: Sound, movement, and meaning","editor":[{"family":"Godøy","given":"Rolf Inge"},{"family":"Leman","given":"Marc"}],"event-place":"New York","ISBN":"978-0-415-99887-1","issued":{"date-parts":[["2010"]]},"page":"154-179","publisher":"Routledge","publisher-place":"New York","title":"The functional role and bio-kinetics of basic and expressive gestures in activation and sonification","type":"chapter"},{"id":"veditzPresidentMessage1912","author":[{"family":"Veditz","given":"George"}],"citation-key":"veditzPresidentMessage1912","container-title":"Proceedings of the Ninth Convention of the National Association and the Third World's Congress of the Deaf, 1910","event-place":"Colorado Springs, Colorado, USA","event-title":"Ninth Convention of the National Association and the Third World's Congress of the Deaf","issued":{"date-parts":[["1912"]]},"page":"22 - 31","publisher":"Philocophus Press","publisher-place":"Colorado Springs, Colorado, USA","title":"The President's Message","type":"paper-conference"},{"id":"vellosoProbabilisticInterpretationMotion2021","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Velloso","given":"Eduardo"},{"family":"Morimoto","given":"Carlos H"}],"citation-key":"vellosoProbabilisticInterpretationMotion2021","container-title":"Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems","DOI":"10.1145/3411764.3445184","event-place":"Yokohama Japan","event-title":"CHI '21: CHI Conference on Human Factors in Computing Systems","ISBN":"978-1-4503-8096-6","issued":{"date-parts":[["2021",5,6]]},"language":"en","page":"1-13","publisher":"ACM","publisher-place":"Yokohama Japan","source":"DOI.org (Crossref)","title":"A Probabilistic Interpretation of Motion Correlation Selection Techniques","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3411764.3445184"},{"id":"verdiMessaRequiemStudy2016","author":[{"family":"Verdi","given":"Giuseppe"},{"family":"Rosen","given":"David"}],"call-number":"M2010.V48 R4 2016","citation-key":"verdiMessaRequiemStudy2016","collection-number":"volume 1","collection-title":"The works of Giuseppe Verdi. Series III, Sacred music = Le opere di Giuseppe Verdi. Series III, musica sacra","edition":"Critical edition","event-place":"Chicago : Milano","ISBN":"978-0-226-42541-2 978-88-8192-002-0","issued":{"date-parts":[["2016"]]},"language":"lat","note":"OCLC: ocn966478078","number-of-pages":"1","publisher":"The University of Chicago Press ; Ricordi","publisher-place":"Chicago : Milano","source":"Library of Congress ISBN","title":"Messa da Requiem: Study Score from the Critical Edition","title-short":"Messa da Requiem","type":"book"},{"id":"viconUs","accessed":{"date-parts":[["2023",7,10]]},"author":[{"literal":"Vicon"}],"citation-key":"viconUs","container-title":"Vicon","title":"About Us","type":"webpage","URL":"https://www.vicon.com/about-us/"},{"id":"vincsTouchingSpaceUsing2010","abstract":"This paper describes the work of a group of artists in Australia who used real-time motion capture and 3D stereo projection to create a large-scale performance environment in which dancers seemed to “touch” the volume. This project re-versions Suzanne Langer's 1950s philosophy of dance as “virtual force” to realize the idea of a “virtual haptics” of dance that extends the dancer's physical agency literally across and through the surrounding spatial volume. The project presents a vision of interactive dance performance that “touches” space by visualizing kinematics as intentionality and agency. In doing so, we suggest the possibility of new kinds of human-computer interfaces that emphasize touch as embodied, nuanced agency that is mediated by the subtle qualities of whole-body movement, in addition to more goal-oriented, task-based gestures such as pointing or clicking.","accessed":{"date-parts":[["2022",9,29]]},"author":[{"family":"Vincs","given":"Kim"},{"family":"McCormick","given":"John"}],"citation-key":"vincsTouchingSpaceUsing2010","container-title":"Leonardo","container-title-short":"Leonardo","DOI":"10.1162/LEON_a_00009","ISSN":"0024-094X, 1530-9282","issue":"4","issued":{"date-parts":[["2010",8]]},"language":"en","page":"359-366","title":"Touching Space: Using Motion Capture and Stereo Projection to Create a “Virtual Haptics” of Dance","title-short":"Touching Space","type":"article-journal","URL":"https://direct.mit.edu/leon/article/43/4/359-366/97838","volume":"43"},{"id":"vinesMusicMyEyes2011","accessed":{"date-parts":[["2022",5,14]]},"author":[{"family":"Vines","given":"Bradley W."},{"family":"Krumhansl","given":"Carol L."},{"family":"Wanderley","given":"Marcelo M."},{"family":"Dalca","given":"Ioana M."},{"family":"Levitin","given":"Daniel J."}],"citation-key":"vinesMusicMyEyes2011","container-title":"Cognition","container-title-short":"Cognition","DOI":"10.1016/j.cognition.2010.11.010","ISSN":"00100277","issue":"2","issued":{"date-parts":[["2011",2]]},"language":"en","page":"157-170","source":"DOI.org (Crossref)","title":"Music to my eyes: Cross-modal interactions in the perception of emotions in musical performance","title-short":"Music to my eyes","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0010027710002817","volume":"118"},{"id":"visiInteractiveMachineLearning2021","abstract":"This chapter presents an overview of Interactive Machine Learning (IML) techniques applied to the analysis and design of musical gestures. We go through the main challenges and needs related to capturing, analysing, and applying IML techniques to human bodily gestures with the purpose of performing with sound synthesis systems. We discuss how different algorithms may be used to accomplish different tasks, including interacting with complex synthesis techniques and exploring interaction possibilities by means of Reinforcement Learning (RL) in an interaction paradigm we developed called Assisted Interactive Machine Learning (AIML). We conclude the chapter with a description of how some of these techniques were employed by the authors for the development of four musical pieces, thus outlining the implications that IML has for musical practice.","author":[{"family":"Visi","given":"Federico Ghelli"},{"family":"Tanaka","given":"Atau"}],"citation-key":"visiInteractiveMachineLearning2021","container-title":"Handbook of Artificial Intelligence for Music: Foundations, Advanced Approaches, and Developments for Creativity","DOI":"10.1007/978-3-030-72116-9_27","editor":[{"family":"Miranda","given":"Eduardo Reck"}],"event-place":"Cham","ISBN":"978-3-030-72116-9","issued":{"date-parts":[["2021"]]},"page":"771–798","publisher":"Springer International Publishing","publisher-place":"Cham","title":"Interactive Machine Learning of Musical Gesture","type":"chapter","URL":"https://doi.org/10.1007/978-3-030-72116-9_27"},{"id":"vodafonenlKytemanOrchestraStay2014","accessed":{"date-parts":[["2021",1,27]]},"author":[{"literal":"vodafonenl"}],"citation-key":"vodafonenlKytemanOrchestraStay2014","container-title":"YouTube","issued":{"date-parts":[["2014",9,2]]},"title":"The Kyteman Orchestra - Stay With Me (Sam Smith Cover)","type":"webpage","URL":"https://www.youtube.com/watch?v=_dAU_YKb-E4"},{"id":"vodafonenlVeraFirstConcert2014","accessed":{"date-parts":[["2021",1,27]]},"author":[{"literal":"vodafonenl"}],"citation-key":"vodafonenlVeraFirstConcert2014","container-title":"YouTube","issued":{"date-parts":[["2014",11,2]]},"title":"Vera's #FirstConcert","type":"webpage","URL":"https://www.youtube.com/watch?v=UNdeQuvguL0"},{"id":"vonarnimAnalysisApplicationsAssistive2021","abstract":"There is a wide variety of multifaceted music created by d/Deaf musicians and musicians with hearing loss. This thesis attempts to examine the interaction of this music with assistive technology. \nThe first section of this thesis examines several models of disability and definitions of d/Deafness. There is also an overview of the socio-linguistic minority of Deaf culture. A framework of analysis for d/Deaf music based upon the network of relationships within a musical work is developed and thereafter the work of several d/Deaf musicians is analysed. The second section of this thesis examines assistive technology, contending that it performs a transformational function within the network of relationships defined in the previous section. Several assistive technologies in d/Deaf music are analysed and their transformational functions are identified. Framing the discussion of the previous sections through the lens of Christopher Small’s theory of musicking, a relationship model \nof assistive technology is posited to form the basis of the final section; a research proposal for a pilot study to gain phenomenological data on the lived experience of d/Deaf musicians in respect to the transformational functions that technology plays in their musical performances.","author":[{"family":"Arnim","given":"Hugh Alexander","non-dropping-particle":"von"}],"citation-key":"vonarnimAnalysisApplicationsAssistive2021","event-place":"Darmstadt","genre":"Bachelor","issued":{"date-parts":[["2021",2,1]]},"language":"English","note":"Unpublished","number-of-pages":"265","publisher":"University of Applied Sciences Darmstadt","publisher-place":"Darmstadt","title":"An Analysis of Applications of Assistive Technology in d/Deaf Musical Culture","type":"thesis"},{"id":"vonarnimReconfigurations2024","accessed":{"date-parts":[["2024",4,23]]},"author":[{"family":"Arnim","given":"Hugh Alexander","non-dropping-particle":"von"}],"citation-key":"vonarnimReconfigurations2024","container-title":"Github","issued":{"date-parts":[["2024",2,19]]},"title":"Reconfigurations","type":"webpage","URL":"https://github.com/Hughav92/Reconfigurations"},{"id":"vonarnimShapeshifter2024","accessed":{"date-parts":[["2024",4,23]]},"author":[{"family":"Arnim","given":"Hugh Alexander","non-dropping-particle":"von"}],"citation-key":"vonarnimShapeshifter2024","container-title":"Github","issued":{"date-parts":[["2024",2,20]]},"title":"The Shapeshifter","type":"webpage","URL":"https://github.com/Hughav92/The-Shapeshifter"},{"id":"vongpaisalIdentificationTVTunes2009","author":[{"family":"Vongpaisal","given":"Tara"},{"family":"Trehub","given":"Sandra E."},{"family":"Schellenberg","given":"E. Glenn"}],"citation-key":"vongpaisalIdentificationTVTunes2009","container-title":"Music Perception","container-title-short":"Music Perception","ISSN":"0730-7829","issue":"1","issued":{"date-parts":[["2009"]]},"page":"17-24","publisher":"University of California Press USA","title":"Identification of TV Tunes by Children with Cochlear Implants","type":"article-journal","volume":"27"},{"id":"vongpaisalSongRecognitionChildren2006","author":[{"family":"Vongpaisal","given":"Tara"},{"family":"Trehub","given":"Sandra E."},{"family":"Schellenberg","given":"E. Glenn"}],"citation-key":"vongpaisalSongRecognitionChildren2006","container-title":"Journal of Speech, Language, and Hearing Research","issued":{"date-parts":[["2006"]]},"page":"1091 - 1103","publisher":"ASHA","title":"Song Recognition by Children and Adolescents with Cochlear Implants","type":"article-journal","volume":"49"},{"id":"vrigkasReviewHumanActivity2015","accessed":{"date-parts":[["2024",8,24]]},"author":[{"family":"Vrigkas","given":"Michalis"},{"family":"Nikou","given":"Christophoros"},{"family":"Kakadiaris","given":"Ioannis A."}],"citation-key":"vrigkasReviewHumanActivity2015","container-title":"Frontiers in Robotics and AI","container-title-short":"Front. Robot. AI","DOI":"10.3389/frobt.2015.00028","ISSN":"2296-9144","issued":{"date-parts":[["2015",11,16]]},"source":"DOI.org (Crossref)","title":"A Review of Human Activity Recognition Methods","type":"article-journal","URL":"http://journal.frontiersin.org/Article/10.3389/frobt.2015.00028/abstract","volume":"2"},{"id":"wallisAmateurMusiciansLongTerm2013","accessed":{"date-parts":[["2022",10,28]]},"author":[{"family":"Wallis","given":"Isaac"},{"family":"Ingalls","given":"Todd"},{"family":"Campana","given":"Ellen"},{"family":"Vuong","given":"Catherine"}],"citation-key":"wallisAmateurMusiciansLongTerm2013","container-title":"Music and Human-Computer Interaction","DOI":"10.1007/978-1-4471-2990-5_3","editor":[{"family":"Holland","given":"Simon"},{"family":"Wilkie","given":"Katie"},{"family":"Mulholland","given":"Paul"},{"family":"Seago","given":"Allan"}],"event-place":"London","ISBN":"978-1-4471-2989-9 978-1-4471-2990-5","issued":{"date-parts":[["2013"]]},"page":"49-66","publisher":"Springer London","publisher-place":"London","source":"DOI.org (Crossref)","title":"Amateur Musicians, Long-Term Engagement, and HCI","type":"chapter","URL":"http://link.springer.com/10.1007/978-1-4471-2990-5_3"},{"id":"waltemateImpactLatencyPerceptual2016","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Waltemate","given":"Thomas"},{"family":"Senna","given":"Irene"},{"family":"Hülsmann","given":"Felix"},{"family":"Rohde","given":"Marieke"},{"family":"Kopp","given":"Stefan"},{"family":"Ernst","given":"Marc"},{"family":"Botsch","given":"Mario"}],"citation-key":"waltemateImpactLatencyPerceptual2016","container-title":"Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology","DOI":"10.1145/2993369.2993381","event-place":"Munich Germany","event-title":"VRST '16: 22th ACM Symposium on Virtual Reality Software and Technology","ISBN":"978-1-4503-4491-3","issued":{"date-parts":[["2016",11,2]]},"language":"en","page":"27-35","publisher":"ACM","publisher-place":"Munich Germany","source":"DOI.org (Crossref)","title":"The impact of latency on perceptual judgments and motor performance in closed-loop interaction in virtual reality","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/2993369.2993381"},{"id":"walther-hansenMakingSenseRecordings2020","abstract":"\"The sonic qualities that emerge from aesthetic and technological decisions in the recording studio have a major impact on how music sounds, yet our ability to describe this impact on the listening experience is limited. Listeners often use very elaborate metaphors when describing sound quality, such as timbral and spatial characteristics. There is, however, a prevalent belief that metaphors are vague and highly subjective, and therefore unsuitable for academic and more exacting discussions of sound. Making Sense of Recordings challenges this assumption by showing how these metaphors are closely connected to our sonic experience and that they make sense within a larger historical context of technological developments and changing discourses of recorded sound. Part 1 of the book starts by tracing written discourses of recorded sound, discussing how everyday listeners and audio professionals describe their experiences of sound in recorded music. The concept of the listener, as it is theorized here, relates both to the production and reception side of recorded music and assumes some sort of conscious evaluative process where people give meaning to their experiences. Listening is approached from a quality-oriented mode of listening concerned with embodied cognition and is conditioned by the specific listening situation and the specific purpose of listening. Building on cognitive sciences, ideas of embodied cognition, and recent studies in discourse analysis, the book then provides new theoretical and methodological approaches to sound perception and conceptualization with particular relevance to recorded music. The aim is not only to expand on existing histories of studio music technologies, from production to reproduction to reception, but also to provide analytical and practical tools to aid in the understanding and communication of sound discourse in the studio and beyond\"--","author":[{"family":"Walther-Hansen","given":"Mads"}],"call-number":"ML3877","citation-key":"walther-hansenMakingSenseRecordings2020","event-place":"New York","ISBN":"978-0-19-753393-2","issued":{"date-parts":[["2020"]]},"number-of-pages":"1","publisher":"Oxford University Press","publisher-place":"New York","source":"Library of Congress ISBN","title":"Making sense of recordings: how cognitive processing of recorded sound works","title-short":"Making sense of recordings","type":"book"},{"id":"wanderleyESCHERmodelingPerformingComposed1998","abstract":"This article presents ESCHER, a sound synthesis environment based on Ircam's real-time audio environment jMax. ESCHER is a modular system providing synthesis-independent prototyping of gesturally-controlled instruments by means of parameter interpolation. The system divides into two components: gestural controller and synthesis engine. Mapping between components takes place on two independent levels, coupled by an intermediate abstract parameter layer. This separation allows a flexible choice of controllers and/or sound synthesis methods.","author":[{"family":"Wanderley","given":"M.M"},{"family":"Schnell","given":"N"},{"family":"Rovan","given":"J"}],"citation-key":"wanderleyESCHERmodelingPerformingComposed1998","container-title":"ICSMC","container-title-short":"ICSMC","DOI":"10.1109/ICSMC.1998.727836","ISBN":"1062-922X","issued":{"date-parts":[["1998"]]},"page":"1080-1084 vol.2","publisher":"IEEE","title":"ESCHER-modeling and performing composed instruments in real-time","type":"paper-conference","volume":"2"},{"id":"wanderleyEvaluationInputDevices2002","abstract":"The input devices for musical expression are evaluated by comparing it to existing research in the field of Human- Computer Interaction (HCI). Musical tasks to allow evaluation of existing input devices are suggested and discussed.","author":[{"family":"Wanderley","given":"Marcelo Mortensen"},{"family":"Orio","given":"Nicola"}],"citation-key":"wanderleyEvaluationInputDevices2002","container-title":"Computer music journal","container-title-short":"COMPUT MUSIC J","DOI":"10.1162/014892602320582981","event-place":"238 Main St., Suite 500, Cambridge, MA 02142-1046, USA","ISSN":"0148-9267","issue":"3","issued":{"date-parts":[["2002"]]},"page":"62-76","publisher":"238 Main St., Suite 500, Cambridge, MA 02142-1046, USA: MIT Press","publisher-place":"238 Main St., Suite 500, Cambridge, MA 02142-1046, USA","title":"Evaluation of Input Devices for Musical Expression: Borrowing Tools from HCI","type":"article-journal","volume":"26"},{"id":"wanderleyGesturalControlSound2004","abstract":"This paper provides a review of gestural control of sound synthesis in the context of the design and evaluation of digital musical instruments. It discusses research in various areas related to this field and equally focuses on four main topics: analysis of music performers' gestures, gestural capture technologies, real-time sound synthesis methods, and strategies for mapping gesture variables to sound synthesis input parameters. Finally, this approach is illustrated by presenting an application of this research to the control of digital audio effects.","author":[{"family":"Wanderley","given":"M.M"},{"family":"Depalle","given":"P"}],"citation-key":"wanderleyGesturalControlSound2004","container-title":"Proceedings of the IEEE","container-title-short":"JPROC","DOI":"10.1109/JPROC.2004.825882","event-place":"PISCATAWAY","ISSN":"0018-9219","issue":"4","issued":{"date-parts":[["2004"]]},"page":"632-644","publisher":"PISCATAWAY: IEEE","publisher-place":"PISCATAWAY","title":"Gestural control of sound synthesis","type":"article-journal","volume":"92"},{"id":"warburtonMeasuringMotiontophotonLatency2022","abstract":"Abstract\n            Consumer virtual reality (VR) systems are increasingly being deployed in research to study sensorimotor behaviors, but properties of such systems require verification before being used as scientific tools. The ‘motion-to-photon’ latency (the lag between a user making a movement and the movement being displayed within the display) is a particularly important metric as temporal delays can degrade sensorimotor performance. Extant approaches to quantifying this measure have involved the use of bespoke software and hardware and produce a single measure of latency and ignore the effect of the motion prediction algorithms used in modern VR systems. This reduces confidence in the generalizability of the results. We developed a novel, system-independent, high-speed camera-based latency measurement technique to co-register real and virtual controller movements, allowing assessment of how latencies change through a movement. We applied this technique to measure the motion-to-photon latency of controller movements in the HTC Vive, Oculus Rift, Oculus Rift S, and Valve Index, using the Unity game engine and SteamVR. For the start of a sudden movement, all measured headsets had mean latencies between 21 and 42 ms. Once motion prediction could account for the inherent delays, the latency was functionally reduced to 2–13 ms, and our technique revealed that this reduction occurs within ~25–58 ms of movement onset. Our findings indicate that sudden accelerations (e.g., movement onset, impacts, and direction changes) will increase latencies and lower spatial accuracy. Our technique allows researchers to measure these factors and determine the impact on their experimental design before collecting sensorimotor data from VR systems.","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Warburton","given":"Matthew"},{"family":"Mon-Williams","given":"Mark"},{"family":"Mushtaq","given":"Faisal"},{"family":"Morehead","given":"J. Ryan"}],"citation-key":"warburtonMeasuringMotiontophotonLatency2022","container-title":"Behavior Research Methods","container-title-short":"Behav Res","DOI":"10.3758/s13428-022-01983-5","ISSN":"1554-3528","issue":"7","issued":{"date-parts":[["2022",10,10]]},"language":"en","page":"3658-3678","source":"DOI.org (Crossref)","title":"Measuring motion-to-photon latency for sensorimotor experiments with virtual reality systems","type":"article-journal","URL":"https://link.springer.com/10.3758/s13428-022-01983-5","volume":"55"},{"id":"washburnDancersEntrainMore2014","accessed":{"date-parts":[["2022",5,15]]},"author":[{"family":"Washburn","given":"Auriel"},{"family":"DeMarco","given":"Mariana"},{"family":"Vries","given":"Simon","non-dropping-particle":"de"},{"family":"Ariyabuddhiphongs","given":"Kris"},{"family":"Schmidt","given":"R. C."},{"family":"Richardson","given":"Michael J."},{"family":"Riley","given":"Michael A."}],"citation-key":"washburnDancersEntrainMore2014","container-title":"Frontiers in Human Neuroscience","container-title-short":"Front. Hum. Neurosci.","DOI":"10.3389/fnhum.2014.00800","ISSN":"1662-5161","issued":{"date-parts":[["2014",10,8]]},"source":"DOI.org (Crossref)","title":"Dancers entrain more effectively than non-dancers to another actor's movements","type":"article-journal","URL":"http://journal.frontiersin.org/article/10.3389/fnhum.2014.00800/abstract","volume":"8"},{"id":"waves.comAmbisonicsExplainedGuide2017","accessed":{"date-parts":[["2022",4,23]]},"author":[{"literal":"waves.com"}],"citation-key":"waves.comAmbisonicsExplainedGuide2017","container-title":"waves","issued":{"date-parts":[["2017",10,10]]},"title":"Ambisonics Explained: A Guide for Sound Engineers","type":"webpage","URL":"https://www.waves.com/ambisonics-explained-guide-for-sound-engineers"},{"id":"weinbergInterconnectedMusicalNetworks2005","accessed":{"date-parts":[["2021",8,30]]},"author":[{"family":"Weinberg","given":"Gil"}],"citation-key":"weinbergInterconnectedMusicalNetworks2005","container-title":"Computer Music Journal","container-title-short":"Computer Music Journal","DOI":"10.1162/0148926054094350","ISSN":"0148-9267, 1531-5169","issue":"2","issued":{"date-parts":[["2005",6]]},"language":"en","page":"23-39","source":"DOI.org (Crossref)","title":"Interconnected Musical Networks: Toward a Theoretical Framework","title-short":"Interconnected Musical Networks","type":"article-journal","URL":"https://direct.mit.edu/comj/article/29/2/23-39/93954","volume":"29"},{"id":"weiTCNattentionHARHumanActivity2024","abstract":"Abstract\n            Wearable sensors are widely used in medical applications and human–computer interaction because of their portability and powerful privacy. Human activity identification based on sensor data plays a vital role in these fields. Therefore, it is important to improve the recognition performance of different types of actions. Aiming at the problems of insufficient time-varying feature extraction and gradient explosion caused by too many network layers, a time convolution network recognition model with attention mechanism (TCN-Attention-HAR) was proposed. The model effectively recognizes and emphasizes the key feature information. The ability of extracting temporal features from TCN (temporal convolution network) is improved by using the appropriate size of the receiver domain. In addition, attention mechanisms are used to assign higher weights to important information, enabling models to learn and identify human activities more effectively. The performance of the Open Data Set (WISDM, PAMAP2 and USC-HAD) is improved by 1.13%, 1.83% and 0.51%, respectively, compared with other advanced models, these results clearly show that the network model presented in this paper has excellent recognition performance. In the knowledge distillation experiment, the parameters of student model are only about 0.1% of those of teacher model, and the accuracy of the model has been greatly improved, and in the WISDM data set, compared with the teacher's model, the accuracy is 0.14% higher.","accessed":{"date-parts":[["2024",9,2]]},"author":[{"family":"Wei","given":"Xiong"},{"family":"Wang","given":"Zifan"}],"citation-key":"weiTCNattentionHARHumanActivity2024","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-024-57912-3","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2024",3,28]]},"language":"en","page":"7414","source":"DOI.org (Crossref)","title":"TCN-attention-HAR: human activity recognition based on attention mechanism time convolutional network","title-short":"TCN-attention-HAR","type":"article-journal","URL":"https://www.nature.com/articles/s41598-024-57912-3","volume":"14"},{"id":"wesselProblemsProspectsIntimate2002","author":[{"family":"Wessel","given":"David"},{"family":"Wright","given":"Matthew"}],"citation-key":"wesselProblemsProspectsIntimate2002","container-title":"Comput. Music J.","DOI":"10.1162/014892602320582945","event-place":"Cambridge, MA, USA","ISSN":"0148-9267","issue":"3","issued":{"date-parts":[["2002",9]]},"page":"11–22","publisher":"MIT Press","publisher-place":"Cambridge, MA, USA","title":"Problems and Prospects for Intimate Musical Control of Computers","type":"article-journal","URL":"https://doi.org/10.1162/014892602320582945","volume":"26"},{"id":"westergaardGeometriesSoundsTime1996","accessed":{"date-parts":[["2020",9,27]]},"author":[{"family":"Westergaard","given":"Peter"}],"citation-key":"westergaardGeometriesSoundsTime1996","container-title":"Music Theory Spectrum","container-title-short":"Music Theory Spectrum","DOI":"10.2307/745843","ISSN":"01956167, 15338339","issue":"1","issued":{"date-parts":[["1996",4]]},"page":"1-21","source":"DOI.org (Crossref)","title":"Geometries of Sounds in Time","type":"article-journal","URL":"https://academic.oup.com/mts/article-lookup/doi/10.2307/745843","volume":"18"},{"id":"williamsonRealNavExploringNatural2010","accessed":{"date-parts":[["2024",4,2]]},"author":[{"family":"Williamson","given":"Brian"},{"family":"Wingrave","given":"Chadwick"},{"family":"LaViola","given":"Joseph J."}],"citation-key":"williamsonRealNavExploringNatural2010","container-title":"2010 IEEE Symposium on 3D User Interfaces (3DUI)","DOI":"10.1109/3DUI.2010.5444737","event-place":"Waltham, MA, USA","event-title":"2010 IEEE Symposium on 3D User Interfaces (3DUI)","ISBN":"978-1-4244-6846-1","issued":{"date-parts":[["2010",3]]},"page":"3-10","publisher":"IEEE","publisher-place":"Waltham, MA, USA","source":"DOI.org (Crossref)","title":"RealNav: Exploring natural user interfaces for locomotion in video games","title-short":"RealNav","type":"paper-conference","URL":"http://ieeexplore.ieee.org/document/5444737/"},{"id":"wilsonEngineeringDesignCochlear2004","abstract":"Cochlear implants have instigated a popular but controversial revolution in the treatment of deafness. This book discusses the physiological bases of using artificial devices to electrically stimulate the brain to interpret sounds. As the first successful device to restore neural function, the cochlear implant serves as a model for research in neuroscience and biomedical engineering. These and other auditory prostheses are discussed in the context of historical treatments, engineering, psychophysics and clinical issues as well as implications for speech, behavior, cognition and long-term effects on people.","accessed":{"date-parts":[["2021",1,20]]},"author":[{"family":"Wilson","given":"Blake S."}],"citation-key":"wilsonEngineeringDesignCochlear2004","collection-number":"20","collection-title":"Springer Handbook of Auditory Research","container-title":"Cochlear Implants: Auditory Prostheses and Electric Hearing","editor":[{"family":"Zeng","given":"Fan-Gang"},{"family":"Popper","given":"Arthur N"},{"family":"Fay","given":"Richard R"}],"event-place":"New York","ISBN":"978-0-387-22585-2 978-1-4419-2346-2","issued":{"date-parts":[["2004"]]},"language":"English","note":"OCLC: 910559232","page":"14 - 52","publisher":"Springer","publisher-place":"New York","source":"Open WorldCat","title":"Engineering Design of Cochlear Implants","type":"chapter","URL":"https://doi.org/10.1007/978-0-387-22585-2"},{"id":"wirzVoiceDeaf1991","accessed":{"date-parts":[["2021",1,4]]},"author":[{"family":"Wirz","given":"Sheila"}],"citation-key":"wirzVoiceDeaf1991","container-title":"Voice Disorders and their Management","DOI":"10.1007/978-1-4899-2861-0_14","editor":[{"family":"Fawcus","given":"Margaret"}],"event-place":"Boston, MA","ISBN":"978-0-412-36480-8 978-1-4899-2861-0","issued":{"date-parts":[["1991"]]},"language":"en","page":"283-303","publisher":"Springer US","publisher-place":"Boston, MA","source":"DOI.org (Crossref)","title":"The Voice of the Deaf","type":"chapter","URL":"http://link.springer.com/10.1007/978-1-4899-2861-0_14"},{"id":"wiseCollaborativeLearningAnalytics2021","abstract":"The use of data from computer-based learning environments has been a long-standing feature of CSCL. Learning Analytics (LA) can enrich this established work in CSCL. This chapter outlines synergies and tensions between the two fields. Drawing on examples, we discuss established work to use learning analytics as a research tool (analytics of collaborative learning—ACL). Beyond this potential though, we discuss the use of analytics as a mediational tool in CSCL—collaborative learning analytics (CLA). This shift raises important challenges regarding the role of the computer—and analytics—in supporting and developing human agency and learning. LA offers a new tool for CSCL research. CSCL offers important contemporary perspectives on learning for a knowledge society, and as such is an important site of action for LA research that both builds our understanding of collaborative learning and supports that learning.","accessed":{"date-parts":[["2024",12,9]]},"author":[{"family":"Wise","given":"Alyssa Friend"},{"family":"Knight","given":"Simon"},{"family":"Shum","given":"Simon Buckingham"}],"citation-key":"wiseCollaborativeLearningAnalytics2021","container-title":"International Handbook of Computer-Supported Collaborative Learning","DOI":"10.1007/978-3-030-65291-3_23","editor":[{"family":"Cress","given":"Ulrike"},{"family":"Rosé","given":"Carolyn"},{"family":"Wise","given":"Alyssa Friend"},{"family":"Oshima","given":"Jun"}],"event-place":"Cham","ISBN":"978-3-030-65291-3","issued":{"date-parts":[["2021"]]},"language":"en","page":"425-443","publisher":"Springer International Publishing","publisher-place":"Cham","source":"Springer Link","title":"Collaborative Learning Analytics","type":"chapter","URL":"https://doi.org/10.1007/978-3-030-65291-3_23"},{"id":"wiseEffectsExpansionAlgorithms2008","author":[{"family":"Wise","given":"Christi L"},{"family":"Zakis","given":"Justin A"}],"citation-key":"wiseEffectsExpansionAlgorithms2008","container-title":"Journal of the American Academy of Audiology","container-title-short":"Journal of the American Academy of Audiology","ISSN":"1050-0545","issue":"2","issued":{"date-parts":[["2008"]]},"page":"147-157","publisher":"American Academy of Audiology","title":"Effects of Expansion Algorithms on Speech Reception Thresholds","type":"article-journal","volume":"19"},{"id":"wishartSonicArt1996","author":[{"family":"Wishart","given":"Trevor"},{"family":"Emmerson","given":"Simon"}],"call-number":"ML3800 .W57 1996","citation-key":"wishartSonicArt1996","collection-number":"v. 12","collection-title":"Contemporary music studies","edition":"New and rev. ed","event-place":"Amsterdam","ISBN":"978-3-7186-5846-6 978-3-7186-5847-3 978-3-7186-5848-0","issued":{"date-parts":[["1996"]]},"note":"OCLC: ocm35617339","number-of-pages":"357","publisher":"Harwood Academic Publishers","publisher-place":"Amsterdam","source":"Library of Congress ISBN","title":"On Sonic Art","type":"book"},{"id":"wlodarskiIdeaCanNever2007","abstract":"This article explores the role of memory within Schoenberg's Gedanke Manuscripts and its musical encoding in A Survivor From Warsaw, his 1947 Holocaust cantata. In the Gedanke Manuscripts human memory serves as analogy for the connective processes that aid the listener in comprehending and identifying the musical idea. Schoenberg argues that a musical idea is recognized (erkennt), retained, and then re-recognized (wiedererkennt) by the listener in a process similar to that of memory. These comments form the basis for an analysis that demonstrates the patterning of Survivor's 12-tone rows according to such mnemonic principles. The encoding of memory in the narrator's testimony as well as in the musical structure suggests that memory functions as an overriding poetic idea that holds several implications for evaluations of the cantata's musical and religious significance within Schoenberg's corpus.","accessed":{"date-parts":[["2021",1,14]]},"author":[{"family":"Wlodarski","given":"Amy Lynn"}],"citation-key":"wlodarskiIdeaCanNever2007","container-title":"Journal of Musicology","DOI":"10.1525/jm.2007.24.4.581","ISSN":"0277-9269, 1533-8347","issue":"4","issued":{"date-parts":[["2007",10,1]]},"language":"en","page":"581-608","source":"DOI.org (Crossref)","title":"““An Idea Can Never Perish””: Memory, the Musical Idea, and Schoenberg's A Survivor From Warsaw (1947)","title-short":"““An Idea Can Never Perish””","type":"article-journal","URL":"https://online.ucpress.edu/jm/article/24/4/581/63414/An-Idea-Can-Never-Perish-Memory-the-Musical-Idea","volume":"24"},{"id":"wojtachEmpiricalExplanationFlashlag2008","abstract":"When a flash of light is presented in physical alignment with a moving object, the flash is perceived to lag behind the position of the object. This phenomenon, known as the flash-lag effect, has been of particular interest to vision scientists because of the challenge it presents to understanding how the visual system generates perceptions of objects in motion. Although various explanations have been offered, the significance of this effect remains a matter of debate. Here, we show that: (i) contrary to previous reports based on limited data, the flash-lag effect is an increasing nonlinear function of image speed; and (ii) this function is accurately predicted by the frequency of occurrence of image speeds generated by the perspective transformation of moving objects. These results support the conclusion that perceptions of the relative position of a moving object are determined by accumulated experience with image speeds, in this way allowing for visual behavior in response to real-world sources whose speeds and positions cannot be perceived directly.","author":[{"family":"Wojtach","given":"William"},{"family":"Sung","given":"Kyongje"},{"family":"Truong","given":"S."},{"family":"Purves","given":"D."}],"citation-key":"wojtachEmpiricalExplanationFlashlag2008","container-title":"Proceedings of the National Academy of Sciences","DOI":"10.1073/pnas.0808916105","issued":{"date-parts":[["2008"]]},"note":"QID: Q36935743","page":"16338 - 16343","PMID":"18852459","title":"An empirical explanation of the flash-lag effect","type":"article-journal","URL":"https://www.semanticscholar.org/paper/9b0edcaea6724a8df0740f8275756a17f942bb9f","volume":"105"},{"id":"wonwooriWOWLOG","accessed":{"date-parts":[["2021",1,27]]},"author":[{"literal":"WONWOORI"}],"citation-key":"wonwooriWOWLOG","title":"WOW-LOG","type":"webpage","URL":"https://thirdgarden.space/WOW-Log/#information"},{"id":"woolfordBreakdownHarmonicaExtending2017","abstract":"Breakdown Harmonica1 is a research project focusing on analysing, understanding, and communicating an historical dance piece (Jane Dudley's 1937 Harmonica Breakdown) to dance scholars and practitioners, as well as researchers from movement and computing disciplines. The project explored the use of animation and video games development tools to extend the traditional Labanotation score in order to make the score more readable for those without extensive training in Laban Notation and Laban Movement Analysis. This paper articulates some of the challenges faced in movement notation, and in the use of tools developed for video games and animation.","author":[{"family":"Woolford","given":"Kirk"}],"citation-key":"woolfordBreakdownHarmonicaExtending2017","collection-title":"MOCO '17","container-title":"Proceedings of the 4th international conference on movement computing","DOI":"10.1145/3077981.3078051","event-place":"London, United Kingdom","ISBN":"978-1-4503-5209-3","issued":{"date-parts":[["2017"]]},"number-of-pages":"7","publisher":"Association for Computing Machinery","publisher-place":"London, United Kingdom","title":"Breakdown harmonica: Extending laban notation with video game development tools","type":"paper-conference","URL":"https://doi.org/10.1145/3077981.3078051"},{"id":"worldhealthorganizationBasicEarHearing2020","author":[{"literal":"World Health Organization"}],"citation-key":"worldhealthorganizationBasicEarHearing2020","event-place":"Geneva","issued":{"date-parts":[["2020"]]},"publisher":"World Health Organization","publisher-place":"Geneva","title":"Basic Ear and Hearing Care Resource","type":"report","URL":"https://apps.who.int/iris/rest/bitstreams/1270187/retrieve"},{"id":"worldhealthorganizationGlossaryTermsCommunity2004","author":[{"literal":"World Health Organization"}],"citation-key":"worldhealthorganizationGlossaryTermsCommunity2004","collection-title":"Ageing and health technical report","issued":{"date-parts":[["2004"]]},"publisher":"WHO","title":"A Glossary of Terms for Community Health Care and Services for Older Persons","type":"book","URL":"https://apps.who.int/iris/bitstream/handle/10665/68896/WHO_WKC_Tech.Ser._04.2.pdf?sequence=1&isAllowed=y"},{"id":"worldhealthorganizationInternationalClassificationFunctioning2001","author":[{"literal":"World Health Organization"}],"citation-key":"worldhealthorganizationInternationalClassificationFunctioning2001","ISBN":"92-4-154732-4","issued":{"date-parts":[["2001"]]},"publisher":"World Health Organization","title":"International Classification of Functioning, Disability, and Health","type":"book"},{"id":"wrenComparisonKinematicsTheia2023","abstract":"Background\nMarkerless motion capture systems have the potential to make clinical gait analysis more efficient and convenient. Theia3D is a commercially available markerless system that may serve as an alternative to traditional gait analysis for clinical gait laboratories.\nResearch Question\nWhat is the concurrent validity of markerless gait analysis using Theia3D compared to traditional marker-based gait analysis in pediatric clinical gait patients?\nMethods\nThirty-six patients (20 male, age 2–25 years) with a range of diagnoses underwent clinical gait analysis with data being captured concurrently by a traditional marker-based motion capture system (Vicon Nexus) and a commercial markerless system (Theia3D). Multiple left strides were averaged for each subject, and the difference in kinematics (Theia - Vicon) was calculated over the gait cycle and evaluated using root mean square difference (RMSD), mean difference, and RMSD after subtracting the mean value across the gait cycle (RMSDoffset). Sub-analysis was performed for 25 patients with foot deformities, 9 wearing ankle-foot orthoses, and 6 walking with assistance (cane, crutches, walker, or handheld).\nResults\nKinematics showed similar patterns between the marker-based and markerless systems. RMSD was < 6° except for pelvic tilt, hip flexion, ankle inversion, foot progression, and transverse plane rotation of the hip, knee, and ankle. These measures mainly differed due to an offset between the curves. After adjusting for offsets, all RMSDoffset were < 6°. RMSD was larger for patients with foot deformities, wearing orthoses, or using assistive devices, but all RMSDoffset were still < 8°. In some cases, however, the markerless system had greater trial-to-trial variability, showed a larger knee varus “bump” in swing, or failed to track the subject.\nSignificance\nThis study provides preliminary evidence of concurrent validity of Theia3D for pediatric patients with abnormal gait. However, some questions remain regarding identification of the knee axis and for patients with foot deformity or assistive devices.","author":[{"family":"Wren","given":"Tishya A.L."},{"family":"Isakov","given":"Pavel"},{"family":"Rethlefsen","given":"Susan A."}],"citation-key":"wrenComparisonKinematicsTheia2023","container-title":"Gait & Posture","container-title-short":"Gait & Posture","DOI":"10.1016/j.gaitpost.2023.05.029","ISSN":"0966-6362","issued":{"date-parts":[["2023",7,1]]},"page":"9-14","title":"Comparison of kinematics between Theia markerless and conventional marker-based gait analysis in clinical patients","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0966636223001443","volume":"104"},{"id":"wrightOpenSoundControlState2003","abstract":"OpenSound Control (\"OSC\") is a protocol for communication among computers, sound synthesizers, and other multimedia devices that is optimized for modern networking technology. OSC has achieved wide use in the field of computer-based new interfaces for musical expression for wide-area and local-area networked distributed music systems, inter-process communication, and even within a single application.","author":[{"family":"Wright","given":"Matthew"},{"family":"Freed","given":"Adrian"},{"family":"Momeni","given":"Ali"}],"citation-key":"wrightOpenSoundControlState2003","collection-title":"NIME '03","container-title":"Proceedings of the 2003 Conference on New Interfaces for Musical Expression","event-place":"Montreal, Quebec, Canada","issued":{"date-parts":[["2003"]]},"page":"153–160","publisher":"National University of Singapore","publisher-place":"SGP","title":"OpenSound Control: State of the Art 2003","type":"paper-conference"},{"id":"xkcdStandards","accessed":{"date-parts":[["2024",12,5]]},"author":[{"literal":"xkcd"}],"citation-key":"xkcdStandards","container-title":"xkcd","title":"Standards","type":"webpage","URL":"https://xkcd.com/927/"},{"id":"xuTangibleUserInterface2005","author":[{"family":"Xu","given":"Diana"}],"citation-key":"xuTangibleUserInterface2005","event-title":"Proc. of the UCLAN Department of Computing Conference","issued":{"date-parts":[["2005"]]},"publisher":"Citeseer","title":"Tangible user interface for children-an overview","type":"paper-conference"},{"id":"yadavReviewMultimodalHuman2021","accessed":{"date-parts":[["2024",9,5]]},"author":[{"family":"Yadav","given":"Santosh Kumar"},{"family":"Tiwari","given":"Kamlesh"},{"family":"Pandey","given":"Hari Mohan"},{"family":"Akbar","given":"Shaik Ali"}],"citation-key":"yadavReviewMultimodalHuman2021","container-title":"Knowledge-Based Systems","container-title-short":"Knowledge-Based Systems","DOI":"10.1016/j.knosys.2021.106970","ISSN":"09507051","issued":{"date-parts":[["2021",7]]},"language":"en","page":"106970","source":"DOI.org (Crossref)","title":"A review of multimodal human activity recognition with special emphasis on classification, applications, challenges and future directions","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0950705121002331","volume":"223"},{"id":"yanCharacterisingIndividualLevelCollaborative2023","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Yan","given":"Lixiang"},{"family":"Tan","given":"Yuanru"},{"family":"Swiecki","given":"Zachari"},{"family":"Gašević","given":"Dragan"},{"family":"Williamson Shaffer","given":"David"},{"family":"Zhao","given":"Linxuan"},{"family":"Li","given":"Xinyu"},{"family":"Martinez-Maldonado","given":"Roberto"}],"citation-key":"yanCharacterisingIndividualLevelCollaborative2023","container-title":"Advances in Quantitative Ethnography","DOI":"10.1007/978-3-031-47014-1_5","editor":[{"family":"Arastoopour Irgens","given":"Golnaz"},{"family":"Knight","given":"Simon"}],"event-place":"Cham","ISBN":"978-3-031-47013-4 978-3-031-47014-1","issued":{"date-parts":[["2023"]]},"language":"en","page":"66-80","publisher":"Springer Nature Switzerland","publisher-place":"Cham","source":"DOI.org (Crossref)","title":"Characterising Individual-Level Collaborative Learning Behaviours Using Ordered Network Analysis and Wearable Sensors","type":"chapter","URL":"https://link.springer.com/10.1007/978-3-031-47014-1_5","volume":"1895"},{"id":"yanHowTeachersUse2022","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Yan","given":"Lixiang"},{"family":"Martinez-Maldonado","given":"Roberto"},{"family":"Zhao","given":"Linxuan"},{"family":"Deppeler","given":"Joanne"},{"family":"Corrigan","given":"Deborah"},{"family":"Gasevic","given":"Dragan"}],"citation-key":"yanHowTeachersUse2022","container-title":"LAK22: 12th International Learning Analytics and Knowledge Conference","DOI":"10.1145/3506860.3506872","event-place":"Online USA","event-title":"LAK22: 12th International Learning Analytics and Knowledge Conference","ISBN":"978-1-4503-9573-1","issued":{"date-parts":[["2022",3,21]]},"language":"en","page":"87-97","publisher":"ACM","publisher-place":"Online USA","source":"DOI.org (Crossref)","title":"How do Teachers Use Open Learning Spaces? Mapping from Teachers’ Socio-spatial Data to Spatial Pedagogy","title-short":"How do Teachers Use Open Learning Spaces?","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3506860.3506872"},{"id":"yanPhysiologicalSynchronyArousal2023","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Yan","given":"Lixiang"},{"family":"Martinez-Maldonado","given":"Roberto"},{"family":"Zhao","given":"Linxuan"},{"family":"Li","given":"Xinyu"},{"family":"Gašević","given":"Dragan"}],"citation-key":"yanPhysiologicalSynchronyArousal2023","container-title":"Artificial Intelligence in Education","DOI":"10.1007/978-3-031-36272-9_49","editor":[{"family":"Wang","given":"Ning"},{"family":"Rebolledo-Mendez","given":"Genaro"},{"family":"Matsuda","given":"Noboru"},{"family":"Santos","given":"Olga C."},{"family":"Dimitrova","given":"Vania"}],"event-place":"Cham","ISBN":"978-3-031-36271-2 978-3-031-36272-9","issued":{"date-parts":[["2023"]]},"language":"en","page":"602-614","publisher":"Springer Nature Switzerland","publisher-place":"Cham","source":"DOI.org (Crossref)","title":"Physiological Synchrony and Arousal as Indicators of Stress and Learning Performance in Embodied Collaborative Learning","type":"chapter","URL":"https://link.springer.com/10.1007/978-3-031-36272-9_49","volume":"13916"},{"id":"yanRoleIndoorPositioning2023","abstract":"Abstract \n             \n               \n              Simulation‐based learning provides students with unique opportunities to develop key procedural and teamwork skills in close‐to‐authentic physical learning and training environments. Yet, assessing students' performance in such situations can be challenging and mentally exhausting for teachers. Multimodal learning analytics can support the assessment of simulation‐based learning by making salient aspects of students' activities visible for evaluation. Although descriptive analytics have been used to study students' motor behaviours in simulation‐based learning, their validity and utility for assessing performance remain unclear. This study aims at addressing this knowledge gap by investigating how indoor positioning analytics can be used to generate meaningful insights about students' tasks and collaboration performance in simulation‐based learning. We collected and analysed the positioning data of 304 healthcare students, organised in 76 teams, through correlation, predictive and epistemic network analyses. The primary findings were (1) large correlations between students' spatial‐procedural behaviours and their group performances; (2) predictive learning analytics that achieved an acceptable level (0.74 AUC) in distinguishing between low‐performing and high‐performing teams regarding collaboration performance; and (3) epistemic networks that can be used for assessing the behavioural differences across multiple teams. We also present the teachers' qualitative evaluation of the utility of these analytics and implications for supporting formative assessment in simulation‐based learning. \n             \n             \n               \n               \n                 \n                   \n                    Practitioner notes \n                   \n                   \n                    What is currently known about this topic \n                     \n                       \n                        Assessing students' performance in simulation‐based learning is often challenging and mentally exhausting. \n                       \n                       \n                        The combination of learning analytics and sensing technologies has the potential to uncover meaningful behavioural insights in physical learning spaces. \n                       \n                       \n                        Observational studies have suggested the potential value of analytics extracted from positioning data as indicators of highly‐effective behaviour in simulation‐based learning. \n                       \n                     \n                   \n                   \n                    What this paper adds \n                     \n                       \n                        Indoor positioning analytics for supporting teachers' formative assessment and timely feedback on students' group/team‐level performance in simulation‐based learning. \n                       \n                       \n                        Empirical evidence supported the potential use of epistemic networks for assessing the behavioural differences between low‐performing and high‐performing teams. \n                       \n                       \n                        Teachers' positively validated the utility of indoor positioning analytics in supporting reflective practices and formative assessment in simulation‐based learning. \n                       \n                     \n                   \n                   \n                    Implications for practitioners \n                     \n                       \n                        Indoor positioning tracking and spatial analysis can be used to investigate students' teamwork and task performance in simulation‐based learning. \n                       \n                       \n                        Predictive learning analytics should be developed based on features that have direct relevance to teachers' learning design. \n                       \n                       \n                        Epistemic networks analysis and comparison plots can be useful in identifying and assessing behavioural differences across multiple teams.","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Yan","given":"Lixiang"},{"family":"Martinez‐Maldonado","given":"Roberto"},{"family":"Zhao","given":"Linxuan"},{"family":"Dix","given":"Samantha"},{"family":"Jaggard","given":"Hollie"},{"family":"Wotherspoon","given":"Rosie"},{"family":"Li","given":"Xinyu"},{"family":"Gašević","given":"Dragan"}],"citation-key":"yanRoleIndoorPositioning2023","container-title":"British Journal of Educational Technology","container-title-short":"Brit J Educational Tech","DOI":"10.1111/bjet.13262","ISSN":"0007-1013, 1467-8535","issue":"1","issued":{"date-parts":[["2023",1]]},"language":"en","page":"267-292","source":"DOI.org (Crossref)","title":"The role of indoor positioning analytics in assessment of simulation‐based learning","type":"article-journal","URL":"https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.13262","volume":"54"},{"id":"yitaoMusicCochlearImplants2013","author":[{"family":"Yitao","given":"Mao"},{"family":"Li","given":"Xu"}],"citation-key":"yitaoMusicCochlearImplants2013","container-title":"Journal of Otology","container-title-short":"Journal of Otology","ISSN":"1672-2930","issue":"1","issued":{"date-parts":[["2013"]]},"page":"32-38","publisher":"Elsevier","title":"Music and Cochlear Implants","type":"article-journal","volume":"8"},{"id":"yookEXTRAPOLATIONDEPENDSPERCEIVED2021","abstract":"30 31 In the flash-lag effect (FLE), a flash in spatiotemporal alignment with a moving object is often 32 misperceived as lagging behind the moving object. One proposed explanation for the illusion is 33 based on predictive motion extrapolation of trajectories. In this interpretation, observers require 34 an estimate of the object’s velocity to anticipate future positions, implying that the FLE is 35 dependent on a neural representation of perceived velocity. By contrast, alternative models of the 36 FLE based on differential latencies or temporal averaging should not rely on such a representation 37 of velocity. Here, we test the extrapolation account by investigating whether the FLE is sensitive 38 to illusory changes in perceived speed when physical speed is actually constant. This was tested 39 using rotational wedge stimuli with variable noise texture (Experiment 1) and luminance contrast 40 (Experiment 2). We show for both manipulations, differences in perceived speed corresponded to 41 differences in the FLE: dynamic versus static noise, and low versus high contrast stimuli led to 42 increases in perceived speed and FLE magnitudes. These effects were consistent across different 43 textures and were not due to low-level factors. Our results support the idea that the FLE depends 44 on a neural representation of velocity, which is consistent with mechanisms of motion 45 extrapolation. Hence, the faster the perceived speed, the larger the extrapolation, the stronger the 46 flash-lag. 47 48","author":[{"family":"Yook","given":"Jane"},{"family":"Lee","given":"Lysha"},{"family":"Vossel","given":"S."},{"family":"Weidner","given":"R."},{"family":"Hogendoorn","given":"Hinze"}],"citation-key":"yookEXTRAPOLATIONDEPENDSPERCEIVED2021","issued":{"date-parts":[["2021"]]},"title":"EXTRAPOLATION DEPENDS ON PERCEIVED SPEED 1 1 2 3 4 5 Motion extrapolation in the flash-lag effect depends on perceived , rather than physical speed 6 7 8 9","type":"article-journal","URL":"https://www.semanticscholar.org/paper/4a0ea9094d28de25059c2b50761b287cabf81a95"},{"id":"yookMotionExtrapolationFlashlag2021","abstract":"In the flash-lag effect (FLE), a flash in spatiotemporal alignment with a moving object is misperceived as lagging behind the moving object. One proposed explanation for this illusion is based on predictive motion extrapolation of trajectories. In this interpretation, the diverging effects of velocity on the perceived position of the moving object suggest that FLE might be based on the neural representation of perceived, rather than physical, velocity. By contrast, alternative explanations based on differential latency or temporal averaging would predict that the FLE does not rely on such a representation of perceived velocity. Here we examined whether the FLE is sensitive to illusory changes in perceived speed that result in changes to perceived velocity, while physical speed is constant. The perceived speed of the moving object was manipulated using revolving wedge stimuli with variable pattern textures (Experiment 1) and luminance contrast (Experiment 2). The motion extrapolation interpretation would predict that the changes in FLE magnitude should correspond to the changes in the perceived speed of the moving object. In the current study, two experiments demonstrated that perceived speed and FLE magnitude increased in the dynamic pattern relative to the static pattern conditions, and that the same effect was found in the low contrast compared to the high contrast conditions. These results showed that manipulations of texture and contrast that are known to alter judgments of perceived speed also modulate perceived position. We interpret this as a consequence of motion extrapolation mechanisms and discuss possible explanations for why we observed no cross-effect correlation.","author":[{"family":"Yook","given":"Jane"},{"family":"Lee","given":"Lysha"},{"family":"Vossel","given":"S."},{"family":"Weidner","given":"R."},{"family":"Hogendoorn","given":"Hinze"}],"citation-key":"yookMotionExtrapolationFlashlag2021","container-title":"Vision Research","DOI":"10.1101/2021.03.22.436374","issued":{"date-parts":[["2021"]]},"page":"null","PMID":"34942429","title":"Motion extrapolation in the flash-lag effect depends on perceived, rather than physical speed","type":"article-journal","URL":"https://www.semanticscholar.org/paper/6c9d7b0245365c76e9b6604c2f96a8a159403c3c","volume":"193"},{"id":"zabolotnaExaminingInterplayKnowledge2023","accessed":{"date-parts":[["2024",6,28]]},"author":[{"family":"Zabolotna","given":"Kateryna"},{"family":"Malmberg","given":"Jonna"},{"family":"Järvenoja","given":"Hanna"}],"citation-key":"zabolotnaExaminingInterplayKnowledge2023","container-title":"Computers in Human Behavior","container-title-short":"Computers in Human Behavior","DOI":"10.1016/j.chb.2022.107494","ISSN":"07475632","issued":{"date-parts":[["2023",1]]},"language":"en","page":"107494","source":"DOI.org (Crossref)","title":"Examining the interplay of knowledge construction and group-level regulation in a computer-supported collaborative learning physics task","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0747563222003144","volume":"138"},{"id":"zagorski-thomasMusicologyRecordProduction2014","abstract":"Recorded music is as different to live music as film is to theatre. In this book, Simon Zagorski-Thomas employs current theories from psychology and sociology to examine how recorded music is made and how we listen to it. Setting out a framework for the study of recorded music and record production, he explains how recorded music is fundamentally different to live performance, how record production influences our interpretation of musical meaning and how the various participants in the process interact with technology to produce recorded music. He combines ideas from the ecological approach to perception, embodied cognition and the social construction of technological systems to provide a summary of theoretical approaches that are applied to the sound of the music and the creative activity of production. A wide range of examples from Zagorski-Thomas&apos;s professional experience reveal these ideas in action.","accessed":{"date-parts":[["2024",1,23]]},"author":[{"family":"Zagorski-Thomas","given":"Simon"}],"citation-key":"zagorski-thomasMusicologyRecordProduction2014","DOI":"10.1017/CBO9781139871846","edition":"1","ISBN":"978-1-139-87184-6 978-1-107-07564-1 978-1-107-42834-8","issued":{"date-parts":[["2014",8,14]]},"publisher":"Cambridge University Press","source":"DOI.org (Crossref)","title":"The Musicology of Record Production","type":"book","URL":"https://www.cambridge.org/core/product/identifier/9781139871846/type/book"},{"id":"zajoncAttitudinalEffectsMere1968","abstract":"HYPOTHESIZES THAT MERE REPEATED EXPOSURE OF THE INDIVIDUAL TO A STIMULUS OBJECT ENHANCES HIS ATTITUDE TOWARD IT. BY \"MERE\" EXPOSURE IS MEANT A CONDITION MAKING THE STIMULUS ACCESSIBLE TO PERCEPTION. SUPPORT FOR THE HYPOTHESIS CONSISTS OF 4 TYPES OF EVIDENCE, PRESENTED AND REVIEWED: (1) THE CORRELATION BETWEEN AFFECTIVE CONNOTATION OF WORDS AND WORD FREQUENCY, (2) THE EFFECT OF EXPERIMENTALLY MANIPULATED FREQUENCY OF EXPOSURE UPON THE AFFECTIVE CONNOTATION OF NONSENSE WORDS AND SYMBOLS, (3) THE CORRELATION BETWEEN WORD FREQUENCY AND THE ATTITUDE TO THEIR REFERENTS, AND (4) THE EFFECTS OF EXPERIMENTALLY MANIPULATED FREQUENCY OF EXPOSURE ON ATTITUDE. THE RELEVANCE FOR THE EXPOSURE-ATTITUDE HYPOTHESIS OF THE EXPLORATION THEORY AND OF THE SEMANTIC SATIATION FINDINGS WERE EXAMINED. (PsycINFO Database Record (c) 2017 APA, all rights reserved)","author":[{"family":"Zajonc","given":"Robert B."}],"citation-key":"zajoncAttitudinalEffectsMere1968","container-title":"Journal of Personality and Social Psychology","DOI":"10.1037/h0025848","event-place":"US","ISSN":"1939-1315(Electronic),0022-3514(Print)","issue":"2, Pt.2","issued":{"date-parts":[["1968"]]},"page":"1-27","publisher":"American Psychological Association","publisher-place":"US","title":"Attitudinal effects of mere exposure.","type":"article-journal","volume":"9"},{"id":"zakisAcousticPerceptualEffects2007","author":[{"family":"Zakis","given":"Justin A"},{"family":"Wise","given":"Christi"}],"citation-key":"zakisAcousticPerceptualEffects2007","container-title":"The Journal of the Acoustical Society of America","container-title-short":"The Journal of the Acoustical Society of America","ISSN":"0001-4966","issue":"1","issued":{"date-parts":[["2007"]]},"page":"433-441","publisher":"Acoustical Society of America","title":"The Acoustic and Perceptual Effects of Two Noise-Suppression Algorithms","type":"article-journal","volume":"121"},{"id":"zakisHowCanDigital2009","author":[{"family":"Zakis","given":"Justin A."},{"family":"Fulton","given":"Bernadette"}],"citation-key":"zakisHowCanDigital2009","container-title":"Hearing Review","container-title-short":"Hearing Review","issue":"5","issued":{"date-parts":[["2009"]]},"page":"44-48","title":"How Can Digital Signal Processing Help Musicians?","type":"article-journal","volume":"16"},{"id":"zakisMusicPerceptionHearing2016","abstract":"This volume will serve as the first Handbook of its kind in the area of hearing aid research, often the least-defined, least-understood, part of the multi-disciplinary research process. Most scientific training is very advanced within the particular disciplines but provides little opportunity for systematic introduction to the issues and obstacles that prevent effective hearing-aid related research. This area has emerged as one of critical importance, as signified by a single specialized meeting (the International Hearing Aid Conference, IHCON) that brings together specialists from the disparate disciplines involved, including both university and industry researchers. Identification of the key steps that enable high-impact basic science to ultimately result in significant clinical advances that improve patient outcome is critical. This volume will provide an overview of current key issues in hearing aid research from the perspective of many different disciplines, not only from the perspective of the key funding agencies, but also from the scientists and clinicians who are currently involved in hearing aid research. It will offer insight into the experience, current technology and future technology that can help improve hearing aids, as scientists and clinicians typically have little or no formal training over the whole range of the individual disciplines that are relevant. The selection and coverage of topics insures that it will have lasting impact, well beyond immediate, short-term, or parochial concerns.","accessed":{"date-parts":[["2021",1,20]]},"author":[{"family":"Zakis","given":"Justin A."}],"citation-key":"zakisMusicPerceptionHearing2016","collection-number":"56","collection-title":"Springer Handbook of Auditory Research","container-title":"Hearing Aids","editor":[{"family":"Popelka","given":"Gerald R."},{"family":"Moore","given":"Brian C. J."},{"family":"Fay","given":"Richard R."},{"family":"Popper","given":"Arthur N."}],"event-place":"Cham","ISBN":"978-3-319-33036-5","issued":{"date-parts":[["2016"]]},"language":"English","note":"OCLC: 984801900","page":"217 - 252","publisher":"Springer International Publishing : Imprint : Springer","publisher-place":"Cham","source":"Open WorldCat","title":"Music Perception and Hearing Aids","type":"chapter","URL":"https://doi.org/10.1007/978-3-319-33036-5"},{"id":"zakPoeticsRockCutting2001","author":[{"family":"Zak","given":"Albin"}],"call-number":"ML3534 .Z35 2001","citation-key":"zakPoeticsRockCutting2001","event-place":"Berkeley","ISBN":"978-0-520-21809-3 978-0-520-23224-2","issued":{"date-parts":[["2001"]]},"number-of-pages":"259","publisher":"University of California Press","publisher-place":"Berkeley","source":"Library of Congress ISBN","title":"The Poetics of Rock: Cutting Tracks, Making Records","title-short":"The poetics of rock","type":"book"},{"id":"zankIronySoundMusic2009","author":[{"family":"Zank","given":"Stephen"}],"call-number":"ML410.R23 Z36 2009","citation-key":"zankIronySoundMusic2009","collection-number":"66","collection-title":"Eastman studies in music","event-place":"Rochester, NY","ISBN":"978-1-58046-189-4","issued":{"date-parts":[["2009"]]},"note":"OCLC: ocn213307981","number-of-pages":"434","publisher":"University of Rochester Press","publisher-place":"Rochester, NY","source":"Library of Congress ISBN","title":"Irony and Sound: the Music of Maurice Ravel","title-short":"Irony and sound","type":"book"},{"id":"zbikowskiConceptualizingMusicCognitive2005","author":[{"family":"Zbikowski","given":"Lawrence Michael"}],"citation-key":"zbikowskiConceptualizingMusicCognitive2005","event-place":"New York; Oxford","ISBN":"978-0-19-518797-7","issued":{"date-parts":[["2005"]]},"language":"English","note":"OCLC: 475560431","publisher":"Oxford University Press","publisher-place":"New York; Oxford","source":"Open WorldCat","title":"Conceptualizing Music: Cognitive Structure, Theory, and Analysis","title-short":"Conceptualizing music","type":"book"},{"id":"zeitounPerceptualEvaluationQualitative2014","abstract":"Since the discover of point-light display experimental technique, it's been shown how much movement is an important carrier of socially relevant information. From the identity of a subject up to his emotional state of mind, it appears that our visual perception system is especially tuned to analyse biological motion in all its forms.Thus, I issued the hypothesis that point-light display might preserve most socially relevant information that convey through dance, including in qualitative terms. The relevancy of such an hypothesis will be discussed in comparison with full-light display. Also, in this paper I review some key point-light display experiments to relate with visual perception experiments in order to suggest a method to inspect such an hypothesis. Would it be concluding, point-light display could be considered for dance analysis, in qualitative terms, thru gestural rhythm analysis.","author":[{"family":"Zeitoun","given":"Yohan"}],"citation-key":"zeitounPerceptualEvaluationQualitative2014","collection-title":"MOCO '14","container-title":"Proceedings of the 2014 international workshop on movement and computing","DOI":"10.1145/2617995.2618025","event-place":"Paris, France","ISBN":"978-1-4503-2814-2","issued":{"date-parts":[["2014"]]},"number-of-pages":"4","page":"158–161","publisher":"Association for Computing Machinery","publisher-place":"Paris, France","title":"Perceptual evaluation of qualitative information preservation within point-light displays","type":"paper-conference","URL":"https://doi.org/10.1145/2617995.2618025"},{"id":"zempSoftTissueArtefacts2014","abstract":"Soft tissue artefact affects the determination of skeletal kinematics. Thus, it is important to know the accuracy and limitations of kinematic parameters determined and modelled based on skin marker data. Here, the curvature angles, as well as the rotations of the lumbar and thoracic segments, of seven healthy subjects were determined in the sagittal plane using a skin marker set and compared to measurements taken in an open upright MRI scanner in order to understand the influence of soft tissue artefact at the back. The mean STA in the flexed compared to the extended positions were 10.2±6.1 mm (lumbar)/9.3±4.2 mm (thoracic) and 10.7±4.8 mm (lumbar)/9.2±4.9 mm (thoracic) respectively. A linear regression of the lumbar and thoracic curvatures between the marker-based measurements and MRI-based measurements resulted in coefficients of determination, R2, of 0.552 and 0.385 respectively. Skin marker measurements therefore allow for the assessment of changes in the lumbar and thoracic curvature angles, but the absolute values suffer from uncertainty. Nevertheless, this marker set appears to be suitable for quantifying lumbar and thoracic spinal changes between quasi-static whole body postural changes.","author":[{"family":"Zemp","given":"Roland"},{"family":"List","given":"Renate"},{"family":"Gülay","given":"Turgut"},{"family":"Elsig","given":"Jean Pierre"},{"family":"Naxera","given":"Jaroslav"},{"family":"Taylor","given":"William R."},{"family":"Lorenzetti","given":"Silvio"}],"citation-key":"zempSoftTissueArtefacts2014","container-title":"PLOS ONE","container-title-short":"PLOS ONE","DOI":"10.1371/journal.pone.0095426","issue":"4","issued":{"date-parts":[["2014",4,18]]},"page":"e95426","publisher":"Public Library of Science","title":"Soft Tissue Artefacts of the Human Back: Comparison of the Sagittal Curvature of the Spine Measured Using Skin Markers and an Open Upright MRI","type":"article-journal","URL":"https://doi.org/10.1371/journal.pone.0095426","volume":"9"},{"id":"zengAuditoryProsthesesNew2011","call-number":"RF305 .A93 2011","citation-key":"zengAuditoryProsthesesNew2011","collection-number":"39","collection-title":"Springer Handbook of Auditory Research","editor":[{"family":"Zeng","given":"Fan-Gang"},{"family":"Popper","given":"Arthur N."},{"family":"Fay","given":"Richard R."}],"event-place":"New York","ISBN":"978-1-4419-9433-2 978-1-4419-9434-9","issued":{"date-parts":[["2011"]]},"note":"OCLC: ocn733239537","number-of-pages":"389","publisher":"Springer Verlag","publisher-place":"New York","source":"Library of Congress ISBN","title":"Auditory Prostheses: New Horizons","title-short":"Auditory Prostheses","type":"book"},{"id":"zengAuditoryProsthesisPresent2004","abstract":"Cochlear implants have instigated a popular but controversial revolution in the treatment of deafness. This book discusses the physiological bases of using artificial devices to electrically stimulate the brain to interpret sounds. As the first successful device to restore neural function, the cochlear implant serves as a model for research in neuroscience and biomedical engineering. These and other auditory prostheses are discussed in the context of historical treatments, engineering, psychophysics and clinical issues as well as implications for speech, behavior, cognition and long-term effects on people.","accessed":{"date-parts":[["2021",1,20]]},"author":[{"family":"Zeng","given":"Fan-Gang"}],"citation-key":"zengAuditoryProsthesisPresent2004","collection-number":"20","collection-title":"Springer Handbook of Auditory Research","container-title":"Cochlear Implants: Auditory Prostheses and Electric Hearing","editor":[{"family":"Zeng","given":"Fan-Gang"},{"family":"Popper","given":"Arthur N"},{"family":"Fay","given":"Richard R"}],"event-place":"New York","ISBN":"978-0-387-22585-2 978-1-4419-2346-2","issued":{"date-parts":[["2004"]]},"language":"English","note":"OCLC: 910559232","page":"1 - 13","publisher":"Springer","publisher-place":"New York","source":"Open WorldCat","title":"Auditory Prosthesis: Past, Present, and Future","type":"chapter","URL":"https://doi.org/10.1007/978-0-387-22585-2"},{"id":"zengCochlearImplantsAuditory2004","abstract":"Cochlear implants have instigated a popular but controversial revolution in the treatment of deafness. This book discusses the physiological bases of using artificial devices to electrically stimulate the brain to interpret sounds. As the first successful device to restore neural function, the cochlear implant serves as a model for research in neuroscience and biomedical engineering. These and other auditory prostheses are discussed in the context of historical treatments, engineering, psychophysics and clinical issues as well as implications for speech, behavior, cognition and long-term effects on people.","accessed":{"date-parts":[["2021",1,20]]},"citation-key":"zengCochlearImplantsAuditory2004","collection-number":"20","collection-title":"Springer Handbook of Auditory Research","editor":[{"family":"Zeng","given":"Fan-Gang"},{"family":"Popper","given":"Arthur N"},{"family":"Fay","given":"Richard R"}],"event-place":"New York","ISBN":"978-0-387-22585-2 978-1-4419-2346-2","issued":{"date-parts":[["2004"]]},"language":"English","note":"OCLC: 910559232","number-of-pages":"437","publisher":"Springer","publisher-place":"New York","source":"Open WorldCat","title":"Cochlear Implants: Auditory Prostheses and Electric Hearing","title-short":"Cochlear Implants","type":"book","URL":"https://doi.org/10.1007/978-0-387-22585-2"},{"id":"zhangComparativeEvaluationTerm2008","author":[{"family":"Zhang","given":"Ziqi"},{"family":"Iria","given":"José"},{"family":"Brewster","given":"Christopher"},{"family":"Ciravegna","given":"Fabio"}],"citation-key":"zhangComparativeEvaluationTerm2008","container-title":"Proceedings of the sixth international conference on language resources and evaluation","event-place":"Marrakesh, Morocco","event-title":"LREC08","issued":{"date-parts":[["2008"]]},"page":"2108-2113","publisher-place":"Marrakesh, Morocco","title":"A comparative evaluation of term recognition algorithms.","type":"paper-conference","volume":"5"},{"id":"zhangHandbookImageEngineering2021","author":[{"family":"Zhang","given":"Yu-Jin"}],"citation-key":"zhangHandbookImageEngineering2021","DOI":"10.1007/978-981-15-5873-3","event-place":"Singapore","ISBN":"978-981-15-5872-6","issued":{"date-parts":[["2021"]]},"language":"eng","publisher":"Springer","publisher-place":"Singapore","source":"K10plus ISBN","title":"Handbook of image engineering","type":"book"},{"id":"zhangJATE20Java2016","abstract":"Automatic Term Extraction (ATE) or Recognition (ATR) is a fundamental processing step preceding many complex knowledge engineering tasks. However, few methods have been implemented as public tools and in particular, available as open-source freeware. Further, little effort is made to develop an adaptable and scalable framework that enables customization, development, and comparison of algorithms under a uniform environment. This paper introduces JATE 2.0, a complete remake of the free Java Automatic Term Extraction Toolkit (Zhang et al., 2008) delivering new features including: (1) highly modular, adaptable and scalable ATE thanks to integration with Apache Solr, the open source free-text indexing and search platform; (2) an extended collection of state-of-the-art algorithms. We carry out experiments on two well-known benchmarking datasets and compare the algorithms along the dimensions of effectiveness (precision) and efficiency (speed and memory consumption). To the best of our knowledge, this is by far the only free ATE library offering a flexible architecture and the most comprehensive collection of algorithms.","author":[{"family":"Zhang","given":"Ziqi"},{"family":"Gao","given":"Jie"},{"family":"Ciravegna","given":"Fabio"}],"citation-key":"zhangJATE20Java2016","container-title":"Proceedings of the tenth international conference on language resources and evaluation (LREC'16)","editor":[{"family":"Calzolari","given":"Nicoletta"},{"family":"Choukri","given":"Khalid"},{"family":"Declerck","given":"Thierry"},{"family":"Goggi","given":"Sara"},{"family":"Grobelnik","given":"Marko"},{"family":"Maegaard","given":"Bente"},{"family":"Mariani","given":"Joseph"},{"family":"Mazo","given":"Helene"},{"family":"Moreno","given":"Asuncion"},{"family":"Odijk","given":"Jan"},{"family":"Piperidis","given":"Stelios"}],"event-place":"Portorož, Slovenia","issued":{"date-parts":[["2016",5]]},"page":"2262–2269","publisher":"European Language Resources Association (ELRA)","publisher-place":"Portorož, Slovenia","title":"JATE 2.0: Java Automatic Term Extraction with Apache Solr","type":"paper-conference","URL":"https://aclanthology.org/L16-1359"},{"id":"zhaoAnalysingVerbalCommunication2023","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Zhao","given":"Linxuan"},{"family":"Tan","given":"Yuanru"},{"family":"Gašević","given":"Dragan"},{"family":"Shaffer","given":"David Williamson"},{"family":"Yan","given":"Lixiang"},{"family":"Alfredo","given":"Riordan"},{"family":"Li","given":"Xinyu"},{"family":"Martinez-Maldonado","given":"Roberto"}],"citation-key":"zhaoAnalysingVerbalCommunication2023","container-title":"Artificial Intelligence in Education","DOI":"10.1007/978-3-031-36272-9_20","editor":[{"family":"Wang","given":"Ning"},{"family":"Rebolledo-Mendez","given":"Genaro"},{"family":"Matsuda","given":"Noboru"},{"family":"Santos","given":"Olga C."},{"family":"Dimitrova","given":"Vania"}],"event-place":"Cham","ISBN":"978-3-031-36271-2 978-3-031-36272-9","issued":{"date-parts":[["2023"]]},"language":"en","page":"242-254","publisher":"Springer Nature Switzerland","publisher-place":"Cham","source":"DOI.org (Crossref)","title":"Analysing Verbal Communication in Embodied Team Learning Using Multimodal Data and Ordered Network Analysis","type":"chapter","URL":"https://link.springer.com/10.1007/978-3-031-36272-9_20","volume":"13916"},{"id":"zhaoMETSMultimodalLearning2023","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Zhao","given":"Linxuan"},{"family":"Swiecki","given":"Zachari"},{"family":"Gasevic","given":"Dragan"},{"family":"Yan","given":"Lixiang"},{"family":"Dix","given":"Samantha"},{"family":"Jaggard","given":"Hollie"},{"family":"Wotherspoon","given":"Rosie"},{"family":"Osborne","given":"Abra"},{"family":"Li","given":"Xinyu"},{"family":"Alfredo","given":"Riordan"},{"family":"Martinez-Maldonado","given":"Roberto"}],"citation-key":"zhaoMETSMultimodalLearning2023","container-title":"LAK23: 13th International Learning Analytics and Knowledge Conference","DOI":"10.1145/3576050.3576076","event-place":"Arlington TX USA","event-title":"LAK 2023: 13th International Learning Analytics and Knowledge Conference","ISBN":"978-1-4503-9865-7","issued":{"date-parts":[["2023",3,13]]},"language":"en","page":"186-196","publisher":"ACM","publisher-place":"Arlington TX USA","source":"DOI.org (Crossref)","title":"METS: Multimodal Learning Analytics of Embodied Teamwork Learning","title-short":"METS","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3576050.3576076"},{"id":"zhaoModellingColocatedTeam2022","accessed":{"date-parts":[["2024",4,24]]},"author":[{"family":"Zhao","given":"Linxuan"},{"family":"Yan","given":"Lixiang"},{"family":"Gasevic","given":"Dragan"},{"family":"Dix","given":"Samantha"},{"family":"Jaggard","given":"Hollie"},{"family":"Wotherspoon","given":"Rosie"},{"family":"Alfredo","given":"Riordan"},{"family":"Li","given":"Xinyu"},{"family":"Martinez-Maldonado","given":"Roberto"}],"citation-key":"zhaoModellingColocatedTeam2022","container-title":"LAK22: 12th International Learning Analytics and Knowledge Conference","DOI":"10.1145/3506860.3506935","event-place":"Online USA","event-title":"LAK22: 12th International Learning Analytics and Knowledge Conference","ISBN":"978-1-4503-9573-1","issued":{"date-parts":[["2022",3,21]]},"language":"en","page":"370-380","publisher":"ACM","publisher-place":"Online USA","source":"DOI.org (Crossref)","title":"Modelling Co-located Team Communication from Voice Detection and Positioning Data in Healthcare Simulation","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3506860.3506935"},{"id":"zhaoShapeDTWShapeDynamic2018","abstract":"Dynamic Time Warping (DTW) is an algorithm to align temporal sequences with possible local non-linear distortions, and has been widely applied to audio, video and graphics data alignments. DTW is essentially a point-to-point matching method under some boundary and temporal consistency constraints. Although DTW obtains a global optimal solution, it does not necessarily achieve locally sensible matchings. Concretely, two temporal points with entirely dissimilar local structures may be matched by DTW. To address this problem, we propose an improved alignment algorithm, named shape Dynamic Time Warping (shapeDTW), which enhances DTW by taking point-wise local structural information into consideration. shapeDTW is inherently a DTW algorithm, but additionally attempts to pair locally similar structures and to avoid matching points with distinct neighborhood structures. We apply shapeDTW to align audio signal pairs having ground-truth alignments, as well as artificially simulated pairs of aligned sequences, and obtain quantitatively much lower alignment errors than DTW and its two variants. When shapeDTW is used as a distance measure in a nearest neighbor classifier (NN-shapeDTW) to classify time series, it beats DTW on 64 out of 84 UCR time series datasets, with significantly improved classification accuracies. By using a properly designed local structure descriptor, shapeDTW improves accuracies by more than 10% on 18 datasets. To the best of our knowledge, shapeDTW is the first distance measure under the nearest neighbor classifier scheme to significantly outperform DTW, which had been widely recognized as the best distance measure to date. Our code is publicly accessible at: https://github.com/jiapingz/shapeDTW.","author":[{"family":"Zhao","given":"Jiaping"},{"family":"Itti","given":"Laurent"}],"citation-key":"zhaoShapeDTWShapeDynamic2018","container-title":"Pattern Recognition","container-title-short":"Pattern Recognition","DOI":"10.1016/j.patcog.2017.09.020","ISSN":"0031-3203","issued":{"date-parts":[["2018",2,1]]},"page":"171-184","title":"shapeDTW: Shape Dynamic Time Warping","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0031320317303710","volume":"74"},{"id":"zhouExpressiveMultiplatformTeleoperation2019","abstract":"Human motion calls upon embodied strategies, which can be difficult to replicate in teleoperation architectures. This paper presents a teleoperation method that centers around the Space component of Laban Movement Analysis and may improve the dynamic complexity of teleoperation commands, allowing a trained user to command multiple joint angles at one time via a large database of stored poses, which are indexed by Space parameters. In this paper, this method is compared to a benchmark method, utilizing a joint-by-joint manner of control on a Rethink Robotics Baxter with compliant limbs using a Microsoft Xbox controller. Across four tasks with a trained operator, analysis of the number of active joints at a given point in time and time to completion emphasize the utility that comes with the proposed method. In particular, for the two presented static tasks, the average number of joint angles moving at one time improves and completion times reduce for the proposed method. Plots of behavior show additional qualitative differences in operator strategies and resulting motion, which are also discussed. Future work will extend this initial demonstration to more formal trials with multiple operators. This method may help achieve more fluid, continuous, and improvised motion in teleoperation of robots via gamepads as are currently used in disaster response platforms.","author":[{"family":"Zhou","given":"Yichen"},{"family":"Asselmeier","given":"Maxwell"},{"family":"LaViers","given":"Amy"}],"citation-key":"zhouExpressiveMultiplatformTeleoperation2019","collection-title":"MOCO '19","container-title":"Proceedings of the 6th international conference on movement and computing","DOI":"10.1145/3347122.3347138","event-place":"Tempe, AZ, USA","ISBN":"978-1-4503-7654-9","issued":{"date-parts":[["2019"]]},"number-of-pages":"8","publisher":"Association for Computing Machinery","publisher-place":"Tempe, AZ, USA","title":"Toward expressive multi-platform teleoperation: Laban-inspired concurrent operation of multiple joints on the rethink robotics baxter robot in static and dynamic tasks","type":"paper-conference","URL":"https://doi.org/10.1145/3347122.3347138"},{"id":"zotterXYMSFirstOrder2019","abstract":"This chapter describes first-order Ambisonic technologies starting from classical coincident audio recording and playback principles from the 1930s until the invention of first-order Ambisonics in the 1970s. Coincident recording is based on arrangements of directional microphones at the smallest-possible spacings in between. Hereby incident sound approximately arrives with equal delay at all microphones. Intensity-based coincident stereophonic recording such as XY and MS typically yields stable directional playback on a stereophonic loudspeaker pair. While the stereo width is adjustable by MS processing, the directional mapping of first-order Ambisonics is a bit more rigid: the omnidirectional and figure-of-eight recording pickup patterns are reproduced unaltered by equivalent patterns in playback. In perfect appreciation of the benefits of coincident first-order Ambisonic recording technologies in VR and field recording, the chapter gives practical examples for encoding, headphone- and loudspeaker-based decoding. It concludes with a desire for a higher-order Ambisonics format to get a larger sweet area and accommodate first-order resolution-enhancement algorithms, the embedding of alternative, channel-based recordings, etc.","author":[{"family":"Zotter","given":"Franz"},{"family":"Frank","given":"Matthias"}],"citation-key":"zotterXYMSFirstOrder2019","container-title":"Ambisonics: A Practical 3D Audio Theory for Recording, Studio Production, Sound Reinforcement, and Virtual Reality","DOI":"10.1007/978-3-030-17207-7_1","event-place":"Cham","ISBN":"978-3-030-17207-7","issued":{"date-parts":[["2019"]]},"page":"1–22","publisher":"Springer International Publishing","publisher-place":"Cham","title":"XY, MS, and First-Order Ambisonics","type":"chapter","URL":"https://doi.org/10.1007/978-3-030-17207-7_1"},{"id":"zwolanElectrodeDiscriminationSpeech1997","author":[{"family":"Zwolan","given":"Terry A."},{"family":"Collins","given":"Leslie M."},{"family":"Wakefield","given":"Gregory H."}],"citation-key":"zwolanElectrodeDiscriminationSpeech1997","container-title":"The Journal of the Acoustical Society of America","container-title-short":"The Journal of the Acoustical Society of America","ISSN":"0001-4966","issue":"6","issued":{"date-parts":[["1997"]]},"page":"3673-3685","publisher":"Acoustical Society of America","title":"Electrode Discrimination and Speech Recognition in Postlingually Deafened Adult Cochlear Implant Subjects","type":"article-journal","volume":"102"},{"id":"zychowiczMahlerFourthSymphony2005","abstract":"Annotation","accessed":{"date-parts":[["2021",1,14]]},"author":[{"family":"Zychowicz","given":"James L"}],"citation-key":"zychowiczMahlerFourthSymphony2005","event-place":"New York","ISBN":"978-0-19-518165-4","issued":{"date-parts":[["2005"]]},"language":"English","note":"OCLC: 1148160029","publisher":"Oxford University Press, Incorporated","publisher-place":"New York","source":"Open WorldCat","title":"Mahler's Fourth Symphony","type":"book","URL":"https://public.ebookcentral.proquest.com/choice/publicfullrecord.aspx?p=431407"},{"id":"wangNercslipSystemSound2022","type":"report","abstract":"This technical report describes our submission system for the task 3 of the DCASE2022 challenge: Sound Event Localization and Detection (SELD) Evaluated in Real Spatial Sound Scenes. Compared with the official baseline system, the improvements of our method mainly lie in three aspects: data augmentation, more powerful network architecture, and model ensemble. First, our previous work shows that the audio channel swapping (ACS) technique [1] can effectively deal with data sparsity problems in the SELD task, which is utilized in our method and provides an effective improvement with limited real training data. In addition, we generate multichannel recordings by using public datasets and perform data cleaning to drop bad data. Then, based on the augmented data, we employ a ResNet-Conformer architecture which can better model the context dependencies within an audio sequence. Specially, we found that time resolution had a significant impact on the model performance: with the time pooling layer moving back, the model can obtain a higher feature resolution and achieve better results. Finally, to attain robust performance, we employ model ensemble of different target representations (e.g., activity-coupled Cartesian direction of arrival (ACCDOA) and multi-ACCDOA) and post-processing strategies. The proposed system is evaluated on the dev-test set of Sony-TAu Realistic Spatial Soundscapes 2022 (STARS2022) dataset.","publisher":"DCASE2022 Challenge","title":"The nerc-slip system for sound event localization and detection of dcase2022 challenge","author":[{"family":"Wang","given":"Qing"},{"family":"Chai","given":"Li"},{"family":"Wu","given":"Huaxin"},{"family":"Nian","given":"Zhaoxu"},{"family":"Niu","given":"Shutong"},{"family":"Zheng","given":"Siyuan"},{"family":"Wang","given":"Yuyang"},{"family":"Sun","given":"Lei"},{"family":"Fang","given":"Yi"},{"family":"Pan","given":"Jia"},{"family":"Du","given":"Jun"},{"family":"Lee","given":"Chin-Hui"}],"issued":{"date-parts":[["2022",6]]},"citation-key":"wangNercslipSystemSound2022","library":"My Library","citekey":"wangNercslipSystemSound2022"},{"id":"wangNercslipSystemSound2023","type":"report","abstract":"The technical report details our submission system for Task 3 of the DCASE2023 Challenge: Sound Event Localization and Detection (SELD) Evaluated in Real Spatial Sound Scenes. To address the audio-only SELD task, we apply the audio channel swapping (ACS) technique to generate augmented data, upon which a ResNet-Conformer architecture is employed as the acoustic model. Additionally, we introduce a class-dependent sound separation (SS) model to tackle overlapping mixtures and extract features from the SS model as prompts to perform SELD for a specific event class. In the case of audio-visual SELD task, we leverage object detection and human body key point detection algorithms to identify potential sound events and extract Gaussian-like vectors, which are subsequently concatenated with acoustic features as the input. Moreover, we propose a video data augmentation method based on the ACS method of audio data. Finally, we present a post-processing strategy to enhance the results of audio-only SELD models with the location information predicted by video data. We evaluate our approach on the dev-test set of the Sony-TAu Realistic Spatial Soundscapes 2023 (STARSS23) dataset.","publisher":"DCASE2023 Challenge","title":"The nerc-slip system for sound event localization and detection of dcase2023 challenge","author":[{"family":"Wang","given":"Qing"},{"family":"Jiang","given":"Ya"},{"family":"Cheng","given":"Shi"},{"family":"Hu","given":"Maocheng"},{"family":"Nian","given":"Zhaoxu"},{"family":"Hu","given":"Pengfei"},{"family":"Liu","given":"Zeyan"},{"family":"Dong","given":"Yuxuan"},{"family":"Cai","given":"Mingqi"},{"family":"Du","given":"Jun"},{"family":"Lee","given":"Chin-Hui"}],"issued":{"date-parts":[["2023",6]]},"citation-key":"wangNercslipSystemSound2023","library":"My Library","citekey":"wangNercslipSystemSound2023"},{"id":"wangNercslipSystemSound2024","type":"report","abstract":"The technical report presents our submission system for Task 3 of the DCASE 2024 Challenge: Audio and Audiovisual Sound Event Localization and Detection (SELD) with Source Distance Estimation (SDE). In addition to direction of arrival estimation (DOAE) of the sound source, this challenge also requires predicting the source distance. We attempted three methods to enable the system to predict both the DOA and the distance of the sound source. First, we proposed two multi-task learning frameworks. One introduces an extra branch to the original SELD model with multi-task learning framework, resulting in a three-branch output to simultaneously predict the DOA and distance of the sound source. The other integrates the sound source distance into the DOA prediction, estimat- ing the absolute position of the sound source. Second, we trained two models for DOAE and SDE respectively, and then used a joint prediction method based on the outputs of the two models. For the audiovisual SELD task with SDE, we used a ResNet-50 model pretrained on ImageNet as the visual feature extractor. Additionally, we simulated audio-visual data and used a teacher-student learning method to train our multi-modal system. We evaluated our methods on the dev-test set of the Sony-TAu Realistic Spatial Soundscapes 2023 (STARSS23) dataset.","publisher":"DCASE2024 Challenge","title":"The nerc-slip system for sound event localization and detection with source distance estimation of dcase 2024 challenge","author":[{"family":"Wang","given":"Qing"},{"family":"Dong","given":"Yuxuan"},{"family":"Hong","given":"Hengyi"},{"family":"Wei","given":"Ruoyu"},{"family":"Hu","given":"Maocheng"},{"family":"Cheng","given":"Shi"},{"family":"Jiang","given":"Ya"},{"family":"Cai","given":"Mingqi"},{"family":"Fang","given":"Xin"},{"family":"Du","given":"Jun"}],"issued":{"date-parts":[["2024",6]]},"citation-key":"wangNercslipSystemSound2024","library":"My Library","citekey":"wangNercslipSystemSound2024"},{"id":"wangFourstageDataAugmentation2023","type":"article-journal","abstract":"In this paper, we propose a novel four-stage data augmentation approach to ResNet-Conformer based acoustic modeling for sound event localization and detection (SELD). First, we explore two spatial augmentation techniques, namely audio channel swapping (ACS) and multi-channel simulation (MCS), to deal with data sparsity in SELD. ACS and MDS focus on augmenting the limited training data with expanding direction of arrival (DOA) representations such that the acoustic models trained with the augmented data are robust to localization variations of acoustic sources. Next, time-domain mixing (TDM) and time-frequency masking (TFM) are also investigated to deal with overlapping sound events and data diversity. Finally, ACS, MCS, TDM and TFM are combined in a step-by-step manner to form an effective four-stage data augmentation scheme. Tested on the Detection and Classification of Acoustic Scenes and Events (DCASE) 2020 data set, our proposed augmentation approach greatly improves the system performance, ranking our submitted system in the first place in the SELD task of the DCASE 2020 Challenge. Furthermore, we employ a ResNet-Conformer architecture to model both global and local context dependencies of an audio sequence and win the first place in the DCASE 2022 SELD evaluations.","container-title":"IEEE/ACM Trans. Audio, Speech and Lang. Proc.","DOI":"10.1109/TASLP.2023.3256088","ISSN":"2329-9290","page":"1251–1264","title":"A four-stage data augmentation approach to ResNet-conformer based acoustic modeling for sound event localization and detection","URL":"https://doi.org/10.1109/TASLP.2023.3256088","volume":"31","author":[{"family":"Wang","given":"Qing"},{"family":"Du","given":"Jun"},{"family":"Wu","given":"Hua-Xin"},{"family":"Pan","given":"Jia"},{"family":"Ma","given":"Feng"},{"family":"Lee","given":"Chin-Hui"}],"issued":{"date-parts":[["2023",3]]},"citation-key":"wangFourstageDataAugmentation2023","library":"My Library","citekey":"wangFourstageDataAugmentation2023"},{"id":"shimadaAccdoaActivitycoupledCartesian2021","type":"paper-conference","container-title":"ICASSP 2021 - 2021 IEEE international conference on acoustics, speech and signal processing (ICASSP)","DOI":"10.1109/ICASSP39728.2021.9413609","page":"915-919","title":"Accdoa: Activity-coupled cartesian direction of arrival representation for sound event localization and detection","author":[{"family":"Shimada","given":"Kazuki"},{"family":"Koyama","given":"Yuichiro"},{"family":"Takahashi","given":"Naoya"},{"family":"Takahashi","given":"Shusuke"},{"family":"Mitsufuji","given":"Yuki"}],"issued":{"date-parts":[["2021"]]},"citation-key":"shimadaAccdoaActivitycoupledCartesian2021","library":"My Library","citekey":"shimadaAccdoaActivitycoupledCartesian2021"}]